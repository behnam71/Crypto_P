!python crypto-v2/core_v2.py --run DQN --symbol "DOGE/USDT" --num-cpus 2 --framework torch --stop-reward 4.0e+7 --stop-iters 500
Running with following CLI args: Namespace(as_test=False, framework='torch', local_mode=False, no_attention=False, no_tune=False, num_cpus=2, run='DQN', stop_iters=500, stop_reward=40000000.0, stop_timesteps=500000, symbol='DOGE/USDT')
2021-08-18 09:57:04,330	INFO services.py:1247 -- View the Ray dashboard at http://127.0.0.1:8265
== Status ==
Memory usage on this node: 1.6/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 PENDING)
+----------------------------+----------+-------+
| Trial name                 | status   | loc   |
|----------------------------+----------+-------|
| DQN_TradingEnv_a4fd9_00000 | PENDING  |       |
+----------------------------+----------+-------+


(pid=459) 2021-08-18 09:57:25,301	INFO trainer.py:720 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
(pid=460) symbol_Instrument: DOGE/USDT
(pid=460) minimum order size: 10
(pid=460)                      DOGE:open  DOGE:high  ...  DOGE:slowk  DOGE:slowd
(pid=460) date                                       ...                        
(pid=460) 2019-07-05 12:00:00   0.004490   0.004600  ...         NaN         NaN
(pid=460) 2019-07-05 12:30:00   0.003823   0.003925  ...         NaN         NaN
(pid=460) 2019-07-05 13:00:00   0.003915   0.003928  ...         NaN         NaN
(pid=460) 2019-07-05 13:30:00   0.003779   0.003885  ...         NaN         NaN
(pid=460) 2019-07-05 14:00:00   0.003845   0.003920  ...         NaN         NaN
(pid=460) ...                        ...        ...  ...         ...         ...
(pid=460) 2019-07-09 13:30:00   0.003440   0.003440  ...   74.470899   73.170448
(pid=460) 2019-07-09 14:00:00   0.003419   0.003440  ...   67.129630   73.909840
(pid=460) 2019-07-09 14:30:00   0.003431   0.003433  ...   58.201058   66.600529
(pid=460) 2019-07-09 15:00:00   0.003421   0.003431  ...   64.640112   63.323600
(pid=460) 2019-07-09 15:30:00   0.003430   0.003445  ...   68.363214   63.734795
(pid=460) 
(pid=460) [200 rows x 21 columns]
(pid=459) 2021-08-18 09:57:50,894	INFO trainable.py:109 -- Trainable.setup took 25.870 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
(pid=459) 2021-08-18 09:57:50,894	WARNING util.py:55 -- Install gputil for GPU system monitoring.
Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 1000
  custom_metrics: {}
  date: 2021-08-18_09-57-55
  done: false
  episode_len_mean: .nan
  episode_media: {}
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 1000
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 3.3873684406280518
          max_q: 1.5637699365615845
          mean_q: 0.35409778356552124
          mean_td_error: -0.3482620120048523
          min_q: -1.243821382522583
        model: {}
        td_error: "[ 0.10044448  1.3683258  -1.5551707  -0.7224044  -0.61489    -0.9796815\n\
          \ -0.56619567  1.543608   -0.35626018 -0.7955147   0.1894558   0.8274884\n\
          \  0.01904918 -0.858465    0.6209563  -0.37963408  0.45412704 -1.0229483\n\
          \ -0.4345919  -0.52896404  0.21154389 -0.2132901  -1.960324   -1.6323582\n\
          \ -1.844766    1.2980443  -1.7671162  -0.79971755 -0.86824256 -1.7319753\n\
          \  0.36248916 -1.6162251  -1.3504481   1.3046217   0.2894401  -0.25542182\n\
          \ -0.9483036  -1.7801744  -1.975178    1.543608   -1.0229483   0.15798691\n\
          \  0.98000574 -0.6704205  -0.14651346  0.6729126   1.4119394  -0.6744776 ]"
    num_agent_steps_sampled: 1000
    num_agent_steps_trained: 48
    num_steps_sampled: 1000
    num_steps_trained: 48
    num_target_updates: 1
  iterations_since_restore: 1
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.885714285714286
    ram_util_percent: 27.185714285714283
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf: {}
  time_since_restore: 4.518114328384399
  time_this_iter_s: 4.518114328384399
  time_total_s: 4.518114328384399
  timers:
    learn_throughput: 1485.224
    learn_time_ms: 32.318
    update_time_ms: 5.638
  timestamp: 1629280675
  timesteps_since_restore: 0
  timesteps_total: 1000
  training_iteration: 1
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.3/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |      1 |          4.51811 | 1000 |      nan |                  nan |                  nan |                nan |
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 2000
  custom_metrics: {}
  date: 2021-08-18_09-58-07
  done: false
  episode_len_mean: .nan
  episode_media: {}
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 1504
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03927614539861679
          max_q: 2.239279270172119
          mean_q: 1.4002685546875
          mean_td_error: 0.045985519886016846
          min_q: 0.10502368211746216
        model: {}
        td_error: "[ 0.24299884  0.3349198   0.20849538  0.3572266  -0.12659049 -0.18861175\n\
          \  0.22196376 -0.7664063  -0.38867795 -0.15288746 -0.16114879 -0.56397843\n\
          \  0.87154245  0.51785886 -0.12144315  0.44695717  0.34618032  0.08662724\n\
          \ -0.24028516  0.05317378  0.46115756 -0.5045649  -0.20672095  0.16206288\n\
          \  0.38368225  0.35110617 -0.27449608  0.2134645   0.01694298  0.7316847\n\
          \  0.52185136 -0.18861175 -0.24028516 -0.00931323  0.15634334 -0.37042785\n\
          \  0.19937944  0.13216281 -0.15144241 -0.09763074  0.1956712  -0.50173044\n\
          \  0.05021461  0.11125267 -0.2203741   0.3583945   0.27608073 -0.3264637 ]"
    num_agent_steps_sampled: 2000
    num_agent_steps_trained: 12048
    num_steps_sampled: 2000
    num_steps_trained: 12048
    num_target_updates: 2
  iterations_since_restore: 2
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.48333333333333
    ram_util_percent: 27.67222222222222
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf: {}
  time_since_restore: 16.94858431816101
  time_this_iter_s: 12.430469989776611
  time_total_s: 16.94858431816101
  timers:
    learn_throughput: 4941.985
    learn_time_ms: 9.713
    update_time_ms: 2.862
  timestamp: 1629280687
  timesteps_since_restore: 0
  timesteps_total: 2000
  training_iteration: 2
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.3/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |      2 |          16.9486 | 2000 |      nan |                  nan |                  nan |                nan |
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 3000
  custom_metrics: {}
  date: 2021-08-18_09-58-19
  done: false
  episode_len_mean: .nan
  episode_media: {}
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 2512
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03292204439640045
          max_q: 2.550135374069214
          mean_q: 1.9168586730957031
          mean_td_error: 0.038599852472543716
          min_q: 1.1828280687332153
        model: {}
        td_error: "[-0.01585281 -0.38415682 -0.05755854  0.46402597 -0.0168792  -0.25423312\n\
          \ -0.23525703  0.05228055 -0.23063171  0.17975032  0.2423538   0.46538866\n\
          \ -0.20485806  0.04204226  0.3808391  -0.12157071 -0.288777   -0.22966528\n\
          \ -0.02107453  0.21661448  0.0267024  -0.13326645  0.50794077 -0.06616306\n\
          \  1.3945689  -0.3487227  -0.12453938  0.07235706  0.1588068   0.08347976\n\
          \  0.20711899 -0.6343597  -0.22990823  0.327258   -0.10448456  0.0555836\n\
          \  0.22151113 -0.11446524 -0.23269594 -0.20752478 -0.02970386  0.44265687\n\
          \ -0.02929556  0.18333864  0.32000732  0.21411157  0.020684   -0.11098385]"
    num_agent_steps_sampled: 3000
    num_agent_steps_trained: 24048
    num_steps_sampled: 3000
    num_steps_trained: 24048
    num_target_updates: 4
  iterations_since_restore: 3
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.7375
    ram_util_percent: 27.80625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf: {}
  time_since_restore: 28.381799697875977
  time_this_iter_s: 11.433215379714966
  time_total_s: 28.381799697875977
  timers:
    learn_throughput: 4789.34
    learn_time_ms: 10.022
    update_time_ms: 2.994
  timestamp: 1629280699
  timesteps_since_restore: 0
  timesteps_total: 3000
  training_iteration: 3
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.4/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |      3 |          28.3818 | 3000 |      nan |                  nan |                  nan |                nan |
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 4000
  custom_metrics: {}
  date: 2021-08-18_09-58-31
  done: false
  episode_len_mean: 3887.0
  episode_media: {}
  episode_reward_max: -162.74059470304258
  episode_reward_mean: -162.74059470304258
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 3520
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.034354355186223984
          max_q: 2.884580373764038
          mean_q: 2.2816288471221924
          mean_td_error: 0.053773537278175354
          min_q: 1.8672082424163818
        model: {}
        td_error: "[-0.07889128 -0.24502754  0.33652246 -0.27876163 -0.08099341 -0.11712503\n\
          \ -0.07536173  0.67249966  0.06194997  0.07521057  0.17498887 -0.15398741\n\
          \ -0.542644   -0.05331659  0.0729425  -0.17562604  0.33122563 -0.04705453\n\
          \  0.10809731  0.26036406 -0.17150879 -0.05783725  0.11159015  0.4546237\n\
          \  0.10507059  0.09432936  0.07986426  0.30698633 -0.41879237  0.14160848\n\
          \  0.07422185  0.24810672  0.29164362  0.09225631  0.1617322  -0.09330297\n\
          \  0.45757902 -0.11567354 -0.3013065   0.49214125 -0.08358359  0.20771766\n\
          \ -0.20928955  0.15327525 -0.03713536  0.13503838  0.1520629   0.06469989]"
    num_agent_steps_sampled: 4000
    num_agent_steps_trained: 36048
    num_steps_sampled: 4000
    num_steps_trained: 36048
    num_target_updates: 6
  iterations_since_restore: 4
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.89444444444444
    ram_util_percent: 27.899999999999995
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04869114008881813
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.162175051959209
    mean_inference_ms: 1.5782317767230252
    mean_raw_obs_processing_ms: 0.14014435958576274
  time_since_restore: 40.57899332046509
  time_this_iter_s: 12.197193622589111
  time_total_s: 40.57899332046509
  timers:
    learn_throughput: 4960.555
    learn_time_ms: 9.676
    update_time_ms: 2.707
  timestamp: 1629280711
  timesteps_since_restore: 0
  timesteps_total: 4000
  training_iteration: 4
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.4/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |      4 |           40.579 | 4000 | -162.741 |             -162.741 |             -162.741 |               3887 |
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 5000
  custom_metrics: {}
  date: 2021-08-18_09-58-42
  done: false
  episode_len_mean: 3887.0
  episode_media: {}
  episode_reward_max: -162.74059470304258
  episode_reward_mean: -162.74059470304258
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 1
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 4528
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04164591804146767
          max_q: 2.8206164836883545
          mean_q: 2.4702682495117188
          mean_td_error: 0.08391275256872177
          min_q: 2.059636116027832
        model: {}
        td_error: "[ 1.15265846e-01  2.22587109e-01  2.80323029e-02 -3.07478905e-02\n\
          \ -6.04867935e-03 -4.68969345e-04  1.98768616e-01 -1.34201527e-01\n  1.02694273e-01\
          \  7.60009289e-02  8.25812817e-02 -8.36277008e-03\n -1.58865452e-01  1.77191257e-01\
          \  2.50305891e-01 -9.82887745e-02\n -1.85664415e-01  1.09483242e-01 -9.35640335e-02\
          \  1.27210617e-01\n  2.33322382e-01  4.17741776e-01 -9.40058231e-02 -1.89927816e-01\n\
          \  2.34539032e-01  4.27861214e-02  8.58597755e-02  3.50506067e-01\n  1.84094667e-01\
          \ -1.02373362e-01  6.87246323e-02 -1.84734344e-01\n  1.52744055e-01  2.97479630e-01\
          \  2.73978710e-02  1.77111626e-01\n  8.25343132e-02  6.64782524e-03  3.98498297e-01\
          \  5.24213672e-01\n  3.49569321e-03 -1.56517982e-01  1.39919043e-01 -1.21419430e-02\n\
          \ -5.50327301e-02  1.48361206e-01  1.63149834e-01  3.09509993e-01]"
    num_agent_steps_sampled: 5000
    num_agent_steps_trained: 48048
    num_steps_sampled: 5000
    num_steps_trained: 48048
    num_target_updates: 8
  iterations_since_restore: 5
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 67.46666666666668
    ram_util_percent: 28.006666666666668
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04869114008881813
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.162175051959209
    mean_inference_ms: 1.5782317767230252
    mean_raw_obs_processing_ms: 0.14014435958576274
  time_since_restore: 51.58102035522461
  time_this_iter_s: 11.002027034759521
  time_total_s: 51.58102035522461
  timers:
    learn_throughput: 4849.689
    learn_time_ms: 9.898
    update_time_ms: 2.687
  timestamp: 1629280722
  timesteps_since_restore: 0
  timesteps_total: 5000
  training_iteration: 5
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.4/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |      5 |           51.581 | 5000 | -162.741 |             -162.741 |             -162.741 |               3887 |
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 6000
  custom_metrics: {}
  date: 2021-08-18_09-58-54
  done: false
  episode_len_mean: 3887.0
  episode_media: {}
  episode_reward_max: -162.74059470304258
  episode_reward_mean: -162.74059470304258
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 1
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 5536
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02664300613105297
          max_q: 3.1429920196533203
          mean_q: 2.624683380126953
          mean_td_error: 0.04499798268079758
          min_q: 2.1603851318359375
        model: {}
        td_error: "[ 0.05279469 -0.18110824  0.06239271  0.01257658 -0.11494613 -0.05728436\n\
          \ -0.06124163  0.00737882  0.19412398 -0.07281518  0.1621983   0.11917543\n\
          \  0.16559243 -0.08681941  0.15063167 -0.33846116  0.18782496  0.12078428\n\
          \  0.10297155  0.00668263  0.10576391  0.04716134 -0.11300564 -0.13947034\n\
          \ -0.01038837  0.13705254  0.22509766  0.08235812  0.14552283 -0.23642802\n\
          \  0.13724852  0.08178329  0.12068462 -0.02171826  0.25282955  0.05596995\n\
          \ -0.00241113  0.15750241  0.21770287  0.17246485 -0.58582807  0.36674047\n\
          \  0.22771263 -0.04127192  0.05392551 -0.00787854 -0.05134296  0.34967327]"
    num_agent_steps_sampled: 6000
    num_agent_steps_trained: 60048
    num_steps_sampled: 6000
    num_steps_trained: 60048
    num_target_updates: 10
  iterations_since_restore: 6
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.5125
    ram_util_percent: 28.106250000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04869114008881813
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.162175051959209
    mean_inference_ms: 1.5782317767230252
    mean_raw_obs_processing_ms: 0.14014435958576274
  time_since_restore: 62.75625920295715
  time_this_iter_s: 11.175238847732544
  time_total_s: 62.75625920295715
  timers:
    learn_throughput: 5046.854
    learn_time_ms: 9.511
    update_time_ms: 2.648
  timestamp: 1629280734
  timesteps_since_restore: 0
  timesteps_total: 6000
  training_iteration: 6
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.4/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |      6 |          62.7563 | 6000 | -162.741 |             -162.741 |             -162.741 |               3887 |
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 7000
  custom_metrics: {}
  date: 2021-08-18_09-59-05
  done: false
  episode_len_mean: 3887.0
  episode_media: {}
  episode_reward_max: -162.74059470304258
  episode_reward_mean: -162.74059470304258
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 1
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 6544
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.022137057036161423
          max_q: 3.3895061016082764
          mean_q: 2.7770228385925293
          mean_td_error: -0.025398075580596924
          min_q: 2.2234482765197754
        model: {}
        td_error: "[-0.3983693   0.10353708 -0.19103265 -0.06414461 -0.3564527  -0.35981703\n\
          \ -0.0576098   0.05191302 -0.03562808  0.27684855  0.05081463  0.13806272\n\
          \ -0.07052851  0.04162598  0.20392513  0.20212579  0.10955429 -0.08850098\n\
          \ -0.02021551  0.16679335  0.01156163  0.00486803 -0.06772161  0.06321335\n\
          \  0.09990096 -0.12477016 -0.12760949 -0.43412614  0.20870924 -0.07665324\n\
          \ -0.06435561  0.12551689 -0.05085564 -0.0723474  -0.04190469 -0.04395413\n\
          \ -0.06468606  0.01829433 -0.02512908 -0.16601682 -0.539515    0.36514592\n\
          \ -0.06525493  0.09481788 -0.01502419 -0.31292605  0.21624398  0.16256905]"
    num_agent_steps_sampled: 7000
    num_agent_steps_trained: 72048
    num_steps_sampled: 7000
    num_steps_trained: 72048
    num_target_updates: 12
  iterations_since_restore: 7
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.625
    ram_util_percent: 28.125
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04869114008881813
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.162175051959209
    mean_inference_ms: 1.5782317767230252
    mean_raw_obs_processing_ms: 0.14014435958576274
  time_since_restore: 73.73757529258728
  time_this_iter_s: 10.981316089630127
  time_total_s: 73.73757529258728
  timers:
    learn_throughput: 5026.241
    learn_time_ms: 9.55
    update_time_ms: 2.734
  timestamp: 1629280745
  timesteps_since_restore: 0
  timesteps_total: 7000
  training_iteration: 7
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.4/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |      7 |          73.7376 | 7000 | -162.741 |             -162.741 |             -162.741 |               3887 |
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 8000
  custom_metrics: {}
  date: 2021-08-18_09-59-17
  done: false
  episode_len_mean: 3887.0
  episode_media: {}
  episode_reward_max: -162.74059470304258
  episode_reward_mean: -162.74059470304258
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 1
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 7552
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02301974967122078
          max_q: 3.611104965209961
          mean_q: 2.901015281677246
          mean_td_error: 0.013988247141242027
          min_q: 2.330277681350708
        model: {}
        td_error: "[ 1.40572786e-01 -1.08131409e-01 -9.84821320e-02 -7.44199753e-02\n\
          \ -5.17160892e-02 -5.47742844e-02 -1.81665421e-02 -1.29687786e-02\n -1.12235308e-01\
          \  7.97939301e-02 -6.04999065e-02  1.92263603e-01\n  4.36258316e-03 -2.27239847e-01\
          \ -2.82145023e-01  3.37676764e-01\n -4.80268955e-01 -5.77733517e-02  1.24807596e-01\
          \  2.68889904e-01\n  1.23262405e-01 -4.22861576e-02  6.39829636e-02  2.24901676e-01\n\
          \  3.48627806e-01  2.56932497e-01 -1.81665421e-02  2.76432753e-01\n -3.58897686e-01\
          \  2.35758543e-01 -5.25789261e-02 -8.97765160e-03\n  2.18063831e-01  7.94034004e-02\
          \  1.04451418e-01  1.01878643e-01\n  1.60233498e-01 -7.72638321e-02 -5.91306686e-02\
          \ -7.45179653e-02\n -4.65841293e-02  1.07967138e-01 -1.81942701e-01 -4.66346741e-04\n\
          \  2.12881565e-02 -3.34084034e-02 -2.13831425e-01  6.75797462e-03]"
    num_agent_steps_sampled: 8000
    num_agent_steps_trained: 84048
    num_steps_sampled: 8000
    num_steps_trained: 84048
    num_target_updates: 14
  iterations_since_restore: 8
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.55555555555556
    ram_util_percent: 28.205555555555552
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04869114008881813
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.162175051959209
    mean_inference_ms: 1.5782317767230252
    mean_raw_obs_processing_ms: 0.14014435958576274
  time_since_restore: 86.22923874855042
  time_this_iter_s: 12.491663455963135
  time_total_s: 86.22923874855042
  timers:
    learn_throughput: 5059.716
    learn_time_ms: 9.487
    update_time_ms: 2.849
  timestamp: 1629280757
  timesteps_since_restore: 0
  timesteps_total: 8000
  training_iteration: 8
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.4/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |      8 |          86.2292 | 8000 | -162.741 |             -162.741 |             -162.741 |               3887 |
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 9000
  custom_metrics: {}
  date: 2021-08-18_09-59-30
  done: false
  episode_len_mean: 3887.0
  episode_media: {}
  episode_reward_max: -162.74059470304258
  episode_reward_mean: -162.74059470304258
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 1
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 8560
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.027330074459314346
          max_q: 3.9657135009765625
          mean_q: 2.946122884750366
          mean_td_error: -0.013667069375514984
          min_q: 0.044225215911865234
        model: {}
        td_error: "[ 0.01777029  0.14664102 -0.02246809  0.57596564  0.08829355 -0.25365257\n\
          \ -0.07981396 -0.11843109 -0.04625297  0.15476155 -0.09799743  0.28808534\n\
          \  0.22685623 -0.14502263 -0.07995844 -0.28306818  0.18025374  0.06723094\n\
          \ -0.3137071   0.09692907  0.34248686 -0.02560544 -0.24228358  0.01296043\n\
          \ -0.20078564  0.12726927 -0.18057084 -0.04226613  0.10806322 -0.28795505\n\
          \ -0.04254532  0.22935152  0.18415833 -0.28547382 -0.23580146  0.3840449\n\
          \  0.04138017  0.08026028 -0.55675197 -0.4209807   0.13143158  0.31829953\n\
          \  0.07104897  0.22987819  0.12598109 -0.16878462 -0.24546981 -0.5097742 ]"
    num_agent_steps_sampled: 9000
    num_agent_steps_trained: 96048
    num_steps_sampled: 9000
    num_steps_trained: 96048
    num_target_updates: 16
  iterations_since_restore: 9
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.87222222222221
    ram_util_percent: 28.305555555555557
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04869114008881813
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.162175051959209
    mean_inference_ms: 1.5782317767230252
    mean_raw_obs_processing_ms: 0.14014435958576274
  time_since_restore: 98.98729705810547
  time_this_iter_s: 12.758058309555054
  time_total_s: 98.98729705810547
  timers:
    learn_throughput: 4705.926
    learn_time_ms: 10.2
    update_time_ms: 2.951
  timestamp: 1629280770
  timesteps_since_restore: 0
  timesteps_total: 9000
  training_iteration: 9
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.4/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |      9 |          98.9873 | 9000 | -162.741 |             -162.741 |             -162.741 |               3887 |
+----------------------------+----------+----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 10000
  custom_metrics: {}
  date: 2021-08-18_09-59-44
  done: false
  episode_len_mean: 3887.0
  episode_media: {}
  episode_reward_max: -162.74059470304258
  episode_reward_mean: -162.74059470304258
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 1
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 9568
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.044521499425172806
          max_q: 4.0981574058532715
          mean_q: 3.0585384368896484
          mean_td_error: -0.07295767217874527
          min_q: 2.1813409328460693
        model: {}
        td_error: "[-0.007267   -0.02507305  0.16198492  0.08612514 -0.3455379  -0.22435117\n\
          \ -0.05347681 -0.19410896  0.1462934  -0.06727099 -0.01627088 -0.6602864\n\
          \  0.30471063  0.92309165  0.19708276  0.2658999   0.10277271 -0.25996447\n\
          \  0.09514809 -0.06305981  0.07509565 -0.4509921  -0.2026689   0.13753152\n\
          \ -0.2709     -0.12879658 -0.5891845  -0.15959644 -0.11564064  0.1696589\n\
          \ -0.5820427   0.12180662  0.2252841   0.01831532  0.1051867   0.2761948\n\
          \ -0.14386296 -0.19564152 -0.06904221 -0.04104471 -0.07995653 -0.20425439\n\
          \ -0.69893646 -0.17867064 -0.3172412  -0.01259136 -0.4562726  -0.10014701]"
    num_agent_steps_sampled: 10000
    num_agent_steps_trained: 108048
    num_steps_sampled: 10000
    num_steps_trained: 108048
    num_target_updates: 18
  iterations_since_restore: 10
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.085
    ram_util_percent: 28.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04869114008881813
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.162175051959209
    mean_inference_ms: 1.5782317767230252
    mean_raw_obs_processing_ms: 0.14014435958576274
  time_since_restore: 112.98334622383118
  time_this_iter_s: 13.996049165725708
  time_total_s: 112.98334622383118
  timers:
    learn_throughput: 5070.33
    learn_time_ms: 9.467
    update_time_ms: 3.247
  timestamp: 1629280784
  timesteps_since_restore: 0
  timesteps_total: 10000
  training_iteration: 10
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.5/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     10 |          112.983 | 10000 | -162.741 |             -162.741 |             -162.741 |               3887 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 11000
  custom_metrics: {}
  date: 2021-08-18_09-59-56
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 10576
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02325907163321972
          max_q: 4.023881912231445
          mean_q: 3.0786845684051514
          mean_td_error: -0.02555006742477417
          min_q: 2.5761258602142334
        model: {}
        td_error: "[-0.04849839  0.08160949  0.02199984  0.07041407  0.18540072  0.03789091\n\
          \ -0.03489184 -0.04619479  0.26466107  0.00666022  0.15310073  0.05457067\n\
          \ -0.11188269 -0.01961875 -0.01782179 -0.306916   -0.16199684 -0.33712387\n\
          \  0.05784822  0.01318693 -0.1105485   0.5483918  -0.17699957 -0.05622196\n\
          \ -0.1899991  -0.3402965  -0.21960545  0.01133943 -0.41115928  0.13254523\n\
          \ -0.24194694  0.23651361 -0.2024188   0.03483033  0.3005705  -0.07253551\n\
          \ -0.19561505 -0.10739803  0.12972593 -0.08540034 -0.23643112 -0.17503786\n\
          \  0.43451858 -0.09858966  0.02383757  0.21995044  0.02015805 -0.26097894]"
    num_agent_steps_sampled: 11000
    num_agent_steps_trained: 120048
    num_steps_sampled: 11000
    num_steps_trained: 120048
    num_target_updates: 20
  iterations_since_restore: 11
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.59444444444445
    ram_util_percent: 28.505555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 124.9512665271759
  time_this_iter_s: 11.967920303344727
  time_total_s: 124.9512665271759
  timers:
    learn_throughput: 5112.109
    learn_time_ms: 9.389
    update_time_ms: 2.912
  timestamp: 1629280796
  timesteps_since_restore: 0
  timesteps_total: 11000
  training_iteration: 11
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.5/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     11 |          124.951 | 11000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 12000
  custom_metrics: {}
  date: 2021-08-18_10-00-07
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 11584
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0402764156460762
          max_q: 4.163888454437256
          mean_q: 3.300060749053955
          mean_td_error: -0.0591350719332695
          min_q: 2.776071548461914
        model: {}
        td_error: "[-1.50087357e-01 -2.10532188e-01  5.78672886e-02 -1.00831985e-01\n\
          \  9.83514786e-02 -5.56066036e-02  4.70197201e-02  1.53919458e-01\n -3.55687141e-02\
          \ -1.06575727e-01  1.14154816e-02 -2.55857468e-01\n  1.23532295e-01 -5.85529804e-02\
          \ -1.77257061e-02  8.44001770e-05\n -7.51287937e-02  1.01522923e-01  3.11815739e-02\
          \ -1.74997330e-01\n  3.28758478e-01 -6.50322437e-02  1.32977486e-01 -2.43503571e-01\n\
          \ -3.84412527e-01 -2.12666988e-02 -1.31530762e-01 -2.27292776e-01\n -6.78157806e-02\
          \ -3.14115286e-01  3.75370979e-02 -5.94703674e-01\n -1.15041256e-01  5.72533607e-02\
          \ -9.86874104e-02 -2.80137062e-02\n  8.00916195e-01  3.64587307e-02 -1.94879532e-01\
          \  1.56629562e-01\n -1.46485329e-01 -2.13501453e-02  1.39139891e-01 -8.58034134e-01\n\
          \ -4.13393974e-03 -6.00950718e-02 -3.48147392e-01  1.29573345e-02]"
    num_agent_steps_sampled: 12000
    num_agent_steps_trained: 132048
    num_steps_sampled: 12000
    num_steps_trained: 132048
    num_target_updates: 22
  iterations_since_restore: 12
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.0875
    ram_util_percent: 28.6
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 136.0666971206665
  time_this_iter_s: 11.1154305934906
  time_total_s: 136.0666971206665
  timers:
    learn_throughput: 4985.182
    learn_time_ms: 9.629
    update_time_ms: 2.849
  timestamp: 1629280807
  timesteps_since_restore: 0
  timesteps_total: 12000
  training_iteration: 12
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.5/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     12 |          136.067 | 12000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 13000
  custom_metrics: {}
  date: 2021-08-18_10-00-20
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 12592
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.030548574402928352
          max_q: 4.370227813720703
          mean_q: 3.147653579711914
          mean_td_error: 0.013045753352344036
          min_q: 2.279078960418701
        model: {}
        td_error: "[ 0.5066352  -0.01238418  0.1242578  -0.04429722  0.21214461  0.13100243\n\
          \ -0.12474585 -0.02447009 -0.68668723  0.17202449  0.0145762  -0.3395753\n\
          \ -0.07967854  0.00805712 -0.13710308  0.10941029 -0.05235553  0.09396768\n\
          \ -0.20360899  0.16591763  0.0943985   0.34252644  0.48224473 -0.22761607\n\
          \  0.23203635 -0.02998352  0.21180463 -0.434788    0.24451113  0.5330682\n\
          \ -0.08254004  0.06656981 -0.40207648 -0.1068604  -0.1504767  -0.12017894\n\
          \ -0.5171168   0.2452085   0.2840228  -0.20411181 -0.09013414 -0.00976276\n\
          \  0.08575583  0.24699116 -0.18597078 -0.06091166  0.03777814  0.3087206 ]"
    num_agent_steps_sampled: 13000
    num_agent_steps_trained: 144048
    num_steps_sampled: 13000
    num_steps_trained: 144048
    num_target_updates: 24
  iterations_since_restore: 13
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 67.02941176470588
    ram_util_percent: 28.7
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 148.3704183101654
  time_this_iter_s: 12.303721189498901
  time_total_s: 148.3704183101654
  timers:
    learn_throughput: 4949.627
    learn_time_ms: 9.698
    update_time_ms: 2.751
  timestamp: 1629280820
  timesteps_since_restore: 0
  timesteps_total: 13000
  training_iteration: 13
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.5/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     13 |           148.37 | 13000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 14000
  custom_metrics: {}
  date: 2021-08-18_10-00-32
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 13600
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02573397569358349
          max_q: 4.639167308807373
          mean_q: 3.323223114013672
          mean_td_error: 0.0036309610586613417
          min_q: 2.442802906036377
        model: {}
        td_error: "[ 0.26538563  0.08904028 -0.04056001 -0.2071476   0.19914222  0.10221529\n\
          \ -0.00594091  0.03805208 -0.20783973  0.23719645 -0.08248258 -0.17251825\n\
          \  0.00475621  0.18928432  0.02401638 -0.04454136 -0.23385811  0.16553926\n\
          \ -0.01779556 -0.15218997  0.55110216 -0.03538299 -0.1333592  -0.04217482\n\
          \  0.6311662   0.03761625 -0.25467634 -0.2635188  -0.452358   -0.28574467\n\
          \ -0.11616921  0.28767395 -0.2970066   0.27410126 -0.05791426 -0.02126765\n\
          \ -0.22925901 -0.04170656 -0.11601281  0.16809916  0.02716017 -0.03339434\n\
          \  0.16093135  0.00167823 -0.19035721  0.04156232  0.44076324 -0.02701974]"
    num_agent_steps_sampled: 14000
    num_agent_steps_trained: 156048
    num_steps_sampled: 14000
    num_steps_trained: 156048
    num_target_updates: 26
  iterations_since_restore: 14
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.20000000000001
    ram_util_percent: 28.716666666666665
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 160.5832257270813
  time_this_iter_s: 12.212807416915894
  time_total_s: 160.5832257270813
  timers:
    learn_throughput: 4593.037
    learn_time_ms: 10.451
    update_time_ms: 2.981
  timestamp: 1629280832
  timesteps_since_restore: 0
  timesteps_total: 14000
  training_iteration: 14
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.5/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     14 |          160.583 | 14000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 15000
  custom_metrics: {}
  date: 2021-08-18_10-00-45
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 14608
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.043105341494083405
          max_q: 3.9465270042419434
          mean_q: 3.1196417808532715
          mean_td_error: -0.07414495944976807
          min_q: 2.427872896194458
        model: {}
        td_error: "[-0.01726222  0.15175867 -0.23800397  0.28215647 -0.15199804  0.01866746\n\
          \  0.2633536  -0.21895981  0.2995839   0.22887754 -0.084692   -0.21001363\n\
          \ -0.11782503 -0.37875438 -0.16312695 -0.24287248 -0.94963217 -0.5927129\n\
          \ -0.01829576  0.00583696 -0.01808953  0.12215757  0.02950835  0.12844396\n\
          \ -0.41228127  0.02483273 -0.1899817  -0.05938411  0.02090812  0.24737191\n\
          \  0.09774017 -0.03107476 -0.51591945 -0.32119465 -0.2595892  -0.10358691\n\
          \ -0.26278138 -0.33841395  0.06615949 -0.27641988  0.4079392   0.30092168\n\
          \  0.27919364 -0.16640878 -0.5788913   0.4281721  -0.05382848  0.0094533 ]"
    num_agent_steps_sampled: 15000
    num_agent_steps_trained: 168048
    num_steps_sampled: 15000
    num_steps_trained: 168048
    num_target_updates: 28
  iterations_since_restore: 15
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.955555555555556
    ram_util_percent: 28.799999999999997
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 173.55950784683228
  time_this_iter_s: 12.976282119750977
  time_total_s: 173.55950784683228
  timers:
    learn_throughput: 3313.691
    learn_time_ms: 14.485
    update_time_ms: 4.813
  timestamp: 1629280845
  timesteps_since_restore: 0
  timesteps_total: 15000
  training_iteration: 15
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.5/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     15 |           173.56 | 15000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 16000
  custom_metrics: {}
  date: 2021-08-18_10-00-58
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 15616
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.025129761546850204
          max_q: 4.236518383026123
          mean_q: 3.09173583984375
          mean_td_error: -0.02143688127398491
          min_q: 2.3781239986419678
        model: {}
        td_error: "[-0.11464906  0.05408788 -0.4883337   0.02803063 -0.09289646 -0.22374487\n\
          \  0.04425001  0.09606171  0.05533218  0.07990193  0.3823037   0.04639173\n\
          \  0.08438921 -0.05209446 -0.06514335 -0.31541657  0.15314984 -0.37527132\n\
          \  0.00276566  0.05330372  0.10538435  0.17910552 -0.14692593 -0.13781166\n\
          \ -0.05517316 -0.29960394 -0.07271552 -0.2782581  -0.1516571   0.00865126\n\
          \ -0.12775445  0.00544882 -0.37120748  0.30337262  0.408422    0.1493721\n\
          \ -0.02965927 -0.2649672   0.3105681  -0.1868031  -0.27868247 -0.15958428\n\
          \  0.1173892  -0.2222135   0.18612432  0.11241293  0.29572678  0.2196505 ]"
    num_agent_steps_sampled: 16000
    num_agent_steps_trained: 180048
    num_steps_sampled: 16000
    num_steps_trained: 180048
    num_target_updates: 30
  iterations_since_restore: 16
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.16842105263157
    ram_util_percent: 28.905263157894733
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 186.37750267982483
  time_this_iter_s: 12.817994832992554
  time_total_s: 186.37750267982483
  timers:
    learn_throughput: 4910.309
    learn_time_ms: 9.775
    update_time_ms: 2.828
  timestamp: 1629280858
  timesteps_since_restore: 0
  timesteps_total: 16000
  training_iteration: 16
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.5/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     16 |          186.378 | 16000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 17000
  custom_metrics: {}
  date: 2021-08-18_10-01-12
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 16624
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.029939832165837288
          max_q: 3.987685203552246
          mean_q: 3.0869383811950684
          mean_td_error: -0.03661683201789856
          min_q: 2.387571096420288
        model: {}
        td_error: "[ 0.21612239  0.16845417  0.13049817  0.26664853  0.02605677  0.2705791\n\
          \ -0.25724792 -0.11317086  0.10705805 -0.22566748 -0.3982308   0.00559807\n\
          \ -0.3300898   0.06015372 -0.4955089  -0.40801883 -0.33222246  0.15099573\n\
          \  0.00535035  0.09388018 -0.03240442 -0.3467672   0.03373456  0.10591984\n\
          \ -0.07865357  0.2144401  -0.19967318  0.13490939  0.00935936 -0.15965557\n\
          \  0.09407377 -0.18585181 -0.4232304   0.15685534 -0.09951878 -0.01727939\n\
          \  0.0741868  -0.63257957  0.10369658 -0.0305655   0.02659369  0.06448507\n\
          \  0.3580954  -0.05246496  0.16015124  0.07056665  0.07037091 -0.1176405 ]"
    num_agent_steps_sampled: 17000
    num_agent_steps_trained: 192048
    num_steps_sampled: 17000
    num_steps_trained: 192048
    num_target_updates: 32
  iterations_since_restore: 17
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.879999999999995
    ram_util_percent: 29.005000000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 200.21584057807922
  time_this_iter_s: 13.838337898254395
  time_total_s: 200.21584057807922
  timers:
    learn_throughput: 4835.142
    learn_time_ms: 9.927
    update_time_ms: 2.966
  timestamp: 1629280872
  timesteps_since_restore: 0
  timesteps_total: 17000
  training_iteration: 17
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.5/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     17 |          200.216 | 17000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 18000
  custom_metrics: {}
  date: 2021-08-18_10-01-26
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 17632
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.037149637937545776
          max_q: 4.490928649902344
          mean_q: 3.040116310119629
          mean_td_error: 0.07253099977970123
          min_q: 2.326099395751953
        model: {}
        td_error: "[-0.18442559  0.56893516  0.09016633 -0.17477608  0.19710112 -0.09650636\n\
          \  0.19350815  0.3324175   0.53922355  0.2386539  -0.09972525 -0.23309183\n\
          \ -0.07049847  0.19363189 -0.19118977 -0.4481392   0.10166812 -0.35608435\n\
          \ -0.59408426  0.05604935  0.12531114 -0.21466756 -0.09474111 -0.0351851\n\
          \  0.14410496  0.20846057 -0.04746628  0.45218778  0.12382436  0.25411296\n\
          \  0.20919967  0.34140968  0.10967398 -0.20583344  0.41883326  0.34116364\n\
          \ -0.39419198  0.09953094  0.3526342   0.14538336 -0.05553436  0.06496954\n\
          \  0.03880954  0.34194946  0.15022969  0.47537923 -0.15708804  0.2261939 ]"
    num_agent_steps_sampled: 18000
    num_agent_steps_trained: 204048
    num_steps_sampled: 18000
    num_steps_trained: 204048
    num_target_updates: 34
  iterations_since_restore: 18
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.38947368421053
    ram_util_percent: 29.105263157894743
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 213.74738121032715
  time_this_iter_s: 13.531540632247925
  time_total_s: 213.74738121032715
  timers:
    learn_throughput: 4901.653
    learn_time_ms: 9.793
    update_time_ms: 2.97
  timestamp: 1629280886
  timesteps_since_restore: 0
  timesteps_total: 18000
  training_iteration: 18
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.6/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     18 |          213.747 | 18000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 19000
  custom_metrics: {}
  date: 2021-08-18_10-01-40
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 18640
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.029573174193501472
          max_q: 3.9516441822052
          mean_q: 2.9553465843200684
          mean_td_error: 0.0036748996935784817
          min_q: 1.8740429878234863
        model: {}
        td_error: "[ 0.32739782  0.21640372 -0.05121827  0.12704682 -0.16949558 -0.07672596\n\
          \  0.05702662 -0.02819872  0.7287867   0.13149524  0.04158974  0.21445751\n\
          \  0.18309164 -0.22366071  0.27894616 -0.32508397 -0.15781474 -0.45260334\n\
          \ -0.00694728 -0.03591633 -0.13178754 -0.04473948 -0.10513139 -0.05841637\n\
          \  0.11797333 -0.20155     0.53896904  0.06129026 -0.47105098  0.22724462\n\
          \  0.05077934 -0.09902561 -0.03529429 -0.24287796  0.24711418 -0.12173128\n\
          \ -0.15286183 -0.09902561  0.3599298   0.25269365  0.1713829  -0.21386981\n\
          \ -0.04758883  0.06725216 -0.4305339  -0.4220364   0.01278639  0.16792369]"
    num_agent_steps_sampled: 19000
    num_agent_steps_trained: 216048
    num_steps_sampled: 19000
    num_steps_trained: 216048
    num_target_updates: 36
  iterations_since_restore: 19
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.27142857142856
    ram_util_percent: 29.20476190476191
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 228.39363622665405
  time_this_iter_s: 14.646255016326904
  time_total_s: 228.39363622665405
  timers:
    learn_throughput: 4738.523
    learn_time_ms: 10.13
    update_time_ms: 2.8
  timestamp: 1629280900
  timesteps_since_restore: 0
  timesteps_total: 19000
  training_iteration: 19
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.6/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     19 |          228.394 | 19000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 20000
  custom_metrics: {}
  date: 2021-08-18_10-01-55
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 19648
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.025048790499567986
          max_q: 3.9578592777252197
          mean_q: 2.9434571266174316
          mean_td_error: -0.022328441962599754
          min_q: 2.197255849838257
        model: {}
        td_error: "[ 0.22348142 -0.05756521 -0.30580044  0.1294179  -0.010216    0.05096364\n\
          \ -0.0649488  -0.19514894 -0.12641382 -0.8775821   0.02959895  0.20584297\n\
          \  0.19918871  0.2974081   0.39260113 -0.04680324  0.18900204  0.09976196\n\
          \  0.07891703 -0.08990264 -0.10676765 -0.40402937  0.3080778   0.18177676\n\
          \ -0.03997064  0.21257925  0.17446685 -0.12274694  0.37765884  0.1823833\n\
          \  0.13864994  0.02181053 -0.05868936 -0.01674962 -0.14895368  0.54172325\n\
          \  0.35234165  0.05257201 -0.29833078 -0.1568098  -0.74861336 -0.4035945\n\
          \  0.02966189 -0.11000276 -0.25316548 -0.32322598 -0.45781302 -0.11780691]"
    num_agent_steps_sampled: 20000
    num_agent_steps_trained: 228048
    num_steps_sampled: 20000
    num_steps_trained: 228048
    num_target_updates: 38
  iterations_since_restore: 20
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.12857142857143
    ram_util_percent: 29.304761904761897
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 243.25643467903137
  time_this_iter_s: 14.86279845237732
  time_total_s: 243.25643467903137
  timers:
    learn_throughput: 4993.046
    learn_time_ms: 9.613
    update_time_ms: 2.999
  timestamp: 1629280915
  timesteps_since_restore: 0
  timesteps_total: 20000
  training_iteration: 20
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.6/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     20 |          243.256 | 20000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 21000
  custom_metrics: {}
  date: 2021-08-18_10-02-11
  done: false
  episode_len_mean: 5273.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -141.36780379470727
  episode_reward_min: -162.74059470304258
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 20656
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03504061698913574
          max_q: 4.509370803833008
          mean_q: 3.1091747283935547
          mean_td_error: 0.0038582980632781982
          min_q: 2.1884353160858154
        model: {}
        td_error: "[ 0.1640606   0.11764836  0.37019014  0.12287188  0.1980207  -0.3457296\n\
          \ -0.28322768 -0.17098022 -0.1832881  -0.05364156 -0.37810802  0.30986357\n\
          \  0.06019759  0.09000492  0.18728113 -0.47468972  0.23040056  0.11822057\n\
          \  0.00804615  0.28107858  0.00484753  0.2483809   0.41153026 -0.42875242\n\
          \  0.08472061  0.00144339  0.3236482   0.2524283   0.23701572  0.0469842\n\
          \  0.17731285 -0.08392215 -0.6029811  -0.26471853 -0.20315003 -0.22028112\n\
          \ -0.3051746  -0.21597052 -0.22573161  0.12863874 -0.15171814 -0.15229893\n\
          \ -0.25099802 -0.3084638   0.18007135  0.31969428  0.31809258  0.4963305 ]"
    num_agent_steps_sampled: 21000
    num_agent_steps_trained: 240048
    num_steps_sampled: 21000
    num_steps_trained: 240048
    num_target_updates: 40
  iterations_since_restore: 21
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.56818181818182
    ram_util_percent: 29.39999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04903289174779603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.271550379343948
    mean_inference_ms: 1.577598919861268
    mean_raw_obs_processing_ms: 0.14088462168575927
  time_since_restore: 258.5606327056885
  time_this_iter_s: 15.304198026657104
  time_total_s: 258.5606327056885
  timers:
    learn_throughput: 4974.737
    learn_time_ms: 9.649
    update_time_ms: 2.814
  timestamp: 1629280931
  timesteps_since_restore: 0
  timesteps_total: 21000
  training_iteration: 21
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.6/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     21 |          258.561 | 21000 | -141.368 |             -119.995 |             -162.741 |               5273 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 22000
  custom_metrics: {}
  date: 2021-08-18_10-02-26
  done: false
  episode_len_mean: 7282.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -154.21288648831492
  episode_reward_min: -179.90305187553025
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 21664
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02319885417819023
          max_q: 3.8984928131103516
          mean_q: 3.171536922454834
          mean_td_error: -0.024697016924619675
          min_q: 2.4644107818603516
        model: {}
        td_error: "[ 0.14812851 -0.048738    0.17806172  0.05086255 -0.03442788 -0.0833168\n\
          \ -0.11750436  0.4074571   0.24794292 -0.5203829  -0.14758444 -0.12532902\n\
          \  0.15451956 -0.43459177  0.04108214  0.05618119  0.13791585  0.46634173\n\
          \ -0.4251213   0.16988444 -0.06061339 -0.16718245  0.15138173 -0.06478453\n\
          \  0.3868425  -0.06058526 -0.30527115 -0.11772346 -0.22685003  0.00096059\n\
          \  0.2663138  -0.0087347  -0.09327626  0.13570476  0.1452198  -0.35667753\n\
          \ -0.7765076   0.04387999  0.11141777 -0.01950336 -0.36599016  0.23275566\n\
          \  0.11185837 -0.25563312  0.01264548 -0.20146441  0.20263076 -0.02765179]"
    num_agent_steps_sampled: 22000
    num_agent_steps_trained: 252048
    num_steps_sampled: 22000
    num_steps_trained: 252048
    num_target_updates: 42
  iterations_since_restore: 22
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.57619047619047
    ram_util_percent: 29.542857142857148
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049064955975850276
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.5604733759381766
    mean_inference_ms: 1.5779276442271337
    mean_raw_obs_processing_ms: 0.14146850600461405
  time_since_restore: 273.2160716056824
  time_this_iter_s: 14.655438899993896
  time_total_s: 273.2160716056824
  timers:
    learn_throughput: 4866.982
    learn_time_ms: 9.862
    update_time_ms: 2.746
  timestamp: 1629280946
  timesteps_since_restore: 0
  timesteps_total: 22000
  training_iteration: 22
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.6/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     22 |          273.216 | 22000 | -154.213 |             -119.995 |             -179.903 |               7282 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 23000
  custom_metrics: {}
  date: 2021-08-18_10-02-37
  done: false
  episode_len_mean: 7282.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -154.21288648831492
  episode_reward_min: -179.90305187553025
  episodes_this_iter: 0
  episodes_total: 3
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 22672
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.027556657791137695
          max_q: 4.783728122711182
          mean_q: 3.214597225189209
          mean_td_error: -0.013598432764410973
          min_q: 2.3705050945281982
        model: {}
        td_error: "[-0.05848241 -0.69838595 -0.2895496   0.0218854   0.06958389 -0.02144051\n\
          \  0.3797915   0.0889976   0.11443973 -0.13336015 -0.02034259  0.12795281\n\
          \ -0.11821747  0.00902987  0.22472239 -0.3770113  -0.22802019  0.2301054\n\
          \ -0.16205692  0.10763454  0.18131208  0.04928613  0.36315823 -0.3452146\n\
          \  0.08111548 -0.12575936  0.06102896 -0.06473303 -0.02509618  0.24583054\n\
          \ -0.18237472  0.09499383 -0.5288472   0.38663244  0.3954532   0.07197475\n\
          \ -0.07870603 -0.7821102  -0.11312461  0.1456604  -0.13035464 -0.18264532\n\
          \  0.28011942 -0.03427553  0.3638184   0.02045679 -0.04626155 -0.02133846]"
    num_agent_steps_sampled: 23000
    num_agent_steps_trained: 264048
    num_steps_sampled: 23000
    num_steps_trained: 264048
    num_target_updates: 44
  iterations_since_restore: 23
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.3529411764706
    ram_util_percent: 29.55294117647059
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049064955975850276
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.5604733759381766
    mean_inference_ms: 1.5779276442271337
    mean_raw_obs_processing_ms: 0.14146850600461405
  time_since_restore: 284.7322416305542
  time_this_iter_s: 11.516170024871826
  time_total_s: 284.7322416305542
  timers:
    learn_throughput: 5272.787
    learn_time_ms: 9.103
    update_time_ms: 2.771
  timestamp: 1629280957
  timesteps_since_restore: 0
  timesteps_total: 23000
  training_iteration: 23
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.6/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     23 |          284.732 | 23000 | -154.213 |             -119.995 |             -179.903 |               7282 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 24000
  custom_metrics: {}
  date: 2021-08-18_10-02-49
  done: false
  episode_len_mean: 7282.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -154.21288648831492
  episode_reward_min: -179.90305187553025
  episodes_this_iter: 0
  episodes_total: 3
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 23680
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02474052459001541
          max_q: 4.404112339019775
          mean_q: 3.1258723735809326
          mean_td_error: -0.0030122350435703993
          min_q: 2.1373977661132812
        model: {}
        td_error: "[-0.43649983  0.0149622   0.00212622 -0.21610856 -0.00794458  0.5517237\n\
          \ -0.18369961 -0.31610465  0.28090715  0.0978899   0.40087175  0.12180376\n\
          \ -0.33975554  1.0449986  -0.24259329 -0.08750892  0.31742048  0.07765603\n\
          \ -0.20299983  0.07032728 -0.17213845 -0.2661264   0.17304587  0.3699\n -0.3272357\
          \  -0.15157318 -0.0230031   0.53246975 -0.15069199 -0.07395935\n -0.08347917\
          \  0.04358983 -0.3233199   0.11858964 -0.02773929  0.02084756\n -0.12661338\
          \ -0.32777023 -0.53251815  0.17504072  0.09340024  0.07387948\n -0.11557651\
          \ -0.23247552 -0.3040924   0.01733923  0.07319355  0.45495725]"
    num_agent_steps_sampled: 24000
    num_agent_steps_trained: 276048
    num_steps_sampled: 24000
    num_steps_trained: 276048
    num_target_updates: 46
  iterations_since_restore: 24
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.92941176470588
    ram_util_percent: 29.60588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049064955975850276
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.5604733759381766
    mean_inference_ms: 1.5779276442271337
    mean_raw_obs_processing_ms: 0.14146850600461405
  time_since_restore: 296.7494659423828
  time_this_iter_s: 12.017224311828613
  time_total_s: 296.7494659423828
  timers:
    learn_throughput: 3767.797
    learn_time_ms: 12.74
    update_time_ms: 3.303
  timestamp: 1629280969
  timesteps_since_restore: 0
  timesteps_total: 24000
  training_iteration: 24
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     24 |          296.749 | 24000 | -154.213 |             -119.995 |             -179.903 |               7282 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 25000
  custom_metrics: {}
  date: 2021-08-18_10-03-02
  done: false
  episode_len_mean: 7282.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -154.21288648831492
  episode_reward_min: -179.90305187553025
  episodes_this_iter: 0
  episodes_total: 3
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 24688
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.023009149357676506
          max_q: 4.4858503341674805
          mean_q: 3.1098697185516357
          mean_td_error: 0.026948079466819763
          min_q: 2.2243196964263916
        model: {}
        td_error: "[ 0.18089199 -0.06750512 -0.13696861 -0.35823536 -0.0723598  -0.03339577\n\
          \ -0.01372337 -0.04506755 -0.08408189  0.02842879 -0.2836125  -0.0253675\n\
          \  0.04534507 -0.21528292  0.19864202 -0.03329945  0.02876139  0.05018616\n\
          \ -0.1909287  -0.19521141 -0.38318443 -0.07626271  0.41952324 -0.01661396\n\
          \  0.05112457  0.73216605  0.22988677 -0.11142802  0.3499751   0.24481893\n\
          \  0.20172787  0.02864051 -0.01009727  0.12710428  0.06928992  0.16499996\n\
          \  0.18911648 -0.18058562 -0.366354   -0.05241823 -0.06637549  0.31457782\n\
          \ -0.2474842   0.2519822   0.09875894  0.9041536  -0.35959172  0.00884175]"
    num_agent_steps_sampled: 25000
    num_agent_steps_trained: 288048
    num_steps_sampled: 25000
    num_steps_trained: 288048
    num_target_updates: 48
  iterations_since_restore: 25
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.67777777777778
    ram_util_percent: 29.705555555555552
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049064955975850276
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.5604733759381766
    mean_inference_ms: 1.5779276442271337
    mean_raw_obs_processing_ms: 0.14146850600461405
  time_since_restore: 308.88351941108704
  time_this_iter_s: 12.134053468704224
  time_total_s: 308.88351941108704
  timers:
    learn_throughput: 5117.813
    learn_time_ms: 9.379
    update_time_ms: 2.701
  timestamp: 1629280982
  timesteps_since_restore: 0
  timesteps_total: 25000
  training_iteration: 25
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     25 |          308.884 | 25000 | -154.213 |             -119.995 |             -179.903 |               7282 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 26000
  custom_metrics: {}
  date: 2021-08-18_10-03-15
  done: false
  episode_len_mean: 7282.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -154.21288648831492
  episode_reward_min: -179.90305187553025
  episodes_this_iter: 0
  episodes_total: 3
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 25696
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04813413321971893
          max_q: 4.745549201965332
          mean_q: 3.1766536235809326
          mean_td_error: 0.06591817736625671
          min_q: 2.1291258335113525
        model: {}
        td_error: "[-0.03587389  0.4687345  -0.01001692 -0.03062367  0.07317734  0.49474335\n\
          \ -0.22549438 -0.27161956  0.01918364  0.28603935  0.0124445  -0.4988327\n\
          \  0.30900764  0.355124    0.76410437 -0.5588293   0.21555686  0.07326698\n\
          \ -0.21255708 -0.15874267 -0.18139577 -0.00638628 -0.16882157  0.16854906\n\
          \  0.35697365  0.17287755 -0.02016997 -0.092134    0.10844922  0.06628728\n\
          \  0.1125834   0.14906263  0.13691139  0.39923906 -0.12998104  0.17041445\n\
          \  0.40517354 -0.0938282  -0.13914609  0.08814597 -0.09609556  0.42439604\n\
          \  0.04911041 -0.00761843  0.2494452  -0.27845883  0.05496907  0.19672799]"
    num_agent_steps_sampled: 26000
    num_agent_steps_trained: 300048
    num_steps_sampled: 26000
    num_steps_trained: 300048
    num_target_updates: 50
  iterations_since_restore: 26
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.42222222222223
    ram_util_percent: 29.705555555555552
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049064955975850276
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.5604733759381766
    mean_inference_ms: 1.5779276442271337
    mean_raw_obs_processing_ms: 0.14146850600461405
  time_since_restore: 321.77101135253906
  time_this_iter_s: 12.887491941452026
  time_total_s: 321.77101135253906
  timers:
    learn_throughput: 5078.234
    learn_time_ms: 9.452
    update_time_ms: 2.776
  timestamp: 1629280995
  timesteps_since_restore: 0
  timesteps_total: 26000
  training_iteration: 26
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     26 |          321.771 | 26000 | -154.213 |             -119.995 |             -179.903 |               7282 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 27000
  custom_metrics: {}
  date: 2021-08-18_10-03-28
  done: false
  episode_len_mean: 7282.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -154.21288648831492
  episode_reward_min: -179.90305187553025
  episodes_this_iter: 0
  episodes_total: 3
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 26704
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03119104914367199
          max_q: 3.9530177116394043
          mean_q: 2.7583863735198975
          mean_td_error: -0.03493848443031311
          min_q: 1.2938438653945923
        model: {}
        td_error: "[ 0.02670789  0.03763914 -0.20372438  0.4328828   0.12200975 -0.21643639\n\
          \ -0.53085065  0.05889034  0.0881083   0.23081493  0.10869026 -0.23046112\n\
          \  0.05583262  0.15428662  0.10263133  0.02812672 -0.22338319  0.3379612\n\
          \  0.00678992 -0.00076509 -0.08996987  0.03848147  0.04314017 -0.01910019\n\
          \ -0.36046505  0.21739304 -0.13148952  0.3229065  -0.62282515 -0.47030926\n\
          \  0.362139    0.05557466 -0.05475545  0.02902436 -0.06282067 -0.34121752\n\
          \ -0.14603734  0.11526847  0.09995341 -0.3157339  -0.0309751  -0.11207294\n\
          \  0.08822155 -0.2849226  -0.28238034 -0.13410878  0.09670496 -0.07242203]"
    num_agent_steps_sampled: 27000
    num_agent_steps_trained: 312048
    num_steps_sampled: 27000
    num_steps_trained: 312048
    num_target_updates: 52
  iterations_since_restore: 27
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.752631578947366
    ram_util_percent: 29.799999999999997
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049064955975850276
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.5604733759381766
    mean_inference_ms: 1.5779276442271337
    mean_raw_obs_processing_ms: 0.14146850600461405
  time_since_restore: 335.0884852409363
  time_this_iter_s: 13.317473888397217
  time_total_s: 335.0884852409363
  timers:
    learn_throughput: 4659.917
    learn_time_ms: 10.301
    update_time_ms: 3.069
  timestamp: 1629281008
  timesteps_since_restore: 0
  timesteps_total: 27000
  training_iteration: 27
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     27 |          335.088 | 27000 | -154.213 |             -119.995 |             -179.903 |               7282 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 28000
  custom_metrics: {}
  date: 2021-08-18_10-03-42
  done: false
  episode_len_mean: 7282.0
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -154.21288648831492
  episode_reward_min: -179.90305187553025
  episodes_this_iter: 0
  episodes_total: 3
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 27712
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.026037083938717842
          max_q: 3.946078062057495
          mean_q: 2.8476924896240234
          mean_td_error: -0.022080883383750916
          min_q: 1.8180731534957886
        model: {}
        td_error: "[-0.0867939  -0.43058157 -0.03969884  0.26226163  0.14844894  0.02889514\n\
          \  0.19565582 -0.11887026 -0.10021925  0.06576633 -0.2695608   0.06171584\n\
          \ -0.38724756  0.25745058  0.00735688 -0.04305935  0.01124644  0.08791113\n\
          \ -0.01306391  0.12757158  0.38510132  0.06412947 -0.09407735 -0.17682719\n\
          \ -0.3303697   0.2879269  -0.26234698  0.1676848  -0.5569558   0.08239985\n\
          \ -0.08152127  0.02837944 -0.16014886 -0.28743505  0.05557227  0.24622607\n\
          \ -0.38162136 -0.1591487  -0.08297777 -0.49364495 -0.36329985  0.30688\n \
          \ 0.6110866   0.19518805  0.00942373 -0.04242444 -0.23153031  0.43926382]"
    num_agent_steps_sampled: 28000
    num_agent_steps_trained: 324048
    num_steps_sampled: 28000
    num_steps_trained: 324048
    num_target_updates: 54
  iterations_since_restore: 28
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.98571428571429
    ram_util_percent: 29.899999999999995
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049064955975850276
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.5604733759381766
    mean_inference_ms: 1.5779276442271337
    mean_raw_obs_processing_ms: 0.14146850600461405
  time_since_restore: 349.42765974998474
  time_this_iter_s: 14.339174509048462
  time_total_s: 349.42765974998474
  timers:
    learn_throughput: 4721.399
    learn_time_ms: 10.166
    update_time_ms: 3.812
  timestamp: 1629281022
  timesteps_since_restore: 0
  timesteps_total: 28000
  training_iteration: 28
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     28 |          349.428 | 28000 | -154.213 |             -119.995 |             -179.903 |               7282 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 29000
  custom_metrics: {}
  date: 2021-08-18_10-03-56
  done: false
  episode_len_mean: 7162.5
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -165.17065034218143
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 28720
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.029628800228238106
          max_q: 4.395330905914307
          mean_q: 2.8833060264587402
          mean_td_error: 0.05390993505716324
          min_q: 1.4940028190612793
        model: {}
        td_error: "[ 0.27039242  0.11051512  0.03526187  0.211447   -0.15639663 -0.09308386\n\
          \ -0.04404759  0.00352049  0.12487602  0.15930676  0.21609998  0.30283475\n\
          \ -0.04340649  0.01246881  0.16909528 -0.17658186  0.16840363 -0.30799818\n\
          \  0.02501702  0.26739502  0.2514763   0.57883906  0.13607001 -0.02316546\n\
          \ -0.15379333  0.08946347  0.00985312  0.36285782  0.02528143 -0.33939338\n\
          \  0.2856989   0.02666736  0.24700117  0.25718474  0.21838856  0.0361352\n\
          \ -0.24145937  0.20949721  0.12884498 -0.12394428 -0.37937713  0.04588938\n\
          \ -0.32406306 -0.30884385 -0.16130495  0.3588488  -0.06801939  0.18792391]"
    num_agent_steps_sampled: 29000
    num_agent_steps_trained: 336048
    num_steps_sampled: 29000
    num_steps_trained: 336048
    num_target_updates: 56
  iterations_since_restore: 29
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.04736842105264
    ram_util_percent: 29.92105263157894
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04908827973206113
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.7089408929719845
    mean_inference_ms: 1.5776177601390975
    mean_raw_obs_processing_ms: 0.14179894263841158
  time_since_restore: 362.60902857780457
  time_this_iter_s: 13.181368827819824
  time_total_s: 362.60902857780457
  timers:
    learn_throughput: 3982.375
    learn_time_ms: 12.053
    update_time_ms: 3.586
  timestamp: 1629281036
  timesteps_since_restore: 0
  timesteps_total: 29000
  training_iteration: 29
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     29 |          362.609 | 29000 | -165.171 |             -119.995 |             -198.044 |             7162.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 30000
  custom_metrics: {}
  date: 2021-08-18_10-04-06
  done: false
  episode_len_mean: 7162.5
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -165.17065034218143
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 4
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 29728
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.045637793838977814
          max_q: 4.728313446044922
          mean_q: 2.978227376937866
          mean_td_error: -0.031419552862644196
          min_q: 2.080150842666626
        model: {}
        td_error: "[-0.23026085  0.45285606  0.11593556  0.3604157  -0.13026285  0.05676198\n\
          \  0.11449957 -0.06218529  0.28779197 -0.03507042 -0.02670813  0.23271084\n\
          \  0.040416   -0.38977456 -0.44043112  0.20017314  0.19665456 -0.03211594\n\
          \ -0.35836315 -0.17112875  0.01254368 -0.2354083  -0.5924325  -0.10889959\n\
          \ -0.47574782 -0.39271784  0.13626933 -0.45057154  0.27554417 -0.26787782\n\
          \ -0.39248085 -0.00821447  0.2768159  -0.3151896   0.18279052 -0.09542823\n\
          \  0.14510989  0.14519548  0.1468761  -0.26846266 -0.34643722 -0.16681004\n\
          \  0.14736128 -0.14068675  0.08800411  0.44452858  0.39004385  0.17622948]"
    num_agent_steps_sampled: 30000
    num_agent_steps_trained: 348048
    num_steps_sampled: 30000
    num_steps_trained: 348048
    num_target_updates: 58
  iterations_since_restore: 30
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.55333333333332
    ram_util_percent: 30.006666666666668
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04908827973206113
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.7089408929719845
    mean_inference_ms: 1.5776177601390975
    mean_raw_obs_processing_ms: 0.14179894263841158
  time_since_restore: 373.3049261569977
  time_this_iter_s: 10.695897579193115
  time_total_s: 373.3049261569977
  timers:
    learn_throughput: 3122.006
    learn_time_ms: 15.375
    update_time_ms: 4.635
  timestamp: 1629281046
  timesteps_since_restore: 0
  timesteps_total: 30000
  training_iteration: 30
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     30 |          373.305 | 30000 | -165.171 |             -119.995 |             -198.044 |             7162.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 31000
  custom_metrics: {}
  date: 2021-08-18_10-04-18
  done: false
  episode_len_mean: 7162.5
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -165.17065034218143
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 4
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 30736
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.044468414038419724
          max_q: 5.947345733642578
          mean_q: 2.864421844482422
          mean_td_error: -0.09006508439779282
          min_q: 1.8897569179534912
        model: {}
        td_error: "[-0.567384    0.08647251 -0.43912315 -0.13328385  0.25658107 -0.03043103\n\
          \  0.29098248 -0.11691356 -0.01421428 -0.09605122 -0.00587153 -0.2441082\n\
          \  0.07327342 -0.06101489  0.11733711  0.01278639 -0.01399851 -0.10731244\n\
          \  0.40224338 -0.17187285 -0.08036637 -0.07505178 -0.13117743 -0.31486273\n\
          \ -0.3546896  -0.13692427  0.27992272  0.2857299   0.00271153 -0.5066297\n\
          \ -0.06610608 -0.1947906   0.00804949  0.19337821  0.02388024 -0.46658993\n\
          \ -0.38049483 -0.6565342  -0.00683641  0.12132454 -0.12950134 -0.12710452\n\
          \ -0.28255892 -0.24285436 -0.05640578 -0.15075994 -0.06492186 -0.05105662]"
    num_agent_steps_sampled: 31000
    num_agent_steps_trained: 360048
    num_steps_sampled: 31000
    num_steps_trained: 360048
    num_target_updates: 60
  iterations_since_restore: 31
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 67.4
    ram_util_percent: 30.047058823529415
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04908827973206113
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.7089408929719845
    mean_inference_ms: 1.5776177601390975
    mean_raw_obs_processing_ms: 0.14179894263841158
  time_since_restore: 384.8742456436157
  time_this_iter_s: 11.569319486618042
  time_total_s: 384.8742456436157
  timers:
    learn_throughput: 5054.279
    learn_time_ms: 9.497
    update_time_ms: 2.691
  timestamp: 1629281058
  timesteps_since_restore: 0
  timesteps_total: 31000
  training_iteration: 31
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     31 |          384.874 | 31000 | -165.171 |             -119.995 |             -198.044 |             7162.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 32000
  custom_metrics: {}
  date: 2021-08-18_10-04-30
  done: false
  episode_len_mean: 7162.5
  episode_media: {}
  episode_reward_max: -119.99501288637197
  episode_reward_mean: -165.17065034218143
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 4
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 31744
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02201385237276554
          max_q: 4.7960286140441895
          mean_q: 2.751230001449585
          mean_td_error: -0.017318120226264
          min_q: 1.3775149583816528
        model: {}
        td_error: "[ 0.08855677  0.09138775 -0.04812264 -0.0593133  -0.17328691  0.30353022\n\
          \ -0.08933544 -0.03885293 -0.43707252 -0.12860155  0.06741834  0.11997008\n\
          \ -0.03497481 -0.0816021   0.34379745  0.12101889  0.08397555  0.13615596\n\
          \ -0.09787154 -0.00547528  0.1745646  -0.0611136  -0.05726981 -0.06963015\n\
          \  0.03211284 -0.23342633  0.15649223 -0.20683694 -0.4782114  -0.18070579\n\
          \ -0.31579256  0.1641593   0.10886717  0.10992932  0.4069059   0.0247035\n\
          \  0.02315748  0.2522757  -0.1049273  -0.16960192 -0.264498   -0.07499194\n\
          \ -0.12444758  0.10481071  0.07412243 -0.15882778  0.11419773 -0.23858953]"
    num_agent_steps_sampled: 32000
    num_agent_steps_trained: 372048
    num_steps_sampled: 32000
    num_steps_trained: 372048
    num_target_updates: 62
  iterations_since_restore: 32
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.14999999999999
    ram_util_percent: 30.106250000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04908827973206113
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.7089408929719845
    mean_inference_ms: 1.5776177601390975
    mean_raw_obs_processing_ms: 0.14179894263841158
  time_since_restore: 396.46140241622925
  time_this_iter_s: 11.587156772613525
  time_total_s: 396.46140241622925
  timers:
    learn_throughput: 4911.89
    learn_time_ms: 9.772
    update_time_ms: 2.803
  timestamp: 1629281070
  timesteps_since_restore: 0
  timesteps_total: 32000
  training_iteration: 32
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     32 |          396.461 | 32000 | -165.171 |             -119.995 |             -198.044 |             7162.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 33000
  custom_metrics: {}
  date: 2021-08-18_10-04-41
  done: false
  episode_len_mean: 6512.6
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.0365544988915
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 32752
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04103848710656166
          max_q: 4.153274059295654
          mean_q: 2.6876888275146484
          mean_td_error: 0.08330418914556503
          min_q: 1.7018132209777832
        model: {}
        td_error: "[ 0.02936554  0.19022441 -0.30433846  0.08774662 -0.0487864   0.5541513\n\
          \ -0.03088164  0.00601983  0.20558047  0.1685996   0.02928495  0.18302941\n\
          \  0.1585424   0.43280482  0.25839114  0.2214768   0.37750816 -0.25409126\n\
          \  0.08042073  0.20373034  0.05430651 -0.23370004 -0.01694751 -0.06434608\n\
          \  0.37347472 -0.21582937  0.28720236 -0.03513288  0.48009396  0.41064394\n\
          \  0.16367245 -0.07166028 -0.1411488   0.33476925 -0.13383651 -0.23068094\n\
          \  0.19108939 -0.18749905 -0.02713251 -0.05478692 -0.12621093  0.4656632\n\
          \  0.09857488 -0.3460424   0.53840446 -0.09918165 -0.11323833  0.14930129]"
    num_agent_steps_sampled: 33000
    num_agent_steps_trained: 384048
    num_steps_sampled: 33000
    num_steps_trained: 384048
    num_target_updates: 64
  iterations_since_restore: 33
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.28823529411764
    ram_util_percent: 30.2
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907046760613313
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.7673826784334645
    mean_inference_ms: 1.5766200376508304
    mean_raw_obs_processing_ms: 0.14189378768345645
  time_since_restore: 407.72423338890076
  time_this_iter_s: 11.262830972671509
  time_total_s: 407.72423338890076
  timers:
    learn_throughput: 5159.707
    learn_time_ms: 9.303
    update_time_ms: 2.781
  timestamp: 1629281081
  timesteps_since_restore: 0
  timesteps_total: 33000
  training_iteration: 33
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     33 |          407.724 | 33000 | -156.037 |               -119.5 |             -198.044 |             6512.6 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 34000
  custom_metrics: {}
  date: 2021-08-18_10-04-53
  done: false
  episode_len_mean: 6512.6
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.0365544988915
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 5
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 33760
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.033850885927677155
          max_q: 5.137740135192871
          mean_q: 2.759472608566284
          mean_td_error: 0.06615416705608368
          min_q: 1.7364760637283325
        model: {}
        td_error: "[-0.47459364  0.07362008 -0.07938862 -0.0445013   0.0545013  -0.27495193\n\
          \  0.05334234 -0.19162273  0.6231744   0.33184123 -0.32079768  0.10530639\n\
          \ -0.17735505  0.2864504   0.06764507 -0.03667879  0.04226685 -0.16180515\n\
          \  0.7356117  -0.43453908  0.04999781 -0.27575088 -0.1670959   0.1386702\n\
          \  0.0213654   0.3605727   0.45740342  0.34185076  0.22871828  0.04631543\n\
          \ -0.06357312  0.02471757  0.2649629  -0.07610941  0.20107603 -0.04368043\n\
          \  0.46338677  0.06547618  0.12742233 -0.26289654  0.01759815  0.42857027\n\
          \  0.0705359   0.05237913 -0.33119106  0.43253684  0.2215445   0.203071  ]"
    num_agent_steps_sampled: 34000
    num_agent_steps_trained: 396048
    num_steps_sampled: 34000
    num_steps_trained: 396048
    num_target_updates: 66
  iterations_since_restore: 34
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.01875
    ram_util_percent: 30.25
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907046760613313
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.7673826784334645
    mean_inference_ms: 1.5766200376508304
    mean_raw_obs_processing_ms: 0.14189378768345645
  time_since_restore: 419.2899491786957
  time_this_iter_s: 11.565715789794922
  time_total_s: 419.2899491786957
  timers:
    learn_throughput: 3236.169
    learn_time_ms: 14.832
    update_time_ms: 6.614
  timestamp: 1629281093
  timesteps_since_restore: 0
  timesteps_total: 34000
  training_iteration: 34
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.7/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     34 |           419.29 | 34000 | -156.037 |               -119.5 |             -198.044 |             6512.6 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 35000
  custom_metrics: {}
  date: 2021-08-18_10-05-05
  done: false
  episode_len_mean: 6512.6
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.0365544988915
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 5
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 34768
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.052000582218170166
          max_q: 5.002974510192871
          mean_q: 2.6295223236083984
          mean_td_error: -0.11447940766811371
          min_q: 1.5206822156906128
        model: {}
        td_error: "[-0.45266938  0.01012146 -0.50922155  0.3369658   0.01080465 -0.31840992\n\
          \ -0.37132454 -0.64385843  0.12205315  0.1433289  -0.19002056  0.22915411\n\
          \  0.37028027 -0.40507698 -0.37969685  0.09970927 -0.21771455  0.43428755\n\
          \  0.21990204 -0.24706149 -0.63956356 -0.37941027  0.0919466  -0.0160532\n\
          \ -0.34280276 -0.17596436 -0.06993246 -0.04728413  0.1449579  -0.05636954\n\
          \ -0.27255285  0.11080623  0.24448681  0.01376724 -0.22927451  0.22064996\n\
          \ -0.12386322 -0.686841   -0.22462225 -0.16399479 -0.24947095 -0.19392991\n\
          \  0.14355612 -0.29369712  0.13436961 -0.20771384 -0.3568611  -0.11090326]"
    num_agent_steps_sampled: 35000
    num_agent_steps_trained: 408048
    num_steps_sampled: 35000
    num_steps_trained: 408048
    num_target_updates: 68
  iterations_since_restore: 35
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.04117647058824
    ram_util_percent: 30.305882352941172
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907046760613313
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.7673826784334645
    mean_inference_ms: 1.5766200376508304
    mean_raw_obs_processing_ms: 0.14189378768345645
  time_since_restore: 431.02248883247375
  time_this_iter_s: 11.732539653778076
  time_total_s: 431.02248883247375
  timers:
    learn_throughput: 4957.55
    learn_time_ms: 9.682
    update_time_ms: 2.846
  timestamp: 1629281105
  timesteps_since_restore: 0
  timesteps_total: 35000
  training_iteration: 35
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.8/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     35 |          431.022 | 35000 | -156.037 |               -119.5 |             -198.044 |             6512.6 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 36000
  custom_metrics: {}
  date: 2021-08-18_10-05-17
  done: false
  episode_len_mean: 6512.6
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.0365544988915
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 5
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 35776
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03133320435881615
          max_q: 4.166067123413086
          mean_q: 2.720076084136963
          mean_td_error: 0.0398557186126709
          min_q: 1.5562189817428589
        model: {}
        td_error: "[-0.1333754  -0.0780375  -0.28128076  0.0054965  -0.14130163  0.10423923\n\
          \  0.00977945 -0.08961582 -0.05923653  0.25211227  0.31360102  0.05469537\n\
          \  0.15052462 -0.2653072   0.08297944  0.46412683  0.10214019  0.27565622\n\
          \  0.4380715  -0.3729868   0.02780545 -0.15322804  0.13104844 -0.08889246\n\
          \  0.05210829 -0.02881312 -0.02395356 -0.06411457  0.09551454 -0.13300705\n\
          \  0.2775662   0.1250081   0.01375723 -0.2991979   0.41940534  0.18346572\n\
          \  0.29866838  0.47020924 -0.6167526   0.04294872  0.32724428 -0.27192426\n\
          \  0.16157627  0.64854145 -0.31965685 -0.09890223 -0.15536451  0.05973291]"
    num_agent_steps_sampled: 36000
    num_agent_steps_trained: 420048
    num_steps_sampled: 36000
    num_steps_trained: 420048
    num_target_updates: 70
  iterations_since_restore: 36
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.35555555555555
    ram_util_percent: 30.40555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907046760613313
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.7673826784334645
    mean_inference_ms: 1.5766200376508304
    mean_raw_obs_processing_ms: 0.14189378768345645
  time_since_restore: 443.49016642570496
  time_this_iter_s: 12.467677593231201
  time_total_s: 443.49016642570496
  timers:
    learn_throughput: 4667.793
    learn_time_ms: 10.283
    update_time_ms: 2.713
  timestamp: 1629281117
  timesteps_since_restore: 0
  timesteps_total: 36000
  training_iteration: 36
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.8/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     36 |           443.49 | 36000 | -156.037 |               -119.5 |             -198.044 |             6512.6 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 37000
  custom_metrics: {}
  date: 2021-08-18_10-05-30
  done: false
  episode_len_mean: 6061.666666666667
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.67759850593367
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 36784
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.033982183784246445
          max_q: 4.998367786407471
          mean_q: 2.705167770385742
          mean_td_error: 0.040101125836372375
          min_q: 1.2139341831207275
        model: {}
        td_error: "[ 0.18341303  0.23664999 -0.3331648   0.2586881   0.13712955  0.0458951\n\
          \  0.17453337 -0.17572474 -0.17826486  0.18130434 -0.59114265  0.48553228\n\
          \ -0.06811953 -0.0862844  -0.3429327  -0.24570322 -0.26510906  0.23544693\n\
          \  0.64147127  0.10599637  0.22719276 -0.01024055 -0.07726097  0.08719254\n\
          \ -0.00407767 -0.6785693   0.17754388  0.39898324  0.1905092   0.13548756\n\
          \ -0.10233593  0.54430413  0.63668036 -0.18330646  0.20891619 -0.13136959\n\
          \  0.34862614  0.533218    0.05734348 -0.04026604 -0.00721526  0.28334022\n\
          \  0.10848355 -0.09960723 -0.15470243 -0.8427942  -0.04223084 -0.03860521]"
    num_agent_steps_sampled: 37000
    num_agent_steps_trained: 432048
    num_steps_sampled: 37000
    num_steps_trained: 432048
    num_target_updates: 72
  iterations_since_restore: 37
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.58823529411765
    ram_util_percent: 30.5
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907313332952584
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.795532354378
    mean_inference_ms: 1.575863247890008
    mean_raw_obs_processing_ms: 0.14193020959165478
  time_since_restore: 455.6053214073181
  time_this_iter_s: 12.11515498161316
  time_total_s: 455.6053214073181
  timers:
    learn_throughput: 5108.645
    learn_time_ms: 9.396
    update_time_ms: 2.549
  timestamp: 1629281130
  timesteps_since_restore: 0
  timesteps_total: 37000
  training_iteration: 37
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.8/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     37 |          455.605 | 37000 | -156.678 |               -119.5 |             -198.044 |            6061.67 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 38000
  custom_metrics: {}
  date: 2021-08-18_10-05-41
  done: false
  episode_len_mean: 6061.666666666667
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.67759850593367
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 37792
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04638459533452988
          max_q: 4.129251480102539
          mean_q: 2.7821593284606934
          mean_td_error: 0.0966925323009491
          min_q: 1.3431252241134644
        model: {}
        td_error: "[ 0.32134914  0.61912596  0.28653193 -0.07832551  0.13776493 -0.04826236\n\
          \ -0.06421995  0.29831457  0.39422226  0.14477706  0.35329294  0.14438713\n\
          \  0.26551294  0.31161034 -0.13469744  0.38972044 -0.41521668 -0.21742344\n\
          \ -0.35704422  0.12608433  0.27819145  0.5655153  -0.251446   -0.26166224\n\
          \  0.21994066 -0.31702423  0.10237861 -0.1576426  -0.23644519  0.41370082\n\
          \  0.12967396  0.20958686 -0.14311886  0.03092599  0.23043108  0.09218717\n\
          \  0.32721996  0.24609733 -0.20953846 -0.25358176 -0.33153725 -0.3656646\n\
          \  0.02479959  0.03738499  0.5798383   0.877823    0.08431482  0.24138856]"
    num_agent_steps_sampled: 38000
    num_agent_steps_trained: 444048
    num_steps_sampled: 38000
    num_steps_trained: 444048
    num_target_updates: 74
  iterations_since_restore: 38
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.331250000000004
    ram_util_percent: 30.606250000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907313332952584
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.795532354378
    mean_inference_ms: 1.575863247890008
    mean_raw_obs_processing_ms: 0.14193020959165478
  time_since_restore: 466.8102490901947
  time_this_iter_s: 11.204927682876587
  time_total_s: 466.8102490901947
  timers:
    learn_throughput: 5122.071
    learn_time_ms: 9.371
    update_time_ms: 2.742
  timestamp: 1629281141
  timesteps_since_restore: 0
  timesteps_total: 38000
  training_iteration: 38
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.8/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     38 |           466.81 | 38000 | -156.678 |               -119.5 |             -198.044 |            6061.67 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 39000
  custom_metrics: {}
  date: 2021-08-18_10-05-53
  done: false
  episode_len_mean: 6061.666666666667
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.67759850593367
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 38800
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.057950861752033234
          max_q: 4.543605804443359
          mean_q: 2.5831780433654785
          mean_td_error: -0.10279588401317596
          min_q: 1.396201729774475
        model: {}
        td_error: "[-0.09935379 -0.18323827 -0.34165645  0.1701392   0.9747517  -0.36667824\n\
          \ -0.19539475 -0.36775446  0.11218286  0.0376575  -0.5982487  -0.12762189\n\
          \  0.20094132  0.10803938 -0.2685306   0.14429164 -0.04452538 -0.1558516\n\
          \ -0.57504034  0.21989846 -0.29232264 -0.29083443 -0.70643187  0.3747306\n\
          \ -0.99659514 -0.4262557   0.04904366  0.16108894 -0.00444794 -0.1342653\n\
          \  0.0787189   0.61177516 -0.47009563 -0.3830793  -0.3145888  -0.6032381\n\
          \ -0.0598439  -0.10229397 -0.07855368  0.03386831  0.47132826 -0.57183456\n\
          \  0.17813015 -0.45184588  0.17538023 -0.2233007   0.5825813  -0.18502784]"
    num_agent_steps_sampled: 39000
    num_agent_steps_trained: 456048
    num_steps_sampled: 39000
    num_steps_trained: 456048
    num_target_updates: 76
  iterations_since_restore: 39
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.970588235294116
    ram_util_percent: 30.60588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907313332952584
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.795532354378
    mean_inference_ms: 1.575863247890008
    mean_raw_obs_processing_ms: 0.14193020959165478
  time_since_restore: 478.64805722236633
  time_this_iter_s: 11.83780813217163
  time_total_s: 478.64805722236633
  timers:
    learn_throughput: 4838.186
    learn_time_ms: 9.921
    update_time_ms: 2.931
  timestamp: 1629281153
  timesteps_since_restore: 0
  timesteps_total: 39000
  training_iteration: 39
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.8/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     39 |          478.648 | 39000 | -156.678 |               -119.5 |             -198.044 |            6061.67 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 40000
  custom_metrics: {}
  date: 2021-08-18_10-06-06
  done: false
  episode_len_mean: 6061.666666666667
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.67759850593367
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 39808
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03909721598029137
          max_q: 4.37965202331543
          mean_q: 2.6557986736297607
          mean_td_error: -0.003779033897444606
          min_q: 0.2718488574028015
        model: {}
        td_error: "[-0.49133134 -0.15264964  0.23214364  0.4157114  -0.02989769  0.29533648\n\
          \  0.03090048  0.36551     0.01492262  0.12260675  0.27953434 -0.49986076\n\
          \ -0.5273025   0.33495998 -0.37136889  0.20189548  0.14356232 -0.04593205\n\
          \  0.10527849  0.19172382  0.35453463  0.24150395 -0.2219137   0.08369398\n\
          \ -0.13637376  0.3672706  -0.22377086 -0.05500698  0.08793867  0.12467456\n\
          \ -0.02258277 -0.00712204  0.19530725  0.175668   -0.1024611  -0.00531745\n\
          \  0.5401287  -1.3343186   0.01411474 -0.06295681 -0.5903225   0.02317429\n\
          \ -0.37273645 -0.01952267 -0.09199947 -0.0341748   0.47669482 -0.2012608 ]"
    num_agent_steps_sampled: 40000
    num_agent_steps_trained: 468048
    num_steps_sampled: 40000
    num_steps_trained: 468048
    num_target_updates: 78
  iterations_since_restore: 40
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.53333333333335
    ram_util_percent: 30.70555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907313332952584
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.795532354378
    mean_inference_ms: 1.575863247890008
    mean_raw_obs_processing_ms: 0.14193020959165478
  time_since_restore: 491.3540871143341
  time_this_iter_s: 12.706029891967773
  time_total_s: 491.3540871143341
  timers:
    learn_throughput: 4489.298
    learn_time_ms: 10.692
    update_time_ms: 2.861
  timestamp: 1629281166
  timesteps_since_restore: 0
  timesteps_total: 40000
  training_iteration: 40
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.8/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     40 |          491.354 | 40000 | -156.678 |               -119.5 |             -198.044 |            6061.67 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 41000
  custom_metrics: {}
  date: 2021-08-18_10-06-18
  done: false
  episode_len_mean: 6061.666666666667
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.67759850593367
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 40816
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0664299726486206
          max_q: 4.607616901397705
          mean_q: 2.405221462249756
          mean_td_error: -0.1618446260690689
          min_q: 0.5364932417869568
        model: {}
        td_error: "[ 0.03636456 -0.40165877 -0.6446402  -0.47193623 -0.61007977 -0.08656001\n\
          \ -0.06705022 -0.22767562 -0.12481451 -0.57076406 -0.02756548 -0.59148765\n\
          \ -0.07408309 -0.14100718  0.2705325  -0.3176551   0.02816033 -0.06845546\n\
          \  0.07192397 -0.3270297  -0.47054136 -0.03510129 -0.37545872  0.10151756\n\
          \ -0.289711   -0.22361135  0.00503445 -0.29222274 -0.055583   -0.10105109\n\
          \  0.18303633 -0.6522248   0.3465606  -0.37297678 -0.7184025  -0.2029674\n\
          \  0.0368588  -0.14435339 -0.47419918  0.23522139  0.17782426 -0.5656798\n\
          \ -0.12219286 -0.00350058 -0.22593045  0.4736843  -0.07380939  0.41671968]"
    num_agent_steps_sampled: 41000
    num_agent_steps_trained: 480048
    num_steps_sampled: 41000
    num_steps_trained: 480048
    num_target_updates: 80
  iterations_since_restore: 41
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.863157894736844
    ram_util_percent: 30.805263157894736
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907313332952584
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.795532354378
    mean_inference_ms: 1.575863247890008
    mean_raw_obs_processing_ms: 0.14193020959165478
  time_since_restore: 503.93466091156006
  time_this_iter_s: 12.580573797225952
  time_total_s: 503.93466091156006
  timers:
    learn_throughput: 3703.532
    learn_time_ms: 12.961
    update_time_ms: 3.761
  timestamp: 1629281178
  timesteps_since_restore: 0
  timesteps_total: 41000
  training_iteration: 41
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.8/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     41 |          503.935 | 41000 | -156.678 |               -119.5 |             -198.044 |            6061.67 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 42000
  custom_metrics: {}
  date: 2021-08-18_10-06-32
  done: false
  episode_len_mean: 6061.666666666667
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.67759850593367
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 41824
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.030827147886157036
          max_q: 5.377354621887207
          mean_q: 2.58571720123291
          mean_td_error: 0.011338196694850922
          min_q: 1.1607531309127808
        model: {}
        td_error: "[ 0.4919598   0.62070894  0.17344284  0.03543878 -0.13109994  0.09416294\n\
          \ -0.30853248  0.22054815  0.05818176  0.16020536 -0.19473433 -0.01435184\n\
          \ -0.17465794  0.32362092 -0.21850574  0.33694732  0.0931443   0.49752438\n\
          \  0.43405712  0.06119084  0.03898203  0.11134219  0.2685188   0.12827206\n\
          \  0.08271742 -0.28855658 -0.44155395  0.1455903  -0.0166502   0.1824832\n\
          \ -0.25073957  0.20770168 -0.93433094  0.01535845 -0.40697432 -0.22927141\n\
          \  0.24527884  0.06414843 -0.15252805 -0.11244559  0.22851515 -0.3203237\n\
          \ -0.22559643  0.12255955 -0.07887602  0.00845766 -0.02984738 -0.37724936]"
    num_agent_steps_sampled: 42000
    num_agent_steps_trained: 492048
    num_steps_sampled: 42000
    num_steps_trained: 492048
    num_target_updates: 82
  iterations_since_restore: 42
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.4157894736842
    ram_util_percent: 30.905263157894733
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907313332952584
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.795532354378
    mean_inference_ms: 1.575863247890008
    mean_raw_obs_processing_ms: 0.14193020959165478
  time_since_restore: 517.2439243793488
  time_this_iter_s: 13.309263467788696
  time_total_s: 517.2439243793488
  timers:
    learn_throughput: 4788.724
    learn_time_ms: 10.024
    update_time_ms: 2.901
  timestamp: 1629281192
  timesteps_since_restore: 0
  timesteps_total: 42000
  training_iteration: 42
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.8/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     42 |          517.244 | 42000 | -156.678 |               -119.5 |             -198.044 |            6061.67 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 43000
  custom_metrics: {}
  date: 2021-08-18_10-06-45
  done: false
  episode_len_mean: 6061.666666666667
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -156.67759850593367
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 42832
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03288676589727402
          max_q: 4.971924781799316
          mean_q: 2.2276532649993896
          mean_td_error: -0.03785949945449829
          min_q: 0.07735517621040344
        model: {}
        td_error: "[-0.08183056  0.11036348 -0.25818256 -0.2380271  -0.18220353  0.08177269\n\
          \  0.20189667 -0.3732009   0.05776334  0.24291253 -0.3107643   0.15264082\n\
          \ -0.19230735  0.27906573 -0.19055581 -0.33078122  0.69840455  0.27018994\n\
          \  0.428154    0.00414252  0.21432376 -0.40239942 -0.0106945   0.66369534\n\
          \  0.21360266 -0.01456642 -0.34735763 -0.324188    0.14033365  0.05932271\n\
          \ -0.25079322 -0.17364168 -0.13056731  0.11211526 -0.17472649  0.4596572\n\
          \ -0.32306027  0.15256953 -0.08293867  0.2624495  -0.24669218 -0.43345952\n\
          \  0.10763478 -0.2233249  -0.09882331 -0.54936445 -0.42999363 -0.35582185]"
    num_agent_steps_sampled: 43000
    num_agent_steps_trained: 504048
    num_steps_sampled: 43000
    num_steps_trained: 504048
    num_target_updates: 84
  iterations_since_restore: 43
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.37368421052632
    ram_util_percent: 31.00526315789474
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907313332952584
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.795532354378
    mean_inference_ms: 1.575863247890008
    mean_raw_obs_processing_ms: 0.14193020959165478
  time_since_restore: 530.758193731308
  time_this_iter_s: 13.514269351959229
  time_total_s: 530.758193731308
  timers:
    learn_throughput: 4926.156
    learn_time_ms: 9.744
    update_time_ms: 2.966
  timestamp: 1629281205
  timesteps_since_restore: 0
  timesteps_total: 43000
  training_iteration: 43
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     43 |          530.758 | 43000 | -156.678 |               -119.5 |             -198.044 |            6061.67 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 44000
  custom_metrics: {}
  date: 2021-08-18_10-06-57
  done: false
  episode_len_mean: 6167.714285714285
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -160.1482354981201
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 43840
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.046007391065359116
          max_q: 5.055877685546875
          mean_q: 2.4530627727508545
          mean_td_error: 0.08284659683704376
          min_q: 0.569881021976471
        model: {}
        td_error: "[-0.23893404  0.22128129  0.22622633  0.05297375  0.14045835  0.569191\n\
          \  0.22269773  0.2892046   0.18785882 -0.15238822  0.05784333  0.1549567\n\
          \  0.50967073  0.8129801  -0.4923818  -0.11729646 -0.14219475 -0.04233813\n\
          \ -0.00679326 -0.59225655  0.44094288  0.22931862 -0.12793875 -0.11058402\n\
          \  0.28454232 -0.14992476 -0.33754587 -0.06437612  0.6209749   0.01020217\n\
          \  0.08883047  0.02879381 -0.47558427  0.3664719  -0.15190911  0.28812408\n\
          \  0.07842159  0.668113   -0.18083    -0.24722862  0.24068713 -0.02047431\n\
          \  0.43157935  0.12535     0.23249197  0.20548892 -0.06917477 -0.08888578]"
    num_agent_steps_sampled: 44000
    num_agent_steps_trained: 516048
    num_steps_sampled: 44000
    num_steps_trained: 516048
    num_target_updates: 86
  iterations_since_restore: 44
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.86470588235294
    ram_util_percent: 31.1
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907498415723468
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.813680594678382
    mean_inference_ms: 1.575014202343309
    mean_raw_obs_processing_ms: 0.1419470820336464
  time_since_restore: 542.1124589443207
  time_this_iter_s: 11.354265213012695
  time_total_s: 542.1124589443207
  timers:
    learn_throughput: 5105.303
    learn_time_ms: 9.402
    update_time_ms: 2.653
  timestamp: 1629281217
  timesteps_since_restore: 0
  timesteps_total: 44000
  training_iteration: 44
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     44 |          542.112 | 44000 | -160.148 |               -119.5 |             -198.044 |            6167.71 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 45000
  custom_metrics: {}
  date: 2021-08-18_10-07-09
  done: false
  episode_len_mean: 6167.714285714285
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -160.1482354981201
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 7
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 44848
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06284185498952866
          max_q: 7.319008827209473
          mean_q: 2.325352430343628
          mean_td_error: 0.13689956068992615
          min_q: 0.10948881506919861
        model: {}
        td_error: "[ 0.16492629  0.36598372  0.3775288  -0.13111973  0.19147778  0.9498657\n\
          \  0.0384984  -0.48329937 -0.4202187   0.780898    0.5830276   0.11115658\n\
          \ -0.2370745  -0.05559897  0.37845898 -0.0169642  -0.10494041  0.27025604\n\
          \ -0.30023205  0.22074294  0.26970887 -0.13687313  0.283566    0.12054992\n\
          \ -0.01051497  0.5510211   0.33030176  0.48099518  0.49850142 -0.2209127\n\
          \ -0.01783919 -0.26125705 -0.22465491  0.5010892   0.13151908 -0.0789907\n\
          \  0.2875185   0.12416339  0.49278945  0.02645469  0.833218   -0.8845091\n\
          \ -0.48180962  0.2132206   0.02797961  0.18871748  0.90514886 -0.06129634]"
    num_agent_steps_sampled: 45000
    num_agent_steps_trained: 528048
    num_steps_sampled: 45000
    num_steps_trained: 528048
    num_target_updates: 88
  iterations_since_restore: 45
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.83125
    ram_util_percent: 31.106250000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907498415723468
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.813680594678382
    mean_inference_ms: 1.575014202343309
    mean_raw_obs_processing_ms: 0.1419470820336464
  time_since_restore: 554.283124923706
  time_this_iter_s: 12.170665979385376
  time_total_s: 554.283124923706
  timers:
    learn_throughput: 4903.874
    learn_time_ms: 9.788
    update_time_ms: 3.028
  timestamp: 1629281229
  timesteps_since_restore: 0
  timesteps_total: 45000
  training_iteration: 45
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     45 |          554.283 | 45000 | -160.148 |               -119.5 |             -198.044 |            6167.71 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 46000
  custom_metrics: {}
  date: 2021-08-18_10-07-21
  done: false
  episode_len_mean: 6167.714285714285
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -160.1482354981201
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 7
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 45856
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03390233963727951
          max_q: 4.2403340339660645
          mean_q: 2.431262493133545
          mean_td_error: -0.011816213838756084
          min_q: 0.28868627548217773
        model: {}
        td_error: "[ 0.44041443  0.0095427   0.21082234 -0.29228067  0.5556338   0.03794193\n\
          \  0.3051864   0.43474483  0.2111181  -0.0219363  -0.3432815   0.36355567\n\
          \ -0.544868    0.00306129 -0.15886092 -0.47926736 -0.01443005 -0.1429112\n\
          \ -0.35966277 -0.22886658  0.19131327  0.92315114 -0.14227426 -0.58796453\n\
          \  0.12141275 -0.11340785 -0.40445793  0.01972878 -0.0711081  -0.27678084\n\
          \ -0.5127585  -0.11689448 -0.17360306  0.22877407  0.26582527 -0.22101057\n\
          \  0.6448829  -0.00760293 -0.32070732  0.5037701  -0.2742281   0.00534415\n\
          \  0.03434348  0.46327668  0.02999973 -0.25690198 -0.27456903 -0.23038697]"
    num_agent_steps_sampled: 46000
    num_agent_steps_trained: 540048
    num_steps_sampled: 46000
    num_steps_trained: 540048
    num_target_updates: 90
  iterations_since_restore: 46
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.0235294117647
    ram_util_percent: 31.2
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907498415723468
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.813680594678382
    mean_inference_ms: 1.575014202343309
    mean_raw_obs_processing_ms: 0.1419470820336464
  time_since_restore: 566.0718371868134
  time_this_iter_s: 11.7887122631073
  time_total_s: 566.0718371868134
  timers:
    learn_throughput: 5052.719
    learn_time_ms: 9.5
    update_time_ms: 2.86
  timestamp: 1629281241
  timesteps_since_restore: 0
  timesteps_total: 46000
  training_iteration: 46
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     46 |          566.072 | 46000 | -160.148 |               -119.5 |             -198.044 |            6167.71 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 47000
  custom_metrics: {}
  date: 2021-08-18_10-07-34
  done: false
  episode_len_mean: 6167.714285714285
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -160.1482354981201
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 7
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 46864
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.055363040417432785
          max_q: 5.601102828979492
          mean_q: 2.511011838912964
          mean_td_error: 0.1437370777130127
          min_q: 0.19254961609840393
        model: {}
        td_error: "[-0.48044252  0.32636142 -0.36219263 -0.25469398  0.21055329 -0.0834682\n\
          \  0.2868352   0.62096286  0.35571766  0.7267097   0.30434752 -0.36987424\n\
          \ -0.70088816  0.24860764  0.35756016 -0.29048252  0.06243694  0.26086164\n\
          \ -0.28654647 -0.02964258  0.3581307   0.9120915   0.5414833   0.2118994\n\
          \  0.48288774  0.06476998  0.08698463  0.07584667  0.18993878  0.23740646\n\
          \  0.11433733  0.3544507   0.64655864  0.1066854  -0.0659585  -0.26588297\n\
          \  0.26863766  0.6973995  -0.43340206  0.070539    0.1683166  -0.0348419\n\
          \  0.5663022   0.22715664  0.23778105  0.43518698 -0.21776962 -0.04027903]"
    num_agent_steps_sampled: 47000
    num_agent_steps_trained: 552048
    num_steps_sampled: 47000
    num_steps_trained: 552048
    num_target_updates: 92
  iterations_since_restore: 47
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.35555555555555
    ram_util_percent: 31.27777777777777
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907498415723468
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.813680594678382
    mean_inference_ms: 1.575014202343309
    mean_raw_obs_processing_ms: 0.1419470820336464
  time_since_restore: 578.564888715744
  time_this_iter_s: 12.493051528930664
  time_total_s: 578.564888715744
  timers:
    learn_throughput: 4131.717
    learn_time_ms: 11.617
    update_time_ms: 4.136
  timestamp: 1629281254
  timesteps_since_restore: 0
  timesteps_total: 47000
  training_iteration: 47
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     47 |          578.565 | 47000 | -160.148 |               -119.5 |             -198.044 |            6167.71 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 48000
  custom_metrics: {}
  date: 2021-08-18_10-07-46
  done: false
  episode_len_mean: 6167.714285714285
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -160.1482354981201
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 7
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 47872
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05014532804489136
          max_q: 5.838928699493408
          mean_q: 2.554539442062378
          mean_td_error: -0.04039103537797928
          min_q: -0.9561907649040222
        model: {}
        td_error: "[-0.1919601   0.49712658 -0.06340277  0.34873128  0.4048561   0.07015014\n\
          \ -0.10833216 -0.11415625  0.11606264 -0.12273544  0.4903953  -0.37728906\n\
          \ -0.20439696  0.10407948 -0.1163609  -0.56222314  0.02721763 -0.37120295\n\
          \  0.17333984 -0.21909654  0.61106545  0.5327023  -0.7697623  -0.22194207\n\
          \ -0.14673376 -0.49299026  0.19623995  0.20578742 -0.43829465 -0.05501223\n\
          \  0.33564734  0.36533177 -0.06441951 -0.22553825 -0.12115335  0.00734901\n\
          \  0.27964306  0.30688298 -0.9961252  -0.18274331 -0.14633834  0.12686086\n\
          \  0.05825329 -0.22052336 -0.11654973 -0.2877822  -0.37763548  0.11820817]"
    num_agent_steps_sampled: 48000
    num_agent_steps_trained: 564048
    num_steps_sampled: 48000
    num_steps_trained: 564048
    num_target_updates: 94
  iterations_since_restore: 48
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.766666666666666
    ram_util_percent: 31.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907498415723468
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.813680594678382
    mean_inference_ms: 1.575014202343309
    mean_raw_obs_processing_ms: 0.1419470820336464
  time_since_restore: 591.1786231994629
  time_this_iter_s: 12.613734483718872
  time_total_s: 591.1786231994629
  timers:
    learn_throughput: 3525.959
    learn_time_ms: 13.613
    update_time_ms: 3.746
  timestamp: 1629281266
  timesteps_since_restore: 0
  timesteps_total: 48000
  training_iteration: 48
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     48 |          591.179 | 48000 | -160.148 |               -119.5 |             -198.044 |            6167.71 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 49000
  custom_metrics: {}
  date: 2021-08-18_10-08-00
  done: false
  episode_len_mean: 6167.714285714285
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -160.1482354981201
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 7
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 48880
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04772379249334335
          max_q: 4.995628356933594
          mean_q: 2.5405690670013428
          mean_td_error: 0.0056733861565589905
          min_q: 0.6294562220573425
        model: {}
        td_error: "[-0.25563192  0.94365597  0.25381422  0.01909041 -0.8815818   0.21173573\n\
          \ -0.49726892 -0.13551974  0.11103451 -0.05415845  0.36499834  0.26099932\n\
          \ -0.16190577 -0.3179729  -0.1942246   0.21318191 -0.05645537 -0.12813056\n\
          \ -0.10459542 -0.25471282 -0.46190524  0.01020288  0.63667643  0.06623948\n\
          \  0.16845596  0.14855301  0.16110754 -0.08931875 -0.21886992  0.26914668\n\
          \ -0.13461566  0.13857579  0.3395126  -0.6686423   0.11585641  1.5391086\n\
          \ -0.00740671 -0.5053582  -0.49059153 -0.0508852  -0.58313227  0.00974631\n\
          \  0.03407454 -0.35443258 -0.08905721  0.21893501  0.49544793  0.23854661]"
    num_agent_steps_sampled: 49000
    num_agent_steps_trained: 576048
    num_steps_sampled: 49000
    num_steps_trained: 576048
    num_target_updates: 96
  iterations_since_restore: 49
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.136842105263156
    ram_util_percent: 31.42105263157895
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04907498415723468
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.813680594678382
    mean_inference_ms: 1.575014202343309
    mean_raw_obs_processing_ms: 0.1419470820336464
  time_since_restore: 604.1501045227051
  time_this_iter_s: 12.971481323242188
  time_total_s: 604.1501045227051
  timers:
    learn_throughput: 4821.478
    learn_time_ms: 9.955
    update_time_ms: 2.765
  timestamp: 1629281280
  timesteps_since_restore: 0
  timesteps_total: 49000
  training_iteration: 49
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     49 |           604.15 | 49000 | -160.148 |               -119.5 |             -198.044 |            6167.71 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 50000
  custom_metrics: {}
  date: 2021-08-18_10-08-13
  done: false
  episode_len_mean: 6233.75
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -164.6146147872935
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 49888
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06881243735551834
          max_q: 4.276002883911133
          mean_q: 1.9353091716766357
          mean_td_error: -0.10109257698059082
          min_q: -0.637755811214447
        model: {}
        td_error: "[ 0.41682005 -0.10381174 -0.5872475  -0.10050988  0.4628566  -0.04904664\n\
          \ -0.16847157 -0.08265424 -0.4871807  -0.34698164  0.15086424 -0.44435525\n\
          \ -0.67843366 -0.7313324  -0.11493909  0.20118055 -0.08712721 -0.4493177\n\
          \ -0.15529966 -0.8786824   0.05430782 -0.47033262 -0.45489404  0.09470916\n\
          \ -0.37874413  0.9291889  -0.15869522  0.44563854  0.13947666 -0.01388443\n\
          \ -0.3804773  -0.4040923  -0.00946271  0.62168     0.20922035 -0.17033052\n\
          \  0.009727   -0.53124976 -0.09171796  0.03100514 -0.07442164  0.6538571\n\
          \ -0.12518036 -0.59008884 -0.07580996  0.05778551  0.19313836 -0.12912667]"
    num_agent_steps_sampled: 50000
    num_agent_steps_trained: 588048
    num_steps_sampled: 50000
    num_steps_trained: 588048
    num_target_updates: 98
  iterations_since_restore: 50
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.54736842105264
    ram_util_percent: 31.50526315789474
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049075396045146054
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.827525504976389
    mean_inference_ms: 1.5740631359547352
    mean_raw_obs_processing_ms: 0.1419616860315055
  time_since_restore: 617.6914901733398
  time_this_iter_s: 13.541385650634766
  time_total_s: 617.6914901733398
  timers:
    learn_throughput: 4912.717
    learn_time_ms: 9.771
    update_time_ms: 2.722
  timestamp: 1629281293
  timesteps_since_restore: 0
  timesteps_total: 50000
  training_iteration: 50
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     50 |          617.691 | 50000 | -164.615 |               -119.5 |             -198.044 |            6233.75 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 51000
  custom_metrics: {}
  date: 2021-08-18_10-08-24
  done: false
  episode_len_mean: 6233.75
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -164.6146147872935
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 8
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 50896
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08294899761676788
          max_q: 5.610738754272461
          mean_q: 2.4809088706970215
          mean_td_error: -0.11377229541540146
          min_q: 0.23905222117900848
        model: {}
        td_error: "[ 0.27576137 -0.72026515  0.26680255 -0.16575837 -0.14933896  0.25045806\n\
          \ -0.24599373 -0.35537148 -0.2062645  -0.39837456 -0.88854146 -0.53586936\n\
          \  0.36117554  0.1569655  -0.02547908 -0.22108984  0.18078065 -0.8116729\n\
          \ -0.2878189   0.2799083  -0.24644804  0.00203943  0.33739245  0.03888679\n\
          \ -1.3492022  -0.09742022  0.11269641 -0.11207485 -0.13913178 -0.7050445\n\
          \  0.12720287 -0.07187793  0.14811707  0.20520353  0.4328524  -0.46669388\n\
          \  0.2297548   0.00821233  0.37264812 -1.0475996  -0.41741514 -0.09031165\n\
          \ -0.0467875   0.16174221  0.0663861   0.67187643  0.24642348 -0.59251094]"
    num_agent_steps_sampled: 51000
    num_agent_steps_trained: 600048
    num_steps_sampled: 51000
    num_steps_trained: 600048
    num_target_updates: 100
  iterations_since_restore: 51
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.26470588235294
    ram_util_percent: 31.594117647058823
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049075396045146054
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.827525504976389
    mean_inference_ms: 1.5740631359547352
    mean_raw_obs_processing_ms: 0.1419616860315055
  time_since_restore: 628.8448152542114
  time_this_iter_s: 11.153325080871582
  time_total_s: 628.8448152542114
  timers:
    learn_throughput: 5262.326
    learn_time_ms: 9.121
    update_time_ms: 2.88
  timestamp: 1629281304
  timesteps_since_restore: 0
  timesteps_total: 51000
  training_iteration: 51
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     51 |          628.845 | 51000 | -164.615 |               -119.5 |             -198.044 |            6233.75 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 52000
  custom_metrics: {}
  date: 2021-08-18_10-08-38
  done: false
  episode_len_mean: 6233.75
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -164.6146147872935
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 8
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 51904
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0651305764913559
          max_q: 5.660904884338379
          mean_q: 2.512971878051758
          mean_td_error: -0.009163601323962212
          min_q: 0.6336513161659241
        model: {}
        td_error: "[ 6.4585149e-01 -1.1144948e-01  1.0089540e+00 -3.8680255e-01\n -8.2348597e-01\
          \ -5.5759192e-02  6.4433098e-02  7.3928356e-02\n  2.8467560e-01  1.9653428e-01\
          \ -4.2499137e-01 -2.7529514e-01\n -5.0182152e-01  3.8812852e-01 -9.2990398e-02\
          \  3.7823510e-01\n  8.3153725e-02 -1.7359698e-01  5.0695276e-01 -1.3481641e-01\n\
          \ -2.0185161e-01  2.7226853e-01 -1.1253357e-04  1.3045001e-01\n -6.7175746e-01\
          \ -3.9221787e-01  2.4278283e-02 -4.5202351e-01\n -7.5025493e-01 -6.6009521e-02\
          \  7.6965928e-02  1.0642914e+00\n -3.4817338e-02 -3.1637239e-01  8.0263925e-01\
          \ -1.0779929e-01\n -2.2761226e-02  1.7600584e-01  3.3575308e-01 -6.2855673e-01\n\
          \ -3.2877231e-01 -3.8508368e-01 -3.6692357e-01  7.7401042e-01\n -6.9672108e-02\
          \  1.1065030e-01  1.3960576e-01 -2.0162344e-01]"
    num_agent_steps_sampled: 52000
    num_agent_steps_trained: 612048
    num_steps_sampled: 52000
    num_steps_trained: 612048
    num_target_updates: 102
  iterations_since_restore: 52
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.77777777777777
    ram_util_percent: 31.600000000000005
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049075396045146054
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.827525504976389
    mean_inference_ms: 1.5740631359547352
    mean_raw_obs_processing_ms: 0.1419616860315055
  time_since_restore: 641.8445317745209
  time_this_iter_s: 12.999716520309448
  time_total_s: 641.8445317745209
  timers:
    learn_throughput: 3904.796
    learn_time_ms: 12.293
    update_time_ms: 6.213
  timestamp: 1629281318
  timesteps_since_restore: 0
  timesteps_total: 52000
  training_iteration: 52
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     52 |          641.845 | 52000 | -164.615 |               -119.5 |             -198.044 |            6233.75 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 53000
  custom_metrics: {}
  date: 2021-08-18_10-08-50
  done: false
  episode_len_mean: 6233.75
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -164.6146147872935
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 8
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 52912
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06063682958483696
          max_q: 6.030473709106445
          mean_q: 2.189589023590088
          mean_td_error: 0.041341304779052734
          min_q: -0.09156867861747742
        model: {}
        td_error: "[-0.29377508  0.2581265   0.3239467  -0.13622165 -0.16441584  0.05177158\n\
          \  0.15909457  0.7880851   0.18672252  0.33540392 -0.0026499  -0.39946198\n\
          \  0.52238154  0.2564987  -0.01151967  0.5753461  -0.5275328  -0.02143884\n\
          \ -0.23984516  0.1702404   0.36846387  0.12206244 -0.6656251   0.06285214\n\
          \  0.28582942 -0.32890165  0.43343472 -0.05394936 -0.15079856  0.37012482\n\
          \ -0.27296984  0.52306443  0.1266849   0.02471685 -0.624068   -0.2181201\n\
          \ -0.07928538 -0.15762186  0.17668235 -0.6641145   0.24333414  0.0614717\n\
          \  0.01128268 -0.06711829  0.5427878   0.6076653  -0.10755777 -0.41670132]"
    num_agent_steps_sampled: 53000
    num_agent_steps_trained: 624048
    num_steps_sampled: 53000
    num_steps_trained: 624048
    num_target_updates: 104
  iterations_since_restore: 53
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.14705882352941
    ram_util_percent: 31.60588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049075396045146054
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.827525504976389
    mean_inference_ms: 1.5740631359547352
    mean_raw_obs_processing_ms: 0.1419616860315055
  time_since_restore: 653.8109264373779
  time_this_iter_s: 11.966394662857056
  time_total_s: 653.8109264373779
  timers:
    learn_throughput: 5084.133
    learn_time_ms: 9.441
    update_time_ms: 2.701
  timestamp: 1629281330
  timesteps_since_restore: 0
  timesteps_total: 53000
  training_iteration: 53
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     53 |          653.811 | 53000 | -164.615 |               -119.5 |             -198.044 |            6233.75 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 54000
  custom_metrics: {}
  date: 2021-08-18_10-09-03
  done: false
  episode_len_mean: 6233.75
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -164.6146147872935
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 8
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 53920
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.059047143906354904
          max_q: 5.103323936462402
          mean_q: 2.322242021560669
          mean_td_error: 0.030072985216975212
          min_q: 0.6693313717842102
        model: {}
        td_error: "[ 0.566905   -0.60194135 -0.15006816  0.39868367 -0.50948715 -0.21740842\n\
          \  0.11345029  0.70891595 -0.0933013   0.2017951   0.27254403 -0.3666892\n\
          \ -0.13816011  0.07678819 -0.05446601 -0.42076874 -0.5277078   0.02787983\n\
          \ -0.13898611 -0.09599829  0.6406809   0.40306675  0.11926126 -0.71580267\n\
          \  0.05261898  0.42718518  0.14580679 -0.10946488 -0.19799578  0.27604097\n\
          \ -0.14256668  0.39692605 -0.38510227  0.1363194  -0.19445825 -0.25615048\n\
          \ -0.39966345  0.1569798   0.62982357  0.10584402 -0.21339673 -0.18278766\n\
          \  0.71044374  0.6338904   0.17149258 -0.20668578 -0.01190495  0.40112305]"
    num_agent_steps_sampled: 54000
    num_agent_steps_trained: 636048
    num_steps_sampled: 54000
    num_steps_trained: 636048
    num_target_updates: 106
  iterations_since_restore: 54
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.33157894736843
    ram_util_percent: 31.600000000000005
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049075396045146054
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.827525504976389
    mean_inference_ms: 1.5740631359547352
    mean_raw_obs_processing_ms: 0.1419616860315055
  time_since_restore: 666.6769335269928
  time_this_iter_s: 12.866007089614868
  time_total_s: 666.6769335269928
  timers:
    learn_throughput: 4602.329
    learn_time_ms: 10.43
    update_time_ms: 3.08
  timestamp: 1629281343
  timesteps_since_restore: 0
  timesteps_total: 54000
  training_iteration: 54
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     54 |          666.677 | 54000 | -164.615 |               -119.5 |             -198.044 |            6233.75 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 55000
  custom_metrics: {}
  date: 2021-08-18_10-09-16
  done: false
  episode_len_mean: 6233.75
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -164.6146147872935
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 8
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 54928
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05784107372164726
          max_q: 4.91623592376709
          mean_q: 2.0883498191833496
          mean_td_error: 0.06534978002309799
          min_q: -0.0860815942287445
        model: {}
        td_error: "[ 0.4858892   0.17522155  0.3067907   0.28067082  0.01143122 -0.09378707\n\
          \  0.52621174 -0.9392061  -0.35528862  0.34975243 -0.61558557  0.25856638\n\
          \  0.07066798  0.10647929 -0.03609967  0.48015356  0.11863136  0.23021889\n\
          \  0.5326725  -0.306391   -0.00883341  0.04897046  0.09384441 -0.0645811\n\
          \  0.03478819 -0.32629704  0.50548244 -0.13838434  0.07855564 -0.15370393\n\
          \  0.1318565   0.38154984 -0.521379    0.09406257  1.2537711  -0.06082809\n\
          \  0.02778992 -0.01742005  0.02341229 -1.060505    0.5092807  -0.01878488\n\
          \  0.06111658  0.3285843   0.00600958  0.33158374 -0.08787274  0.0977211 ]"
    num_agent_steps_sampled: 55000
    num_agent_steps_trained: 648048
    num_steps_sampled: 55000
    num_steps_trained: 648048
    num_target_updates: 108
  iterations_since_restore: 55
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.215
    ram_util_percent: 31.615000000000002
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049075396045146054
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.827525504976389
    mean_inference_ms: 1.5740631359547352
    mean_raw_obs_processing_ms: 0.1419616860315055
  time_since_restore: 680.3704364299774
  time_this_iter_s: 13.69350290298462
  time_total_s: 680.3704364299774
  timers:
    learn_throughput: 5053.454
    learn_time_ms: 9.498
    update_time_ms: 2.977
  timestamp: 1629281356
  timesteps_since_restore: 0
  timesteps_total: 55000
  training_iteration: 55
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     55 |           680.37 | 55000 | -164.615 |               -119.5 |             -198.044 |            6233.75 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 56000
  custom_metrics: {}
  date: 2021-08-18_10-09-30
  done: false
  episode_len_mean: 6233.75
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -164.6146147872935
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 8
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 55936
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06302408874034882
          max_q: 6.087388515472412
          mean_q: 2.5210556983947754
          mean_td_error: 0.11964055895805359
          min_q: -0.1985563337802887
        model: {}
        td_error: "[ 0.25786126 -0.08272564 -0.45468092 -0.08357739 -0.11675549  0.43351376\n\
          \  0.80642796 -0.03488421  0.22339225 -0.49062192 -0.5405786   0.3256365\n\
          \  0.3530407   0.15079069  0.22942102  0.42571902  0.00217962 -0.64783216\n\
          \  0.3918699  -0.1659286   0.02331173  0.17058992  0.18814707 -0.01388645\n\
          \  0.12579203  0.551826    0.12526798  1.2104882  -0.10406566  0.3678769\n\
          \ -0.5288458   0.61064243 -0.7185254   0.46863317  0.41359234 -0.03647184\n\
          \  0.28950346 -0.25239265 -0.14648533  0.7525803   0.31399322  0.25376463\n\
          \  0.20634508  0.02735567 -0.01919103  0.06277919  0.00917482  0.408679  ]"
    num_agent_steps_sampled: 56000
    num_agent_steps_trained: 660048
    num_steps_sampled: 56000
    num_steps_trained: 660048
    num_target_updates: 110
  iterations_since_restore: 56
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.305263157894736
    ram_util_percent: 31.600000000000005
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049075396045146054
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.827525504976389
    mean_inference_ms: 1.5740631359547352
    mean_raw_obs_processing_ms: 0.1419616860315055
  time_since_restore: 693.789065361023
  time_this_iter_s: 13.418628931045532
  time_total_s: 693.789065361023
  timers:
    learn_throughput: 4648.276
    learn_time_ms: 10.326
    update_time_ms: 3.098
  timestamp: 1629281370
  timesteps_since_restore: 0
  timesteps_total: 56000
  training_iteration: 56
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     56 |          693.789 | 56000 | -164.615 |               -119.5 |             -198.044 |            6233.75 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 57000
  custom_metrics: {}
  date: 2021-08-18_10-09-43
  done: false
  episode_len_mean: 6298.888888888889
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.4471029039169
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 56944
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06355978548526764
          max_q: 6.226449966430664
          mean_q: 2.0740318298339844
          mean_td_error: -0.0062888688407838345
          min_q: 0.016682222485542297
        model: {}
        td_error: "[ 0.64411867 -0.03033504  0.19266939  0.03625262  0.11797571  0.03598309\n\
          \  0.17025615 -0.10527784 -0.16628003  0.54654336 -0.12163901 -0.7158809\n\
          \  0.00666153 -0.74739563  0.0146054  -0.41513944  0.49374938 -0.82426023\n\
          \  0.25586128 -0.36828232  0.00334132 -0.00285554  0.3740368  -0.555511\n\
          \ -0.17309523 -0.0644393  -0.39316082  0.16597998  0.5293708   0.07954216\n\
          \ -0.84716785 -0.42786455 -0.25408244 -0.03869951 -0.22378772  0.47478014\n\
          \  0.24428272  1.1754034  -0.5127044   0.60963476  0.22955751  0.253541\n\
          \  0.2894249  -0.15998733 -0.03948748 -0.2883432   0.14363945  0.08659983]"
    num_agent_steps_sampled: 57000
    num_agent_steps_trained: 672048
    num_steps_sampled: 57000
    num_steps_trained: 672048
    num_target_updates: 112
  iterations_since_restore: 57
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.7421052631579
    ram_util_percent: 31.63157894736842
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049077966438922975
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8407162692832912
    mean_inference_ms: 1.573278194607783
    mean_raw_obs_processing_ms: 0.14199223370938632
  time_since_restore: 706.887120962143
  time_this_iter_s: 13.098055601119995
  time_total_s: 706.887120962143
  timers:
    learn_throughput: 3225.07
    learn_time_ms: 14.883
    update_time_ms: 4.314
  timestamp: 1629281383
  timesteps_since_restore: 0
  timesteps_total: 57000
  training_iteration: 57
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     57 |          706.887 | 57000 | -167.447 |               -119.5 |             -198.044 |            6298.89 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 58000
  custom_metrics: {}
  date: 2021-08-18_10-09-55
  done: false
  episode_len_mean: 6298.888888888889
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.4471029039169
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 9
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 57952
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04968443512916565
          max_q: 5.728682518005371
          mean_q: 2.04494309425354
          mean_td_error: 0.03506868705153465
          min_q: -0.7368834018707275
        model: {}
        td_error: "[-0.5846305   0.1206516   0.5189128   0.35778868  0.43656778 -0.00328135\n\
          \  0.25947094  0.3529718  -0.275342    0.32723472  0.89695036 -0.2708156\n\
          \ -0.01084447  0.17707121 -0.27961636  0.31680834  0.16028786  0.06837153\n\
          \  0.08637428 -0.07840204 -0.28112888 -0.08917999 -0.15048158 -0.10237503\n\
          \  0.0980444   0.17064762 -0.08265758 -0.9003191   0.01378335 -0.37213087\n\
          \  0.20384479  0.01621604 -0.43152905 -0.36694956 -0.0546174   0.44187617\n\
          \  0.06108189  0.32049     0.7702074  -0.858402    0.404418   -0.6451428\n\
          \  0.10127246  0.0272572   0.3467641   0.17503712  0.25280452  0.03793609]"
    num_agent_steps_sampled: 58000
    num_agent_steps_trained: 684048
    num_steps_sampled: 58000
    num_steps_trained: 684048
    num_target_updates: 114
  iterations_since_restore: 58
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.78125
    ram_util_percent: 31.606250000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049077966438922975
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8407162692832912
    mean_inference_ms: 1.573278194607783
    mean_raw_obs_processing_ms: 0.14199223370938632
  time_since_restore: 718.4355299472809
  time_this_iter_s: 11.54840898513794
  time_total_s: 718.4355299472809
  timers:
    learn_throughput: 5042.746
    learn_time_ms: 9.519
    update_time_ms: 2.708
  timestamp: 1629281395
  timesteps_since_restore: 0
  timesteps_total: 58000
  training_iteration: 58
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     58 |          718.436 | 58000 | -167.447 |               -119.5 |             -198.044 |            6298.89 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 59000
  custom_metrics: {}
  date: 2021-08-18_10-10-07
  done: false
  episode_len_mean: 6298.888888888889
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.4471029039169
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 9
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 58960
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06394258141517639
          max_q: 4.664446830749512
          mean_q: 2.2503011226654053
          mean_td_error: 0.08938251435756683
          min_q: 0.5031753778457642
        model: {}
        td_error: "[ 0.7661545  -0.04878902 -0.08776951  0.23839462 -0.03659081  0.57713753\n\
          \ -0.24962068 -0.13439274  0.11427307  0.34572768 -0.49345827 -0.38246572\n\
          \ -0.2803862  -0.02214527  0.3472929  -0.16269708  0.25822735 -0.02207375\n\
          \  0.02798182  0.02343369 -0.20131433 -0.3523283   0.10833383  0.17387879\n\
          \  0.26033115 -0.82486534  0.0021351   0.5362356   0.04286557  0.3196112\n\
          \  0.26567912 -0.00636983 -0.11937618  0.62125576 -0.16946149  0.12027836\n\
          \  0.33327937 -0.1884501   0.4966538   0.01444983  0.29223308  0.20008636\n\
          \ -0.13579547  0.35899997  0.4335935   0.4476676   0.1892705   0.2932489 ]"
    num_agent_steps_sampled: 59000
    num_agent_steps_trained: 696048
    num_steps_sampled: 59000
    num_steps_trained: 696048
    num_target_updates: 116
  iterations_since_restore: 59
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.900000000000006
    ram_util_percent: 31.600000000000005
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049077966438922975
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8407162692832912
    mean_inference_ms: 1.573278194607783
    mean_raw_obs_processing_ms: 0.14199223370938632
  time_since_restore: 730.5285203456879
  time_this_iter_s: 12.092990398406982
  time_total_s: 730.5285203456879
  timers:
    learn_throughput: 5066.936
    learn_time_ms: 9.473
    update_time_ms: 2.615
  timestamp: 1629281407
  timesteps_since_restore: 0
  timesteps_total: 59000
  training_iteration: 59
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     59 |          730.529 | 59000 | -167.447 |               -119.5 |             -198.044 |            6298.89 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 60000
  custom_metrics: {}
  date: 2021-08-18_10-10-20
  done: false
  episode_len_mean: 6298.888888888889
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.4471029039169
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 9
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 59968
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07571335881948471
          max_q: 5.3012285232543945
          mean_q: 1.9639594554901123
          mean_td_error: -0.023300211876630783
          min_q: -1.1921133995056152
        model: {}
        td_error: "[ 2.5902629e-02  2.5349665e-01  4.9329197e-01  1.4394671e-02\n -2.3672363e-01\
          \ -5.0895834e-01 -5.9203291e-01  5.7229066e-01\n -4.4609547e-02 -3.8603425e-02\
          \ -1.0028818e+00 -1.2877131e-01\n -3.2442570e-01  1.5026259e-01 -2.8895187e-01\
          \ -2.4110961e-01\n  1.2768507e-03  5.9789783e-01 -1.8315053e-01  4.0231115e-01\n\
          \  2.2929549e-02 -1.5076113e-01  1.1448622e+00  2.0620763e-01\n -9.8903656e-02\
          \  1.1877608e-01 -2.6668942e-01  5.8815795e-01\n  5.2738070e-02 -1.0093343e+00\
          \ -1.0643065e-01 -3.6004257e-01\n -4.1042018e-01  1.9857156e-01 -3.1326771e-02\
          \ -1.2987387e-01\n  5.8627248e-02  2.9088330e-01  7.1858311e-01  4.9440885e-01\n\
          \  1.3517165e-01  6.7080855e-01 -1.2633228e-01  1.6836166e-02\n -3.4868312e-01\
          \ -1.0197401e-02  5.5241823e-02 -1.7631247e+00]"
    num_agent_steps_sampled: 60000
    num_agent_steps_trained: 708048
    num_steps_sampled: 60000
    num_steps_trained: 708048
    num_target_updates: 118
  iterations_since_restore: 60
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.72222222222222
    ram_util_percent: 31.60555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049077966438922975
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8407162692832912
    mean_inference_ms: 1.573278194607783
    mean_raw_obs_processing_ms: 0.14199223370938632
  time_since_restore: 743.0115010738373
  time_this_iter_s: 12.482980728149414
  time_total_s: 743.0115010738373
  timers:
    learn_throughput: 5146.464
    learn_time_ms: 9.327
    update_time_ms: 2.829
  timestamp: 1629281420
  timesteps_since_restore: 0
  timesteps_total: 60000
  training_iteration: 60
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     60 |          743.012 | 60000 | -167.447 |               -119.5 |             -198.044 |            6298.89 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 61000
  custom_metrics: {}
  date: 2021-08-18_10-10-34
  done: false
  episode_len_mean: 6298.888888888889
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.4471029039169
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 9
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 60976
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.059777483344078064
          max_q: 7.132004261016846
          mean_q: 2.0039353370666504
          mean_td_error: 0.09013301134109497
          min_q: -1.4145784378051758
        model: {}
        td_error: "[-0.37450695  0.5796019   0.79248786  0.01831585  0.04887581 -0.02304554\n\
          \ -0.06659198 -0.516026    0.31758595 -0.25136733  0.3092332   1.3321176\n\
          \  1.3633478  -0.5070965  -0.20218539 -0.44454622 -0.05563855 -0.48151731\n\
          \  0.2857092  -0.06804633 -0.30703998  0.41856885  0.06207883 -0.11604929\n\
          \  0.23669839  0.36221647  0.14719856  0.325274   -0.2615428   0.11975861\n\
          \ -0.69786084 -0.21387398 -0.26766482  0.46347272  0.09979981  0.4223547\n\
          \  0.56885624  0.22127247 -0.02777767  0.2933917   0.2731965   0.04701853\n\
          \  0.04272664  0.23460603 -0.23822045  0.6069049  -0.22491455 -0.32077205]"
    num_agent_steps_sampled: 61000
    num_agent_steps_trained: 720048
    num_steps_sampled: 61000
    num_steps_trained: 720048
    num_target_updates: 120
  iterations_since_restore: 61
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.83500000000001
    ram_util_percent: 31.605000000000008
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049077966438922975
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8407162692832912
    mean_inference_ms: 1.573278194607783
    mean_raw_obs_processing_ms: 0.14199223370938632
  time_since_restore: 757.1045980453491
  time_this_iter_s: 14.09309697151184
  time_total_s: 757.1045980453491
  timers:
    learn_throughput: 4343.307
    learn_time_ms: 11.051
    update_time_ms: 3.28
  timestamp: 1629281434
  timesteps_since_restore: 0
  timesteps_total: 61000
  training_iteration: 61
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     61 |          757.105 | 61000 | -167.447 |               -119.5 |             -198.044 |            6298.89 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 62000
  custom_metrics: {}
  date: 2021-08-18_10-10-48
  done: false
  episode_len_mean: 6298.888888888889
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.4471029039169
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 9
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 61984
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06562869995832443
          max_q: 6.8616838455200195
          mean_q: 1.924092173576355
          mean_td_error: -0.09248951077461243
          min_q: -0.49924376606941223
        model: {}
        td_error: "[-0.45087004 -0.87271523 -0.3604071  -0.6648023  -0.18234217  0.23255503\n\
          \  0.17086846 -0.1273284   0.36947986 -0.0942874  -2.0383973   0.5153848\n\
          \  0.1638031   0.31288862 -0.36341965  0.36182404  0.16378117  0.58176684\n\
          \  0.01877189  0.18536472  0.47004712 -0.27154136 -0.0238812  -0.5378034\n\
          \  0.01441622 -0.96856856 -1.0437015  -0.15186629  0.16397226 -0.42396033\n\
          \  0.27411997 -0.66830015 -0.03358281  0.37816286 -0.80747867  0.00258791\n\
          \  0.01278996  0.5359999  -0.75125444 -0.32138348  0.4951719   0.26285982\n\
          \  0.10740256 -0.25785184  0.04094791  0.80917835  0.25101197  0.08108974]"
    num_agent_steps_sampled: 62000
    num_agent_steps_trained: 732048
    num_steps_sampled: 62000
    num_steps_trained: 732048
    num_target_updates: 122
  iterations_since_restore: 62
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.11500000000001
    ram_util_percent: 31.605000000000008
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049077966438922975
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8407162692832912
    mean_inference_ms: 1.573278194607783
    mean_raw_obs_processing_ms: 0.14199223370938632
  time_since_restore: 771.2978262901306
  time_this_iter_s: 14.193228244781494
  time_total_s: 771.2978262901306
  timers:
    learn_throughput: 4820.935
    learn_time_ms: 9.957
    update_time_ms: 2.935
  timestamp: 1629281448
  timesteps_since_restore: 0
  timesteps_total: 62000
  training_iteration: 62
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     62 |          771.298 | 62000 | -167.447 |               -119.5 |             -198.044 |            6298.89 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 63000
  custom_metrics: {}
  date: 2021-08-18_10-11-04
  done: false
  episode_len_mean: 6298.888888888889
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.4471029039169
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 9
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 62992
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0988338366150856
          max_q: 5.847373962402344
          mean_q: 2.578922986984253
          mean_td_error: 0.10800223797559738
          min_q: 0.1378437727689743
        model: {}
        td_error: "[ 0.7550667   0.37732196  0.2943871   1.0266156   0.6743598   0.27926743\n\
          \ -1.0169327  -0.16393161  0.24076533  0.37902737 -0.17012715  0.10883546\n\
          \ -0.661103   -0.07116759 -0.38826442  0.16698003  1.0752258  -0.39772177\n\
          \  0.83846617  0.26175594  0.21601939 -0.62048984  0.36770332  1.7136214\n\
          \ -0.24702227  0.5911565  -1.233913   -0.26012903  0.27808237  0.05273008\n\
          \ -0.3987112  -0.73362756  0.12744391 -0.7604518   0.04733586  0.2225473\n\
          \  0.727458    0.7258475   0.80669504  0.6881361   0.24793231  0.08488107\n\
          \ -0.04663169 -0.3967762  -0.4644133   0.63844824 -0.35044146 -0.44815016]"
    num_agent_steps_sampled: 63000
    num_agent_steps_trained: 744048
    num_steps_sampled: 63000
    num_steps_trained: 744048
    num_target_updates: 124
  iterations_since_restore: 63
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.059090909090905
    ram_util_percent: 31.668181818181832
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049077966438922975
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8407162692832912
    mean_inference_ms: 1.573278194607783
    mean_raw_obs_processing_ms: 0.14199223370938632
  time_since_restore: 786.3665630817413
  time_this_iter_s: 15.068736791610718
  time_total_s: 786.3665630817413
  timers:
    learn_throughput: 4922.603
    learn_time_ms: 9.751
    update_time_ms: 2.863
  timestamp: 1629281464
  timesteps_since_restore: 0
  timesteps_total: 63000
  training_iteration: 63
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     63 |          786.367 | 63000 | -167.447 |               -119.5 |             -198.044 |            6298.89 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 64000
  custom_metrics: {}
  date: 2021-08-18_10-11-16
  done: false
  episode_len_mean: 6339.4
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -168.71965335356825
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 64000
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05751416087150574
          max_q: 5.619146347045898
          mean_q: 2.0476574897766113
          mean_td_error: -0.06601717323064804
          min_q: -0.9974396228790283
        model: {}
        td_error: "[ 0.35767674  0.37158358 -0.4614296  -0.02730155 -0.202281    0.0316968\n\
          \ -0.5327034  -0.47590566  0.04687321  0.40457237 -0.3778615  -0.89158964\n\
          \ -0.02293587  0.04278076 -0.01470885 -0.7324635   0.17510664 -0.19234061\n\
          \  0.18077111 -0.35912     0.0544737   0.03461254 -0.16143441 -0.66242015\n\
          \  0.07716441 -0.21758461  0.49209303  0.12536383  0.17509604 -0.14473224\n\
          \ -0.4646654   0.1447354   0.15966249 -0.22773242 -0.4678434   0.41015375\n\
          \  0.25669384 -0.32446933  0.07226729 -0.77139187  0.16155404  0.01101434\n\
          \  0.14592195 -0.04193377 -0.4807868   0.33398032  0.18319178  0.63777137]"
    num_agent_steps_sampled: 64000
    num_agent_steps_trained: 756048
    num_steps_sampled: 64000
    num_steps_trained: 756048
    num_target_updates: 126
  iterations_since_restore: 64
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.96666666666666
    ram_util_percent: 31.65555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04909081508161232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.855875399728673
    mean_inference_ms: 1.5731786074599383
    mean_raw_obs_processing_ms: 0.14206200970445876
  time_since_restore: 798.7230064868927
  time_this_iter_s: 12.356443405151367
  time_total_s: 798.7230064868927
  timers:
    learn_throughput: 4990.075
    learn_time_ms: 9.619
    update_time_ms: 2.788
  timestamp: 1629281476
  timesteps_since_restore: 0
  timesteps_total: 64000
  training_iteration: 64
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     64 |          798.723 | 64000 |  -168.72 |               -119.5 |             -198.044 |             6339.4 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 65000
  custom_metrics: {}
  date: 2021-08-18_10-11-28
  done: false
  episode_len_mean: 6339.4
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -168.71965335356825
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 10
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 64504
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06520210951566696
          max_q: 5.871379375457764
          mean_q: 1.918688178062439
          mean_td_error: -0.08479966968297958
          min_q: -1.3889590501785278
        model: {}
        td_error: "[ 0.01362681 -0.43382496  0.18013334  0.566589   -0.24226734 -0.38365638\n\
          \  0.19668078 -0.5963243  -0.33951378 -0.04593754 -0.31608033  0.3118043\n\
          \ -0.44675994  0.10911512 -0.35199928 -0.22737789  0.54619455  0.16618454\n\
          \  0.2553742   0.22937018 -0.6183109  -0.23485172  0.23515105 -0.3480549\n\
          \  0.18384242  0.05939651 -0.13320947  0.05887115  0.56440604  0.05957294\n\
          \ -0.300771   -0.47191417 -0.11084318  0.4503262  -0.37610316 -0.75191736\n\
          \  0.02666759  0.3702979  -0.8127296  -0.54258466 -0.35359097 -0.04984763\n\
          \  0.17727089 -0.09874704 -0.1163497  -0.31608033  0.1273303   0.06105804]"
    num_agent_steps_sampled: 65000
    num_agent_steps_trained: 768048
    num_steps_sampled: 65000
    num_steps_trained: 768048
    num_target_updates: 127
  iterations_since_restore: 65
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.39411764705882
    ram_util_percent: 31.60588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04909081508161232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.855875399728673
    mean_inference_ms: 1.5731786074599383
    mean_raw_obs_processing_ms: 0.14206200970445876
  time_since_restore: 810.2840106487274
  time_this_iter_s: 11.561004161834717
  time_total_s: 810.2840106487274
  timers:
    learn_throughput: 4887.339
    learn_time_ms: 9.821
    update_time_ms: 3.484
  timestamp: 1629281488
  timesteps_since_restore: 0
  timesteps_total: 65000
  training_iteration: 65
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     65 |          810.284 | 65000 |  -168.72 |               -119.5 |             -198.044 |             6339.4 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 66000
  custom_metrics: {}
  date: 2021-08-18_10-11-40
  done: false
  episode_len_mean: 6339.4
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -168.71965335356825
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 10
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 65512
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.084830641746521
          max_q: 5.707250118255615
          mean_q: 2.12868332862854
          mean_td_error: 0.15706996619701385
          min_q: -0.3408069312572479
        model: {}
        td_error: "[ 0.06804895  0.13341784  0.05776858  0.09552431  1.3710667   0.17324662\n\
          \  0.4788803   0.27023268 -0.410882    0.37199426 -0.58821726 -0.03059411\n\
          \ -0.11731398 -0.5367943   0.3389296   0.17162561  0.2773497   0.34444618\n\
          \  0.5561366  -0.42163944  0.07054257  0.00791824 -0.18790066  0.08442807\n\
          \  0.850279    0.37141895  0.03629088  0.73177105  0.46833682 -0.35030925\n\
          \  0.33692396 -0.0422326   0.24860543 -0.30905855  0.5713489   0.36154985\n\
          \  0.02765775 -0.03727603  0.3797785   0.21141428  0.2836218  -0.34572017\n\
          \  0.10154414 -0.22578695  0.3950733   0.51324797  0.26220673  0.1204567 ]"
    num_agent_steps_sampled: 66000
    num_agent_steps_trained: 780048
    num_steps_sampled: 66000
    num_steps_trained: 780048
    num_target_updates: 129
  iterations_since_restore: 66
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.8235294117647
    ram_util_percent: 31.60588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04909081508161232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.855875399728673
    mean_inference_ms: 1.5731786074599383
    mean_raw_obs_processing_ms: 0.14206200970445876
  time_since_restore: 822.4845805168152
  time_this_iter_s: 12.200569868087769
  time_total_s: 822.4845805168152
  timers:
    learn_throughput: 4122.917
    learn_time_ms: 11.642
    update_time_ms: 3.515
  timestamp: 1629281500
  timesteps_since_restore: 0
  timesteps_total: 66000
  training_iteration: 66
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     66 |          822.485 | 66000 |  -168.72 |               -119.5 |             -198.044 |             6339.4 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 67000
  custom_metrics: {}
  date: 2021-08-18_10-11-53
  done: false
  episode_len_mean: 6339.4
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -168.71965335356825
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 10
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 66520
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07500189542770386
          max_q: 5.533170700073242
          mean_q: 1.9747356176376343
          mean_td_error: 0.040482282638549805
          min_q: -0.47761571407318115
        model: {}
        td_error: "[-0.595801   -0.3372047   0.04488063 -0.55356026  1.5966289   0.06101573\n\
          \  0.34211516  0.89934814  0.17490268  0.2871722   0.4407344   0.03527188\n\
          \ -0.8162172   0.46856976 -0.16883314  0.55146575  0.14479601 -0.3457799\n\
          \ -0.03494668 -0.00741804 -0.00597501  0.1785891  -0.13927722  0.24036765\n\
          \ -0.4931178   0.4305663  -0.22731686 -0.27326512 -0.15958309  0.09623909\n\
          \ -0.5407069   0.11298919  0.09660983 -0.00223875 -0.10189271  0.3494974\n\
          \ -0.24495459  0.04808885  0.01033151 -0.2881372   0.15541208 -0.30359417\n\
          \  0.36511493 -0.08739376  0.15269458 -0.20305723  0.10734105  0.48267794]"
    num_agent_steps_sampled: 67000
    num_agent_steps_trained: 792048
    num_steps_sampled: 67000
    num_steps_trained: 792048
    num_target_updates: 131
  iterations_since_restore: 67
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.90526315789473
    ram_util_percent: 31.605263157894743
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04909081508161232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.855875399728673
    mean_inference_ms: 1.5731786074599383
    mean_raw_obs_processing_ms: 0.14206200970445876
  time_since_restore: 835.6402246952057
  time_this_iter_s: 13.155644178390503
  time_total_s: 835.6402246952057
  timers:
    learn_throughput: 5035.028
    learn_time_ms: 9.533
    update_time_ms: 2.913
  timestamp: 1629281513
  timesteps_since_restore: 0
  timesteps_total: 67000
  training_iteration: 67
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     67 |           835.64 | 67000 |  -168.72 |               -119.5 |             -198.044 |             6339.4 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 68000
  custom_metrics: {}
  date: 2021-08-18_10-12-05
  done: false
  episode_len_mean: 6116.272727272727
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.13894187379776
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 67528
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04384082928299904
          max_q: 42.98937225341797
          mean_q: 24.14612579345703
          mean_td_error: -3929675.0
          min_q: 0.2456335425376892
        model: {}
        td_error: "[-7.25478450e+06 -7.25478450e+06  5.27726412e-01 -7.25478450e+06\n\
          \  5.15700936e-01 -1.54206753e-01  6.95081890e-01  5.33276737e-01\n -3.27214688e-01\
          \ -5.54035664e-01 -7.25478450e+06 -7.25478450e+06\n -7.25478450e+06 -7.25478450e+06\
          \ -3.77458572e-01 -7.25478450e+06\n -7.25478450e+06  1.66101217e-01 -7.25478450e+06\
          \ -7.25478450e+06\n -7.25478450e+06 -7.25478450e+06 -7.25478450e+06 -7.25478450e+06\n\
          \ -7.25478450e+06  3.36944401e-01 -1.02576196e-01 -4.17315245e-01\n -7.25478450e+06\
          \ -7.25478450e+06 -7.25478450e+06 -5.25825977e-01\n  5.98213673e-02 -4.36631203e-01\
          \  4.18019295e-02  1.45448685e-01\n -8.15866947e-01 -7.25478450e+06 -7.25478450e+06\
          \ -7.25478450e+06\n -7.25478450e+06 -4.57586169e-01 -7.25478450e+06 -1.31644011e-01\n\
          \ -7.25478450e+06 -7.25478450e+06 -1.20107174e-01  6.84294105e-02]"
    num_agent_steps_sampled: 68000
    num_agent_steps_trained: 804048
    num_steps_sampled: 68000
    num_steps_trained: 804048
    num_target_updates: 133
  iterations_since_restore: 68
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.14117647058823
    ram_util_percent: 31.641176470588235
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04910874260680402
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.864699328242327
    mean_inference_ms: 1.573283633584622
    mean_raw_obs_processing_ms: 0.14213146395839338
  time_since_restore: 847.2018179893494
  time_this_iter_s: 11.561593294143677
  time_total_s: 847.2018179893494
  timers:
    learn_throughput: 5094.0
    learn_time_ms: 9.423
    update_time_ms: 2.79
  timestamp: 1629281525
  timesteps_since_restore: 0
  timesteps_total: 68000
  training_iteration: 68
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 4.9/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     68 |          847.202 | 68000 | -167.139 |               -119.5 |             -198.044 |            6116.27 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 69000
  custom_metrics: {}
  date: 2021-08-18_10-12-16
  done: false
  episode_len_mean: 6116.272727272727
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.13894187379776
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 11
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 68536
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.393206924200058
          max_q: 9575.072265625
          mean_q: 3990.630615234375
          mean_td_error: -3018873.75
          min_q: 0.2222454845905304
        model: {}
        td_error: "[-4.4715667e-01 -5.3622317e-01 -7.2452540e+06  1.5994236e-02\n -7.2452540e+06\
          \ -7.2452540e+06 -7.2452540e+06 -7.2452540e+06\n -7.2452540e+06  7.3632240e-01\
          \ -1.0443413e+00 -1.2084532e-01\n -3.0322409e-01 -7.2452540e+06  1.1386757e+00\
          \ -2.0209241e-01\n  1.3896635e+00 -7.2452540e+06 -7.2452540e+06 -1.7436866e+00\n\
          \ -1.3826102e+00 -7.2452540e+06 -7.2452540e+06 -2.3111737e-01\n -7.2452540e+06\
          \  5.0544155e-01 -3.5753670e+00 -7.2452540e+06\n -1.4339082e+00 -7.2452540e+06\
          \ -4.9692255e-01  7.1242893e-01\n -7.2452540e+06 -7.2452540e+06  6.6030169e-01\
          \ -5.7237864e-01\n -7.2452540e+06  4.6369445e-01 -4.5374227e-01 -8.5087933e+02\n\
          \ -7.2452540e+06 -7.2452540e+06  4.4884694e-01 -1.7651258e+00\n -7.2452540e+06\
          \  8.0273747e-01 -8.3558935e-01 -4.7518301e-01]"
    num_agent_steps_sampled: 69000
    num_agent_steps_trained: 816048
    num_steps_sampled: 69000
    num_steps_trained: 816048
    num_target_updates: 135
  iterations_since_restore: 69
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.5625
    ram_util_percent: 31.6125
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04910874260680402
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.864699328242327
    mean_inference_ms: 1.573283633584622
    mean_raw_obs_processing_ms: 0.14213146395839338
  time_since_restore: 858.5378959178925
  time_this_iter_s: 11.33607792854309
  time_total_s: 858.5378959178925
  timers:
    learn_throughput: 4921.207
    learn_time_ms: 9.754
    update_time_ms: 3.154
  timestamp: 1629281536
  timesteps_since_restore: 0
  timesteps_total: 69000
  training_iteration: 69
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     69 |          858.538 | 69000 | -167.139 |               -119.5 |             -198.044 |            6116.27 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 70000
  custom_metrics: {}
  date: 2021-08-18_10-12-29
  done: false
  episode_len_mean: 6116.272727272727
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.13894187379776
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 11
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 69544
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.7030587196350098
          max_q: 31205.83984375
          mean_q: 12353.517578125
          mean_td_error: -2859350.0
          min_q: 1.2300673723220825
        model: {}
        td_error: "[ 7.35989928e-01 -7.22362050e+06  1.41549826e-01  6.13665581e-03\n\
          \  6.15957022e-01 -7.22362050e+06 -7.22362050e+06  8.95965099e-02\n -7.22362050e+06\
          \  1.26570940e-01  4.75572944e-01  2.75335789e-01\n  1.15569353e-01 -5.19774675e-01\
          \ -1.04591560e+00 -7.22362050e+06\n  1.00221515e-01 -1.01417065e-01 -7.22362050e+06\
          \ -7.68348813e-01\n -7.22362050e+06 -7.01465607e-02 -1.70523763e-01 -7.22362050e+06\n\
          \ -7.22362050e+06 -7.22362050e+06  4.85317469e-01  4.92578387e-01\n -7.22362050e+06\
          \ -7.22362050e+06 -7.22362050e+06  1.24006033e-01\n -7.22362050e+06  1.31394386e-01\
          \ -7.22362050e+06 -3.49895239e-01\n -7.22362050e+06 -2.65818834e-01 -8.75517488e-01\
          \  4.11031842e-01\n  3.16892385e-01 -7.22362050e+06 -7.22362050e+06 -1.12307549e-01\n\
          \ -8.72219920e-01 -1.34390116e-01  4.91743088e-01 -7.22362050e+06]"
    num_agent_steps_sampled: 70000
    num_agent_steps_trained: 828048
    num_steps_sampled: 70000
    num_steps_trained: 828048
    num_target_updates: 137
  iterations_since_restore: 70
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.205555555555556
    ram_util_percent: 31.700000000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04910874260680402
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.864699328242327
    mean_inference_ms: 1.573283633584622
    mean_raw_obs_processing_ms: 0.14213146395839338
  time_since_restore: 870.9351863861084
  time_this_iter_s: 12.397290468215942
  time_total_s: 870.9351863861084
  timers:
    learn_throughput: 4875.916
    learn_time_ms: 9.844
    update_time_ms: 2.822
  timestamp: 1629281549
  timesteps_since_restore: 0
  timesteps_total: 70000
  training_iteration: 70
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     70 |          870.935 | 70000 | -167.139 |               -119.5 |             -198.044 |            6116.27 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 71000
  custom_metrics: {}
  date: 2021-08-18_10-12-42
  done: false
  episode_len_mean: 6116.272727272727
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.13894187379776
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 11
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 70552
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.8779899477958679
          max_q: 56909.83203125
          mean_q: 20157.234375
          mean_td_error: -2549998.5
          min_q: 1.2417564392089844
        model: {}
        td_error: "[ 3.3338320e-01 -7.8696847e-02 -7.1979170e+06  3.2138705e-02\n -2.3128438e-01\
          \ -4.6451044e-01 -7.1979170e+06 -5.6527019e-02\n -7.1979170e+06 -1.4206886e-02\
          \ -2.2433853e-01  3.9854538e-01\n -1.9342589e-01 -7.1979170e+06  9.7468615e-02\
          \ -7.1979170e+06\n -7.1979170e+06 -1.8309672e+03  1.0114384e-01 -7.1979170e+06\n\
          \ -7.1979170e+06 -7.1979170e+06 -3.1950259e-01 -1.7471879e+04\n  2.0804250e-01\
          \  5.7640076e-03 -3.9900053e-01 -7.1979170e+06\n  4.3603504e-01 -5.3106904e-02\
          \ -7.1979170e+06  6.9456339e-02\n -7.1979170e+06  4.5125270e-01 -7.1979170e+06\
          \  1.0098410e-01\n -2.5185430e-01 -7.1979170e+06 -8.0140488e+03 -8.0128833e+03\n\
          \ -7.1979170e+06 -3.3947706e-01  2.5268281e-01  2.1423221e-01\n -7.1979170e+06\
          \ -7.1979170e+06 -2.6433849e-01 -1.8316150e-02]"
    num_agent_steps_sampled: 71000
    num_agent_steps_trained: 840048
    num_steps_sampled: 71000
    num_steps_trained: 840048
    num_target_updates: 139
  iterations_since_restore: 71
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.02631578947368
    ram_util_percent: 31.700000000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04910874260680402
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.864699328242327
    mean_inference_ms: 1.573283633584622
    mean_raw_obs_processing_ms: 0.14213146395839338
  time_since_restore: 883.9068303108215
  time_this_iter_s: 12.971643924713135
  time_total_s: 883.9068303108215
  timers:
    learn_throughput: 4914.372
    learn_time_ms: 9.767
    update_time_ms: 2.95
  timestamp: 1629281562
  timesteps_since_restore: 0
  timesteps_total: 71000
  training_iteration: 71
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     71 |          883.907 | 71000 | -167.139 |               -119.5 |             -198.044 |            6116.27 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 72000
  custom_metrics: {}
  date: 2021-08-18_10-12-56
  done: false
  episode_len_mean: 6116.272727272727
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.13894187379776
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 11
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 71560
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.9329811334609985
          max_q: 86684.4453125
          mean_q: 23488.01953125
          mean_td_error: -1942640.75
          min_q: 1.3099944591522217
        model: {}
        td_error: "[-7.1681455e+06  7.7064991e-02 -2.0741596e+04 -1.6503574e+03\n -1.6503574e+03\
          \ -1.1822224e-01 -1.7260838e-01 -7.1681455e+06\n  1.1398363e-01  4.0378928e-02\
          \  1.6073167e-01 -2.0741596e+04\n  7.4235404e-01  2.3525524e-01  3.7252307e-01\
          \  2.9104710e-02\n -1.0414124e-02 -7.1681455e+06 -7.1681455e+06 -5.0195336e-02\n\
          \ -7.1681455e+06 -1.2389779e-01  4.0727942e+02 -7.1681455e+06\n -7.1681455e+06\
          \ -1.6493096e+04 -9.6492290e-02  2.5958252e-01\n  2.5895047e-01  2.0298278e-01\
          \ -7.1681455e+06 -7.1681455e+06\n -4.7274590e-02 -7.1681455e+06 -2.2185183e-01\
          \ -7.1681455e+06\n -7.1681455e+06  2.5197268e-02  3.1491113e-01  1.7912591e-01\n\
          \  2.8440475e-02 -3.0031168e-01  7.0362234e-01  3.4149468e-01\n  8.9136720e-01\
          \  6.7678547e-01  3.7846136e-01 -7.1681455e+06]"
    num_agent_steps_sampled: 72000
    num_agent_steps_trained: 852048
    num_steps_sampled: 72000
    num_steps_trained: 852048
    num_target_updates: 141
  iterations_since_restore: 72
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.152631578947364
    ram_util_percent: 31.700000000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04910874260680402
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.864699328242327
    mean_inference_ms: 1.573283633584622
    mean_raw_obs_processing_ms: 0.14213146395839338
  time_since_restore: 897.1746249198914
  time_this_iter_s: 13.267794609069824
  time_total_s: 897.1746249198914
  timers:
    learn_throughput: 4834.491
    learn_time_ms: 9.929
    update_time_ms: 2.891
  timestamp: 1629281576
  timesteps_since_restore: 0
  timesteps_total: 72000
  training_iteration: 72
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     72 |          897.175 | 72000 | -167.139 |               -119.5 |             -198.044 |            6116.27 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 73000
  custom_metrics: {}
  date: 2021-08-18_10-13-09
  done: false
  episode_len_mean: 6116.272727272727
  episode_media: {}
  episode_reward_max: -119.5001711257318
  episode_reward_mean: -167.13894187379776
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 11
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 72568
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 1.885765790939331
          max_q: 123036.984375
          mean_q: 61520.33984375
          mean_td_error: -3566049.75
          min_q: 1.507855772972107
        model: {}
        td_error: "[-7.1317930e+06 -2.6105285e-02 -8.1908596e-01 -7.1317930e+06\n -7.1026802e-02\
          \ -7.1317930e+06  1.7360425e-01 -7.1317930e+06\n -7.1317930e+06  1.7343307e-01\
          \ -7.1317930e+06 -5.7600617e-02\n -7.1317930e+06 -1.5831661e-01 -7.1317930e+06\
          \  4.7834754e-02\n -7.1317930e+06  8.3603621e-02 -7.1317930e+06 -7.3432246e+03\n\
          \  4.2776918e-01 -7.1317930e+06 -1.0983837e-01  7.2825122e-01\n -9.4845176e-02\
          \ -7.1317930e+06 -2.5523150e-01 -7.1317930e+06\n  2.7925801e-01 -7.1317930e+06\
          \  4.7134316e-01 -7.1317930e+06\n -7.1317930e+06 -7.1317930e+06 -7.1317930e+06\
          \  2.5830841e-01\n -7.1317930e+06 -7.1317930e+06 -2.6493907e-02 -7.1317930e+06\n\
          \ -3.5126085e+00 -7.1317930e+06 -4.2086363e-01  3.9856541e-01\n -3.4729946e-01\
          \ -1.9814801e-01 -7.1317930e+06 -7.1317930e+06]"
    num_agent_steps_sampled: 73000
    num_agent_steps_trained: 864048
    num_steps_sampled: 73000
    num_steps_trained: 864048
    num_target_updates: 143
  iterations_since_restore: 73
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.378947368421066
    ram_util_percent: 31.700000000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04910874260680402
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.864699328242327
    mean_inference_ms: 1.573283633584622
    mean_raw_obs_processing_ms: 0.14213146395839338
  time_since_restore: 910.5117795467377
  time_this_iter_s: 13.337154626846313
  time_total_s: 910.5117795467377
  timers:
    learn_throughput: 4901.916
    learn_time_ms: 9.792
    update_time_ms: 2.845
  timestamp: 1629281589
  timesteps_since_restore: 0
  timesteps_total: 73000
  training_iteration: 73
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     73 |          910.512 | 73000 | -167.139 |               -119.5 |             -198.044 |            6116.27 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 74000
  custom_metrics: {}
  date: 2021-08-18_10-13-24
  done: false
  episode_len_mean: 6164.5
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 604401.0711048108
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 73576
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 1.5726290941238403
          max_q: 164205.671875
          mean_q: 58502.203125
          mean_td_error: -2513060.5
          min_q: 1.9320706129074097
        model: {}
        td_error: "[-1.8213201e-01 -3.2329545e+04  1.4648032e-01  4.0039396e-01\n -7.0906250e+06\
          \ -3.2329545e+04 -7.0906250e+06 -8.7655592e-01\n -7.0906250e+06  9.1696262e-02\
          \  8.2209229e-02 -4.9243093e-01\n -7.0906250e+06 -7.0906250e+06 -7.0906250e+06\
          \ -2.4563909e-01\n -7.0906250e+06 -7.0906250e+06  5.7175350e-01 -5.2531538e+03\n\
          \ -7.0906250e+06 -7.0906250e+06  5.1009870e-01  2.3803544e-01\n -7.0906250e+06\
          \ -1.1310339e-02  1.8305278e-01  7.5784206e-02\n -7.0906250e+06 -3.2372438e+04\
          \ -7.0906250e+06  1.4126635e-01\n  2.4893641e-01 -2.8357196e-01 -7.0906250e+06\
          \  1.8646574e-01\n -7.0906250e+06  1.6017965e+04 -7.0906250e+06 -7.0906250e+06\n\
          \  6.7772865e-02 -7.0040274e-01 -9.4568968e-02 -7.9699516e-02\n  1.7563820e-02\
          \  2.4943709e-01  1.8895590e-01 -6.9030643e-01]"
    num_agent_steps_sampled: 74000
    num_agent_steps_trained: 876048
    num_steps_sampled: 74000
    num_steps_trained: 876048
    num_target_updates: 145
  iterations_since_restore: 74
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.67272727272727
    ram_util_percent: 31.704545454545464
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491216536447355
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.87486372729623
    mean_inference_ms: 1.573667207164749
    mean_raw_obs_processing_ms: 0.14221013427112378
  time_since_restore: 925.6482682228088
  time_this_iter_s: 15.136488676071167
  time_total_s: 925.6482682228088
  timers:
    learn_throughput: 5044.616
    learn_time_ms: 9.515
    update_time_ms: 2.763
  timestamp: 1629281604
  timesteps_since_restore: 0
  timesteps_total: 74000
  training_iteration: 74
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     74 |          925.648 | 74000 |   604401 |          7.25465e+06 |             -198.044 |             6164.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 75000
  custom_metrics: {}
  date: 2021-08-18_10-13-36
  done: false
  episode_len_mean: 6164.5
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 604401.0711048108
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 12
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 74584
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 2.249481439590454
          max_q: 204193.859375
          mean_q: 81878.8125
          mean_td_error: -2789828.0
          min_q: 1.8887559175491333
        model: {}
        td_error: "[ 1.6802867e+04 -7.3552370e-02 -9.0258121e-03  1.8401766e-01\n -7.0506395e+06\
          \  8.1012964e-02 -7.0506395e+06 -5.3487015e-01\n -7.0506395e+06 -1.1332297e-01\
          \ -4.4645774e-01 -7.0506395e+06\n -5.8620739e-01 -1.1163831e-01 -2.7349997e-01\
          \ -7.0506395e+06\n -3.1082153e-02  8.3804131e-03 -2.8310943e-01 -7.0506395e+06\n\
          \ -1.7417312e-01 -7.1256638e-01 -7.0506395e+06  3.7770510e-02\n -2.5630975e-01\
          \ -7.0506395e+06 -7.0506395e+06 -7.0506395e+06\n  2.8138900e-01  5.8218944e-01\
          \ -7.0506395e+06  2.9308748e-01\n -1.4084220e-01  2.2651982e-01  4.4464922e-01\
          \ -1.7346239e-01\n -7.0506395e+06 -7.0506395e+06 -7.0506395e+06 -7.0506395e+06\n\
          \ -7.0506395e+06 -2.2076082e-01 -7.0506395e+06 -7.0506395e+06\n -3.1397986e-01\
          \  1.6802867e+04  1.6802867e+04 -7.0506395e+06]"
    num_agent_steps_sampled: 75000
    num_agent_steps_trained: 888048
    num_steps_sampled: 75000
    num_steps_trained: 888048
    num_target_updates: 147
  iterations_since_restore: 75
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.956250000000004
    ram_util_percent: 31.7
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491216536447355
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.87486372729623
    mean_inference_ms: 1.573667207164749
    mean_raw_obs_processing_ms: 0.14221013427112378
  time_since_restore: 937.3240768909454
  time_this_iter_s: 11.675808668136597
  time_total_s: 937.3240768909454
  timers:
    learn_throughput: 5010.255
    learn_time_ms: 9.58
    update_time_ms: 2.713
  timestamp: 1629281616
  timesteps_since_restore: 0
  timesteps_total: 75000
  training_iteration: 75
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     75 |          937.324 | 75000 |   604401 |          7.25465e+06 |             -198.044 |             6164.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 76000
  custom_metrics: {}
  date: 2021-08-18_10-13-49
  done: false
  episode_len_mean: 6164.5
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 604401.0711048108
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 12
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 75592
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 3.782217502593994
          max_q: 262878.8125
          mean_q: 156031.359375
          mean_td_error: -4075963.75
          min_q: 2.1611788272857666
        model: {}
        td_error: "[-2.7628279e-01 -6.9919545e+06 -6.9919545e+06 -6.9919545e+06\n -6.9919545e+06\
          \ -6.9919545e+06 -6.9919545e+06 -6.9919545e+06\n  2.5761621e+04 -6.9919545e+06\
          \  9.0195894e-02 -6.9919545e+06\n -6.9919545e+06 -3.0375242e-02  2.4646020e-01\
          \ -6.9919545e+06\n -6.9919545e+06  2.8813672e-01 -6.9919545e+06 -6.9919545e+06\n\
          \ -6.9919545e+06  2.1450233e-01 -6.9919545e+06 -6.9919545e+06\n  1.4563131e-01\
          \ -6.9919545e+06  2.5761621e+04 -2.3187065e-01\n -4.9937463e-01 -6.9919545e+06\
          \ -1.8904471e-01 -6.9919545e+06\n -6.9919545e+06 -6.9919545e+06  2.5761621e+04\
          \  1.2139273e-01\n  2.5761621e+04 -8.7528229e-03 -6.9919545e+06 -2.1093297e-01\n\
          \ -6.9919545e+06 -6.9919545e+06 -3.3164255e+02 -6.9919545e+06\n -6.9919545e+06\
          \ -6.9919545e+06  2.1638036e-01  2.5761621e+04]"
    num_agent_steps_sampled: 76000
    num_agent_steps_trained: 900048
    num_steps_sampled: 76000
    num_steps_trained: 900048
    num_target_updates: 149
  iterations_since_restore: 76
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.88333333333334
    ram_util_percent: 31.700000000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491216536447355
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.87486372729623
    mean_inference_ms: 1.573667207164749
    mean_raw_obs_processing_ms: 0.14221013427112378
  time_since_restore: 949.7284071445465
  time_this_iter_s: 12.404330253601074
  time_total_s: 949.7284071445465
  timers:
    learn_throughput: 4950.638
    learn_time_ms: 9.696
    update_time_ms: 2.826
  timestamp: 1629281629
  timesteps_since_restore: 0
  timesteps_total: 76000
  training_iteration: 76
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     76 |          949.728 | 76000 |   604401 |          7.25465e+06 |             -198.044 |             6164.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 77000
  custom_metrics: {}
  date: 2021-08-18_10-14-02
  done: false
  episode_len_mean: 6164.5
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 604401.0711048108
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 12
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 76600
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.011188983917236
          max_q: 323147.96875
          mean_q: 146422.75
          mean_td_error: -3030617.5
          min_q: 2.1810901165008545
        model: {}
        td_error: "[-6.9316835e+06 -2.9021764e+04 -2.9082793e+04 -1.5331125e-01\n  2.8837466e-01\
          \ -6.9316835e+06  3.4412348e+04 -7.8044176e-02\n  3.4412348e+04 -2.9021764e+04\
          \ -6.9316835e+06 -6.9316835e+06\n -6.9316835e+06 -6.9316835e+06 -6.9316835e+06\
          \  1.1073995e-01\n -6.9316835e+06 -6.9316835e+06 -6.9316835e+06  3.4412348e+04\n\
          \  3.4412348e+04 -3.8695335e-02 -6.5780163e-02  6.7894459e-02\n  7.7676296e-02\
          \ -6.9316835e+06  3.4412348e+04  2.0586491e-02\n -1.1549783e-01  1.5478778e-01\
          \ -6.9316835e+06 -6.9316835e+06\n -6.9316835e+06 -6.9316835e+06  3.4412348e+04\
          \ -6.9316835e+06\n -2.9021750e+04  6.0034490e-01 -6.9316835e+06 -6.9316835e+06\n\
          \ -2.9021732e+04  3.4412348e+04 -6.9316835e+06 -1.6909432e-01\n -6.9316835e+06\
          \ -6.4436817e-01 -6.9316835e+06 -1.0479903e-01]"
    num_agent_steps_sampled: 77000
    num_agent_steps_trained: 912048
    num_steps_sampled: 77000
    num_steps_trained: 912048
    num_target_updates: 151
  iterations_since_restore: 77
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.48421052631579
    ram_util_percent: 31.70526315789474
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491216536447355
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.87486372729623
    mean_inference_ms: 1.573667207164749
    mean_raw_obs_processing_ms: 0.14221013427112378
  time_since_restore: 962.8724081516266
  time_this_iter_s: 13.144001007080078
  time_total_s: 962.8724081516266
  timers:
    learn_throughput: 4627.07
    learn_time_ms: 10.374
    update_time_ms: 3.024
  timestamp: 1629281642
  timesteps_since_restore: 0
  timesteps_total: 77000
  training_iteration: 77
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     77 |          962.872 | 77000 |   604401 |          7.25465e+06 |             -198.044 |             6164.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 78000
  custom_metrics: {}
  date: 2021-08-18_10-14-15
  done: false
  episode_len_mean: 6164.5
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 604401.0711048108
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 12
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 77608
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 3.618035316467285
          max_q: 382560.78125
          mean_q: 186941.25
          mean_td_error: -3289332.0
          min_q: 2.144355297088623
        model: {}
        td_error: "[-6.8722675e+06 -3.0400920e-01 -6.8722675e+06 -2.7129793e-01\n -4.1081905e-02\
          \  4.3551953e+04 -6.8722675e+06 -6.8722675e+06\n -6.8722675e+06 -2.6723385e-02\
          \ -6.8722675e+06  7.7591157e-01\n -6.8722675e+06  2.1646929e-01 -5.8758020e-01\
          \ -6.8722675e+06\n -6.8722675e+06 -4.3139863e-01 -6.8722675e+06 -6.8722675e+06\n\
          \ -6.8722675e+06 -6.8722675e+06 -2.7253628e-03  4.3551953e+04\n -6.8722675e+06\
          \ -6.8722675e+06 -6.8722675e+06 -1.2868595e-01\n  8.0814838e-02  2.4717879e-01\
          \ -6.8722675e+06 -6.8722675e+06\n -6.8722675e+06 -6.8722675e+06 -6.8722675e+06\
          \ -6.8722675e+06\n -2.4998736e-01 -3.7672186e-01 -1.5400648e-01  1.4216971e-01\n\
          \  4.3551953e+04 -6.8722675e+06 -1.0781503e-01  4.3551953e+04\n -2.3860455e-01\
          \ -1.1456013e-02  1.7044878e-01  1.0254669e-01]"
    num_agent_steps_sampled: 78000
    num_agent_steps_trained: 924048
    num_steps_sampled: 78000
    num_steps_trained: 924048
    num_target_updates: 153
  iterations_since_restore: 78
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.342105263157904
    ram_util_percent: 31.70526315789474
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491216536447355
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.87486372729623
    mean_inference_ms: 1.573667207164749
    mean_raw_obs_processing_ms: 0.14221013427112378
  time_since_restore: 976.1628136634827
  time_this_iter_s: 13.290405511856079
  time_total_s: 976.1628136634827
  timers:
    learn_throughput: 4920.859
    learn_time_ms: 9.754
    update_time_ms: 2.678
  timestamp: 1629281655
  timesteps_since_restore: 0
  timesteps_total: 78000
  training_iteration: 78
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     78 |          976.163 | 78000 |   604401 |          7.25465e+06 |             -198.044 |             6164.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 79000
  custom_metrics: {}
  date: 2021-08-18_10-14-29
  done: false
  episode_len_mean: 6164.5
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 604401.0711048108
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 12
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 78616
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.097370624542236
          max_q: 447857.15625
          mean_q: 217867.84375
          mean_td_error: -3258407.0
          min_q: 2.067460536956787
        model: {}
        td_error: "[-6.8069740e+06 -6.8069740e+06 -3.2518077e-01 -6.8069740e+06\n -9.5166206e-02\
          \ -6.1190605e-02 -6.8069740e+06 -8.1890106e-02\n  3.9089441e-02 -2.5494599e-01\
          \ -6.8069740e+06 -6.8069740e+06\n  5.2289207e+04 -6.8069740e+06  5.2289207e+04\
          \ -6.8069740e+06\n -6.8069740e+06 -3.8972139e-02 -6.8069740e+06 -6.8069740e+06\n\
          \ -6.8069740e+06 -6.8069740e+06 -6.8069740e+06 -2.4429560e-01\n -3.2185078e-02\
          \  5.2289207e+04 -6.8069740e+06 -1.3111019e-01\n -3.8917017e-01 -8.0910444e-02\
          \ -6.8069740e+06 -6.8069740e+06\n -2.7169609e-01  2.5809050e-02  3.4878254e-02\
          \ -6.8069740e+06\n -6.8069740e+06 -3.3348489e-01  1.5429747e-01 -6.8069740e+06\n\
          \ -6.8069740e+06 -2.6547694e-01 -6.8069740e+06 -1.5524650e-01\n -8.4798813e-02\
          \ -2.8362846e-01 -3.5525918e-01 -6.8069740e+06]"
    num_agent_steps_sampled: 79000
    num_agent_steps_trained: 936048
    num_steps_sampled: 79000
    num_steps_trained: 936048
    num_target_updates: 155
  iterations_since_restore: 79
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.4
    ram_util_percent: 31.700000000000006
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491216536447355
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.87486372729623
    mean_inference_ms: 1.573667207164749
    mean_raw_obs_processing_ms: 0.14221013427112378
  time_since_restore: 990.0952444076538
  time_this_iter_s: 13.932430744171143
  time_total_s: 990.0952444076538
  timers:
    learn_throughput: 4772.525
    learn_time_ms: 10.058
    update_time_ms: 3.06
  timestamp: 1629281669
  timesteps_since_restore: 0
  timesteps_total: 79000
  training_iteration: 79
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     79 |          990.095 | 79000 |   604401 |          7.25465e+06 |             -198.044 |             6164.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 80000
  custom_metrics: {}
  date: 2021-08-18_10-14-45
  done: false
  episode_len_mean: 6164.5
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 604401.0711048108
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 12
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 79624
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.627266883850098
          max_q: 512755.03125
          mean_q: 251994.875
          mean_td_error: -3226782.5
          min_q: 2.116340160369873
        model: {}
        td_error: "[ 6.0276035e+04 -6.7420730e+06  1.4779687e-01 -6.7420730e+06\n -2.9811398e+04\
          \ -6.7420730e+06 -6.7420730e+06 -6.7420730e+06\n -6.7420730e+06 -2.5798559e-02\
          \ -6.7420730e+06 -6.7420730e+06\n -6.7420730e+06 -6.7420730e+06  4.1910410e-02\
          \ -1.5324593e-02\n -3.9921045e-01 -6.7420730e+06 -2.6489663e-01 -4.4572091e-01\n\
          \ -6.7420730e+06 -2.8929996e-01  6.0276035e+04 -1.9625664e-02\n -1.4381409e-01\
          \ -6.7420730e+06 -6.7420730e+06 -6.7420730e+06\n  1.2003577e+00  1.7189980e-04\
          \ -6.7420730e+06 -6.7420730e+06\n -2.9811383e+04  6.0276035e+04 -6.7420730e+06\
          \  6.0276035e+04\n  4.7737837e-02  6.0276035e+04 -6.7420730e+06 -2.9811428e+04\n\
          \ -6.7420730e+06 -6.7420730e+06 -1.4257622e-01 -7.2393417e-03\n -6.7420730e+06\
          \ -2.9811383e+04 -6.7420730e+06 -1.7576170e-01]"
    num_agent_steps_sampled: 80000
    num_agent_steps_trained: 948048
    num_steps_sampled: 80000
    num_steps_trained: 948048
    num_target_updates: 157
  iterations_since_restore: 80
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.75000000000001
    ram_util_percent: 31.70454545454546
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491216536447355
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.87486372729623
    mean_inference_ms: 1.573667207164749
    mean_raw_obs_processing_ms: 0.14221013427112378
  time_since_restore: 1005.0808880329132
  time_this_iter_s: 14.9856436252594
  time_total_s: 1005.0808880329132
  timers:
    learn_throughput: 3607.202
    learn_time_ms: 13.307
    update_time_ms: 3.971
  timestamp: 1629281685
  timesteps_since_restore: 0
  timesteps_total: 80000
  training_iteration: 80
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     80 |          1005.08 | 80000 |   604401 |          7.25465e+06 |             -198.044 |             6164.5 |
+----------------------------+----------+----------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 81000
  custom_metrics: {}
  date: 2021-08-18_10-14-58
  done: false
  episode_len_mean: 6205.923076923077
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 1115958.673676563
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 80632
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.670351982116699
          max_q: 580074.75
          mean_q: 356151.09375
          mean_td_error: -4026976.0
          min_q: 2.053379774093628
        model: {}
        td_error: "[-6.6747540e+06 -6.6747540e+06 -2.5343895e-04 -6.6747540e+06\n -6.6747540e+06\
          \ -6.6747540e+06 -6.6747540e+06 -6.6747540e+06\n -6.6747540e+06 -1.0817647e-01\
          \  2.9312611e-01 -3.7654161e-02\n -6.6747540e+06 -6.6747540e+06 -6.6747540e+06\
          \  4.8877954e-02\n -2.2239208e-02  6.8257109e+04 -6.6747540e+06 -6.6747540e+06\n\
          \ -1.4215231e-01  6.8257109e+04 -6.6747540e+06 -6.6747540e+06\n -6.6747540e+06\
          \ -6.6747540e+06 -6.6747540e+06 -6.6747540e+06\n -6.6747540e+06 -6.6747540e+06\
          \  2.8545392e-01 -2.9886961e-01\n -6.6747540e+06 -6.6747540e+06 -1.9603157e-01\
          \ -6.6747540e+06\n -6.6747540e+06 -6.6747540e+06 -6.6747540e+06 -2.2779155e-01\n\
          \ -6.6747540e+06  6.8257109e+04  3.5405278e-01 -1.1245394e-01\n  6.8257109e+04\
          \  1.1626148e-01 -6.6747540e+06  1.8260241e-02]"
    num_agent_steps_sampled: 81000
    num_agent_steps_trained: 960048
    num_steps_sampled: 81000
    num_steps_trained: 960048
    num_target_updates: 159
  iterations_since_restore: 81
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.665
    ram_util_percent: 31.705000000000005
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913159441092669
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8869964908631265
    mean_inference_ms: 1.5743508552752492
    mean_raw_obs_processing_ms: 0.14232011365851022
  time_since_restore: 1018.7751305103302
  time_this_iter_s: 13.694242477416992
  time_total_s: 1018.7751305103302
  timers:
    learn_throughput: 4947.231
    learn_time_ms: 9.702
    update_time_ms: 2.688
  timestamp: 1629281698
  timesteps_since_restore: 0
  timesteps_total: 81000
  training_iteration: 81
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     81 |          1018.78 | 81000 | 1.11596e+06 |          7.25465e+06 |             -198.044 |            6205.92 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 82000
  custom_metrics: {}
  date: 2021-08-18_10-15-09
  done: false
  episode_len_mean: 6205.923076923077
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 1115958.673676563
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 13
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 81640
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.03658390045166
          max_q: 664629.5
          mean_q: 543684.0
          mean_td_error: -5350863.5
          min_q: 1.9438977241516113
        model: {}
        td_error: "[-6.5901975e+06 -6.5901975e+06 -6.5901975e+06 -6.5901975e+06\n  8.8127828e+04\
          \ -6.5901975e+06 -6.5901975e+06 -6.5901975e+06\n -6.5901975e+06 -6.5901975e+06\
          \ -1.8332005e-02 -6.5901975e+06\n -6.5901975e+06 -6.5901975e+06 -1.9353127e-01\
          \ -6.5901975e+06\n -6.5901975e+06 -1.9083357e-01 -6.5901975e+06  2.8947353e-02\n\
          \ -6.5901975e+06 -6.5901975e+06 -6.5901975e+06 -6.5901975e+06\n  2.1127510e-01\
          \ -6.5901975e+06 -6.5901975e+06 -6.5901975e+06\n -6.5901975e+06 -6.5901975e+06\
          \ -6.5901975e+06 -6.5901975e+06\n -6.5901975e+06  8.8127828e+04 -1.6545439e-01\
          \ -6.5901975e+06\n -6.5901975e+06 -6.5901975e+06 -6.5901975e+06 -6.5901975e+06\n\
          \ -6.5901975e+06 -1.0210996e+00 -6.5901975e+06 -6.5901975e+06\n -6.5901975e+06\
          \ -6.5901975e+06 -6.5901975e+06 -6.5901975e+06]"
    num_agent_steps_sampled: 82000
    num_agent_steps_trained: 972048
    num_steps_sampled: 82000
    num_steps_trained: 972048
    num_target_updates: 161
  iterations_since_restore: 82
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.14666666666667
    ram_util_percent: 31.706666666666663
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913159441092669
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8869964908631265
    mean_inference_ms: 1.5743508552752492
    mean_raw_obs_processing_ms: 0.14232011365851022
  time_since_restore: 1029.4687285423279
  time_this_iter_s: 10.69359803199768
  time_total_s: 1029.4687285423279
  timers:
    learn_throughput: 5001.766
    learn_time_ms: 9.597
    update_time_ms: 2.691
  timestamp: 1629281709
  timesteps_since_restore: 0
  timesteps_total: 82000
  training_iteration: 82
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     82 |          1029.47 | 82000 | 1.11596e+06 |          7.25465e+06 |             -198.044 |            6205.92 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 83000
  custom_metrics: {}
  date: 2021-08-18_10-15-23
  done: false
  episode_len_mean: 6205.923076923077
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 1115958.673676563
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 13
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 82648
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.137892246246338
          max_q: 748588.4375
          mean_q: 441142.75
          mean_td_error: -3790840.75
          min_q: 1.9004061222076416
        model: {}
        td_error: "[ 1.22039437e-01 -1.60494804e-01 -6.50623850e+06 -2.46320248e-01\n\
          \ -6.50623850e+06 -6.50623850e+06  7.65422583e-02 -6.50623850e+06\n -6.50623850e+06\
          \  1.64546847e-01 -6.50623850e+06  2.53787041e-02\n -6.50623850e+06 -6.50623850e+06\
          \ -6.50623850e+06 -4.88777161e-02\n -6.50623850e+06 -1.72984123e-01 -6.50623850e+06\
          \ -6.50623850e+06\n -6.50623850e+06 -1.85228229e-01 -6.55478239e-02 -6.50623850e+06\n\
          \  2.22254753e-01  1.07164305e+05 -3.15372705e-01 -6.50623850e+06\n -2.94281244e-02\
          \ -6.50623850e+06 -6.50623850e+06 -6.50623850e+06\n  1.07164305e+05 -6.50623850e+06\
          \ -6.50623850e+06 -6.50623850e+06\n  7.93904066e-02 -6.50623850e+06  2.49992251e-01\
          \ -1.42728567e-01\n -6.50623850e+06 -6.50623850e+06 -6.50623850e+06  1.02097631e-01\n\
          \ -6.50623850e+06 -1.29102945e-01 -6.50623850e+06 -6.50623850e+06]"
    num_agent_steps_sampled: 83000
    num_agent_steps_trained: 984048
    num_steps_sampled: 83000
    num_steps_trained: 984048
    num_target_updates: 163
  iterations_since_restore: 83
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.975
    ram_util_percent: 31.705000000000005
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913159441092669
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8869964908631265
    mean_inference_ms: 1.5743508552752492
    mean_raw_obs_processing_ms: 0.14232011365851022
  time_since_restore: 1043.2910270690918
  time_this_iter_s: 13.822298526763916
  time_total_s: 1043.2910270690918
  timers:
    learn_throughput: 5021.878
    learn_time_ms: 9.558
    update_time_ms: 2.872
  timestamp: 1629281723
  timesteps_since_restore: 0
  timesteps_total: 83000
  training_iteration: 83
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     83 |          1043.29 | 83000 | 1.11596e+06 |          7.25465e+06 |             -198.044 |            6205.92 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 84000
  custom_metrics: {}
  date: 2021-08-18_10-15-36
  done: false
  episode_len_mean: 6205.923076923077
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 1115958.673676563
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 13
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 83656
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.66188907623291
          max_q: 834541.375
          mean_q: 556361.625
          mean_td_error: -4280500.0
          min_q: 1.901747465133667
        model: {}
        td_error: "[-6.42028550e+06  2.39155769e-01 -6.42028550e+06 -6.42028550e+06\n\
          \ -6.42028550e+06 -6.42028550e+06 -6.42028550e+06 -6.42028550e+06\n -6.42028550e+06\
          \ -6.42028550e+06 -1.75340176e-02 -2.26119995e-01\n -6.42028550e+06 -6.42028550e+06\
          \ -6.42028550e+06 -6.42028550e+06\n -6.42028550e+06 -6.42028550e+06 -1.21628284e-01\
          \  2.90415287e-02\n -6.42028550e+06 -8.34295750e-02  3.23222876e-02 -6.42028550e+06\n\
          \ -6.42028550e+06 -4.01072502e-02 -1.48697432e+04 -6.42028550e+06\n -6.42028550e+06\
          \ -6.42028550e+06 -6.42028550e+06  1.59730911e-01\n -2.71787047e-01  3.10976028e-01\
          \ -6.42028550e+06  2.73780465e-01\n  1.62181854e-02 -6.42028550e+06  2.74258733e-01\
          \ -6.42028550e+06\n -6.42028550e+06 -6.42028550e+06 -6.42028550e+06 -6.42028550e+06\n\
          \ -6.42028550e+06 -6.42028550e+06  9.70115662e-02 -6.42028550e+06]"
    num_agent_steps_sampled: 84000
    num_agent_steps_trained: 996048
    num_steps_sampled: 84000
    num_steps_trained: 996048
    num_target_updates: 165
  iterations_since_restore: 84
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.41111111111112
    ram_util_percent: 31.700000000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913159441092669
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8869964908631265
    mean_inference_ms: 1.5743508552752492
    mean_raw_obs_processing_ms: 0.14232011365851022
  time_since_restore: 1056.0518975257874
  time_this_iter_s: 12.760870456695557
  time_total_s: 1056.0518975257874
  timers:
    learn_throughput: 4982.555
    learn_time_ms: 9.634
    update_time_ms: 2.819
  timestamp: 1629281736
  timesteps_since_restore: 0
  timesteps_total: 84000
  training_iteration: 84
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     84 |          1056.05 | 84000 | 1.11596e+06 |          7.25465e+06 |             -198.044 |            6205.92 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 85000
  custom_metrics: {}
  date: 2021-08-18_10-15-51
  done: false
  episode_len_mean: 6205.923076923077
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 1115958.673676563
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 13
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 84664
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.3639373779296875
          max_q: 919021.625
          mean_q: 541285.6875
          mean_td_error: -3539556.75
          min_q: 1.9882783889770508
        model: {}
        td_error: "[-7.3536873e-02  1.4600711e+05 -6.3358065e+06  1.4600711e+05\n -6.3358065e+06\
          \ -6.3358065e+06 -6.3358065e+06 -3.3652616e-01\n -9.3361616e-02 -6.3358065e+06\
          \  2.5421584e-01 -6.3358065e+06\n  7.7194452e-02  3.4292555e-01 -6.3358065e+06\
          \ -6.3358065e+06\n  1.4600711e+05  2.1804976e-01 -6.3358065e+06  3.1894946e-01\n\
          \ -6.3358065e+06 -6.3358065e+06 -3.9319992e-02 -6.3358065e+06\n -6.3358065e+06\
          \ -6.3358065e+06  1.4600711e+05 -6.3358065e+06\n -6.3358065e+06 -6.3358065e+06\
          \ -6.3358065e+06 -6.3358065e+06\n -6.3358065e+06  1.4600711e+05 -6.3358065e+06\
          \  1.4600711e+05\n -6.3358065e+06 -1.2435794e-01 -6.3358065e+06 -6.3358065e+06\n\
          \ -6.3358065e+06  1.4600711e+05  1.4600711e+05  2.0418751e-01\n -6.3358065e+06\
          \ -2.1622896e-01  1.4251506e-01 -6.3358065e+06]"
    num_agent_steps_sampled: 85000
    num_agent_steps_trained: 1008048
    num_steps_sampled: 85000
    num_steps_trained: 1008048
    num_target_updates: 167
  iterations_since_restore: 85
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.37619047619047
    ram_util_percent: 31.714285714285715
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913159441092669
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8869964908631265
    mean_inference_ms: 1.5743508552752492
    mean_raw_obs_processing_ms: 0.14232011365851022
  time_since_restore: 1070.6276924610138
  time_this_iter_s: 14.57579493522644
  time_total_s: 1070.6276924610138
  timers:
    learn_throughput: 3953.053
    learn_time_ms: 12.143
    update_time_ms: 3.227
  timestamp: 1629281751
  timesteps_since_restore: 0
  timesteps_total: 85000
  training_iteration: 85
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     85 |          1070.63 | 85000 | 1.11596e+06 |          7.25465e+06 |             -198.044 |            6205.92 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 86000
  custom_metrics: {}
  date: 2021-08-18_10-16-05
  done: false
  episode_len_mean: 6205.923076923077
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 1115958.673676563
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 13
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 85672
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.980386734008789
          max_q: 1008960.9375
          mean_q: 574473.375
          mean_td_error: -3506368.5
          min_q: 1.7847650051116943
        model: {}
        td_error: "[-6.24586700e+06 -6.11565709e-01  1.19462132e-01 -6.24586700e+06\n\
          \ -6.24586700e+06 -6.24586700e+06 -6.24586700e+06 -1.01612759e+00\n -6.24586700e+06\
          \ -6.24586700e+06 -6.24586700e+06 -6.24586700e+06\n -6.24586700e+06 -1.43257976e-01\
          \ -1.63776875e-02 -3.13540459e-01\n -6.24586700e+06 -6.24586700e+06 -6.24586700e+06\
          \ -9.55033302e-02\n -6.24586700e+06  1.66364375e+05 -6.24586700e+06 -6.24586700e+06\n\
          \ -6.24586700e+06 -1.49014115e-01 -6.24586700e+06 -6.24586700e+06\n -1.77175641e-01\
          \ -6.24586700e+06 -3.35583448e-01 -6.24586700e+06\n  1.20197535e-01 -3.05040240e-01\
          \  1.66364375e+05 -6.24586700e+06\n -6.24586700e+06 -6.24586700e+06  3.35431099e-02\
          \  2.08157420e-01\n  4.46910858e-02  8.57477188e-02 -3.88556719e-02 -6.24586700e+06\n\
          \  7.85681009e-02 -6.24586700e+06 -3.32884431e-01 -6.24586700e+06]"
    num_agent_steps_sampled: 86000
    num_agent_steps_trained: 1020048
    num_steps_sampled: 86000
    num_steps_trained: 1020048
    num_target_updates: 169
  iterations_since_restore: 86
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.89
    ram_util_percent: 31.705000000000005
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913159441092669
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8869964908631265
    mean_inference_ms: 1.5743508552752492
    mean_raw_obs_processing_ms: 0.14232011365851022
  time_since_restore: 1084.4721834659576
  time_this_iter_s: 13.844491004943848
  time_total_s: 1084.4721834659576
  timers:
    learn_throughput: 4947.171
    learn_time_ms: 9.703
    update_time_ms: 2.796
  timestamp: 1629281765
  timesteps_since_restore: 0
  timesteps_total: 86000
  training_iteration: 86
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     86 |          1084.47 | 86000 | 1.11596e+06 |          7.25465e+06 |             -198.044 |            6205.92 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 87000
  custom_metrics: {}
  date: 2021-08-18_10-16-20
  done: false
  episode_len_mean: 6205.923076923077
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 1115958.673676563
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 13
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 86680
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.884578704833984
          max_q: 1102040.5
          mean_q: 593668.25
          mean_td_error: -3185163.5
          min_q: 1.8090147972106934
        model: {}
        td_error: "[-6.1527870e+06 -1.3169585e+04 -6.1527870e+06  3.6230087e-03\n -6.1527870e+06\
          \  1.8899988e+05 -6.1527870e+06 -6.1527870e+06\n -1.6350198e-01 -6.1527870e+06\
          \ -6.1527870e+06  1.8899988e+05\n  9.2702627e-02 -7.6041079e-01  3.9734697e-01\
          \ -6.1527870e+06\n -4.0798759e-01 -6.1527870e+06 -6.1527870e+06  3.1266689e-02\n\
          \  5.2747726e-02 -6.1527870e+06 -6.1527870e+06 -6.1527870e+06\n -6.1527870e+06\
          \ -6.1527870e+06 -6.1527870e+06  9.0574026e-03\n  3.2933474e-02  1.8899988e+05\
          \  1.2440443e-01 -6.1527870e+06\n -2.4839520e-02  9.4246507e-02 -6.1527870e+06\
          \  9.7297430e-02\n  2.0463228e-01  1.8899988e+05 -6.1527870e+06 -6.1527870e+06\n\
          \ -6.1527870e+06  1.8899988e+05 -6.1527870e+06 -2.9583931e-02\n  2.3925924e-01\
          \ -6.1527870e+06 -6.1527870e+06 -6.1527870e+06]"
    num_agent_steps_sampled: 87000
    num_agent_steps_trained: 1032048
    num_steps_sampled: 87000
    num_steps_trained: 1032048
    num_target_updates: 171
  iterations_since_restore: 87
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.74761904761904
    ram_util_percent: 31.704761904761913
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913159441092669
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8869964908631265
    mean_inference_ms: 1.5743508552752492
    mean_raw_obs_processing_ms: 0.14232011365851022
  time_since_restore: 1099.1617019176483
  time_this_iter_s: 14.689518451690674
  time_total_s: 1099.1617019176483
  timers:
    learn_throughput: 4666.052
    learn_time_ms: 10.287
    update_time_ms: 3.099
  timestamp: 1629281780
  timesteps_since_restore: 0
  timesteps_total: 87000
  training_iteration: 87
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     87 |          1099.16 | 87000 | 1.11596e+06 |          7.25465e+06 |             -198.044 |            6205.92 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 88000
  custom_metrics: {}
  date: 2021-08-18_10-16-35
  done: false
  episode_len_mean: 6205.923076923077
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 1115958.673676563
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 13
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 87688
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 9.42320442199707
          max_q: 1200060.0
          mean_q: 851813.875
          mean_td_error: -4135880.75
          min_q: 1.7776274681091309
        model: {}
        td_error: "[ 3.4337401e-02 -6.0547670e+06  2.1417262e+05 -6.0547670e+06\n -6.0547670e+06\
          \ -6.0547670e+06 -6.0547670e+06 -6.0547670e+06\n -6.0547670e+06  2.4711490e-02\
          \ -1.2402260e-01  1.1077678e-01\n  1.1073792e-01 -6.0547670e+06 -6.0547670e+06\
          \ -6.0547670e+06\n -6.0547670e+06 -6.0547670e+06  2.1417262e+05 -6.0547670e+06\n\
          \ -6.0547670e+06  2.1417262e+05  2.0938015e-01 -6.0547670e+06\n  2.1417262e+05\
          \ -6.0547670e+06 -6.0547670e+06 -3.6581516e-02\n -6.0547670e+06 -6.0547670e+06\
          \ -6.0547670e+06  2.1417262e+05\n -6.0547670e+06 -6.0547670e+06 -6.0547670e+06\
          \ -6.0547670e+06\n -6.0547670e+06 -3.1403065e-02  2.1417262e+05 -6.0547670e+06\n\
          \ -6.0547670e+06 -6.0547670e+06  2.2212207e-01 -6.0547670e+06\n -6.0547670e+06\
          \ -6.0547670e+06 -6.0547670e+06 -6.0547670e+06]"
    num_agent_steps_sampled: 88000
    num_agent_steps_trained: 1044048
    num_steps_sampled: 88000
    num_steps_trained: 1044048
    num_target_updates: 173
  iterations_since_restore: 88
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.13636363636364
    ram_util_percent: 31.736363636363624
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913159441092669
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8869964908631265
    mean_inference_ms: 1.5743508552752492
    mean_raw_obs_processing_ms: 0.14232011365851022
  time_since_restore: 1113.8753037452698
  time_this_iter_s: 14.71360182762146
  time_total_s: 1113.8753037452698
  timers:
    learn_throughput: 3918.156
    learn_time_ms: 12.251
    update_time_ms: 3.912
  timestamp: 1629281795
  timesteps_since_restore: 0
  timesteps_total: 88000
  training_iteration: 88
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     88 |          1113.88 | 88000 | 1.11596e+06 |          7.25465e+06 |             -198.044 |            6205.92 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 89000
  custom_metrics: {}
  date: 2021-08-18_10-16-52
  done: false
  episode_len_mean: 6205.923076923077
  episode_media: {}
  episode_reward_max: 7254651.381618341
  episode_reward_mean: 1115958.673676563
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 13
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 88696
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 10.197856903076172
          max_q: 1298245.375
          mean_q: 954074.75
          mean_td_error: -4184762.0
          min_q: 1.6552646160125732
        model: {}
        td_error: "[-5.9565820e+06 -5.9565820e+06 -5.9565820e+06  2.3645677e+05\n -5.9565820e+06\
          \ -5.9565820e+06 -5.9565820e+06 -5.9565820e+06\n -5.9565820e+06  2.3645677e+05\
          \ -5.9565820e+06 -5.9565820e+06\n  2.3645677e+05 -5.9565820e+06 -9.7017527e-02\
          \ -5.9565820e+06\n -5.9565820e+06 -1.9018555e-01 -5.9565820e+06 -5.9565820e+06\n\
          \  2.3645677e+05  3.5006237e-01 -5.9565820e+06 -5.9565820e+06\n  1.2742472e-01\
          \ -5.9565820e+06  1.3142169e-01 -5.9565820e+06\n -5.9565820e+06 -5.9565820e+06\
          \ -5.9565820e+06 -5.9565820e+06\n  1.9451141e-02  2.3645677e+05  2.3645677e+05\
          \ -5.9565820e+06\n -5.9565820e+06 -5.9565820e+06 -5.9565820e+06 -5.9565820e+06\n\
          \  2.3645677e+05 -5.9565820e+06 -5.9565820e+06 -5.9565820e+06\n -5.9565820e+06\
          \ -5.9565820e+06  1.6079581e-01 -5.9565820e+06]"
    num_agent_steps_sampled: 89000
    num_agent_steps_trained: 1056048
    num_steps_sampled: 89000
    num_steps_trained: 1056048
    num_target_updates: 175
  iterations_since_restore: 89
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.03333333333334
    ram_util_percent: 31.80416666666667
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913159441092669
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.8869964908631265
    mean_inference_ms: 1.5743508552752492
    mean_raw_obs_processing_ms: 0.14232011365851022
  time_since_restore: 1130.5972259044647
  time_this_iter_s: 16.721922159194946
  time_total_s: 1130.5972259044647
  timers:
    learn_throughput: 4812.488
    learn_time_ms: 9.974
    update_time_ms: 3.076
  timestamp: 1629281812
  timesteps_since_restore: 0
  timesteps_total: 89000
  training_iteration: 89
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     89 |           1130.6 | 89000 | 1.11596e+06 |          7.25465e+06 |             -198.044 |            6205.92 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 90000
  custom_metrics: {}
  date: 2021-08-18_10-17-06
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 89704
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 11.51901912689209
          max_q: 1401294.0
          mean_q: 1096475.25
          mean_td_error: -4528267.5
          min_q: 1.5550518035888672
        model: {}
        td_error: "[ 2.5794256e-01  1.4409769e-01 -5.8535330e+06 -5.8535330e+06\n -5.8535330e+06\
          \ -5.8535330e+06 -5.8535330e+06 -5.8535330e+06\n -5.8535330e+06 -5.8535330e+06\
          \ -5.8535330e+06 -5.8535330e+06\n -5.8535330e+06 -5.8535330e+06 -5.8535330e+06\
          \ -5.8535330e+06\n -5.8535330e+06 -7.6295750e+05 -5.8535330e+06 -5.8535330e+06\n\
          \ -5.8535330e+06 -5.8535330e+06 -5.8535330e+06  2.6096761e+05\n -5.8535330e+06\
          \ -5.8535330e+06 -5.8535330e+06 -5.8535330e+06\n -5.8535330e+06 -5.8535330e+06\
          \ -5.8535330e+06 -5.8535330e+06\n -5.8535330e+06 -5.8535330e+06 -1.1993170e-01\
          \ -5.8535330e+06\n -5.8535330e+06 -5.8535330e+06 -3.3085676e+04 -5.8535330e+06\n\
          \ -7.6295750e+05  2.6096761e+05 -5.8535330e+06  2.6096761e+05\n -5.8535330e+06\
          \ -5.9334517e-02 -5.8535330e+06  1.4816415e-01]"
    num_agent_steps_sampled: 90000
    num_agent_steps_trained: 1068048
    num_steps_sampled: 90000
    num_steps_trained: 1068048
    num_target_updates: 177
  iterations_since_restore: 90
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.60000000000002
    ram_util_percent: 31.76315789473685
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1144.6880004405975
  time_this_iter_s: 14.090774536132812
  time_total_s: 1144.6880004405975
  timers:
    learn_throughput: 5043.201
    learn_time_ms: 9.518
    update_time_ms: 2.664
  timestamp: 1629281826
  timesteps_since_restore: 0
  timesteps_total: 90000
  training_iteration: 90
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     90 |          1144.69 | 90000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 91000
  custom_metrics: {}
  date: 2021-08-18_10-17-18
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 90712
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 10.702203750610352
          max_q: 1509653.5
          mean_q: 1056035.75
          mean_td_error: -3983328.75
          min_q: 1.3963632583618164
        model: {}
        td_error: "[-5.7451730e+06 -5.7451730e+06  2.0432413e-01  2.0080602e-01\n  2.9036644e+05\
          \ -9.7026825e-02  2.9036644e+05 -5.7451730e+06\n -8.1990169e+05  2.9036644e+05\
          \ -5.7451730e+06 -5.7451730e+06\n -5.7451730e+06 -5.7451730e+06 -5.7451730e+06\
          \ -8.1990169e+05\n -5.7451730e+06 -5.7451730e+06 -5.7451730e+06 -5.7451730e+06\n\
          \ -5.7451730e+06 -5.7451730e+06 -5.7451730e+06 -5.7451730e+06\n -5.7451730e+06\
          \ -5.7451730e+06 -1.2014282e-01 -5.7451730e+06\n -5.7451730e+06 -5.7451730e+06\
          \  3.8743019e-04 -5.7451730e+06\n -5.7451730e+06  9.2787898e-01 -2.0449883e+04\
          \ -5.7451730e+06\n -5.7451730e+06 -5.7451730e+06 -8.1990169e+05 -5.7451730e+06\n\
          \ -5.7451730e+06  1.5785336e-02 -5.7451730e+06 -8.3973408e-02\n -5.7451730e+06\
          \ -5.7451730e+06 -5.7451730e+06 -5.7451730e+06]"
    num_agent_steps_sampled: 91000
    num_agent_steps_trained: 1080048
    num_steps_sampled: 91000
    num_steps_trained: 1080048
    num_target_updates: 179
  iterations_since_restore: 91
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.44117647058823
    ram_util_percent: 31.705882352941178
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1156.240570306778
  time_this_iter_s: 11.55256986618042
  time_total_s: 1156.240570306778
  timers:
    learn_throughput: 5002.288
    learn_time_ms: 9.596
    update_time_ms: 3.109
  timestamp: 1629281838
  timesteps_since_restore: 0
  timesteps_total: 91000
  training_iteration: 91
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     91 |          1156.24 | 91000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 92000
  custom_metrics: {}
  date: 2021-08-18_10-17-30
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 91720
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 11.079741477966309
          max_q: 1617870.75
          mean_q: 1138787.75
          mean_td_error: -3848907.5
          min_q: 1.1006783246994019
        model: {}
        td_error: "[-5.6369570e+06 -7.6789021e-02 -5.6369570e+06 -5.6369570e+06\n -5.6369570e+06\
          \ -5.6369570e+06 -5.6369570e+06 -5.6369570e+06\n -3.8675499e-01 -5.6369570e+06\
          \ -5.6369570e+06 -5.6369570e+06\n -5.6369570e+06  8.8458180e-02 -5.6369570e+06\
          \ -5.6369570e+06\n  5.6202531e-02 -5.6369570e+06 -5.6369570e+06 -5.6369570e+06\n\
          \  2.2245216e-01 -5.6369570e+06 -5.6369570e+06 -8.8321090e-02\n -5.6369570e+06\
          \ -5.6369570e+06 -5.6369570e+06 -5.6369570e+06\n  3.1800834e+05 -5.6369570e+06\
          \ -5.6369570e+06  3.0998743e-01\n -5.6369570e+06  3.1800834e+05 -5.6369570e+06\
          \  3.1604695e-01\n -5.6369570e+06 -5.6369570e+06 -2.5800717e-01 -5.6369570e+06\n\
          \ -5.6369570e+06  3.1800834e+05  3.1800834e+05  1.4257610e-01\n -5.6369570e+06\
          \ -5.6369570e+06 -2.8842032e-01 -5.6369570e+06]"
    num_agent_steps_sampled: 92000
    num_agent_steps_trained: 1092048
    num_steps_sampled: 92000
    num_steps_trained: 1092048
    num_target_updates: 181
  iterations_since_restore: 92
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 68.13333333333334
    ram_util_percent: 31.70555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1168.884944677353
  time_this_iter_s: 12.644374370574951
  time_total_s: 1168.884944677353
  timers:
    learn_throughput: 5109.773
    learn_time_ms: 9.394
    update_time_ms: 2.752
  timestamp: 1629281850
  timesteps_since_restore: 0
  timesteps_total: 92000
  training_iteration: 92
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     92 |          1168.88 | 92000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 93000
  custom_metrics: {}
  date: 2021-08-18_10-17-42
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 92728
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.179214477539062
          max_q: 1731070.0
          mean_q: 872739.5
          mean_td_error: -2641291.5
          min_q: 1.320713758468628
        model: {}
        td_error: "[ 3.46132188e+05 -5.52375850e+06 -5.52375850e+06 -5.52375850e+06\n\
          \  3.46132188e+05 -1.32471919e-01 -4.98920679e-01 -3.22128534e-02\n -1.31260562e+00\
          \ -6.67268324e+00 -5.52375850e+06  3.71432185e-01\n -5.52375850e+06  3.46132188e+05\
          \ -6.72319770e-01 -4.54266787e-01\n -9.06156438e+05 -1.08279705e-01 -1.44028425e+00\
          \ -5.52375850e+06\n -5.52375850e+06 -5.52375850e+06  1.17282510e-01 -2.26540327e-01\n\
          \ -5.52375850e+06 -5.52375850e+06 -5.52375850e+06  1.62246227e-02\n  3.46132188e+05\
          \ -5.52375850e+06 -5.52375850e+06 -5.52375850e+06\n -9.06156438e+05 -5.52375850e+06\
          \ -5.52375850e+06  3.46132188e+05\n -1.01688862e-01  6.14492893e-02  3.46132188e+05\
          \ -5.52375850e+06\n -2.29078412e-01 -5.52375850e+06 -5.52375850e+06 -5.52375850e+06\n\
          \ -5.52375850e+06 -2.92056799e-02 -5.52375850e+06 -5.52375850e+06]"
    num_agent_steps_sampled: 93000
    num_agent_steps_trained: 1104048
    num_steps_sampled: 93000
    num_steps_trained: 1104048
    num_target_updates: 183
  iterations_since_restore: 93
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.30588235294118
    ram_util_percent: 31.705882352941178
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1180.6502799987793
  time_this_iter_s: 11.765335321426392
  time_total_s: 1180.6502799987793
  timers:
    learn_throughput: 5052.136
    learn_time_ms: 9.501
    update_time_ms: 2.717
  timestamp: 1629281862
  timesteps_since_restore: 0
  timesteps_total: 93000
  training_iteration: 93
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     93 |          1180.65 | 93000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 94000
  custom_metrics: {}
  date: 2021-08-18_10-17-55
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 93736
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 10.27719497680664
          max_q: 1851971.75
          mean_q: 1135699.25
          mean_td_error: -3096287.75
          min_q: 1.304953694343567
        model: {}
        td_error: "[-5.40286000e+06  1.05949879e-01 -5.40286000e+06 -5.40286000e+06\n\
          \  3.79753125e+05  3.79753125e+05  3.79753125e+05 -5.40286000e+06\n -5.40286000e+06\
          \  1.61866188e-01 -5.40286000e+06 -5.40286000e+06\n -5.40286000e+06  1.64295912e-01\
          \  2.52655745e-02 -5.40286000e+06\n -5.40286000e+06 -1.53776765e-01 -5.40286000e+06\
          \ -5.40286000e+06\n -5.40286000e+06 -5.40286000e+06 -5.40286000e+06 -1.51309025e+00\n\
          \ -5.40286000e+06 -5.40286000e+06  2.95125365e-01  3.79753125e+05\n  3.79753125e+05\
          \  2.23572373e-01  9.71730947e-02  5.13484836e-01\n -5.40286000e+06 -5.40286000e+06\
          \ -5.40286000e+06  3.79753125e+05\n -5.40286000e+06 -5.40286000e+06 -5.40286000e+06\
          \  1.05323195e-01\n -5.40286000e+06 -5.40286000e+06 -3.69925857e-01 -3.49554181e-01\n\
          \ -5.40286000e+06 -5.40286000e+06 -5.40286000e+06  3.79753125e+05]"
    num_agent_steps_sampled: 94000
    num_agent_steps_trained: 1116048
    num_steps_sampled: 94000
    num_steps_trained: 1116048
    num_target_updates: 185
  iterations_since_restore: 94
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.28947368421053
    ram_util_percent: 31.700000000000003
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1193.7122745513916
  time_this_iter_s: 13.061994552612305
  time_total_s: 1193.7122745513916
  timers:
    learn_throughput: 4946.478
    learn_time_ms: 9.704
    update_time_ms: 2.918
  timestamp: 1629281875
  timesteps_since_restore: 0
  timesteps_total: 94000
  training_iteration: 94
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     94 |          1193.71 | 94000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 95000
  custom_metrics: {}
  date: 2021-08-18_10-18-11
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 94744
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12.486824035644531
          max_q: 1977185.25
          mean_q: 1393918.75
          mean_td_error: -3593780.5
          min_q: 1.0984578132629395
        model: {}
        td_error: "[-5.2776480e+06 -8.1788898e-02 -5.2776480e+06 -5.2776480e+06\n -5.2776480e+06\
          \ -5.2776480e+06 -5.2776480e+06 -5.2776480e+06\n  4.1523088e+05 -5.2776480e+06\
          \  4.1523088e+05 -5.2776480e+06\n -5.2776480e+06 -1.2247479e-01 -1.5884030e-01\
          \ -5.2776480e+06\n -5.2776480e+06 -5.2776480e+06 -5.2776480e+06  1.1769557e-01\n\
          \  2.4372447e-01  2.8846204e-01 -5.2776480e+06 -5.2776480e+06\n -1.5710056e-01\
          \ -7.1407354e-01  2.3019505e-01 -5.2776480e+06\n -5.2776480e+06 -5.2776480e+06\
          \ -5.2776480e+06 -5.2776480e+06\n -5.2776480e+06  4.1523088e+05 -5.2776480e+06\
          \ -5.2776480e+06\n -5.2776480e+06 -1.3016558e-01 -5.2776480e+06 -5.2776480e+06\n\
          \ -5.2776480e+06 -5.2776480e+06 -5.2776480e+06 -5.2776480e+06\n -5.2776480e+06\
          \  1.5553069e-01 -5.2776480e+06  4.1523088e+05]"
    num_agent_steps_sampled: 95000
    num_agent_steps_trained: 1128048
    num_steps_sampled: 95000
    num_steps_trained: 1128048
    num_target_updates: 187
  iterations_since_restore: 95
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.70434782608696
    ram_util_percent: 31.70434782608697
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1209.3888602256775
  time_this_iter_s: 15.676585674285889
  time_total_s: 1209.3888602256775
  timers:
    learn_throughput: 4939.003
    learn_time_ms: 9.719
    update_time_ms: 2.85
  timestamp: 1629281891
  timesteps_since_restore: 0
  timesteps_total: 95000
  training_iteration: 95
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     95 |          1209.39 | 95000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 96000
  custom_metrics: {}
  date: 2021-08-18_10-18-26
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 95752
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 13.706161499023438
          max_q: 2103924.25
          mean_q: 1580951.75
          mean_td_error: -3709030.75
          min_q: 1.218988060951233
        model: {}
        td_error: "[-5.1509070e+06 -3.0915022e-02  2.6334977e-01 -5.1509070e+06\n -5.1509070e+06\
          \ -5.1509070e+06 -5.1509070e+06 -5.1509070e+06\n  4.4965497e+05 -5.1509070e+06\
          \ -5.1509070e+06 -5.1509070e+06\n -5.1509070e+06 -5.1509070e+06 -5.1509070e+06\
          \ -5.1509070e+06\n -5.1509070e+06  8.4209681e-02 -5.1509070e+06  4.4965497e+05\n\
          \ -1.5921915e-01 -5.1509070e+06 -5.1509070e+06 -5.1509070e+06\n -5.7666802e-01\
          \ -5.1509070e+06 -5.1509070e+06 -5.1509070e+06\n -5.1509070e+06 -5.1509070e+06\
          \ -5.3277588e-01 -5.1509070e+06\n -5.1509070e+06 -5.1509070e+06  4.4965497e+05\
          \ -5.1509070e+06\n -5.1509070e+06 -5.1509070e+06 -5.1509070e+06 -3.7511587e-03\n\
          \  4.4965497e+05  3.1004429e-02  4.4965497e+05 -5.1509070e+06\n -5.1509070e+06\
          \ -5.1509070e+06 -5.1509070e+06 -5.1509070e+06]"
    num_agent_steps_sampled: 96000
    num_agent_steps_trained: 1140048
    num_steps_sampled: 96000
    num_steps_trained: 1140048
    num_target_updates: 189
  iterations_since_restore: 96
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.23333333333333
    ram_util_percent: 31.74761904761904
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1223.983823299408
  time_this_iter_s: 14.594963073730469
  time_total_s: 1223.983823299408
  timers:
    learn_throughput: 4868.241
    learn_time_ms: 9.86
    update_time_ms: 3.257
  timestamp: 1629281906
  timesteps_since_restore: 0
  timesteps_total: 96000
  training_iteration: 96
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     96 |          1223.98 | 96000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 97000
  custom_metrics: {}
  date: 2021-08-18_10-18-42
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 96760
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12.142577171325684
          max_q: 2230774.5
          mean_q: 1454379.375
          mean_td_error: -3079890.0
          min_q: 1.3216112852096558
        model: {}
        td_error: "[-5.02405500e+06  1.74535513e-02  4.81152625e+05 -5.02405500e+06\n\
          \ -5.02405500e+06 -1.03235126e-01 -5.02405500e+06 -5.02405500e+06\n  1.95159078e-01\
          \ -5.02405500e+06 -5.02405500e+06 -3.62087488e-02\n -5.02405500e+06 -5.02405500e+06\
          \ -5.02405500e+06  2.02819109e-02\n -5.02405500e+06 -5.02405500e+06  4.81152625e+05\
          \  1.47476673e-01\n -5.02405500e+06 -5.02405500e+06 -5.02405500e+06  4.81152625e+05\n\
          \ -5.02405500e+06 -5.02405500e+06 -5.02405500e+06 -5.02405500e+06\n -5.02405500e+06\
          \  4.81152625e+05 -2.12250948e-01 -5.02405500e+06\n  8.74410868e-02  2.81752467e-01\
          \ -5.02405500e+06 -5.02405500e+06\n  1.11273646e-01  4.81152625e+05 -5.02405500e+06\
          \  1.76161766e-01\n -5.02405500e+06 -5.02405500e+06  2.63406754e-01  4.81152625e+05\n\
          \ -5.02405500e+06 -5.02405500e+06 -5.02405500e+06 -5.02405500e+06]"
    num_agent_steps_sampled: 97000
    num_agent_steps_trained: 1152048
    num_steps_sampled: 97000
    num_steps_trained: 1152048
    num_target_updates: 191
  iterations_since_restore: 97
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.036363636363625
    ram_util_percent: 31.80454545454544
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1239.4976205825806
  time_this_iter_s: 15.513797283172607
  time_total_s: 1239.4976205825806
  timers:
    learn_throughput: 4944.352
    learn_time_ms: 9.708
    update_time_ms: 2.915
  timestamp: 1629281922
  timesteps_since_restore: 0
  timesteps_total: 97000
  training_iteration: 97
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     97 |           1239.5 | 97000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 98000
  custom_metrics: {}
  date: 2021-08-18_10-18-58
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 97768
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 14.869032859802246
          max_q: 2360649.25
          mean_q: 1682812.0
          mean_td_error: -3456025.0
          min_q: 1.309729814529419
        model: {}
        td_error: "[-4.8941790e+06 -4.8941790e+06 -4.8941790e+06 -4.8941790e+06\n  1.7735827e-01\
          \ -4.8941790e+06  8.5312605e-02 -4.8941790e+06\n -4.8941790e+06 -4.8941790e+06\
          \ -4.8941790e+06 -2.5699139e-02\n -3.1903744e-02  4.1193008e-02 -4.8941790e+06\
          \ -4.8941790e+06\n -5.7303071e-02  9.4080329e-02 -4.8941790e+06 -4.8941790e+06\n\
          \  3.2312298e-01 -4.8941790e+06 -4.8941790e+06 -4.8941790e+06\n -4.8941790e+06\
          \ -4.8941790e+06 -4.8941790e+06  5.1288319e+05\n -4.8941790e+06 -4.8941790e+06\
          \  2.5929427e-01 -4.8941790e+06\n -4.8941790e+06  1.1756182e-02 -1.2517011e-01\
          \ -4.8941790e+06\n -4.8941790e+06 -4.8941790e+06 -4.8941790e+06 -4.8941790e+06\n\
          \ -4.8941790e+06 -1.9986081e-01 -4.8941790e+06  5.5279732e-02\n -4.8941790e+06\
          \ -4.8941790e+06 -4.8941790e+06 -4.8941790e+06]"
    num_agent_steps_sampled: 98000
    num_agent_steps_trained: 1164048
    num_steps_sampled: 98000
    num_steps_trained: 1164048
    num_target_updates: 193
  iterations_since_restore: 98
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.570833333333326
    ram_util_percent: 31.8125
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1256.058694601059
  time_this_iter_s: 16.561074018478394
  time_total_s: 1256.058694601059
  timers:
    learn_throughput: 4867.876
    learn_time_ms: 9.861
    update_time_ms: 2.963
  timestamp: 1629281938
  timesteps_since_restore: 0
  timesteps_total: 98000
  training_iteration: 98
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     98 |          1256.06 | 98000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 99000
  custom_metrics: {}
  date: 2021-08-18_10-19-15
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 98776
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12.584115028381348
          max_q: 2491774.0
          mean_q: 1562210.375
          mean_td_error: -2820916.0
          min_q: 1.3097761869430542
        model: {}
        td_error: "[-4.7630540e+06 -4.7630540e+06 -5.8004618e-02  5.4492112e+05\n  5.4492112e+05\
          \ -2.2054076e-01  2.6468420e-01 -4.7630540e+06\n -4.7630540e+06  1.2932622e-01\
          \ -4.7630540e+06 -7.0492947e-01\n  2.7161324e-01  5.4492112e+05 -4.7630540e+06\
          \ -4.7630540e+06\n -6.9280028e-02 -4.7630540e+06 -4.7630540e+06 -4.7630540e+06\n\
          \ -4.7630540e+06  2.5634027e-01 -4.7630540e+06 -4.7630540e+06\n -4.7630540e+06\
          \ -4.7630540e+06 -4.7630540e+06 -4.7630540e+06\n -4.7630540e+06 -4.7630540e+06\
          \ -4.7630540e+06 -1.3402224e-02\n  1.3523006e-01  5.4692376e-01 -4.7630540e+06\
          \  5.4492112e+05\n -4.7630540e+06 -4.7630540e+06 -4.7630540e+06 -4.7630540e+06\n\
          \ -4.7630540e+06  6.3227296e-02 -4.7630540e+06 -4.7630540e+06\n  1.0824084e-01\
          \ -4.7630540e+06 -4.3236971e-02  5.4492112e+05]"
    num_agent_steps_sampled: 99000
    num_agent_steps_trained: 1176048
    num_steps_sampled: 99000
    num_steps_trained: 1176048
    num_target_updates: 195
  iterations_since_restore: 99
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.13478260869565
    ram_util_percent: 31.89999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1272.2470812797546
  time_this_iter_s: 16.18838667869568
  time_total_s: 1272.2470812797546
  timers:
    learn_throughput: 4856.849
    learn_time_ms: 9.883
    update_time_ms: 3.034
  timestamp: 1629281955
  timesteps_since_restore: 0
  timesteps_total: 99000
  training_iteration: 99
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |    ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |     99 |          1272.25 | 99000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+-------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 100000
  custom_metrics: {}
  date: 2021-08-18_10-19-33
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 99784
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 15.73129653930664
          max_q: 2626587.75
          mean_q: 1884556.0
          mean_td_error: -3254281.75
          min_q: 1.2027900218963623
        model: {}
        td_error: "[-4.6282410e+06 -4.6282410e+06 -4.7444987e-01 -4.6282410e+06\n -4.6282410e+06\
          \ -4.6282410e+06  7.8292370e-02 -4.6282410e+06\n -4.6282410e+06  9.5218062e-02\
          \ -4.6282410e+06 -4.6282410e+06\n -4.6282410e+06 -4.6282410e+06 -4.6282410e+06\
          \ -4.6282410e+06\n -4.6282410e+06  1.5067005e-01 -4.6282410e+06 -4.6282410e+06\n\
          \ -4.6282410e+06 -4.6282410e+06 -4.6282410e+06  9.6143365e-02\n -4.6282410e+06\
          \ -4.3169141e-02 -4.6282410e+06 -4.6282410e+06\n -4.6282410e+06  2.1317911e-01\
          \ -4.6282410e+06 -4.6282410e+06\n  5.3599954e-02 -4.6282410e+06 -4.6282410e+06\
          \ -3.0538726e-01\n -4.6282410e+06  1.9157374e-01 -1.2423742e-01 -4.6282410e+06\n\
          \ -4.6282410e+06 -4.6282410e+06  5.7734012e+05  5.7734012e+05\n -4.6282410e+06\
          \ -4.6282410e+06 -8.0811143e-02 -4.6282410e+06]"
    num_agent_steps_sampled: 100000
    num_agent_steps_trained: 1188048
    num_steps_sampled: 100000
    num_steps_trained: 1188048
    num_target_updates: 197
  iterations_since_restore: 100
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.8
    ram_util_percent: 31.90384615384615
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1290.5435581207275
  time_this_iter_s: 18.2964768409729
  time_total_s: 1290.5435581207275
  timers:
    learn_throughput: 4675.935
    learn_time_ms: 10.265
    update_time_ms: 3.184
  timestamp: 1629281973
  timesteps_since_restore: 0
  timesteps_total: 100000
  training_iteration: 100
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    100 |          1290.54 | 100000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 101000
  custom_metrics: {}
  date: 2021-08-18_10-19-51
  done: false
  episode_len_mean: 6382.214285714285
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1554438.7729301075
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 100792
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12.611682891845703
          max_q: 2775181.0
          mean_q: 1613129.375
          mean_td_error: -2467712.25
          min_q: 1.1366136074066162
        model: {}
        td_error: "[-4.47964700e+06  1.85715914e-01 -4.47964700e+06  1.32455707e-01\n\
          \ -4.47964700e+06 -5.66838980e-02 -4.47964700e+06 -5.57186604e-02\n -4.47964700e+06\
          \ -4.47964700e+06  8.03468227e-02  4.99062538e-02\n -4.47964700e+06 -4.47964700e+06\
          \  1.38242245e-02  1.14409924e-02\n  7.70783424e-03 -4.47964700e+06 -4.47964700e+06\
          \  8.26959610e-02\n -4.47964700e+06 -4.47964700e+06 -4.47964700e+06 -4.47964700e+06\n\
          \ -3.29623222e-02 -4.47964700e+06 -4.47964700e+06 -4.47964700e+06\n -4.47964700e+06\
          \ -4.16858315e-01  6.25070375e+05  7.33007193e-02\n -1.21612072e-01 -4.47964700e+06\
          \ -4.47964700e+06 -4.47964700e+06\n -4.47964700e+06  6.25070375e+05  6.25070375e+05\
          \ -2.20923185e-01\n -4.47964700e+06  6.25070375e+05 -4.47964700e+06 -4.47964700e+06\n\
          \ -4.47964700e+06  4.66026068e-02 -4.47964700e+06  1.89720988e-01]"
    num_agent_steps_sampled: 101000
    num_agent_steps_trained: 1200048
    num_steps_sampled: 101000
    num_steps_trained: 1200048
    num_target_updates: 199
  iterations_since_restore: 101
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.46153846153847
    ram_util_percent: 31.95384615384615
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04913870678582753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.906038130895014
    mean_inference_ms: 1.5752291721104947
    mean_raw_obs_processing_ms: 0.14242221983813852
  time_since_restore: 1308.0262756347656
  time_this_iter_s: 17.482717514038086
  time_total_s: 1308.0262756347656
  timers:
    learn_throughput: 4706.454
    learn_time_ms: 10.199
    update_time_ms: 2.892
  timestamp: 1629281991
  timesteps_since_restore: 0
  timesteps_total: 101000
  training_iteration: 101
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    101 |          1308.03 | 101000 | 1.55444e+06 |          7.25468e+06 |             -198.044 |            6382.21 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 102000
  custom_metrics: {}
  date: 2021-08-18_10-20-05
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 101800
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 16.224695205688477
          max_q: 2924881.25
          mean_q: 2052820.0
          mean_td_error: -2934874.5
          min_q: 1.0838699340820312
        model: {}
        td_error: "[ 2.6978624e-01  6.7141819e+05 -4.3299460e+06 -4.3299460e+06\n -4.3299460e+06\
          \ -4.3299460e+06 -4.3299460e+06 -4.3299460e+06\n  6.7141819e+05 -4.3299460e+06\
          \ -4.3299460e+06 -4.3299460e+06\n -4.8530102e-04  7.7980638e-02 -4.3299460e+06\
          \ -4.3299460e+06\n -4.3299460e+06  2.1791732e-01 -4.3299460e+06  1.5994680e-01\n\
          \ -3.7348509e-02  2.3614442e-01 -4.3299460e+06 -4.3299460e+06\n -4.3299460e+06\
          \ -8.5160255e-02  6.7141819e+05 -4.3299460e+06\n -4.3299460e+06  1.9974351e-02\
          \ -4.3299460e+06 -4.3299460e+06\n -4.3299460e+06 -4.3299460e+06 -4.3299460e+06\
          \ -4.3299460e+06\n -9.8393559e-02 -4.3299460e+06 -4.3299460e+06 -4.3299460e+06\n\
          \ -4.3299460e+06 -4.3299460e+06  2.0692456e-01 -4.3299460e+06\n -4.3299460e+06\
          \ -1.7069578e-03 -4.3299460e+06 -4.3299460e+06]"
    num_agent_steps_sampled: 102000
    num_agent_steps_trained: 1212048
    num_steps_sampled: 102000
    num_steps_trained: 1212048
    num_target_updates: 201
  iterations_since_restore: 102
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.82500000000001
    ram_util_percent: 31.90499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1321.9175922870636
  time_this_iter_s: 13.891316652297974
  time_total_s: 1321.9175922870636
  timers:
    learn_throughput: 4966.147
    learn_time_ms: 9.665
    update_time_ms: 2.587
  timestamp: 1629282005
  timesteps_since_restore: 0
  timesteps_total: 102000
  training_iteration: 102
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    102 |          1321.92 | 102000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 103000
  custom_metrics: {}
  date: 2021-08-18_10-20-16
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 102808
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 15.41361141204834
          max_q: 3074533.0
          mean_q: 1951342.75
          mean_td_error: -2582925.0
          min_q: 0.9455355405807495
        model: {}
        td_error: "[ 7.1421662e+05  2.9873300e-01 -4.1802945e+06 -4.1802945e+06\n -4.1802945e+06\
          \  7.1421662e+05 -4.1802945e+06 -4.1802945e+06\n -4.1802945e+06 -1.8234265e-01\
          \ -4.1802945e+06  1.2364280e-01\n -4.1802945e+06 -4.1802945e+06 -4.1802945e+06\
          \ -4.1802945e+06\n -4.7668338e-02 -4.1802945e+06  5.1142931e-02  2.3790318e-01\n\
          \ -4.1802945e+06 -1.8111873e-01 -4.1802945e+06  1.1163044e-01\n -6.5853834e-02\
          \  9.9212527e-02 -4.1802945e+06 -4.1802945e+06\n  7.9550207e-02 -4.1802945e+06\
          \ -2.6690733e-01 -4.1802945e+06\n -4.1802945e+06 -4.1802945e+06 -4.1802945e+06\
          \ -4.1802945e+06\n  3.1953573e-02 -4.1802945e+06 -4.1802945e+06 -4.1802945e+06\n\
          \  1.2400389e-01 -4.1802945e+06 -4.1802945e+06  9.5507145e-02\n -4.1802945e+06\
          \ -4.1802945e+06 -4.4825375e-02 -4.1802945e+06]"
    num_agent_steps_sampled: 103000
    num_agent_steps_trained: 1224048
    num_steps_sampled: 103000
    num_steps_trained: 1224048
    num_target_updates: 203
  iterations_since_restore: 103
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.0625
    ram_util_percent: 31.80625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1332.9348011016846
  time_this_iter_s: 11.017208814620972
  time_total_s: 1332.9348011016846
  timers:
    learn_throughput: 4958.881
    learn_time_ms: 9.68
    update_time_ms: 2.908
  timestamp: 1629282016
  timesteps_since_restore: 0
  timesteps_total: 103000
  training_iteration: 103
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    103 |          1332.93 | 103000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 104000
  custom_metrics: {}
  date: 2021-08-18_10-20-29
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 103816
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 13.378677368164062
          max_q: 3225733.0
          mean_q: 1825980.75
          mean_td_error: -2103718.5
          min_q: 0.8173639178276062
        model: {}
        td_error: "[-4.0290945e+06 -4.0290945e+06 -4.0290945e+06 -8.2864106e-02\n -4.0290945e+06\
          \  1.5322244e-01  4.0388703e-02 -4.0290945e+06\n  7.5559512e+05 -4.0290945e+06\
          \  3.0047995e-01 -4.0290945e+06\n -5.2709222e-02 -4.0290945e+06 -1.4252532e-01\
          \ -2.2267866e-01\n -4.0290945e+06 -4.0290945e+06  1.0405731e-01  7.5559512e+05\n\
          \ -4.0290945e+06 -4.0290945e+06  7.5559512e+05 -4.0290945e+06\n  3.0870652e-01\
          \  7.5559512e+05 -2.8811097e-02  7.5559512e+05\n -4.0290945e+06 -4.0290945e+06\
          \ -4.0290945e+06 -4.0290945e+06\n -4.0290945e+06  2.0797551e-02 -4.0290945e+06\
          \ -1.3755202e-02\n -4.0290945e+06 -4.0290945e+06 -4.0290945e+06 -4.0290945e+06\n\
          \  5.0981343e-02 -2.0029759e-01  1.1718249e-01 -4.0290945e+06\n -4.0290945e+06\
          \ -4.0290945e+06 -2.0458114e-01 -5.5469096e-02]"
    num_agent_steps_sampled: 104000
    num_agent_steps_trained: 1236048
    num_steps_sampled: 104000
    num_steps_trained: 1236048
    num_target_updates: 205
  iterations_since_restore: 104
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.66111111111111
    ram_util_percent: 31.811111111111106
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1345.5751004219055
  time_this_iter_s: 12.640299320220947
  time_total_s: 1345.5751004219055
  timers:
    learn_throughput: 4692.129
    learn_time_ms: 10.23
    update_time_ms: 2.882
  timestamp: 1629282029
  timesteps_since_restore: 0
  timesteps_total: 104000
  training_iteration: 104
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    104 |          1345.58 | 104000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 105000
  custom_metrics: {}
  date: 2021-08-18_10-20-43
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 104824
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 18.445934295654297
          max_q: 3380681.0
          mean_q: 2340816.0
          mean_td_error: -2646878.5
          min_q: 0.9414954781532288
        model: {}
        td_error: "[-3.8741465e+06 -3.8741465e+06  1.1038607e-01  1.5659636e-01\n -3.8741465e+06\
          \ -3.8741465e+06 -3.8741465e+06  7.9667119e+05\n -2.0227003e-01  2.3613209e-01\
          \ -9.0471721e-01 -3.8741465e+06\n -3.8741465e+06 -3.8741465e+06  1.1962372e-01\
          \  5.4617524e-03\n -3.8741465e+06 -3.8741465e+06  1.4691395e-01  1.9855845e-01\n\
          \ -3.8741465e+06 -3.8741465e+06 -3.8741465e+06 -3.8741465e+06\n -3.8741465e+06\
          \  1.2032437e-01 -3.8741465e+06 -1.4122856e-01\n  1.6715306e-01 -3.8741465e+06\
          \ -3.8741465e+06 -3.8741465e+06\n -3.8741465e+06 -3.8741465e+06 -3.8741465e+06\
          \ -3.8741465e+06\n  3.7972903e-01 -3.8741465e+06 -3.8741465e+06 -3.8741465e+06\n\
          \ -3.8741465e+06 -2.1827793e-01 -3.8741465e+06 -3.8741465e+06\n -3.8741465e+06\
          \ -3.8741465e+06 -3.8741465e+06 -3.8741465e+06]"
    num_agent_steps_sampled: 105000
    num_agent_steps_trained: 1248048
    num_steps_sampled: 105000
    num_steps_trained: 1248048
    num_target_updates: 207
  iterations_since_restore: 105
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.32631578947369
    ram_util_percent: 31.799999999999997
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1358.9378759860992
  time_this_iter_s: 13.362775564193726
  time_total_s: 1358.9378759860992
  timers:
    learn_throughput: 4672.018
    learn_time_ms: 10.274
    update_time_ms: 3.061
  timestamp: 1629282043
  timesteps_since_restore: 0
  timesteps_total: 105000
  training_iteration: 105
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    105 |          1358.94 | 105000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 106000
  custom_metrics: {}
  date: 2021-08-18_10-20-56
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 105832
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 16.28922462463379
          max_q: 3537148.5
          mean_q: 2189399.5
          mean_td_error: -2193726.0
          min_q: 0.8596998453140259
        model: {}
        td_error: "[ 8.82503986e-02 -1.50826633e-01 -3.71767900e+06 -3.71767900e+06\n\
          \ -3.71767900e+06 -1.10589504e-01  1.45618260e-01  8.37947625e+05\n  9.54702497e-02\
          \ -3.71767900e+06  1.34613633e-01 -3.71767900e+06\n  8.37947625e+05 -3.71767900e+06\
          \ -3.71767900e+06 -3.71767900e+06\n  3.64088595e-01 -1.15631819e-02 -3.71767900e+06\
          \ -3.71767900e+06\n -3.71767900e+06 -3.71767900e+06 -3.71767900e+06 -3.71767900e+06\n\
          \ -2.89026797e-01 -3.71767900e+06 -6.42118454e-02 -4.07653809e-01\n  4.91699576e-02\
          \  8.37947625e+05 -3.71767900e+06  2.50175893e-01\n -3.71767900e+06 -3.71767900e+06\
          \ -3.71767900e+06 -3.71767900e+06\n -7.27351308e-02 -3.71767900e+06 -3.71767900e+06\
          \ -3.71767900e+06\n  7.98719525e-02  1.64567649e-01 -3.71767900e+06 -3.71767900e+06\n\
          \ -3.71767900e+06 -3.71767900e+06 -3.71767900e+06 -3.71767900e+06]"
    num_agent_steps_sampled: 106000
    num_agent_steps_trained: 1260048
    num_steps_sampled: 106000
    num_steps_trained: 1260048
    num_target_updates: 209
  iterations_since_restore: 106
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.43157894736842
    ram_util_percent: 31.80526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1371.7994270324707
  time_this_iter_s: 12.86155104637146
  time_total_s: 1371.7994270324707
  timers:
    learn_throughput: 5007.85
    learn_time_ms: 9.585
    update_time_ms: 2.963
  timestamp: 1629282056
  timesteps_since_restore: 0
  timesteps_total: 106000
  training_iteration: 106
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    106 |           1371.8 | 106000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 107000
  custom_metrics: {}
  date: 2021-08-18_10-21-10
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 106840
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 19.11216163635254
          max_q: 3706777.5
          mean_q: 2622060.75
          mean_td_error: -2365637.5
          min_q: 0.8982825875282288
        model: {}
        td_error: "[ 8.83799750e+05 -1.32231712e-01 -3.54805450e+06 -3.54805450e+06\n\
          \ -3.54805450e+06 -3.54805450e+06 -3.54805450e+06 -3.54805450e+06\n  8.83799750e+05\
          \ -3.54805450e+06 -3.54805450e+06 -3.54805450e+06\n -3.54805450e+06 -3.54805450e+06\
          \ -3.54805450e+06 -3.54805450e+06\n -3.54805450e+06 -1.05807900e-01 -3.54805450e+06\
          \ -3.54805450e+06\n -1.58806980e-01 -3.54805450e+06 -3.54805450e+06 -3.54805450e+06\n\
          \ -3.54805450e+06  1.19976819e-01  1.17810845e-01  1.99976563e-02\n -3.54805450e+06\
          \ -1.13371313e-01 -3.54805450e+06 -3.54805450e+06\n -3.54805450e+06 -3.54805450e+06\
          \ -5.81642985e-02  8.83799750e+05\n -3.54805450e+06 -3.54805450e+06  8.83799750e+05\
          \ -3.54805450e+06\n  1.60906971e-01 -3.54805450e+06 -3.54805450e+06  2.73597360e-01\n\
          \ -2.60817409e-02 -3.54805450e+06 -3.54805450e+06 -3.54805450e+06]"
    num_agent_steps_sampled: 107000
    num_agent_steps_trained: 1272048
    num_steps_sampled: 107000
    num_steps_trained: 1272048
    num_target_updates: 211
  iterations_since_restore: 107
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.45714285714287
    ram_util_percent: 31.87142857142857
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1386.3327414989471
  time_this_iter_s: 14.53331446647644
  time_total_s: 1386.3327414989471
  timers:
    learn_throughput: 4769.427
    learn_time_ms: 10.064
    update_time_ms: 2.768
  timestamp: 1629282070
  timesteps_since_restore: 0
  timesteps_total: 107000
  training_iteration: 107
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    107 |          1386.33 | 107000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 108000
  custom_metrics: {}
  date: 2021-08-18_10-21-25
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 107848
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 21.49680519104004
          max_q: 3879825.0
          mean_q: 2867806.75
          mean_td_error: -2422175.25
          min_q: 0.8821969628334045
        model: {}
        td_error: "[-3.3750065e+06 -3.3750065e+06  5.3563178e-02  3.2860219e-02\n -3.3750065e+06\
          \ -3.3750065e+06 -3.3750065e+06 -3.3750065e+06\n  9.3040994e+05 -3.3750065e+06\
          \  2.1577370e-01 -3.3750065e+06\n  9.3040994e+05 -1.4223367e-01 -3.3750065e+06\
          \ -3.3750065e+06\n -3.3750065e+06 -3.3750065e+06 -3.3750065e+06 -3.3750065e+06\n\
          \ -5.3262591e-02 -3.3750065e+06  2.1537423e-02 -3.3750065e+06\n -3.3750065e+06\
          \ -3.3750065e+06 -3.3750065e+06 -3.3750065e+06\n  3.5979509e-02  2.4645281e-01\
          \ -3.3750065e+06 -3.3750065e+06\n -6.7770481e-03 -3.3750065e+06 -3.3750065e+06\
          \ -3.3750065e+06\n -3.3750065e+06  1.0578251e-01 -3.3750065e+06 -3.3750065e+06\n\
          \ -3.3750065e+06 -3.3750065e+06 -3.3750065e+06 -3.3750065e+06\n -3.3750065e+06\
          \ -3.3750065e+06  1.9472325e-01 -3.3750065e+06]"
    num_agent_steps_sampled: 108000
    num_agent_steps_trained: 1284048
    num_steps_sampled: 108000
    num_steps_trained: 1284048
    num_target_updates: 213
  iterations_since_restore: 108
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.97142857142857
    ram_util_percent: 31.904761904761898
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1400.8228368759155
  time_this_iter_s: 14.490095376968384
  time_total_s: 1400.8228368759155
  timers:
    learn_throughput: 4631.274
    learn_time_ms: 10.364
    update_time_ms: 3.022
  timestamp: 1629282085
  timesteps_since_restore: 0
  timesteps_total: 108000
  training_iteration: 108
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    108 |          1400.82 | 108000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 109000
  custom_metrics: {}
  date: 2021-08-18_10-21-40
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 108856
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 19.019676208496094
          max_q: 4051467.0
          mean_q: 2572780.75
          mean_td_error: -1961489.75
          min_q: 0.696864902973175
        model: {}
        td_error: "[-1.0440824e+00 -3.2033645e+06 -3.2033645e+06 -1.6959918e-01\n -3.2033645e+06\
          \ -3.2033645e+06  3.2062352e-02  2.9232681e-02\n -3.2033645e+06 -4.0916204e-02\
          \  3.6198825e-01  9.0516210e-02\n -3.2033645e+06 -3.2033645e+06 -3.2033645e+06\
          \ -3.2033645e+06\n -3.2033645e+06 -3.2033645e+06 -3.2033645e+06 -3.2033645e+06\n\
          \ -3.2033645e+06 -3.2033645e+06 -1.7074901e-01 -3.2033645e+06\n -3.2033645e+06\
          \ -3.2033645e+06 -3.2033645e+06 -2.2184134e-01\n -3.2033645e+06 -3.2033645e+06\
          \ -3.2033645e+06 -4.7069412e-01\n -1.3587552e-01 -3.2033645e+06 -3.2033645e+06\
          \ -3.2033645e+06\n  3.4726441e-02 -3.2033645e+06  9.7471469e+05 -1.7735505e-01\n\
          \  2.9630065e-03 -3.2033645e+06 -3.8939077e-01 -3.2033645e+06\n -7.0758283e-02\
          \ -3.2033645e+06 -3.2033645e+06  9.7471469e+05]"
    num_agent_steps_sampled: 109000
    num_agent_steps_trained: 1296048
    num_steps_sampled: 109000
    num_steps_trained: 1296048
    num_target_updates: 215
  iterations_since_restore: 109
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.78095238095237
    ram_util_percent: 31.904761904761898
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1415.5275869369507
  time_this_iter_s: 14.704750061035156
  time_total_s: 1415.5275869369507
  timers:
    learn_throughput: 4876.306
    learn_time_ms: 9.844
    update_time_ms: 2.914
  timestamp: 1629282100
  timesteps_since_restore: 0
  timesteps_total: 109000
  training_iteration: 109
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    109 |          1415.53 | 109000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 110000
  custom_metrics: {}
  date: 2021-08-18_10-21-55
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 109864
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 26.047727584838867
          max_q: 4223100.5
          mean_q: 3452461.5
          mean_td_error: -2442087.0
          min_q: 0.7861129641532898
        model: {}
        td_error: "[-3.0317280e+06 -3.0317280e+06 -3.0317280e+06 -3.0317280e+06\n -3.0317280e+06\
          \ -3.0317280e+06 -3.0317280e+06 -3.0317280e+06\n -3.0317280e+06 -3.0317280e+06\
          \ -3.0317280e+06 -3.0317280e+06\n  8.9118898e-02 -3.0317280e+06 -3.0317280e+06\
          \ -3.0317280e+06\n -5.8113813e-02 -3.0317280e+06  1.5523624e-01 -3.0317280e+06\n\
          \  1.0172189e+06  2.0345503e-01 -3.0317280e+06 -3.0317280e+06\n -3.0317280e+06\
          \ -3.0317280e+06 -2.0517111e-01 -3.0317280e+06\n -3.0317280e+06 -3.0317280e+06\
          \ -9.3222022e-02 -3.0317280e+06\n -3.0317280e+06 -3.0317280e+06 -3.0317280e+06\
          \ -3.0317280e+06\n -3.0317280e+06 -3.0317280e+06 -3.0317280e+06 -3.0317280e+06\n\
          \ -3.0317280e+06 -3.0317280e+06 -8.2648933e-02 -3.0317280e+06\n -3.0317280e+06\
          \ -3.0317280e+06  1.6881770e-01 -3.0317280e+06]"
    num_agent_steps_sampled: 110000
    num_agent_steps_trained: 1308048
    num_steps_sampled: 110000
    num_steps_trained: 1308048
    num_target_updates: 217
  iterations_since_restore: 110
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.286363636363646
    ram_util_percent: 31.90454545454545
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1430.788634777069
  time_this_iter_s: 15.261047840118408
  time_total_s: 1430.788634777069
  timers:
    learn_throughput: 4694.854
    learn_time_ms: 10.224
    update_time_ms: 3.123
  timestamp: 1629282115
  timesteps_since_restore: 0
  timesteps_total: 110000
  training_iteration: 110
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    110 |          1430.79 | 110000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 111000
  custom_metrics: {}
  date: 2021-08-18_10-22-11
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 110872
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 21.544511795043945
          max_q: 4391772.5
          mean_q: 2994075.5
          mean_td_error: -1842477.25
          min_q: 0.7367109060287476
        model: {}
        td_error: "[-1.5952098e-01  1.0596226e+06 -7.7836156e-02 -2.7283692e-01\n -2.8630555e+06\
          \ -2.8630555e+06 -2.8630555e+06 -2.8630555e+06\n -2.8630555e+06  1.0596226e+06\
          \  1.6472906e-01 -2.8630555e+06\n -2.8630555e+06 -2.8630555e+06  6.2929213e-02\
          \ -2.8630555e+06\n  1.0596226e+06 -1.4710158e-01 -2.8630555e+06 -2.8630555e+06\n\
          \  1.3284230e-01 -2.8630555e+06 -2.8630555e+06 -2.8630555e+06\n  8.0326319e-02\
          \ -2.8630555e+06 -2.8630555e+06 -2.8630555e+06\n -2.8630555e+06 -2.8630555e+06\
          \ -2.8630555e+06 -2.8630555e+06\n -2.8630555e+06 -2.8630555e+06  1.8398708e-01\
          \ -2.8630555e+06\n  2.3604631e-02 -2.8630555e+06  5.9408545e-03 -2.8630555e+06\n\
          \ -2.8630555e+06 -2.8630555e+06 -2.8630555e+06  2.3903960e-01\n -2.8630555e+06\
          \ -2.8630555e+06 -2.8630555e+06 -9.8072648e-02]"
    num_agent_steps_sampled: 111000
    num_agent_steps_trained: 1320048
    num_steps_sampled: 111000
    num_steps_trained: 1320048
    num_target_updates: 219
  iterations_since_restore: 111
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.39545454545455
    ram_util_percent: 31.909090909090903
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1446.5042383670807
  time_this_iter_s: 15.715603590011597
  time_total_s: 1446.5042383670807
  timers:
    learn_throughput: 4854.214
    learn_time_ms: 9.888
    update_time_ms: 2.99
  timestamp: 1629282131
  timesteps_since_restore: 0
  timesteps_total: 111000
  training_iteration: 111
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    111 |           1446.5 | 111000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 112000
  custom_metrics: {}
  date: 2021-08-18_10-22-28
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 111880
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 19.813983917236328
          max_q: 4568744.0
          mean_q: 2875104.5
          mean_td_error: -1508022.875
          min_q: 0.8615737557411194
        model: {}
        td_error: "[-2.6860855e+06 -2.6860855e+06  9.5750690e-02  6.5924764e-02\n -2.6860855e+06\
          \ -1.5640736e-02 -2.6203001e-01 -2.6860855e+06\n -2.6860855e+06 -2.6860855e+06\
          \  1.1022768e+06 -1.4731580e-01\n -2.6860855e+06 -2.6860855e+06 -2.3176223e-01\
          \ -2.6860855e+06\n -2.6860855e+06 -2.6860855e+06  1.1022768e+06  1.1022768e+06\n\
          \  2.1256965e-01  1.1022768e+06  2.2937512e-01 -2.6860855e+06\n -2.6860855e+06\
          \ -2.6860855e+06 -2.6860855e+06 -2.6860855e+06\n -2.6860855e+06  9.3263984e-03\
          \ -1.0480219e-01  1.1022768e+06\n -2.3153305e-01 -2.6860855e+06 -2.6860855e+06\
          \ -2.6860855e+06\n -2.6860855e+06 -2.6860855e+06 -2.6860855e+06  2.1657121e-01\n\
          \ -2.6860855e+06 -2.6860855e+06 -8.3474517e-03 -2.6860855e+06\n -2.6860855e+06\
          \ -2.6860855e+06  2.7876395e-01 -2.6860855e+06]"
    num_agent_steps_sampled: 112000
    num_agent_steps_trained: 1332048
    num_steps_sampled: 112000
    num_steps_trained: 1332048
    num_target_updates: 221
  iterations_since_restore: 112
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.725
    ram_util_percent: 31.904166666666665
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1462.6746261119843
  time_this_iter_s: 16.170387744903564
  time_total_s: 1462.6746261119843
  timers:
    learn_throughput: 4616.576
    learn_time_ms: 10.397
    update_time_ms: 2.981
  timestamp: 1629282148
  timesteps_since_restore: 0
  timesteps_total: 112000
  training_iteration: 112
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    112 |          1462.67 | 112000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 113000
  custom_metrics: {}
  date: 2021-08-18_10-22-44
  done: false
  episode_len_mean: 6758.8
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 1934453.5702562192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 15
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 112888
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 21.688671112060547
          max_q: 4746401.5
          mean_q: 3038022.0
          mean_td_error: -1496246.0
          min_q: 0.8344747424125671
        model: {}
        td_error: "[-2.50842650e+06 -2.50842650e+06 -2.50842650e+06 -2.50842650e+06\n\
          \  6.69914484e-02 -2.50842650e+06 -1.73580825e-01 -2.50842650e+06\n -7.53840208e-02\
          \ -2.50842650e+06 -2.50842650e+06 -4.70079780e-02\n  1.14432812e+06 -1.90135241e-01\
          \ -2.50842650e+06 -2.50842650e+06\n -2.50842650e+06 -2.50842650e+06 -2.50842650e+06\
          \ -2.50842650e+06\n -2.50842650e+06 -2.50842650e+06 -2.50842650e+06 -1.03243291e-01\n\
          \ -2.50842650e+06 -2.50842650e+06 -1.79879189e-01 -2.50842650e+06\n -2.50842650e+06\
          \ -1.26039803e-01 -2.50842650e+06  1.14432812e+06\n -2.50842650e+06  8.64527822e-02\
          \ -1.10895276e-01 -2.50842650e+06\n  1.74803436e-01 -1.88655853e-02  1.47000611e-01\
          \  1.21892631e-01\n  3.22335005e-01 -2.50842650e+06 -2.50842650e+06 -2.50842650e+06\n\
          \  1.14432812e+06 -2.50842650e+06 -2.50842650e+06 -2.50842650e+06]"
    num_agent_steps_sampled: 113000
    num_agent_steps_trained: 1344048
    num_steps_sampled: 113000
    num_steps_trained: 1344048
    num_target_updates: 223
  iterations_since_restore: 113
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.1625
    ram_util_percent: 31.933333333333334
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04915359161134978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.937647182862674
    mean_inference_ms: 1.5762420006480786
    mean_raw_obs_processing_ms: 0.14254411097220057
  time_since_restore: 1479.3408408164978
  time_this_iter_s: 16.66621470451355
  time_total_s: 1479.3408408164978
  timers:
    learn_throughput: 4604.413
    learn_time_ms: 10.425
    update_time_ms: 3.022
  timestamp: 1629282164
  timesteps_since_restore: 0
  timesteps_total: 113000
  training_iteration: 113
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    113 |          1479.34 | 113000 | 1.93445e+06 |          7.25468e+06 |             -198.044 |             6758.8 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 114000
  custom_metrics: {}
  date: 2021-08-18_10-22-58
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 113896
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 29.74930191040039
          max_q: 4944558.0
          mean_q: 3914442.0
          mean_td_error: -1828963.375
          min_q: 0.8542490601539612
        model: {}
        td_error: "[-2.3102695e+06 -2.3102695e+06 -2.3102695e+06  1.6017556e-02\n  9.3555868e-02\
          \ -2.3102695e+06 -2.3102695e+06 -2.3102695e+06\n -2.3102695e+06 -2.3102695e+06\
          \ -2.3102695e+06 -2.3102695e+06\n -2.3102695e+06 -2.3102695e+06 -2.3102695e+06\
          \ -2.3102695e+06\n -2.3102695e+06 -2.3102695e+06 -2.3102695e+06 -2.3102695e+06\n\
          \ -3.3642292e-02 -1.0155201e-01 -2.3102695e+06 -1.7547643e-01\n -2.3102695e+06\
          \ -2.3102695e+06 -2.3102695e+06  2.1170402e-01\n -1.9322175e-01  1.1388564e-01\
          \ -2.3102695e+06 -2.3102695e+06\n -2.3102695e+06 -1.0721564e-02 -2.3102695e+06\
          \  2.5265414e-01\n -2.3102695e+06 -2.3102695e+06 -2.3102695e+06 -2.3102695e+06\n\
          \ -2.3102695e+06 -2.3102695e+06 -2.3102695e+06 -2.3102695e+06\n -2.3102695e+06\
          \ -2.3102695e+06 -2.3102695e+06 -2.3102695e+06]"
    num_agent_steps_sampled: 114000
    num_agent_steps_trained: 1356048
    num_steps_sampled: 114000
    num_steps_trained: 1356048
    num_target_updates: 225
  iterations_since_restore: 114
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.43684210526317
    ram_util_percent: 31.905263157894726
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1492.9458680152893
  time_this_iter_s: 13.605027198791504
  time_total_s: 1492.9458680152893
  timers:
    learn_throughput: 4905.678
    learn_time_ms: 9.785
    update_time_ms: 2.854
  timestamp: 1629282178
  timesteps_since_restore: 0
  timesteps_total: 114000
  training_iteration: 114
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    114 |          1492.95 | 114000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 115000
  custom_metrics: {}
  date: 2021-08-18_10-23-10
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 114904
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 29.45760726928711
          max_q: 5152565.5
          mean_q: 3864424.75
          mean_td_error: -1576696.5
          min_q: 0.8877293467521667
        model: {}
        td_error: "[-2.1022620e+06 -2.1022620e+06 -4.1137636e-02 -1.1604738e-01\n -2.1022620e+06\
          \  2.2165990e-01 -2.1022620e+06 -2.1022620e+06\n -2.1022620e+06 -2.1022620e+06\
          \  1.3973469e-01 -2.1022620e+06\n -2.1022620e+06 -2.1022620e+06  6.6949129e-02\
          \ -2.1022620e+06\n -1.6003752e-01 -2.1022620e+06 -2.1022620e+06  1.5842116e-01\n\
          \ -2.1022620e+06 -2.1022620e+06 -2.1022620e+06 -2.1022620e+06\n -2.1022620e+06\
          \ -2.1022620e+06 -2.1664202e-01 -2.1022620e+06\n -2.1022620e+06 -6.2532425e-02\
          \ -2.1022620e+06 -2.1022620e+06\n -5.7157099e-02 -2.1022620e+06 -2.1022620e+06\
          \ -2.1022620e+06\n -2.1022620e+06  2.0977616e-02 -2.1022620e+06 -2.1022620e+06\n\
          \ -2.1022620e+06 -2.1022620e+06 -2.1022620e+06 -2.1022620e+06\n -2.1022620e+06\
          \ -2.1022620e+06 -1.2780517e-01 -2.1022620e+06]"
    num_agent_steps_sampled: 115000
    num_agent_steps_trained: 1368048
    num_steps_sampled: 115000
    num_steps_trained: 1368048
    num_target_updates: 227
  iterations_since_restore: 115
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.88333333333334
    ram_util_percent: 31.811111111111106
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1504.9425647258759
  time_this_iter_s: 11.996696710586548
  time_total_s: 1504.9425647258759
  timers:
    learn_throughput: 3389.531
    learn_time_ms: 14.161
    update_time_ms: 5.685
  timestamp: 1629282190
  timesteps_since_restore: 0
  timesteps_total: 115000
  training_iteration: 115
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    115 |          1504.94 | 115000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 116000
  custom_metrics: {}
  date: 2021-08-18_10-23-23
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 115912
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 32.590335845947266
          max_q: 5366502.5
          mean_q: 4248481.5
          mean_td_error: -1494924.375
          min_q: 0.9516445398330688
        model: {}
        td_error: "[-1.8883255e+06 -1.8883255e+06  2.2008586e-01 -1.8883255e+06\n -1.8883255e+06\
          \ -1.8883255e+06 -1.8883255e+06 -1.8883255e+06\n -1.8883255e+06 -1.8883255e+06\
          \ -1.8883255e+06  1.8781936e-01\n -1.8883255e+06 -1.8883255e+06 -5.4817021e-02\
          \ -1.8883255e+06\n -1.8883255e+06 -1.8883255e+06 -1.8883255e+06 -1.8883255e+06\n\
          \ -1.8883255e+06 -1.8883255e+06 -1.8883255e+06 -1.8883255e+06\n -1.8883255e+06\
          \ -2.9993916e-01 -1.8883255e+06 -6.3900948e-02\n -1.8883255e+06 -1.8883255e+06\
          \  1.2925899e-01 -1.8883255e+06\n -1.8883255e+06 -1.8883255e+06  3.7102175e-01\
          \ -1.8883255e+06\n -1.8883255e+06 -1.8883255e+06 -1.8883255e+06  2.2306597e-01\n\
          \ -1.8883255e+06 -1.8883255e+06 -1.8883255e+06  9.4573438e-02\n -1.8883255e+06\
          \  2.8254128e-01 -1.8883255e+06 -1.8883255e+06]"
    num_agent_steps_sampled: 116000
    num_agent_steps_trained: 1380048
    num_steps_sampled: 116000
    num_steps_trained: 1380048
    num_target_updates: 229
  iterations_since_restore: 116
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.08235294117646
    ram_util_percent: 31.805882352941172
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1517.1991937160492
  time_this_iter_s: 12.25662899017334
  time_total_s: 1517.1991937160492
  timers:
    learn_throughput: 4872.353
    learn_time_ms: 9.852
    update_time_ms: 3.081
  timestamp: 1629282203
  timesteps_since_restore: 0
  timesteps_total: 116000
  training_iteration: 116
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    116 |           1517.2 | 116000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 117000
  custom_metrics: {}
  date: 2021-08-18_10-23-36
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 116920
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 30.61921501159668
          max_q: 5578800.5
          mean_q: 3951650.75
          mean_td_error: -1187186.125
          min_q: 0.6948364973068237
        model: {}
        td_error: "[ 2.4621475e-01  1.4767838e-01 -1.6760275e+06 -1.6760275e+06\n -1.6760275e+06\
          \ -1.6760275e+06  2.3241067e-01 -1.6760275e+06\n  6.2289774e-02 -1.8078297e-01\
          \ -1.6760275e+06 -1.6760275e+06\n -1.6760275e+06 -1.7005563e-02 -1.6760275e+06\
          \  2.1918720e-01\n -1.6760275e+06 -1.6760275e+06 -1.6760275e+06  9.3050718e-02\n\
          \ -1.6760275e+06 -4.0860713e-02 -1.6760275e+06 -1.6760275e+06\n -1.6760275e+06\
          \ -1.6760275e+06 -1.6760275e+06 -1.6760275e+06\n -1.6760275e+06 -1.6760275e+06\
          \ -1.6760275e+06 -1.5096223e-01\n  5.2611113e-02 -1.6760275e+06 -1.6760275e+06\
          \ -1.6760275e+06\n -1.6760275e+06 -1.6760275e+06 -1.6760275e+06 -1.6760275e+06\n\
          \  7.3107719e-02 -1.6760275e+06  9.1834366e-02 -1.6760275e+06\n  5.6842029e-02\
          \ -1.6760275e+06 -1.6760275e+06 -1.6760275e+06]"
    num_agent_steps_sampled: 117000
    num_agent_steps_trained: 1392048
    num_steps_sampled: 117000
    num_steps_trained: 1392048
    num_target_updates: 231
  iterations_since_restore: 117
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.5578947368421
    ram_util_percent: 31.810526315789467
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1529.9046490192413
  time_this_iter_s: 12.705455303192139
  time_total_s: 1529.9046490192413
  timers:
    learn_throughput: 4901.534
    learn_time_ms: 9.793
    update_time_ms: 2.891
  timestamp: 1629282216
  timesteps_since_restore: 0
  timesteps_total: 117000
  training_iteration: 117
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    117 |           1529.9 | 117000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 118000
  custom_metrics: {}
  date: 2021-08-18_10-23-51
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 117928
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 24.613691329956055
          max_q: 5783196.0
          mean_q: 3132565.0
          mean_td_error: -797133.6875
          min_q: 0.8041531443595886
        model: {}
        td_error: "[-1.4716315e+06  1.8971193e-01 -1.4716315e+06 -1.4716315e+06\n -3.4029019e-01\
          \ -1.1798024e-02 -1.4716315e+06 -1.4716315e+06\n -1.4716315e+06  2.4827141e-01\
          \ -1.4716315e+06 -1.4716315e+06\n -1.4716315e+06 -1.4716315e+06 -1.4716315e+06\
          \ -1.5147686e-01\n -1.4716315e+06  1.5805721e-01 -1.4716315e+06  1.1262226e-01\n\
          \  1.8929255e-01 -1.4716315e+06 -2.1852791e-01 -1.6509169e-01\n -1.4716315e+06\
          \  4.6260536e-01 -1.4716315e+06 -1.4716315e+06\n -1.4716315e+06  1.8182468e-01\
          \  1.2190825e-01 -9.2953980e-02\n -1.3805115e-01 -4.5600772e-02  3.8768470e-02\
          \  3.0095458e-02\n -1.4716315e+06 -1.7115635e-01 -1.4716315e+06 -1.4716315e+06\n\
          \ -1.9913161e-01 -1.4716315e+06 -1.4716315e+06 -1.4716315e+06\n -5.3659916e-02\
          \ -1.4716315e+06 -1.4716315e+06  1.2734538e-01]"
    num_agent_steps_sampled: 118000
    num_agent_steps_trained: 1404048
    num_steps_sampled: 118000
    num_steps_trained: 1404048
    num_target_updates: 233
  iterations_since_restore: 118
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.18095238095238
    ram_util_percent: 31.804761904761893
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1544.8371024131775
  time_this_iter_s: 14.932453393936157
  time_total_s: 1544.8371024131775
  timers:
    learn_throughput: 4962.609
    learn_time_ms: 9.672
    update_time_ms: 2.832
  timestamp: 1629282231
  timesteps_since_restore: 0
  timesteps_total: 118000
  training_iteration: 118
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    118 |          1544.84 | 118000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 119000
  custom_metrics: {}
  date: 2021-08-18_10-24-05
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 118936
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 28.966602325439453
          max_q: 5986608.0
          mean_q: 3616909.5
          mean_td_error: -766216.0
          min_q: 0.8827265501022339
        model: {}
        td_error: "[-1.9131941e-01 -1.2682195e+06 -9.2489743e-01 -1.2682195e+06\n -1.2682195e+06\
          \ -1.2682195e+06 -1.2682195e+06 -1.2682195e+06\n -1.2682195e+06 -1.2682195e+06\
          \ -1.2682195e+06 -1.2682195e+06\n -7.2153366e-01 -1.2682195e+06 -1.2682195e+06\
          \ -1.2682195e+06\n -7.7249146e-01 -1.2682195e+06 -1.2682195e+06 -3.1524777e-02\n\
          \ -3.1728446e-01 -1.2682195e+06 -1.2682195e+06 -1.2682195e+06\n -1.1720383e-01\
          \ -1.2682195e+06 -1.2682195e+06 -1.2682195e+06\n  1.4190245e-01 -6.1846018e-02\
          \ -1.2682195e+06 -2.5997019e-01\n -1.2682195e+06 -1.2682195e+06 -1.2682195e+06\
          \ -1.2682195e+06\n -1.1860591e-01  1.2848198e-01 -1.2682195e+06 -9.4795364e-01\n\
          \  2.0431024e-01 -1.3787603e-01 -1.2682195e+06 -1.2682195e+06\n  7.8039289e-02\
          \  4.4000149e-02  2.7521527e-01  6.1954260e-03]"
    num_agent_steps_sampled: 119000
    num_agent_steps_trained: 1416048
    num_steps_sampled: 119000
    num_steps_trained: 1416048
    num_target_updates: 235
  iterations_since_restore: 119
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.56666666666667
    ram_util_percent: 31.804761904761893
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1559.0559849739075
  time_this_iter_s: 14.21888256072998
  time_total_s: 1559.0559849739075
  timers:
    learn_throughput: 4009.563
    learn_time_ms: 11.971
    update_time_ms: 5.237
  timestamp: 1629282245
  timesteps_since_restore: 0
  timesteps_total: 119000
  training_iteration: 119
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    119 |          1559.06 | 119000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 120000
  custom_metrics: {}
  date: 2021-08-18_10-24-21
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 119944
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 29.645549774169922
          max_q: 6186713.0
          mean_q: 3608916.75
          mean_td_error: -629433.4375
          min_q: 0.8763687014579773
        model: {}
        td_error: "[-1.0681145e+06 -1.0681145e+06 -3.4382600e-01  1.8239534e-01\n -3.0559575e+05\
          \ -4.0241480e-03 -1.0681145e+06  5.3822815e-02\n -1.0681145e+06 -1.0681145e+06\
          \ -1.0681145e+06  1.6414809e-01\n -1.0681145e+06  1.2741101e-01  1.7746127e-01\
          \ -7.3121846e-02\n -1.0681145e+06 -1.0681145e+06 -1.0681145e+06 -1.0681145e+06\n\
          \ -1.0681145e+06  3.0107033e-01 -1.0681145e+06 -1.0681145e+06\n -1.0681145e+06\
          \  2.1178091e-01  3.7304479e-01  1.9607359e-01\n -1.0681145e+06 -1.0681145e+06\
          \ -1.6744354e+00  1.2013191e-01\n -1.0681145e+06 -1.0681145e+06 -1.0681145e+06\
          \  2.6558620e-01\n -1.0681145e+06 -1.0681145e+06  9.0359753e-01 -1.0681145e+06\n\
          \ -1.0681145e+06  1.3534558e-01  1.3575196e-02 -1.0681145e+06\n -1.0681145e+06\
          \ -1.0103810e+00 -1.0681145e+06 -1.0681145e+06]"
    num_agent_steps_sampled: 120000
    num_agent_steps_trained: 1428048
    num_steps_sampled: 120000
    num_steps_trained: 1428048
    num_target_updates: 237
  iterations_since_restore: 120
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.66521739130435
    ram_util_percent: 31.8391304347826
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1575.015711069107
  time_this_iter_s: 15.959726095199585
  time_total_s: 1575.015711069107
  timers:
    learn_throughput: 4796.94
    learn_time_ms: 10.006
    update_time_ms: 2.85
  timestamp: 1629282261
  timesteps_since_restore: 0
  timesteps_total: 120000
  training_iteration: 120
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    120 |          1575.02 | 120000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 121000
  custom_metrics: {}
  date: 2021-08-18_10-24-37
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 120952
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 27.114295959472656
          max_q: 6383018.0
          mean_q: 3191510.75
          mean_td_error: -455119.34375
          min_q: 0.8660034537315369
        model: {}
        td_error: "[ 4.94591594e-02 -8.71810000e+05 -4.61145031e+05  1.17805719e-01\n\
          \  3.14957857e-01 -2.48125196e-02  4.55307961e-02 -8.32736492e-04\n -8.71810000e+05\
          \ -8.71810000e+05  4.16863561e-02  3.30628335e-01\n -2.61275768e-02 -8.71810000e+05\
          \ -1.55507863e-01 -8.71810000e+05\n -8.71810000e+05 -8.71810000e+05 -8.71810000e+05\
          \  7.83377886e-02\n  1.28753185e-01 -8.71810000e+05 -8.71810000e+05 -8.71810000e+05\n\
          \ -4.61145031e+05  1.03602290e-01 -8.71810000e+05 -6.44583702e-02\n -8.71810000e+05\
          \ -8.71810000e+05 -8.71810000e+05 -8.71810000e+05\n -8.71810000e+05 -8.71810000e+05\
          \ -8.71810000e+05  4.60659266e-02\n -1.09338045e-01 -1.23697877e-01 -1.70720696e-01\
          \ -8.71810000e+05\n  6.24178648e-02 -8.71810000e+05 -8.71810000e+05 -8.71810000e+05\n\
          \  2.53017843e-01  2.60903358e-01 -8.71810000e+05  6.72894716e-03]"
    num_agent_steps_sampled: 121000
    num_agent_steps_trained: 1440048
    num_steps_sampled: 121000
    num_steps_trained: 1440048
    num_target_updates: 239
  iterations_since_restore: 121
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.42727272727271
    ram_util_percent: 31.90454545454545
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1590.0984950065613
  time_this_iter_s: 15.082783937454224
  time_total_s: 1590.0984950065613
  timers:
    learn_throughput: 4760.102
    learn_time_ms: 10.084
    update_time_ms: 2.868
  timestamp: 1629282277
  timesteps_since_restore: 0
  timesteps_total: 121000
  training_iteration: 121
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    121 |           1590.1 | 121000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 122000
  custom_metrics: {}
  date: 2021-08-18_10-24-54
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 121960
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 44.59525680541992
          max_q: 6598832.0
          mean_q: 3574373.0
          mean_td_error: -420660.5
          min_q: 0.7359936237335205
        model: {}
        td_error: "[-2.8204298e-01 -6.5599750e+05 -6.5599750e+05 -6.5599750e+05\n -1.4360428e-02\
          \ -6.5599750e+05 -6.5599750e+05 -6.5599750e+05\n -6.2715375e+05 -6.5599750e+05\
          \ -6.5599750e+05 -6.2715375e+05\n -1.3906699e-01 -6.5599750e+05 -1.8317461e-02\
          \ -6.5599750e+05\n  3.6882937e-02 -2.0517778e-01 -6.5599750e+05 -6.5599750e+05\n\
          \ -6.5599750e+05 -6.5599750e+05 -1.9775510e-02 -6.5599750e+05\n -6.5599750e+05\
          \ -6.2715375e+05 -1.1130524e-01 -6.5599750e+05\n -6.2715375e+05  1.3366616e-01\
          \ -3.1508148e-02 -6.5599750e+05\n -6.5599750e+05 -6.5599750e+05  3.0567473e-01\
          \ -6.5599750e+05\n -6.5599750e+05 -1.2862444e-02  2.6963419e-01 -6.5599750e+05\n\
          \ -6.5599750e+05 -1.4405918e-01 -6.5599750e+05  6.5574646e-03\n -6.2715375e+05\
          \  2.2845423e-01  2.2809148e-02 -6.5599750e+05]"
    num_agent_steps_sampled: 122000
    num_agent_steps_trained: 1452048
    num_steps_sampled: 122000
    num_steps_trained: 1452048
    num_target_updates: 241
  iterations_since_restore: 122
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.55
    ram_util_percent: 31.90833333333333
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1607.1010947227478
  time_this_iter_s: 17.002599716186523
  time_total_s: 1607.1010947227478
  timers:
    learn_throughput: 4499.713
    learn_time_ms: 10.667
    update_time_ms: 3.01
  timestamp: 1629282294
  timesteps_since_restore: 0
  timesteps_total: 122000
  training_iteration: 122
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    122 |           1607.1 | 122000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 123000
  custom_metrics: {}
  date: 2021-08-18_10-25-11
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 122968
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 36.86663055419922
          max_q: 6832448.5
          mean_q: 2704535.5
          mean_td_error: -304322.0625
          min_q: 0.7687938809394836
        model: {}
        td_error: "[ 3.9453566e-01 -3.8413820e+00  1.3672566e-01  3.9858699e-02\n -9.8627931e-01\
          \ -4.2238350e+05  8.6824417e-02 -8.2276962e+05\n -9.4726503e-02 -4.2238350e+05\
          \  7.1357596e-01  6.1291575e-02\n -4.2238350e+05 -4.2238350e+05 -4.2238350e+05\
          \ -4.2238350e+05\n -8.2276962e+05 -3.1756663e-01 -4.2238350e+05 -6.2216699e-02\n\
          \ -2.2348619e-01 -8.2276962e+05 -4.2238350e+05 -4.2238350e+05\n  1.2511009e-01\
          \ -8.2276962e+05 -1.6758801e+01 -8.2276962e+05\n -4.2238350e+05 -8.2276962e+05\
          \ -2.3574054e-02 -4.2238350e+05\n -4.2238350e+05 -4.2238350e+05  3.8869822e-01\
          \ -4.2238350e+05\n -4.2238350e+05 -4.2238350e+05 -4.2238350e+05 -8.2276962e+05\n\
          \ -4.2238350e+05  1.4425987e-01  6.5652966e-02 -8.2276962e+05\n -4.2238350e+05\
          \  9.4058156e-02 -1.0101825e-01  5.3295946e+00]"
    num_agent_steps_sampled: 123000
    num_agent_steps_trained: 1464048
    num_steps_sampled: 123000
    num_steps_trained: 1464048
    num_target_updates: 243
  iterations_since_restore: 123
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.45416666666667
    ram_util_percent: 31.90833333333333
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1623.5251104831696
  time_this_iter_s: 16.424015760421753
  time_total_s: 1623.5251104831696
  timers:
    learn_throughput: 4715.648
    learn_time_ms: 10.179
    update_time_ms: 3.099
  timestamp: 1629282311
  timesteps_since_restore: 0
  timesteps_total: 123000
  training_iteration: 123
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    123 |          1623.53 | 123000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 124000
  custom_metrics: {}
  date: 2021-08-18_10-25-28
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 123976
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 21.020803451538086
          max_q: 7046551.5
          mean_q: 1321268.875
          mean_td_error: -94744.859375
          min_q: 0.5588243007659912
        model: {}
        td_error: "[ 4.5351923e-02 -1.0492897e-01  2.9934585e-01 -3.3414112e+05\n -9.3083215e-01\
          \ -1.4441413e-01 -2.0829150e+05 -3.3414116e+05\n  1.7089325e-01 -2.0829150e+05\
          \ -1.3572478e-01 -3.4042293e-01\n  3.6472195e-01 -1.9638360e-02  2.5794381e-01\
          \  1.9365185e-01\n -3.3414116e+05  5.0395429e-02 -5.1923096e-01  1.5457523e-01\n\
          \  3.2609075e-01 -2.0829150e+05 -3.3414112e+05 -5.7928815e+00\n -2.8796911e-02\
          \  2.4674851e-01 -4.1729963e-01 -2.6668179e-01\n -1.7696744e-01 -2.0829150e+05\
          \ -3.3414116e+05 -2.0829150e+05\n  1.9463120e+00  4.7630233e-01 -3.3414116e+05\
          \  3.7977915e+00\n -2.0829150e+05 -3.3414116e+05 -2.4732459e-01  4.3201470e-01\n\
          \ -7.6735842e-01 -2.0829150e+05 -3.3414112e+05  1.4918286e-01\n  1.9990814e-01\
          \ -2.0829150e+05 -2.0829150e+05  1.3943964e-01]"
    num_agent_steps_sampled: 124000
    num_agent_steps_trained: 1476048
    num_steps_sampled: 124000
    num_steps_trained: 1476048
    num_target_updates: 245
  iterations_since_restore: 124
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.396
    ram_util_percent: 32.004
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1640.763508796692
  time_this_iter_s: 17.23839831352234
  time_total_s: 1640.763508796692
  timers:
    learn_throughput: 4785.082
    learn_time_ms: 10.031
    update_time_ms: 2.911
  timestamp: 1629282328
  timesteps_since_restore: 0
  timesteps_total: 124000
  training_iteration: 124
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    124 |          1640.76 | 124000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 125000
  custom_metrics: {}
  date: 2021-08-18_10-25-45
  done: false
  episode_len_mean: 7084.5625
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2266966.454969454
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 16
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 124984
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 3.2935948371887207
          max_q: 7202400.0
          mean_q: 150052.375
          mean_td_error: -1096.364501953125
          min_q: 0.4306373596191406
        model: {}
        td_error: "[-3.77143025e-02  8.18799138e-02  2.04571962e-01 -3.80814624e+00\n\
          \ -5.24765000e+04 -1.94509375e+00 -1.65330291e-01  7.90717602e-02\n -2.64002323e-01\
          \ -4.42833066e-01 -1.99843526e-01 -4.97795868e+01\n -4.52327728e-02 -1.67893589e-01\
          \ -1.54909730e-01 -1.77769840e-01\n -1.23764634e-01 -4.21664715e-02  3.13261356e+01\
          \  2.34021211e+00\n -6.36446238e-01 -2.27467060e-01  6.83855772e+00 -3.21258664e-01\n\
          \  3.69613910e+00  3.74475718e-02 -4.16053295e-01 -2.28430212e-01\n -1.55233860e-01\
          \ -3.19219351e-01 -6.56324625e-03  1.65844560e-01\n  1.38006628e-01 -2.13902950e-01\
          \ -2.46460915e-01 -2.35706997e+01\n -9.84473572e+01 -1.94357991e-01 -1.19658542e+00\
          \ -2.73557901e-01\n  3.84321451e-01 -1.18996563e+01  5.79258144e-01  4.11893129e-02\n\
          \ -2.82911837e-01  1.11959362e+00 -6.64147735e-02  3.71556878e-02]"
    num_agent_steps_sampled: 125000
    num_agent_steps_trained: 1488048
    num_steps_sampled: 125000
    num_steps_trained: 1488048
    num_target_updates: 247
  iterations_since_restore: 125
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.520833333333336
    ram_util_percent: 32.00416666666667
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04917089402931736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 3.9730080898152456
    mean_inference_ms: 1.577342338374953
    mean_raw_obs_processing_ms: 0.14266926550578965
  time_since_restore: 1657.962568283081
  time_this_iter_s: 17.19905948638916
  time_total_s: 1657.962568283081
  timers:
    learn_throughput: 4741.034
    learn_time_ms: 10.124
    update_time_ms: 2.975
  timestamp: 1629282345
  timesteps_since_restore: 0
  timesteps_total: 125000
  training_iteration: 125
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    125 |          1657.96 | 125000 | 2.26697e+06 |          7.25468e+06 |             -198.044 |            7084.56 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 126000
  custom_metrics: {}
  date: 2021-08-18_10-26-00
  done: false
  episode_len_mean: 7373.529411764706
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2560360.681350101
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 125992
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.99780559539795
          max_q: 7255517.0
          mean_q: 151157.5625
          mean_td_error: 13.456942558288574
          min_q: 0.5731241703033447
        model: {}
        td_error: "[ 1.0214508e-02 -2.6790142e-02  1.2496376e-01 -2.7923548e-01\n -9.6586883e-02\
          \ -2.1191835e-03 -1.0174340e+00 -3.0865186e-01\n  1.8319190e-02  2.9175079e-01\
          \  2.5644422e-02 -1.4469624e-01\n -1.9339502e-01  6.6905880e-01 -7.9296470e-02\
          \ -2.1643102e-02\n -1.0174334e-02  4.0981770e-02  7.0310593e-02 -6.1720839e+00\n\
          \  1.9606869e+00  7.7021360e-02 -1.8619776e-02  6.8841612e-01\n -1.2472832e-01\
          \ -1.2503988e-01  3.6561728e-02  1.8070847e-01\n  1.5503269e-01 -1.2355983e-02\
          \  1.3453883e-01  1.4641249e-01\n  3.0132914e-01 -1.7691481e-01 -3.6096411e+00\
          \ -1.2359822e-01\n  4.8288226e-02 -1.6635865e-01  6.9675267e-02  2.5616682e-01\n\
          \ -1.8799448e-01  6.5400000e+02 -1.9062805e-01  4.2365253e-01\n -4.3633008e-01\
          \  2.4205780e-01 -5.5480301e-02 -4.5873618e-01]"
    num_agent_steps_sampled: 126000
    num_agent_steps_trained: 1500048
    num_steps_sampled: 126000
    num_steps_trained: 1500048
    num_target_updates: 249
  iterations_since_restore: 126
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.31428571428573
    ram_util_percent: 31.952380952380945
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049184992046109655
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.013270315116778
    mean_inference_ms: 1.5786010597148625
    mean_raw_obs_processing_ms: 0.14280813860196875
  time_since_restore: 1672.1037650108337
  time_this_iter_s: 14.141196727752686
  time_total_s: 1672.1037650108337
  timers:
    learn_throughput: 4889.891
    learn_time_ms: 9.816
    update_time_ms: 2.68
  timestamp: 1629282360
  timesteps_since_restore: 0
  timesteps_total: 126000
  training_iteration: 126
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    126 |           1672.1 | 126000 | 2.56036e+06 |          7.25468e+06 |             -198.044 |            7373.53 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 127000
  custom_metrics: {}
  date: 2021-08-18_10-26-13
  done: false
  episode_len_mean: 7373.529411764706
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2560360.681350101
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 17
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 127000
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.12374984472990036
          max_q: 2.22727108001709
          mean_q: 0.9357103109359741
          mean_td_error: -0.3221450448036194
          min_q: 0.7076718807220459
        model: {}
        td_error: "[-7.6646793e-01  3.5710102e-01  1.2832785e-01  8.9437723e-02\n -3.5183430e-03\
          \  3.0358195e-02 -3.2039678e-01  2.8554404e-01\n  9.0876579e-02 -7.5758636e-02\
          \ -1.3059938e-01 -1.2185289e+00\n -3.4587324e-02  3.2581389e-02  4.4327974e-04\
          \ -8.5724950e-02\n  2.4016953e-01 -4.9388404e+00 -8.0552280e-02 -3.0871463e-01\n\
          \  3.5356456e-01  5.0125051e-01  5.8912635e-03  2.8641444e-01\n -7.1979141e-01\
          \  1.3458210e-01  1.7745709e-01 -4.9710155e-02\n  4.6164912e-01 -6.4189553e-02\
          \ -3.6799669e-02 -2.6115537e-01\n  2.5011861e-01  5.5420423e-01 -3.7770927e-02\
          \  7.9448342e-02\n -6.9336863e+00  1.3892335e-01 -1.3813561e-01  1.0866684e-01\n\
          \  1.7346740e-01 -3.9638269e+00 -5.2193356e-01 -1.7447990e-01\n  1.6050637e-02\
          \  2.2442925e-01  2.4051261e-01  4.4073743e-01]"
    num_agent_steps_sampled: 127000
    num_agent_steps_trained: 1512048
    num_steps_sampled: 127000
    num_steps_trained: 1512048
    num_target_updates: 251
  iterations_since_restore: 127
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.57368421052631
    ram_util_percent: 31.905263157894733
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049184992046109655
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.013270315116778
    mean_inference_ms: 1.5786010597148625
    mean_raw_obs_processing_ms: 0.14280813860196875
  time_since_restore: 1685.15505361557
  time_this_iter_s: 13.051288604736328
  time_total_s: 1685.15505361557
  timers:
    learn_throughput: 4621.77
    learn_time_ms: 10.386
    update_time_ms: 2.884
  timestamp: 1629282373
  timesteps_since_restore: 0
  timesteps_total: 127000
  training_iteration: 127
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    127 |          1685.16 | 127000 | 2.56036e+06 |          7.25468e+06 |             -198.044 |            7373.53 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 128000
  custom_metrics: {}
  date: 2021-08-18_10-26-27
  done: false
  episode_len_mean: 7373.529411764706
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2560360.681350101
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 17
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 127504
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04206930473446846
          max_q: 2.255542278289795
          mean_q: 0.7723905444145203
          mean_td_error: 0.02640225552022457
          min_q: 0.5849734544754028
        model: {}
        td_error: "[ 0.08214605 -0.00622427  0.10777175 -0.05611229  0.05295205  0.03827268\n\
          \ -0.3510841   0.21407932  0.32886678  0.07456946  0.18382025 -0.16240108\n\
          \ -0.03662616  0.20948803  0.09202445 -0.20695049  0.08339006  0.03996724\n\
          \  0.01749194  0.08292246  0.37551448 -0.25860912  0.01885158 -0.053527\n\
          \ -0.04051423  0.04072726  0.07981837  0.15633512 -0.03175867 -0.05925971\n\
          \ -0.015535    0.00096905 -0.18860209 -0.09243393 -0.16063046  0.1801734\n\
          \  0.11585355  0.06002969  0.45880985 -0.13201517  0.14713979  0.15829426\n\
          \ -0.07029957  0.08796489  0.36803102 -0.4325217  -0.12408459 -0.10977697]"
    num_agent_steps_sampled: 128000
    num_agent_steps_trained: 1524048
    num_steps_sampled: 128000
    num_steps_trained: 1524048
    num_target_updates: 252
  iterations_since_restore: 128
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.75
    ram_util_percent: 31.86499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049184992046109655
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.013270315116778
    mean_inference_ms: 1.5786010597148625
    mean_raw_obs_processing_ms: 0.14280813860196875
  time_since_restore: 1699.1250393390656
  time_this_iter_s: 13.969985723495483
  time_total_s: 1699.1250393390656
  timers:
    learn_throughput: 4938.809
    learn_time_ms: 9.719
    update_time_ms: 2.83
  timestamp: 1629282387
  timesteps_since_restore: 0
  timesteps_total: 128000
  training_iteration: 128
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    128 |          1699.13 | 128000 | 2.56036e+06 |          7.25468e+06 |             -198.044 |            7373.53 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 129000
  custom_metrics: {}
  date: 2021-08-18_10-26-41
  done: false
  episode_len_mean: 7373.529411764706
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2560360.681350101
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 17
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 128512
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05109172314405441
          max_q: 2.5820417404174805
          mean_q: 0.7967416644096375
          mean_td_error: 0.035371359437704086
          min_q: 0.6196931600570679
        model: {}
        td_error: "[-0.01703739 -0.04623818  0.09572703 -0.18691742 -0.14101505  0.22156262\n\
          \ -0.03615236  0.08033943 -0.08202231  0.01464146  0.35328454 -0.03392851\n\
          \  0.12122023 -0.08879662 -0.2319566   0.05432588  0.12071967  0.08503675\n\
          \ -0.04892272  0.21808213  0.20907551 -0.20480978  0.01162863 -0.32222116\n\
          \  0.11493576  0.5558691   0.02368629  0.18572414  0.05148208 -0.01630062\n\
          \  0.13358235 -0.17419487  0.04653001  0.10709459  0.02186501  0.18644893\n\
          \ -0.28502464  0.27831167  0.24517378  0.02063268  0.08929932  0.06768155\n\
          \ -0.2943033  -0.06018817  0.22583312  0.01696068 -0.1659103   0.1770103 ]"
    num_agent_steps_sampled: 129000
    num_agent_steps_trained: 1536048
    num_steps_sampled: 129000
    num_steps_trained: 1536048
    num_target_updates: 254
  iterations_since_restore: 129
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.145
    ram_util_percent: 31.829999999999995
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049184992046109655
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.013270315116778
    mean_inference_ms: 1.5786010597148625
    mean_raw_obs_processing_ms: 0.14280813860196875
  time_since_restore: 1713.019582748413
  time_this_iter_s: 13.894543409347534
  time_total_s: 1713.019582748413
  timers:
    learn_throughput: 4834.991
    learn_time_ms: 9.928
    update_time_ms: 2.952
  timestamp: 1629282401
  timesteps_since_restore: 0
  timesteps_total: 129000
  training_iteration: 129
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    129 |          1713.02 | 129000 | 2.56036e+06 |          7.25468e+06 |             -198.044 |            7373.53 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 130000
  custom_metrics: {}
  date: 2021-08-18_10-26-56
  done: false
  episode_len_mean: 7373.529411764706
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2560360.681350101
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 17
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 129520
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.910613059997559
          max_q: 7255147.0
          mean_q: 151149.59375
          mean_td_error: 6.637618541717529
          min_q: 0.4760042428970337
        model: {}
        td_error: "[ 2.01591372e-01  9.93220210e-02 -1.76609099e-01 -6.41687512e-02\n\
          \ -8.87335539e-02 -2.45137453e-01  1.60449982e-01  3.82466316e-02\n -1.08824432e-01\
          \ -1.74748302e-01 -1.07310581e+00  9.07341242e-02\n  8.47103000e-02 -5.51216006e-02\
          \  1.13498509e-01 -7.80173540e-02\n  6.08503819e-04  1.49054050e-01  1.09601915e-01\
          \  3.11799109e-01\n  1.56848431e-01  3.03713679e-02  3.20872664e-02  5.02381921e-02\n\
          \ -5.69791198e-02 -5.12622595e-02 -4.67491627e-01  3.20000000e+02\n  2.40728259e-02\
          \  6.28417730e-02  7.53848553e-02  1.55793965e-01\n  6.66187406e-02 -8.57430696e-02\
          \ -2.52254605e-02 -1.70784533e-01\n  1.12815499e-01 -5.17848134e-01  1.37601852e-01\
          \  4.98223305e-03\n -1.88619196e-01 -7.67260790e-02 -2.45313108e-01  8.44609737e-02\n\
          \  1.12817585e-01  1.52038336e-02  3.90476644e-01 -3.16057682e-01]"
    num_agent_steps_sampled: 130000
    num_agent_steps_trained: 1548048
    num_steps_sampled: 130000
    num_steps_trained: 1548048
    num_target_updates: 256
  iterations_since_restore: 130
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.29523809523808
    ram_util_percent: 31.838095238095235
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049184992046109655
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.013270315116778
    mean_inference_ms: 1.5786010597148625
    mean_raw_obs_processing_ms: 0.14280813860196875
  time_since_restore: 1727.757964849472
  time_this_iter_s: 14.73838210105896
  time_total_s: 1727.757964849472
  timers:
    learn_throughput: 3346.402
    learn_time_ms: 14.344
    update_time_ms: 5.534
  timestamp: 1629282416
  timesteps_since_restore: 0
  timesteps_total: 130000
  training_iteration: 130
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    130 |          1727.76 | 130000 | 2.56036e+06 |          7.25468e+06 |             -198.044 |            7373.53 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 131000
  custom_metrics: {}
  date: 2021-08-18_10-27-11
  done: false
  episode_len_mean: 7373.529411764706
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2560360.681350101
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 17
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 130528
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08300714939832687
          max_q: 1.5727627277374268
          mean_q: 0.7373573184013367
          mean_td_error: 0.06324562430381775
          min_q: 0.2311573028564453
        model: {}
        td_error: "[ 0.46878177  0.06249708 -0.17203355  0.23737979  0.09412992  0.32291022\n\
          \  0.37759984 -0.18765628  0.39081067 -0.2934187  -0.06960875  0.02760154\n\
          \  0.32582462  0.09829468  0.2089467   0.14656103  0.22429168  0.15232897\n\
          \  0.18934143  0.079476   -0.02443719 -0.13086593  0.2571949   0.304097\n\
          \  0.17169756 -0.10051721  0.10243607  0.20733547  0.13848495 -0.11490834\n\
          \  0.0314036  -0.1001811   0.18525684 -0.13465291  0.16731995  0.1011734\n\
          \ -0.08530253 -0.12323689 -0.04688364 -0.09623474  0.02561849  0.24201745\n\
          \ -0.03689206  0.02674848 -0.43972164  0.11862016 -0.45060134  0.15676236]"
    num_agent_steps_sampled: 131000
    num_agent_steps_trained: 1560048
    num_steps_sampled: 131000
    num_steps_trained: 1560048
    num_target_updates: 258
  iterations_since_restore: 131
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.85000000000002
    ram_util_percent: 31.813636363636352
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049184992046109655
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.013270315116778
    mean_inference_ms: 1.5786010597148625
    mean_raw_obs_processing_ms: 0.14280813860196875
  time_since_restore: 1742.951166152954
  time_this_iter_s: 15.193201303482056
  time_total_s: 1742.951166152954
  timers:
    learn_throughput: 4999.754
    learn_time_ms: 9.6
    update_time_ms: 2.85
  timestamp: 1629282431
  timesteps_since_restore: 0
  timesteps_total: 131000
  training_iteration: 131
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    131 |          1742.95 | 131000 | 2.56036e+06 |          7.25468e+06 |             -198.044 |            7373.53 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 132000
  custom_metrics: {}
  date: 2021-08-18_10-27-27
  done: false
  episode_len_mean: 7373.529411764706
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2560360.681350101
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 17
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 131536
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04027631878852844
          max_q: 2.3208162784576416
          mean_q: 0.7648295164108276
          mean_td_error: -0.005261638667434454
          min_q: 0.5924385786056519
        model: {}
        td_error: "[-2.9395318e-01  7.4399114e-02 -2.3322022e-01 -1.2757897e-01\n -5.2447557e-02\
          \  6.5043092e-02 -1.7647743e-02 -7.0700407e-02\n  2.2741061e-01  2.9375675e-01\
          \ -2.2799134e-02  3.2915884e-01\n -2.9551983e-04  1.8237823e-01 -1.3671672e-01\
          \  2.8758597e-01\n -1.2207085e-01 -1.5669584e-02  2.3577118e-01 -3.8665676e-01\n\
          \ -3.7705898e-02 -1.2955093e-01 -2.1243989e-02 -8.9398742e-02\n  1.1893034e-01\
          \ -9.4082475e-02 -4.7172904e-03 -1.0564953e-01\n -1.4396948e-01  7.5557709e-02\
          \  1.1509180e-01  7.8926563e-02\n  3.8612792e-01 -6.7679942e-02  4.4692814e-02\
          \ -2.1956325e-02\n -8.7099910e-01  1.0952550e-01  2.7968439e-01 -6.8760812e-02\n\
          \ -3.6901164e-01  3.3594143e-01  5.3994179e-02 -1.3680005e-01\n -2.3386836e-02\
          \  1.3215685e-01 -8.4840715e-02  7.0818365e-02]"
    num_agent_steps_sampled: 132000
    num_agent_steps_trained: 1572048
    num_steps_sampled: 132000
    num_steps_trained: 1572048
    num_target_updates: 260
  iterations_since_restore: 132
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.2090909090909
    ram_util_percent: 31.890909090909087
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049184992046109655
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.013270315116778
    mean_inference_ms: 1.5786010597148625
    mean_raw_obs_processing_ms: 0.14280813860196875
  time_since_restore: 1757.9118733406067
  time_this_iter_s: 14.960707187652588
  time_total_s: 1757.9118733406067
  timers:
    learn_throughput: 4657.944
    learn_time_ms: 10.305
    update_time_ms: 3.473
  timestamp: 1629282447
  timesteps_since_restore: 0
  timesteps_total: 132000
  training_iteration: 132
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    132 |          1757.91 | 132000 | 2.56036e+06 |          7.25468e+06 |             -198.044 |            7373.53 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 133000
  custom_metrics: {}
  date: 2021-08-18_10-27-39
  done: false
  episode_len_mean: 7343.0
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2821154.4251448377
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 132544
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.9128618240356445
          max_q: 7254799.0
          mean_q: 151142.25
          mean_td_error: -0.6620882153511047
          min_q: 0.5213886499404907
        model: {}
        td_error: "[-4.10583615e-02 -7.18604922e-02  8.41681957e-02  2.52036452e-02\n\
          \  2.13927627e-01 -5.94609976e-03  2.05845833e-02 -1.39853716e-01\n -3.75744820e-01\
          \ -2.89689600e-01 -1.69388413e-01 -6.89041615e-02\n  2.51206756e-02 -6.45272136e-02\
          \ -1.07581258e-01  4.01354432e-02\n  2.31929243e-01 -2.72429705e-01 -4.84221339e-01\
          \ -4.12175298e-01\n -1.23281121e-01 -2.85000000e+01 -1.38735533e-01  5.00401258e-02\n\
          \  1.04745388e-01 -1.21665716e-01  1.55817688e-01 -1.58263445e-01\n -1.12306952e-01\
          \  2.28496075e-01 -1.57404184e-01  4.54304814e-02\n -3.70351315e-01 -2.80169606e-01\
          \ -1.58873320e-01 -1.74158335e-01\n -1.80707872e-01  1.23190701e-01 -4.15447831e-01\
          \  3.23852301e-02\n  5.34344316e-02  5.93715906e-02  2.28022933e-02  1.18620574e-01\n\
          \ -1.42898977e-01  1.28281116e-01  5.98597527e-03 -1.22593045e-02]"
    num_agent_steps_sampled: 133000
    num_agent_steps_trained: 1584048
    num_steps_sampled: 133000
    num_steps_trained: 1584048
    num_target_updates: 262
  iterations_since_restore: 133
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.15882352941176
    ram_util_percent: 31.829411764705885
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196732640978263
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.050030134618469
    mean_inference_ms: 1.5798321006473102
    mean_raw_obs_processing_ms: 0.1429365062901627
  time_since_restore: 1769.9405195713043
  time_this_iter_s: 12.028646230697632
  time_total_s: 1769.9405195713043
  timers:
    learn_throughput: 4835.641
    learn_time_ms: 9.926
    update_time_ms: 2.964
  timestamp: 1629282459
  timesteps_since_restore: 0
  timesteps_total: 133000
  training_iteration: 133
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    133 |          1769.94 | 133000 | 2.82115e+06 |          7.25468e+06 |             -198.044 |               7343 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 134000
  custom_metrics: {}
  date: 2021-08-18_10-27-51
  done: false
  episode_len_mean: 7343.0
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2821154.4251448377
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 18
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 133552
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04434289410710335
          max_q: 0.9899129867553711
          mean_q: 0.6482600569725037
          mean_td_error: 0.0017648836364969611
          min_q: 0.5110127925872803
        model: {}
        td_error: "[ 0.1066736  -0.08818626  0.26958233 -0.24996078 -0.21912467 -0.08697641\n\
          \ -0.01227087 -0.04791284 -0.20524067 -0.1394962  -0.23411334 -0.20113206\n\
          \  0.06907451 -0.27421045  0.09760964  0.04256946 -0.22027987  0.11685395\n\
          \  0.11805961  0.09893304 -0.00990748  0.00819886  0.04034525 -0.18244535\n\
          \  0.11328891  0.33905286  0.05802208 -0.10676378  0.2446366   0.20596129\n\
          \  0.05240387  0.12432134  0.09511173  0.33872348  0.16407034 -0.21492624\n\
          \  0.08110309  0.26839477 -0.16811532 -0.0536716  -0.28020912 -0.38187182\n\
          \  0.26965982 -0.23500472 -0.07415271  0.25665855  0.14859137  0.04278672]"
    num_agent_steps_sampled: 134000
    num_agent_steps_trained: 1596048
    num_steps_sampled: 134000
    num_steps_trained: 1596048
    num_target_updates: 264
  iterations_since_restore: 134
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.45882352941176
    ram_util_percent: 31.8
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196732640978263
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.050030134618469
    mean_inference_ms: 1.5798321006473102
    mean_raw_obs_processing_ms: 0.1429365062901627
  time_since_restore: 1781.6815872192383
  time_this_iter_s: 11.74106764793396
  time_total_s: 1781.6815872192383
  timers:
    learn_throughput: 4949.749
    learn_time_ms: 9.697
    update_time_ms: 2.753
  timestamp: 1629282471
  timesteps_since_restore: 0
  timesteps_total: 134000
  training_iteration: 134
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    134 |          1781.68 | 134000 | 2.82115e+06 |          7.25468e+06 |             -198.044 |               7343 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 135000
  custom_metrics: {}
  date: 2021-08-18_10-28-04
  done: false
  episode_len_mean: 7343.0
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2821154.4251448377
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 18
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 134560
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.838379859924316
          max_q: 7253251.0
          mean_q: 151110.0625
          mean_td_error: -32.810646057128906
          min_q: 0.5934305191040039
        model: {}
        td_error: "[ 3.8812160e-02 -7.9563260e-03  8.0743790e-02 -2.1474016e-01\n -2.1693653e-01\
          \ -1.7743832e-01  2.6853886e-01 -7.1196258e-02\n  9.4797134e-02  1.4315563e-01\
          \ -6.3401461e-04 -1.8424332e-01\n -9.5317483e-02  2.2725272e-01  1.8881470e-01\
          \  1.8168217e-01\n  5.6409299e-02 -8.1697106e-03  1.1635375e-01  1.7586100e-01\n\
          \  3.9155245e-02 -3.2593578e-01  1.2187803e-01 -1.5760000e+03\n -1.8822014e-02\
          \  2.3483518e-01 -1.3605875e-01  1.4161700e-01\n  3.4185529e-02 -8.1860185e-02\
          \  8.0324531e-02 -1.0172409e-01\n  1.8813848e-02  1.8330777e-01 -9.7198486e-02\
          \  1.5338904e-01\n  2.5310338e-02  1.9145098e-01  1.3154525e-01  8.1809759e-03\n\
          \ -9.2906594e-02  2.6736206e-01  2.1068180e-01 -9.7387731e-02\n -1.3365704e-01\
          \ -2.1193701e-01 -2.0319498e-01  1.5196878e-01]"
    num_agent_steps_sampled: 135000
    num_agent_steps_trained: 1608048
    num_steps_sampled: 135000
    num_steps_trained: 1608048
    num_target_updates: 266
  iterations_since_restore: 135
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.08947368421053
    ram_util_percent: 31.80526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196732640978263
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.050030134618469
    mean_inference_ms: 1.5798321006473102
    mean_raw_obs_processing_ms: 0.1429365062901627
  time_since_restore: 1794.781403541565
  time_this_iter_s: 13.09981632232666
  time_total_s: 1794.781403541565
  timers:
    learn_throughput: 4751.799
    learn_time_ms: 10.101
    update_time_ms: 2.812
  timestamp: 1629282484
  timesteps_since_restore: 0
  timesteps_total: 135000
  training_iteration: 135
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    135 |          1794.78 | 135000 | 2.82115e+06 |          7.25468e+06 |             -198.044 |               7343 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 136000
  custom_metrics: {}
  date: 2021-08-18_10-28-17
  done: false
  episode_len_mean: 7343.0
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2821154.4251448377
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 18
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 135568
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.536740779876709
          max_q: 7253895.0
          mean_q: 151123.40625
          mean_td_error: -19.440444946289062
          min_q: 0.46052098274230957
        model: {}
        td_error: "[ 1.28825754e-01  4.05773222e-02  2.08501458e-01  1.11622870e-01\n\
          \  8.18003416e-02  1.43163323e-01  1.19593322e-01  2.57115364e-02\n  1.71761632e-01\
          \ -1.12339914e-01  1.21705264e-01 -1.54160202e-01\n -2.46196985e-01 -1.93623900e-01\
          \ -3.33850503e-01 -6.27226233e-02\n  1.91194475e-01 -1.72834396e-01 -5.46490312e-01\
          \ -3.88239145e-01\n -3.25690508e-01 -2.71483064e-02  9.77981091e-02  3.47563326e-02\n\
          \  9.82587039e-02 -1.53562725e-01  2.49943316e-01 -1.52135372e-01\n  1.72733843e-01\
          \  7.85144567e-02 -1.85697675e-02 -1.61603332e-01\n  1.20332003e-01  2.84001380e-01\
          \ -2.10144997e-01  9.33318436e-02\n -2.75006771e-01  1.36458367e-01 -2.64867485e-01\
          \ -9.32500000e+02\n -6.31588697e-02  1.64872348e-01 -1.37960911e-03  1.93042517e-01\n\
          \ -1.01230502e-01  3.44191194e-01 -1.67358994e-01  7.82988667e-02]"
    num_agent_steps_sampled: 136000
    num_agent_steps_trained: 1620048
    num_steps_sampled: 136000
    num_steps_trained: 1620048
    num_target_updates: 268
  iterations_since_restore: 136
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.59473684210526
    ram_util_percent: 31.80526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196732640978263
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.050030134618469
    mean_inference_ms: 1.5798321006473102
    mean_raw_obs_processing_ms: 0.1429365062901627
  time_since_restore: 1807.8459062576294
  time_this_iter_s: 13.064502716064453
  time_total_s: 1807.8459062576294
  timers:
    learn_throughput: 4799.192
    learn_time_ms: 10.002
    update_time_ms: 2.849
  timestamp: 1629282497
  timesteps_since_restore: 0
  timesteps_total: 136000
  training_iteration: 136
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    136 |          1807.85 | 136000 | 2.82115e+06 |          7.25468e+06 |             -198.044 |               7343 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 137000
  custom_metrics: {}
  date: 2021-08-18_10-28-32
  done: false
  episode_len_mean: 7343.0
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2821154.4251448377
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 18
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 136576
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0526747889816761
          max_q: 0.8087362051010132
          mean_q: 0.6663939356803894
          mean_td_error: 0.019330937415361404
          min_q: 0.6023784875869751
        model: {}
        td_error: "[ 0.1643681  -0.11534923 -0.03240162  0.09888411  0.12924308 -0.03933984\n\
          \ -0.4254241   0.05020052 -0.10521799 -0.06856185  0.1741767   0.06680632\n\
          \  0.30617476  0.16192943  0.28039467 -0.06488961  0.00732023  0.08505809\n\
          \ -0.20181048 -0.17752385 -0.06307298  0.0546515   0.20030475  0.11767447\n\
          \ -0.05245656  0.00113934 -0.15340519  0.00897121 -0.1652413   0.24610835\n\
          \ -0.1568197   0.0510419   0.09803206 -0.15970981 -0.06590581  0.26377183\n\
          \  0.02455533  0.03484547  0.21377409  0.01378894  0.03606987  0.0484668\n\
          \  0.08485681  0.04476559  0.24158138 -0.29469538 -0.09163558  0.05239022]"
    num_agent_steps_sampled: 137000
    num_agent_steps_trained: 1632048
    num_steps_sampled: 137000
    num_steps_trained: 1632048
    num_target_updates: 270
  iterations_since_restore: 137
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.9
    ram_util_percent: 31.804999999999996
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196732640978263
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.050030134618469
    mean_inference_ms: 1.5798321006473102
    mean_raw_obs_processing_ms: 0.1429365062901627
  time_since_restore: 1821.9220957756042
  time_this_iter_s: 14.076189517974854
  time_total_s: 1821.9220957756042
  timers:
    learn_throughput: 4792.315
    learn_time_ms: 10.016
    update_time_ms: 2.906
  timestamp: 1629282512
  timesteps_since_restore: 0
  timesteps_total: 137000
  training_iteration: 137
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    137 |          1821.92 | 137000 | 2.82115e+06 |          7.25468e+06 |             -198.044 |               7343 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 138000
  custom_metrics: {}
  date: 2021-08-18_10-28-47
  done: false
  episode_len_mean: 7343.0
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2821154.4251448377
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 18
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 137584
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.048286356031894684
          max_q: 1.1321288347244263
          mean_q: 0.6490447521209717
          mean_td_error: -0.04466808959841728
          min_q: 0.5626916885375977
        model: {}
        td_error: "[-0.0233261   0.24230072 -0.01307595 -0.00191575  0.02460545 -0.1254667\n\
          \ -0.02053267  0.10160488 -0.06389201 -0.32243878 -0.22853899  0.26337746\n\
          \ -0.06799734 -0.13481432 -0.2426483  -0.05263907 -0.04776102  0.10746258\n\
          \ -0.08112669  0.10407472 -0.25213403 -0.11080772 -0.2608685  -0.02714115\n\
          \ -0.07207578 -0.06782591 -0.16775346  0.13983625 -0.0239954   0.02907121\n\
          \  0.20223269 -0.23415375  0.09599245  0.06361699  0.05784488 -0.09842092\n\
          \ -0.25478578  0.09096456  0.07419586  0.01330608  0.05312079  0.24069908\n\
          \ -0.40539044 -0.12719297 -0.30508125  0.01565534 -0.2897631   0.0595336 ]"
    num_agent_steps_sampled: 138000
    num_agent_steps_trained: 1644048
    num_steps_sampled: 138000
    num_steps_trained: 1644048
    num_target_updates: 272
  iterations_since_restore: 138
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.463636363636354
    ram_util_percent: 31.80454545454544
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196732640978263
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.050030134618469
    mean_inference_ms: 1.5798321006473102
    mean_raw_obs_processing_ms: 0.1429365062901627
  time_since_restore: 1837.2128174304962
  time_this_iter_s: 15.290721654891968
  time_total_s: 1837.2128174304962
  timers:
    learn_throughput: 4771.711
    learn_time_ms: 10.059
    update_time_ms: 3.295
  timestamp: 1629282527
  timesteps_since_restore: 0
  timesteps_total: 138000
  training_iteration: 138
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    138 |          1837.21 | 138000 | 2.82115e+06 |          7.25468e+06 |             -198.044 |               7343 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 139000
  custom_metrics: {}
  date: 2021-08-18_10-29-02
  done: false
  episode_len_mean: 7343.0
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2821154.4251448377
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 18
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 138592
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 17.58070182800293
          max_q: 7254454.5
          mean_q: 302269.5625
          mean_td_error: -15.618792533874512
          min_q: 0.5307766199111938
        model: {}
        td_error: "[ 2.01174617e-02  2.28989422e-01 -1.73682809e-01  9.54914987e-02\n\
          \ -1.32898569e-01  1.15463257e-01  1.33427858e-01 -2.06242204e-01\n -1.05556631e+00\
          \  1.81388557e-01  2.87959576e-02 -1.10039473e-01\n  7.22801685e-02  7.84873962e-03\
          \ -3.61790121e-01  2.35595644e-01\n -1.33868098e-01  8.61126781e-02  5.97561002e-02\
          \ -3.73500000e+02\n -6.05613828e-01  1.75533533e-01  4.37819093e-01  1.16582990e-01\n\
          \ -3.03761482e-01 -1.02239013e-01  1.37761235e-02 -1.28853858e-01\n -1.13121510e-01\
          \ -3.03030014e-04  1.91575795e-01  7.36798048e-02\n  4.57751751e-03 -2.86589086e-01\
          \ -1.75599813e-01  8.35495591e-02\n -2.04999149e-01 -6.78190827e-01 -3.25301886e-02\
          \ -2.97909498e-01\n -2.87340701e-01 -8.29725266e-02  2.52760053e-02  1.90167010e-01\n\
          \ -1.24968290e-01 -3.73500000e+02  1.89172268e-01  1.30084693e-01]"
    num_agent_steps_sampled: 139000
    num_agent_steps_trained: 1656048
    num_steps_sampled: 139000
    num_steps_trained: 1656048
    num_target_updates: 274
  iterations_since_restore: 139
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.7047619047619
    ram_util_percent: 31.83333333333333
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196732640978263
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.050030134618469
    mean_inference_ms: 1.5798321006473102
    mean_raw_obs_processing_ms: 0.1429365062901627
  time_since_restore: 1851.8061628341675
  time_this_iter_s: 14.593345403671265
  time_total_s: 1851.8061628341675
  timers:
    learn_throughput: 4374.088
    learn_time_ms: 10.974
    update_time_ms: 2.964
  timestamp: 1629282542
  timesteps_since_restore: 0
  timesteps_total: 139000
  training_iteration: 139
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    139 |          1851.81 | 139000 | 2.82115e+06 |          7.25468e+06 |             -198.044 |               7343 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 140000
  custom_metrics: {}
  date: 2021-08-18_10-29-18
  done: false
  episode_len_mean: 7343.0
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2821154.4251448377
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 18
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 139600
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03802314028143883
          max_q: 1.2731292247772217
          mean_q: 0.48866409063339233
          mean_td_error: -0.0020784835796803236
          min_q: 0.37426137924194336
        model: {}
        td_error: "[ 0.06526959 -0.2514826   0.38836628  0.14661315 -0.06718552  0.18996617\n\
          \ -0.07171333 -0.07341957  0.03637701  0.13201809 -0.0918507   0.02797842\n\
          \ -0.09001568 -0.02116251  0.10198259  0.23030618  0.08227992 -0.1565432\n\
          \  0.07953224 -0.2912867   0.15213513 -0.03205705 -0.11142921 -0.01056921\n\
          \ -0.7755904   0.16896787 -0.2729578   0.07679597  0.0878765  -0.0683161\n\
          \ -0.15422505  0.21048701  0.05043155 -0.09262061 -0.07420981  0.10382929\n\
          \ -0.10520941 -0.11617273 -0.02088493  0.1804748  -0.01044133  0.21282052\n\
          \  0.02807945  0.06399229 -0.1313541   0.07181811  0.0842244   0.01830795]"
    num_agent_steps_sampled: 140000
    num_agent_steps_trained: 1668048
    num_steps_sampled: 140000
    num_steps_trained: 1668048
    num_target_updates: 276
  iterations_since_restore: 140
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.2
    ram_util_percent: 31.908695652173908
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196732640978263
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.050030134618469
    mean_inference_ms: 1.5798321006473102
    mean_raw_obs_processing_ms: 0.1429365062901627
  time_since_restore: 1867.6928935050964
  time_this_iter_s: 15.886730670928955
  time_total_s: 1867.6928935050964
  timers:
    learn_throughput: 4886.924
    learn_time_ms: 9.822
    update_time_ms: 2.835
  timestamp: 1629282558
  timesteps_since_restore: 0
  timesteps_total: 140000
  training_iteration: 140
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    140 |          1867.69 | 140000 | 2.82115e+06 |          7.25468e+06 |             -198.044 |               7343 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 141000
  custom_metrics: {}
  date: 2021-08-18_10-29-35
  done: false
  episode_len_mean: 7343.0
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 2821154.4251448377
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 18
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 140608
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.048306550830602646
          max_q: 1.2194550037384033
          mean_q: 0.5261730551719666
          mean_td_error: -0.009766733273863792
          min_q: 0.43250954151153564
        model: {}
        td_error: "[ 0.12930065  0.03356919  0.07720163 -0.00796497  0.18269414  0.15887743\n\
          \ -0.07174218 -0.05192709 -0.05418062 -0.02400613  0.09122622  0.00254017\n\
          \  0.2795344  -0.4992965   0.00336781 -0.08737898  0.2948542  -0.2243104\n\
          \ -0.069462   -0.1502878   0.13171378  0.19067425 -0.09202546  0.29036555\n\
          \ -0.3671785  -0.17671686  0.30369222  0.09982353  0.16208416 -0.12565398\n\
          \  0.16798061  0.201446   -0.26789576 -0.11213839  0.25464314  0.09155509\n\
          \ -0.17274272 -0.02685529  0.05991033 -0.2229085  -0.03597194 -0.2660132\n\
          \ -0.08309889  0.25972602 -0.06281853  0.03682852  0.26808506 -0.98792255]"
    num_agent_steps_sampled: 141000
    num_agent_steps_trained: 1680048
    num_steps_sampled: 141000
    num_steps_trained: 1680048
    num_target_updates: 278
  iterations_since_restore: 141
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.0625
    ram_util_percent: 31.899999999999995
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196732640978263
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.050030134618469
    mean_inference_ms: 1.5798321006473102
    mean_raw_obs_processing_ms: 0.1429365062901627
  time_since_restore: 1884.222815990448
  time_this_iter_s: 16.529922485351562
  time_total_s: 1884.222815990448
  timers:
    learn_throughput: 4869.454
    learn_time_ms: 9.857
    update_time_ms: 2.844
  timestamp: 1629282575
  timesteps_since_restore: 0
  timesteps_total: 141000
  training_iteration: 141
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    141 |          1884.22 | 141000 | 2.82115e+06 |          7.25468e+06 |             -198.044 |               7343 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 142000
  custom_metrics: {}
  date: 2021-08-18_10-29-52
  done: false
  episode_len_mean: 7467.105263157895
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3054495.637012271
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 141616
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.024535050615668297
          max_q: 1.1801769733428955
          mean_q: 0.39005884528160095
          mean_td_error: -0.010799247771501541
          min_q: 0.29664182662963867
        model: {}
        td_error: "[-0.06473523 -0.02327567  0.08219151 -0.00198799  0.02572161 -0.23364258\n\
          \  0.18544579 -0.02665484 -0.21753538 -0.05901501 -0.15618217  0.0225226\n\
          \ -0.03115252 -0.0294697  -0.1539002  -0.11474085  0.06595948  0.18326308\n\
          \  0.09254016  0.1943686   0.33006573 -0.24324131 -0.16022569 -0.11278605\n\
          \  0.12383908  0.07685116 -0.01392546  0.08773005  0.22693908 -0.215352\n\
          \ -0.1577282  -0.15511739  0.17649835 -0.00776482  0.07757789 -0.09141633\n\
          \  0.1440886  -0.3305856  -0.12736964 -0.14024252  0.09498434  0.11691436\n\
          \ -0.11321115 -0.00711033  0.07218069 -0.04871207 -0.10789466  0.24692929]"
    num_agent_steps_sampled: 142000
    num_agent_steps_trained: 1692048
    num_steps_sampled: 142000
    num_steps_trained: 1692048
    num_target_updates: 280
  iterations_since_restore: 142
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.772
    ram_util_percent: 31.932
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049206184854704973
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.086664047229533
    mean_inference_ms: 1.580969122034457
    mean_raw_obs_processing_ms: 0.14305424038615847
  time_since_restore: 1901.325961112976
  time_this_iter_s: 17.103145122528076
  time_total_s: 1901.325961112976
  timers:
    learn_throughput: 4890.01
    learn_time_ms: 9.816
    update_time_ms: 2.778
  timestamp: 1629282592
  timesteps_since_restore: 0
  timesteps_total: 142000
  training_iteration: 142
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    142 |          1901.33 | 142000 | 3.0545e+06 |          7.25468e+06 |             -198.044 |            7467.11 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 143000
  custom_metrics: {}
  date: 2021-08-18_10-30-04
  done: false
  episode_len_mean: 7467.105263157895
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3054495.637012271
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 19
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 142624
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.048889826983213425
          max_q: 1.8500345945358276
          mean_q: 0.4214213788509369
          mean_td_error: -0.032223522663116455
          min_q: 0.3120453357696533
        model: {}
        td_error: "[ 0.24255854  0.21044485 -0.19157046  0.12691261 -0.16518545  0.25121766\n\
          \ -0.08920932  0.07638687  0.15467404  0.07083833 -0.21406549 -0.07692119\n\
          \  0.07192567 -0.2657051  -0.08388782  0.08442742 -0.26434082 -0.04204786\n\
          \ -0.38158578 -0.2638781  -0.24847859 -0.07959661  0.05073744  0.09331477\n\
          \ -0.15086931  0.21881673  0.19145364  0.00191841 -0.11295593 -0.13346064\n\
          \  0.195294   -0.16003484 -0.36148536  0.12492007 -0.09066546 -0.14758581\n\
          \ -0.2713067  -0.1059173   0.04251686  0.09430748  0.06441131 -0.10463345\n\
          \  0.14436965 -0.14869249  0.13912328 -0.10647318  0.07766059 -0.01440623]"
    num_agent_steps_sampled: 143000
    num_agent_steps_trained: 1704048
    num_steps_sampled: 143000
    num_steps_trained: 1704048
    num_target_updates: 282
  iterations_since_restore: 143
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.129411764705885
    ram_util_percent: 31.81176470588235
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049206184854704973
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.086664047229533
    mean_inference_ms: 1.580969122034457
    mean_raw_obs_processing_ms: 0.14305424038615847
  time_since_restore: 1912.9747965335846
  time_this_iter_s: 11.64883542060852
  time_total_s: 1912.9747965335846
  timers:
    learn_throughput: 5092.75
    learn_time_ms: 9.425
    update_time_ms: 2.696
  timestamp: 1629282604
  timesteps_since_restore: 0
  timesteps_total: 143000
  training_iteration: 143
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    143 |          1912.97 | 143000 | 3.0545e+06 |          7.25468e+06 |             -198.044 |            7467.11 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 144000
  custom_metrics: {}
  date: 2021-08-18_10-30-17
  done: false
  episode_len_mean: 7467.105263157895
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3054495.637012271
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 19
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 143632
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.193571090698242
          max_q: 7255201.0
          mean_q: 151150.40625
          mean_td_error: 7.744837760925293
          min_q: 0.2608945369720459
        model: {}
        td_error: "[ 2.1886662e-01 -9.7845733e-02  2.9429197e-03  2.0435286e-01\n  1.3258812e-01\
          \  2.5048882e-02 -4.4942945e-02  2.1819128e-01\n -1.5910074e-01 -3.4285158e-02\
          \ -7.8322083e-02  2.4692631e-01\n  1.9269520e-01 -6.4085424e-02 -1.0638493e-01\
          \  3.0589932e-01\n -9.9418610e-02 -1.9429195e-01 -5.6202757e-01 -9.6511543e-02\n\
          \  3.7200000e+02 -1.9754338e-01 -5.0295877e-01  6.2697113e-02\n  2.1786481e-02\
          \  1.0258973e-02 -1.0003969e-01  2.6994538e-01\n -9.0976864e-02 -3.3458114e-02\
          \ -1.3554335e-01 -2.6044518e-02\n -1.9486701e-01  3.3551368e-01 -3.8030148e-02\
          \  1.1299178e-01\n  2.7532518e-01 -1.3594389e-02 -5.6274682e-02  1.0220255e-01\n\
          \  4.4713855e-02  1.1794925e-01  8.3470404e-02 -3.2123864e-02\n -8.2559437e-02\
          \  4.0190548e-02 -9.9981666e-02 -1.3116157e-01]"
    num_agent_steps_sampled: 144000
    num_agent_steps_trained: 1716048
    num_steps_sampled: 144000
    num_steps_trained: 1716048
    num_target_updates: 284
  iterations_since_restore: 144
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.39999999999999
    ram_util_percent: 31.80555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049206184854704973
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.086664047229533
    mean_inference_ms: 1.580969122034457
    mean_raw_obs_processing_ms: 0.14305424038615847
  time_since_restore: 1925.335500717163
  time_this_iter_s: 12.360704183578491
  time_total_s: 1925.335500717163
  timers:
    learn_throughput: 4912.37
    learn_time_ms: 9.771
    update_time_ms: 2.81
  timestamp: 1629282617
  timesteps_since_restore: 0
  timesteps_total: 144000
  training_iteration: 144
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    144 |          1925.34 | 144000 | 3.0545e+06 |          7.25468e+06 |             -198.044 |            7467.11 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 145000
  custom_metrics: {}
  date: 2021-08-18_10-30-30
  done: false
  episode_len_mean: 7467.105263157895
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3054495.637012271
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 19
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 144640
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.035997506231069565
          max_q: 0.5031228065490723
          mean_q: 0.28527677059173584
          mean_td_error: 0.007662837393581867
          min_q: 0.2049952745437622
        model: {}
        td_error: "[ 0.0363901   0.10712442 -0.14101255 -0.17609686 -0.36469483  0.12106073\n\
          \ -0.12459898 -0.0734719  -0.12196299  0.09997684 -0.14188674  0.06277698\n\
          \  0.09765227 -0.18191391  0.18880288 -0.06885183 -0.12319332 -0.29482555\n\
          \  0.18411992  0.02969682  0.05482328  0.21216239  0.00092852 -0.00555441\n\
          \  0.14158452 -0.15569842 -0.13956499  0.09432629 -0.21459186  0.23593748\n\
          \  0.13256301 -0.0109255   0.01006481  0.20654634  0.22756076  0.2894257\n\
          \ -0.16411304 -0.15370363 -0.08177322  0.11578299 -0.16576922  0.31325382\n\
          \  0.08352619 -0.09545252  0.07723874  0.1223816  -0.27440494  0.39617008]"
    num_agent_steps_sampled: 145000
    num_agent_steps_trained: 1728048
    num_steps_sampled: 145000
    num_steps_trained: 1728048
    num_target_updates: 286
  iterations_since_restore: 145
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.61666666666666
    ram_util_percent: 31.80555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049206184854704973
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.086664047229533
    mean_inference_ms: 1.580969122034457
    mean_raw_obs_processing_ms: 0.14305424038615847
  time_since_restore: 1938.0843415260315
  time_this_iter_s: 12.748840808868408
  time_total_s: 1938.0843415260315
  timers:
    learn_throughput: 4873.379
    learn_time_ms: 9.849
    update_time_ms: 2.925
  timestamp: 1629282630
  timesteps_since_restore: 0
  timesteps_total: 145000
  training_iteration: 145
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    145 |          1938.08 | 145000 | 3.0545e+06 |          7.25468e+06 |             -198.044 |            7467.11 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 146000
  custom_metrics: {}
  date: 2021-08-18_10-30-44
  done: false
  episode_len_mean: 7467.105263157895
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3054495.637012271
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 19
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 145648
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.940797805786133
          max_q: 7255743.0
          mean_q: 151161.484375
          mean_td_error: 19.025585174560547
          min_q: 0.07493919134140015
        model: {}
        td_error: "[ 2.3919073e-01  1.9583626e-01  2.0793159e-01  8.1088349e-02\n  3.3550978e-01\
          \  9.1550000e+02  1.3627946e-02  1.1129156e-01\n -2.6364857e-01 -9.6862197e-02\
          \ -1.7344546e-01 -1.4822105e-01\n -5.5340156e-03  1.1100856e-01 -5.8164299e-02\
          \ -6.2847668e-01\n -4.4703841e-02 -1.0218527e+00  6.8593636e-02  2.6211523e-02\n\
          \  9.1725513e-02  2.2874926e-01 -1.6780972e-01  8.3796397e-02\n -1.5495077e-01\
          \ -2.6064914e-01 -1.2978238e-01 -3.5646969e-01\n  6.5016583e-02 -2.1776092e-01\
          \  1.7579317e-02 -2.3359939e-02\n  1.8235713e-02 -3.9307421e-01  3.0371559e-01\
          \ -1.7168200e-01\n -3.2589093e-02  3.5674936e-01  1.5111372e-02  1.5675275e-01\n\
          \ -5.2797616e-02 -1.1289778e-01 -1.7774031e-02 -1.4442913e-01\n -3.1914294e-02\
          \ -2.2163063e-02 -1.5731239e-01 -1.1144060e-01]"
    num_agent_steps_sampled: 146000
    num_agent_steps_trained: 1740048
    num_steps_sampled: 146000
    num_steps_trained: 1740048
    num_target_updates: 288
  iterations_since_restore: 146
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.38000000000001
    ram_util_percent: 31.804999999999996
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049206184854704973
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.086664047229533
    mean_inference_ms: 1.580969122034457
    mean_raw_obs_processing_ms: 0.14305424038615847
  time_since_restore: 1952.1601750850677
  time_this_iter_s: 14.075833559036255
  time_total_s: 1952.1601750850677
  timers:
    learn_throughput: 3365.377
    learn_time_ms: 14.263
    update_time_ms: 5.684
  timestamp: 1629282644
  timesteps_since_restore: 0
  timesteps_total: 146000
  training_iteration: 146
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    146 |          1952.16 | 146000 | 3.0545e+06 |          7.25468e+06 |             -198.044 |            7467.11 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 147000
  custom_metrics: {}
  date: 2021-08-18_10-30-59
  done: false
  episode_len_mean: 7467.105263157895
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3054495.637012271
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 19
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 146656
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04097538813948631
          max_q: 0.46698886156082153
          mean_q: 0.11549284309148788
          mean_td_error: 0.03384752199053764
          min_q: 0.010392308235168457
        model: {}
        td_error: "[-1.97179496e-01  2.92589903e-01 -3.40051949e-02  4.10786211e-01\n\
          \  9.16568041e-02 -1.92017853e-02  5.90353757e-02 -2.49452144e-02\n  2.35469580e-01\
          \ -1.22155294e-01 -6.77305460e-03 -2.07426906e-01\n  1.48697704e-01 -3.60163450e-02\
          \ -1.35728180e-01 -1.54159650e-01\n  1.38805345e-01 -1.44335240e-01  8.01433399e-02\
          \  6.61370754e-02\n -8.72531831e-02  2.04018205e-01 -1.10235468e-01 -3.80362570e-02\n\
          \  1.96074843e-01  1.76044017e-01  2.39097476e-01 -1.05837584e-01\n  1.16145179e-01\
          \ -3.54206681e-01  1.73326075e-01  1.41384512e-01\n  2.02671051e-01  1.02650471e-01\
          \  1.67165756e-01  1.90822512e-01\n  2.45519206e-01  2.18086094e-02 -1.78295821e-02\
          \ -1.56494766e-01\n -6.35534525e-05 -7.02287853e-02  1.07250512e-01  1.36877269e-01\n\
          \ -1.77662700e-01 -3.48292172e-01  1.73136890e-01  5.54342866e-02]"
    num_agent_steps_sampled: 147000
    num_agent_steps_trained: 1752048
    num_steps_sampled: 147000
    num_steps_trained: 1752048
    num_target_updates: 290
  iterations_since_restore: 147
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.16190476190476
    ram_util_percent: 31.804761904761893
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049206184854704973
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.086664047229533
    mean_inference_ms: 1.580969122034457
    mean_raw_obs_processing_ms: 0.14305424038615847
  time_since_restore: 1966.597734928131
  time_this_iter_s: 14.437559843063354
  time_total_s: 1966.597734928131
  timers:
    learn_throughput: 5038.253
    learn_time_ms: 9.527
    update_time_ms: 2.846
  timestamp: 1629282659
  timesteps_since_restore: 0
  timesteps_total: 147000
  training_iteration: 147
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    147 |           1966.6 | 147000 | 3.0545e+06 |          7.25468e+06 |             -198.044 |            7467.11 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 148000
  custom_metrics: {}
  date: 2021-08-18_10-31-13
  done: false
  episode_len_mean: 7467.105263157895
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3054495.637012271
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 19
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 147664
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03842584788799286
          max_q: 1.0291789770126343
          mean_q: 0.10414876788854599
          mean_td_error: -0.01570587418973446
          min_q: -0.02429276704788208
        model: {}
        td_error: "[-0.22657493 -0.20672357 -0.06724006 -0.14845955  0.11707163  0.23173785\n\
          \  0.0148285  -0.12073934  0.0307811  -0.05689503  0.09795897  0.01684767\n\
          \ -0.08774    -0.10131454  0.03994228  0.02021696  0.12416345  0.2322873\n\
          \  0.13844438  0.06791276  0.11508197  0.12799498 -0.04226314 -0.1231173\n\
          \ -0.22066173  0.10565121 -0.10518664 -0.05917127 -0.14145556  0.10917953\n\
          \  0.22660764  0.2107514  -0.14053392 -0.06241134 -0.06363416 -0.14029518\n\
          \  0.07523131 -0.03708605 -0.25867373 -0.30522004  0.07044695  0.00623813\n\
          \  0.12364473 -0.0715915   0.11078195 -0.10758229 -0.09947421 -0.17363948]"
    num_agent_steps_sampled: 148000
    num_agent_steps_trained: 1764048
    num_steps_sampled: 148000
    num_steps_trained: 1764048
    num_target_updates: 292
  iterations_since_restore: 148
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.766666666666666
    ram_util_percent: 31.828571428571422
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049206184854704973
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.086664047229533
    mean_inference_ms: 1.580969122034457
    mean_raw_obs_processing_ms: 0.14305424038615847
  time_since_restore: 1980.9058618545532
  time_this_iter_s: 14.30812692642212
  time_total_s: 1980.9058618545532
  timers:
    learn_throughput: 4818.535
    learn_time_ms: 9.962
    update_time_ms: 2.985
  timestamp: 1629282673
  timesteps_since_restore: 0
  timesteps_total: 148000
  training_iteration: 148
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    148 |          1980.91 | 148000 | 3.0545e+06 |          7.25468e+06 |             -198.044 |            7467.11 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 149000
  custom_metrics: {}
  date: 2021-08-18_10-31-29
  done: false
  episode_len_mean: 7467.105263157895
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3054495.637012271
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 19
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 148672
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03135927766561508
          max_q: 0.2658701539039612
          mean_q: 0.06852560490369797
          mean_td_error: -0.004076672252267599
          min_q: -0.03254580497741699
        model: {}
        td_error: "[-0.07921448  0.01344069 -0.20051107  0.18772866  0.16357565 -0.11758491\n\
          \  0.1987427  -0.07029854  0.0800478  -0.00620738  0.04232334 -0.06198741\n\
          \  0.0783501   0.17444429  0.1347818   0.1590525   0.23822069 -0.99748814\n\
          \  0.17528214 -0.08937243  0.08517516 -0.22402659  0.2546745  -0.07607636\n\
          \ -0.30028382 -0.03471002 -0.17480749  0.03007795 -0.10526946 -0.1733091\n\
          \  0.0802754   0.28300807  0.19186568  0.05658605  0.06318252 -0.02254795\n\
          \  0.15248862  0.11699722 -0.05580923 -0.13113129  0.09103309 -0.11069286\n\
          \ -0.09888902 -0.08923745 -0.17598945  0.21409069 -0.19185293  0.1261719 ]"
    num_agent_steps_sampled: 149000
    num_agent_steps_trained: 1776048
    num_steps_sampled: 149000
    num_steps_trained: 1776048
    num_target_updates: 294
  iterations_since_restore: 149
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.42173913043477
    ram_util_percent: 31.908695652173908
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049206184854704973
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.086664047229533
    mean_inference_ms: 1.580969122034457
    mean_raw_obs_processing_ms: 0.14305424038615847
  time_since_restore: 1996.8330626487732
  time_this_iter_s: 15.92720079421997
  time_total_s: 1996.8330626487732
  timers:
    learn_throughput: 4834.248
    learn_time_ms: 9.929
    update_time_ms: 3.288
  timestamp: 1629282689
  timesteps_since_restore: 0
  timesteps_total: 149000
  training_iteration: 149
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    149 |          1996.83 | 149000 | 3.0545e+06 |          7.25468e+06 |             -198.044 |            7467.11 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 150000
  custom_metrics: {}
  date: 2021-08-18_10-31-44
  done: false
  episode_len_mean: 7489.6
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3264501.238300591
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 149680
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.731950283050537
          max_q: 7254431.0
          mean_q: 151134.03125
          mean_td_error: -8.275797843933105
          min_q: -0.038582444190979004
        model: {}
        td_error: "[ 1.05003715e-01  1.04765154e-01 -1.67290419e-02  1.09273434e-01\n\
          \ -1.51898175e-01  1.60403639e-01  2.85140201e-02 -1.64327741e-01\n -2.22167671e-02\
          \  3.18078063e-02  4.21550348e-02 -2.68289059e-01\n  5.75447008e-02  3.00424933e-01\
          \ -3.96500000e+02  4.52503338e-02\n -1.15007281e-01 -1.48703426e-01  2.20364034e-02\
          \  3.72924879e-02\n -2.00510144e-01  1.18755840e-01  9.59535688e-02  4.01840135e-02\n\
          \ -1.48632824e-01  1.72007337e-01  1.32585257e-01  8.84175301e-02\n  2.21359730e-02\
          \ -1.75089404e-01 -1.85097992e-01  3.15201506e-02\n -1.32449687e-01  1.53187394e-01\
          \ -3.57772559e-02 -1.63526088e-01\n -3.13770831e-01 -3.09971631e-01  6.96174055e-02\
          \ -9.13579464e-02\n -1.39235944e-01 -1.29218012e-01  8.14995170e-02 -1.56342655e-01\n\
          \  1.25168473e-01 -2.80321389e-02 -3.18840966e-02  2.14295268e-01]"
    num_agent_steps_sampled: 150000
    num_agent_steps_trained: 1788048
    num_steps_sampled: 150000
    num_steps_trained: 1788048
    num_target_updates: 296
  iterations_since_restore: 150
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.6952380952381
    ram_util_percent: 31.899999999999995
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921157863539061
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.12048074685722
    mean_inference_ms: 1.5819208654173103
    mean_raw_obs_processing_ms: 0.14315643982247522
  time_since_restore: 2011.1271798610687
  time_this_iter_s: 14.294117212295532
  time_total_s: 2011.1271798610687
  timers:
    learn_throughput: 5042.544
    learn_time_ms: 9.519
    update_time_ms: 2.741
  timestamp: 1629282704
  timesteps_since_restore: 0
  timesteps_total: 150000
  training_iteration: 150
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    150 |          2011.13 | 150000 | 3.2645e+06 |          7.25468e+06 |             -198.044 |             7489.6 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 151000
  custom_metrics: {}
  date: 2021-08-18_10-31-55
  done: false
  episode_len_mean: 7489.6
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3264501.238300591
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 20
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 150688
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.11992987990379333
          max_q: 0.7023363709449768
          mean_q: 0.0714995265007019
          mean_td_error: 0.10105252265930176
          min_q: -0.07603853940963745
        model: {}
        td_error: "[-0.05374034  0.03499287  0.13022271  0.3863418   0.3368253   0.03884902\n\
          \  0.17948139  0.02719953  0.09564343  0.15449665  0.14718333 -0.20047292\n\
          \  0.1246391  -0.04720987  0.15677375  0.10607283  0.1583572  -0.23220068\n\
          \  0.03745733  0.12272549 -0.0488318   0.17304584  0.25568882 -0.1037171\n\
          \  0.06866283  0.20167756  0.24976492  0.08656808  0.134061   -0.0428574\n\
          \  0.15195125  0.19739237  0.12846169  0.20406356  0.20293316  0.06874154\n\
          \  0.08757697 -0.00433706  0.47777262  0.04297678 -0.02108496 -0.05934286\n\
          \  0.311312    0.10724512 -0.064036    0.17403845 -0.15157893  0.3187348 ]"
    num_agent_steps_sampled: 151000
    num_agent_steps_trained: 1800048
    num_steps_sampled: 151000
    num_steps_trained: 1800048
    num_target_updates: 298
  iterations_since_restore: 151
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.29375
    ram_util_percent: 31.9
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921157863539061
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.12048074685722
    mean_inference_ms: 1.5819208654173103
    mean_raw_obs_processing_ms: 0.14315643982247522
  time_since_restore: 2022.197670698166
  time_this_iter_s: 11.070490837097168
  time_total_s: 2022.197670698166
  timers:
    learn_throughput: 4978.452
    learn_time_ms: 9.642
    update_time_ms: 2.728
  timestamp: 1629282715
  timesteps_since_restore: 0
  timesteps_total: 151000
  training_iteration: 151
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    151 |           2022.2 | 151000 | 3.2645e+06 |          7.25468e+06 |             -198.044 |             7489.6 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 152000
  custom_metrics: {}
  date: 2021-08-18_10-32-07
  done: false
  episode_len_mean: 7489.6
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3264501.238300591
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 20
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 151696
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05726756155490875
          max_q: 0.14417171478271484
          mean_q: 0.023883065208792686
          mean_td_error: -0.036400336772203445
          min_q: -0.06232947111129761
        model: {}
        td_error: "[-0.21432096 -0.14079824  0.02992202  0.00873767  0.07355262 -0.2713207\n\
          \  0.04943879 -0.07144383  0.04655039  0.04828692 -0.1418886  -0.03581432\n\
          \  0.11556277  0.05939848 -0.03952777 -0.1261071  -0.11958732  0.06524935\n\
          \ -0.06321824 -0.25894853 -0.1213773   0.2666084   0.02138489  0.12080958\n\
          \  0.3839054  -0.01719698  0.13135771 -0.02044076 -0.14060768 -0.08401419\n\
          \ -0.08959459 -0.06734046 -0.14548664  0.19250005 -0.04876314 -0.00621492\n\
          \  0.01089036 -0.10854127 -0.01872296 -0.07603223 -0.1664401  -0.16038284\n\
          \ -0.2303443  -0.00622393 -0.19948445  0.05206181  0.01683864 -0.25008756]"
    num_agent_steps_sampled: 152000
    num_agent_steps_trained: 1812048
    num_steps_sampled: 152000
    num_steps_trained: 1812048
    num_target_updates: 300
  iterations_since_restore: 152
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.98235294117646
    ram_util_percent: 31.88823529411765
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921157863539061
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.12048074685722
    mean_inference_ms: 1.5819208654173103
    mean_raw_obs_processing_ms: 0.14315643982247522
  time_since_restore: 2034.3319220542908
  time_this_iter_s: 12.134251356124878
  time_total_s: 2034.3319220542908
  timers:
    learn_throughput: 4675.935
    learn_time_ms: 10.265
    update_time_ms: 3.057
  timestamp: 1629282727
  timesteps_since_restore: 0
  timesteps_total: 152000
  training_iteration: 152
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    152 |          2034.33 | 152000 | 3.2645e+06 |          7.25468e+06 |             -198.044 |             7489.6 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 153000
  custom_metrics: {}
  date: 2021-08-18_10-32-20
  done: false
  episode_len_mean: 7489.6
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3264501.238300591
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 20
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 152704
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03285256028175354
          max_q: 0.6043923497200012
          mean_q: -0.009947109036147594
          mean_td_error: -0.005564277525991201
          min_q: -0.1308993101119995
        model: {}
        td_error: "[-0.07113703 -0.05853233 -0.19147357 -0.01719987  0.08984677  0.05350102\n\
          \ -0.13226417  0.07949464  0.23988983 -0.2689193   0.16304551 -0.20887446\n\
          \  0.0331433  -0.25493526 -0.05088766 -0.31804192 -0.10232279  0.18911421\n\
          \ -0.08467433  0.18704283  0.18023685 -0.04376404  0.17709422  0.16910756\n\
          \  0.3225552   0.1199847  -0.14159442 -0.1232921  -0.01721619  0.2947488\n\
          \  0.11454001 -0.19698966 -0.10945372  0.26758918 -0.03544737 -0.03444673\n\
          \  0.074138   -0.18782473 -0.21165368 -0.05789674  0.00516719 -0.09514115\n\
          \ -0.07344918 -0.05300321  0.05080119  0.0643337   0.05189222 -0.05391681]"
    num_agent_steps_sampled: 153000
    num_agent_steps_trained: 1824048
    num_steps_sampled: 153000
    num_steps_trained: 1824048
    num_target_updates: 302
  iterations_since_restore: 153
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.17777777777778
    ram_util_percent: 31.883333333333333
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921157863539061
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.12048074685722
    mean_inference_ms: 1.5819208654173103
    mean_raw_obs_processing_ms: 0.14315643982247522
  time_since_restore: 2046.4097590446472
  time_this_iter_s: 12.077836990356445
  time_total_s: 2046.4097590446472
  timers:
    learn_throughput: 5130.83
    learn_time_ms: 9.355
    update_time_ms: 2.75
  timestamp: 1629282740
  timesteps_since_restore: 0
  timesteps_total: 153000
  training_iteration: 153
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    153 |          2046.41 | 153000 | 3.2645e+06 |          7.25468e+06 |             -198.044 |             7489.6 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 154000
  custom_metrics: {}
  date: 2021-08-18_10-32-33
  done: false
  episode_len_mean: 7322.285714285715
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3454507.5248962506
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 153712
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.039382513612508774
          max_q: 0.19807541370391846
          mean_q: -0.05150390416383743
          mean_td_error: 0.02459091693162918
          min_q: -0.14134448766708374
        model: {}
        td_error: "[ 0.06731482  0.19577214  0.1721417   0.03518075  0.10488392  0.17124367\n\
          \  0.17697781 -0.13798237 -0.08949776  0.13928618 -0.19314182 -0.17163059\n\
          \  0.22379056  0.06137108  0.2512499  -0.06255272 -0.07005748  0.18188497\n\
          \  0.14292337 -0.03595506 -0.22108828  0.10313402  0.1897129  -0.02669351\n\
          \  0.01028845  0.0860227   0.11286178 -0.26018634  0.04505391 -0.08964589\n\
          \ -0.17625676 -0.00502039  0.3345886   0.05295069 -0.04050807 -0.07159825\n\
          \  0.24010414 -0.01203743 -0.10332307 -0.16450821 -0.04276199  0.15352939\n\
          \  0.04361334  0.02104426  0.02090649 -0.10961039  0.09376688 -0.16717795]"
    num_agent_steps_sampled: 154000
    num_agent_steps_trained: 1836048
    num_steps_sampled: 154000
    num_steps_trained: 1836048
    num_target_updates: 304
  iterations_since_restore: 154
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.10555555555555
    ram_util_percent: 31.90555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921719744359635
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.149241071973131
    mean_inference_ms: 1.5828478103288135
    mean_raw_obs_processing_ms: 0.14324415154758205
  time_since_restore: 2059.260906457901
  time_this_iter_s: 12.851147413253784
  time_total_s: 2059.260906457901
  timers:
    learn_throughput: 4686.22
    learn_time_ms: 10.243
    update_time_ms: 2.948
  timestamp: 1629282753
  timesteps_since_restore: 0
  timesteps_total: 154000
  training_iteration: 154
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    154 |          2059.26 | 154000 | 3.45451e+06 |          7.25468e+06 |             -198.044 |            7322.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 155000
  custom_metrics: {}
  date: 2021-08-18_10-32-44
  done: false
  episode_len_mean: 7322.285714285715
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3454507.5248962506
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 21
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 154720
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.155843734741211
          max_q: 7254272.0
          mean_q: 151130.6875
          mean_td_error: -11.613561630249023
          min_q: -0.25121402740478516
        model: {}
        td_error: "[-7.27743581e-02 -1.34424061e-01  1.65967941e-02 -1.21848106e-01\n\
          \ -2.40641087e-01  1.15060881e-02 -4.11010757e-02 -1.25530541e-01\n -6.19430840e-02\
          \  1.99632064e-01  6.56341314e-02 -1.28281742e-01\n -1.98218614e-01  1.08003467e-02\
          \  2.76901871e-02 -4.99277115e-02\n  1.67755932e-02  8.66398513e-02 -2.03235745e-01\
          \ -2.25381106e-01\n  1.77062213e-01  2.08343267e-01 -5.56000000e+02 -7.94960558e-03\n\
          \ -4.26204562e-01  5.65539300e-02  2.22679347e-01  1.03236660e-01\n -4.78862673e-01\
          \ -3.37788433e-01  1.02875769e-01 -2.33105570e-03\n  1.44465685e-01  2.12313786e-01\
          \  1.59387976e-01 -1.52453125e-01\n -1.39955252e-01 -6.42790645e-02  7.46543109e-02\
          \ -9.38673615e-02\n -1.16503522e-01  1.18692905e-01 -1.85230628e-01 -3.70243192e-03\n\
          \ -1.49232626e-01  1.75034821e-01  2.83647627e-01 -1.63496852e-01]"
    num_agent_steps_sampled: 155000
    num_agent_steps_trained: 1848048
    num_steps_sampled: 155000
    num_steps_trained: 1848048
    num_target_updates: 306
  iterations_since_restore: 155
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.5875
    ram_util_percent: 31.9
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921719744359635
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.149241071973131
    mean_inference_ms: 1.5828478103288135
    mean_raw_obs_processing_ms: 0.14324415154758205
  time_since_restore: 2070.3378841876984
  time_this_iter_s: 11.076977729797363
  time_total_s: 2070.3378841876984
  timers:
    learn_throughput: 5016.235
    learn_time_ms: 9.569
    update_time_ms: 2.713
  timestamp: 1629282764
  timesteps_since_restore: 0
  timesteps_total: 155000
  training_iteration: 155
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    155 |          2070.34 | 155000 | 3.45451e+06 |          7.25468e+06 |             -198.044 |            7322.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 156000
  custom_metrics: {}
  date: 2021-08-18_10-32-57
  done: false
  episode_len_mean: 7322.285714285715
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3454507.5248962506
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 21
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 155728
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0325000137090683
          max_q: 0.44686293601989746
          mean_q: -0.08104118704795837
          mean_td_error: -0.017178788781166077
          min_q: -0.2546885013580322
        model: {}
        td_error: "[ 0.10706384  0.15639095 -0.2902486  -0.2805079   0.01558185  0.20643425\n\
          \ -0.2223069  -0.3192102  -0.25363484 -0.19919515 -0.02995434 -0.11185198\n\
          \ -0.007677    0.25690988 -0.01627518 -0.11647341  0.07362068  0.06856448\n\
          \ -0.0383043   0.18723397 -0.00292781  0.06816487 -0.04658823 -0.1553645\n\
          \ -0.00208785  0.17956197 -0.24358219  0.12284508 -0.14060646 -0.13380828\n\
          \  0.14581439  0.13162073  0.20782906 -0.1471507   0.17144072 -0.2885809\n\
          \ -0.1402581   0.12118582 -0.23198585  0.20263427 -0.06805633 -0.48878944\n\
          \  0.05211231  0.30720443  0.06437424  0.22119066 -0.1649282   0.24799445]"
    num_agent_steps_sampled: 156000
    num_agent_steps_trained: 1860048
    num_steps_sampled: 156000
    num_steps_trained: 1860048
    num_target_updates: 308
  iterations_since_restore: 156
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.15555555555557
    ram_util_percent: 31.90555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921719744359635
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.149241071973131
    mean_inference_ms: 1.5828478103288135
    mean_raw_obs_processing_ms: 0.14324415154758205
  time_since_restore: 2082.783962249756
  time_this_iter_s: 12.446078062057495
  time_total_s: 2082.783962249756
  timers:
    learn_throughput: 5014.811
    learn_time_ms: 9.572
    update_time_ms: 2.748
  timestamp: 1629282777
  timesteps_since_restore: 0
  timesteps_total: 156000
  training_iteration: 156
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    156 |          2082.78 | 156000 | 3.45451e+06 |          7.25468e+06 |             -198.044 |            7322.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 157000
  custom_metrics: {}
  date: 2021-08-18_10-33-09
  done: false
  episode_len_mean: 7322.285714285715
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3454507.5248962506
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 21
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 156736
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.806352615356445
          max_q: 7255285.0
          mean_q: 302303.4375
          mean_td_error: 19.120861053466797
          min_q: -0.2239634394645691
        model: {}
        td_error: "[-3.43879312e-02  8.10173750e-02  1.17348671e-01  1.45150840e-01\n\
          \  3.74469161e-03 -2.19105512e-01 -4.88156676e-02  2.62955040e-01\n  1.31941199e-01\
          \  4.57500000e+02  1.17726326e-01 -4.77434099e-02\n  1.70388669e-01 -1.02622807e-01\
          \  2.31514096e-01  2.24671066e-02\n -2.30948329e-01  2.72306114e-01  2.36063600e-02\
          \  2.35716462e-01\n -1.25098974e-01 -8.23324919e-02  2.79175848e-01  2.77840734e-01\n\
          \ -9.07593966e-03 -1.59425795e-01  3.53215486e-02  5.47662377e-03\n  2.23267585e-01\
          \  7.31394142e-02 -1.15460545e-01 -1.87602311e-01\n  3.55692655e-02  1.21723101e-01\
          \ -1.87293902e-01  1.55737013e-01\n  1.95243895e-01  1.96021438e-01  4.57500000e+02\
          \  3.33660901e-01\n  7.54522830e-02 -9.99738201e-02 -1.86351746e-01  1.92020714e-01\n\
          \  9.11896229e-02 -3.78564745e-02 -1.68687016e-01  7.37373471e-01]"
    num_agent_steps_sampled: 157000
    num_agent_steps_trained: 1872048
    num_steps_sampled: 157000
    num_steps_trained: 1872048
    num_target_updates: 310
  iterations_since_restore: 157
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.64444444444445
    ram_util_percent: 31.90555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921719744359635
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.149241071973131
    mean_inference_ms: 1.5828478103288135
    mean_raw_obs_processing_ms: 0.14324415154758205
  time_since_restore: 2095.036273956299
  time_this_iter_s: 12.252311706542969
  time_total_s: 2095.036273956299
  timers:
    learn_throughput: 4949.506
    learn_time_ms: 9.698
    update_time_ms: 2.781
  timestamp: 1629282789
  timesteps_since_restore: 0
  timesteps_total: 157000
  training_iteration: 157
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    157 |          2095.04 | 157000 | 3.45451e+06 |          7.25468e+06 |             -198.044 |            7322.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 158000
  custom_metrics: {}
  date: 2021-08-18_10-33-22
  done: false
  episode_len_mean: 7322.285714285715
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3454507.5248962506
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 21
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 157744
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04463067278265953
          max_q: 0.22184360027313232
          mean_q: -0.14376014471054077
          mean_td_error: -0.040993984788656235
          min_q: -0.25065332651138306
        model: {}
        td_error: "[-0.17979035 -0.04495431  0.10377726 -0.10638148 -0.18637323  0.10222012\n\
          \ -0.31757185  0.19690323  0.02635416  0.0213723   0.19283861 -0.9489608\n\
          \  0.11449102  0.00968613 -0.46365678 -0.19499946 -0.16275968  0.0213723\n\
          \  0.12188394  0.12412384 -0.2635805  -0.14096946  0.11890517  0.2863387\n\
          \  0.21035978 -0.0509526  -0.16174412 -0.27820787 -0.0507504  -0.15389897\n\
          \ -0.10139269 -0.23961005  0.23214829  0.02366823  0.21748245  0.20424384\n\
          \  0.0115054   0.02055937 -0.07029594 -0.06383917  0.10519961 -0.2084053\n\
          \ -0.15078992  0.16302788  0.04187417  0.09097072 -0.26044643  0.07131365]"
    num_agent_steps_sampled: 158000
    num_agent_steps_trained: 1884048
    num_steps_sampled: 158000
    num_steps_trained: 1884048
    num_target_updates: 312
  iterations_since_restore: 158
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.431578947368415
    ram_util_percent: 31.899999999999995
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921719744359635
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.149241071973131
    mean_inference_ms: 1.5828478103288135
    mean_raw_obs_processing_ms: 0.14324415154758205
  time_since_restore: 2107.97162938118
  time_this_iter_s: 12.935355424880981
  time_total_s: 2107.97162938118
  timers:
    learn_throughput: 4872.093
    learn_time_ms: 9.852
    update_time_ms: 2.875
  timestamp: 1629282802
  timesteps_since_restore: 0
  timesteps_total: 158000
  training_iteration: 158
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    158 |          2107.97 | 158000 | 3.45451e+06 |          7.25468e+06 |             -198.044 |            7322.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 159000
  custom_metrics: {}
  date: 2021-08-18_10-33-38
  done: false
  episode_len_mean: 7322.285714285715
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3454507.5248962506
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 21
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 158752
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.12354935705661774
          max_q: 0.09099924564361572
          mean_q: -0.21117669343948364
          mean_td_error: -0.09391441941261292
          min_q: -0.3261197805404663
        model: {}
        td_error: "[-0.05951701 -0.03455154 -0.17169645  0.11396539 -0.23389092 -0.18225554\n\
          \ -0.13218926  0.05972087 -0.17188655 -0.4132521  -0.11193798 -0.3193206\n\
          \  0.09788495 -0.16487294 -0.20489189  0.03604674 -0.1830259  -0.36034617\n\
          \ -0.24055594 -0.09256972 -0.04436045 -0.15136507 -0.17684634 -0.20479354\n\
          \ -0.16514382  0.15984261 -0.04478786 -0.39772156  0.15187877 -0.29450276\n\
          \ -0.01444921  0.17751557  0.06170955  0.16847283 -0.32651407 -0.33910477\n\
          \ -0.15411523  0.0998207  -0.06310026  0.06698644  0.08501494 -0.04897849\n\
          \ -0.2573489  -0.16355848 -0.11306621  0.16723782  0.0848976  -0.00236943]"
    num_agent_steps_sampled: 159000
    num_agent_steps_trained: 1896048
    num_steps_sampled: 159000
    num_steps_trained: 1896048
    num_target_updates: 314
  iterations_since_restore: 159
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.05454545454546
    ram_util_percent: 31.909090909090903
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921719744359635
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.149241071973131
    mean_inference_ms: 1.5828478103288135
    mean_raw_obs_processing_ms: 0.14324415154758205
  time_since_restore: 2123.26384806633
  time_this_iter_s: 15.292218685150146
  time_total_s: 2123.26384806633
  timers:
    learn_throughput: 3501.028
    learn_time_ms: 13.71
    update_time_ms: 4.592
  timestamp: 1629282818
  timesteps_since_restore: 0
  timesteps_total: 159000
  training_iteration: 159
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    159 |          2123.26 | 159000 | 3.45451e+06 |          7.25468e+06 |             -198.044 |            7322.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 160000
  custom_metrics: {}
  date: 2021-08-18_10-33-52
  done: false
  episode_len_mean: 7322.285714285715
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3454507.5248962506
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 21
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 159760
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07013323903083801
          max_q: 0.2051335573196411
          mean_q: -0.2616472840309143
          mean_td_error: -0.04468122869729996
          min_q: -0.42071110010147095
        model: {}
        td_error: "[ 0.24831747 -0.03904693  0.09942889  0.13337398 -0.21073034  0.04523677\n\
          \ -0.19591215 -0.28152305  0.15421695 -0.09504402 -0.3358893   0.19386104\n\
          \  0.11125453 -0.21071798  0.01134674 -0.11433807 -0.13867499  0.05029768\n\
          \ -0.17727986 -0.2857828   0.05517769 -0.09219196 -0.27583042  0.02445734\n\
          \  0.05109495  0.1465677  -0.12876722  0.07075649  0.12875327  0.07842141\n\
          \ -0.09653047  0.15173656 -0.19215682 -0.1347141  -0.25168097  0.05706266\n\
          \ -0.09458236  0.22851434 -0.04867381 -0.12406681  0.07943356 -0.16149014\n\
          \  0.03346732 -0.27821422 -0.2637443  -0.2315944   0.18147653 -0.0197753 ]"
    num_agent_steps_sampled: 160000
    num_agent_steps_trained: 1908048
    num_steps_sampled: 160000
    num_steps_trained: 1908048
    num_target_updates: 316
  iterations_since_restore: 160
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.171428571428564
    ram_util_percent: 31.899999999999995
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921719744359635
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.149241071973131
    mean_inference_ms: 1.5828478103288135
    mean_raw_obs_processing_ms: 0.14324415154758205
  time_since_restore: 2137.915196657181
  time_this_iter_s: 14.65134859085083
  time_total_s: 2137.915196657181
  timers:
    learn_throughput: 4968.622
    learn_time_ms: 9.661
    update_time_ms: 2.821
  timestamp: 1629282832
  timesteps_since_restore: 0
  timesteps_total: 160000
  training_iteration: 160
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    160 |          2137.92 | 160000 | 3.45451e+06 |          7.25468e+06 |             -198.044 |            7322.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 161000
  custom_metrics: {}
  date: 2021-08-18_10-34-06
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 160768
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12.548905372619629
          max_q: 7254550.0
          mean_q: 302272.59375
          mean_td_error: -11.551292419433594
          min_q: -0.4648779630661011
        model: {}
        td_error: "[ 2.11022973e-01 -3.84380519e-02  1.85744822e-01 -2.77500000e+02\n\
          \ -2.77500000e+02  3.39043438e-02 -1.00966007e-01  1.62350923e-01\n  2.27415621e-01\
          \ -1.94401979e-01  3.27145100e-01  1.40955389e-01\n  2.11016953e-01 -9.47691798e-02\
          \ -2.12816000e-02 -1.28734723e-01\n  8.89722705e-02  1.24516189e-01 -1.13075376e-01\
          \  1.12232804e-01\n -1.82529390e-01  8.49819183e-02  2.54918933e-02 -3.34209353e-01\n\
          \  2.48640776e-02 -2.93963969e-01 -1.48792818e-01  1.44702554e-01\n -5.61931878e-02\
          \ -1.00433201e-01 -2.89022446e-01 -8.97059739e-02\n -9.66185033e-02  2.82211900e-02\
          \  1.53503299e-01  1.46524429e-01\n -1.67764306e-01 -2.19642118e-01 -1.40434951e-01\
          \  2.07980633e-01\n -3.80069673e-01  2.19345868e-01 -1.05539173e-01  2.96869636e-01\n\
          \  3.12747717e-01  2.29607254e-01 -5.73151112e-02  1.91738844e-01]"
    num_agent_steps_sampled: 161000
    num_agent_steps_trained: 1920048
    num_steps_sampled: 161000
    num_steps_trained: 1920048
    num_target_updates: 318
  iterations_since_restore: 161
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.685
    ram_util_percent: 31.924999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2151.3370747566223
  time_this_iter_s: 13.421878099441528
  time_total_s: 2151.3370747566223
  timers:
    learn_throughput: 5087.808
    learn_time_ms: 9.434
    update_time_ms: 2.958
  timestamp: 1629282846
  timesteps_since_restore: 0
  timesteps_total: 161000
  training_iteration: 161
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    161 |          2151.34 | 161000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 162000
  custom_metrics: {}
  date: 2021-08-18_10-34-18
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 161776
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 13.0536527633667
          max_q: 7255155.0
          mean_q: 302297.71875
          mean_td_error: 13.63172721862793
          min_q: -0.5604153871536255
        model: {}
        td_error: "[-1.07252270e-01 -3.08632255e-02 -1.25861794e-01 -9.02210176e-02\n\
          \  1.26909614e-02  1.31898582e-01 -2.22240508e-01 -1.80386424e-01\n -1.24069333e-01\
          \  1.17739856e-01  1.23984873e-01 -2.81062543e-01\n  9.47653651e-02  1.38116121e-01\
          \ -3.12711596e-02  1.39710009e-01\n  1.93114340e-01 -4.25166935e-01  3.27500000e+02\
          \  1.71158910e-01\n  4.25846577e-02  2.13565230e-02  1.83655351e-01 -3.13403547e-01\n\
          \  3.62504900e-01 -1.07624948e-01 -5.17584682e-02 -1.17091626e-01\n -6.47687614e-02\
          \ -3.64269018e-02 -6.61999881e-02  1.42818689e-01\n  1.57657802e-01 -2.54059970e-01\
          \ -1.79567009e-01 -6.23602271e-02\n  1.83131039e-01  3.27500000e+02 -1.38986275e-01\
          \  7.82337189e-02\n  1.26640141e-01 -1.63356423e-01  6.85751438e-05  8.24276209e-02\n\
          \ -1.10365689e-01  1.01132989e-02 -1.06690675e-01  1.99532390e-01]"
    num_agent_steps_sampled: 162000
    num_agent_steps_trained: 1932048
    num_steps_sampled: 162000
    num_steps_trained: 1932048
    num_target_updates: 320
  iterations_since_restore: 162
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.45
    ram_util_percent: 31.90625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2162.607694387436
  time_this_iter_s: 11.270619630813599
  time_total_s: 2162.607694387436
  timers:
    learn_throughput: 5029.745
    learn_time_ms: 9.543
    update_time_ms: 2.762
  timestamp: 1629282858
  timesteps_since_restore: 0
  timesteps_total: 162000
  training_iteration: 162
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    162 |          2162.61 | 162000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 163000
  custom_metrics: {}
  date: 2021-08-18_10-34-31
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 162784
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.029298176988959312
          max_q: -0.13278907537460327
          mean_q: -0.4435163736343384
          mean_td_error: -0.004646233282983303
          min_q: -0.5511317253112793
        model: {}
        td_error: "[ 0.05292228  0.14726442  0.18883526 -0.50895     0.09582222  0.17951226\n\
          \ -0.2392      0.20652258 -0.02376145  0.16205835  0.16520429 -0.1024504\n\
          \ -0.0082691   0.08615178  0.10939109 -0.02304822  0.08376157 -0.03475186\n\
          \ -0.24060187  0.04594141  0.0726546   0.05481413  0.05813834 -0.06953385\n\
          \  0.04230016  0.15000588  0.23751199 -0.22272098 -0.01596174  0.11821568\n\
          \ -0.27836412  0.17092079 -0.06120479  0.02786511 -0.07052252  0.19124168\n\
          \  0.24470854 -0.01254195 -0.35701266  0.33534527 -0.18282159  0.13052458\n\
          \  0.14419109  0.03080589  0.00186348 -1.0031819  -0.21210068 -0.09051415]"
    num_agent_steps_sampled: 163000
    num_agent_steps_trained: 1944048
    num_steps_sampled: 163000
    num_steps_trained: 1944048
    num_target_updates: 322
  iterations_since_restore: 163
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.833333333333336
    ram_util_percent: 31.90555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2175.3253235816956
  time_this_iter_s: 12.717629194259644
  time_total_s: 2175.3253235816956
  timers:
    learn_throughput: 5073.205
    learn_time_ms: 9.461
    update_time_ms: 2.906
  timestamp: 1629282871
  timesteps_since_restore: 0
  timesteps_total: 163000
  training_iteration: 163
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    163 |          2175.33 | 163000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 164000
  custom_metrics: {}
  date: 2021-08-18_10-34-45
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 163792
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04751281812787056
          max_q: -0.1141771674156189
          mean_q: -0.49339255690574646
          mean_td_error: 0.02331772819161415
          min_q: -0.6280047297477722
        model: {}
        td_error: "[-1.84641689e-01  1.73212886e-01  3.45810056e-02 -1.45208597e-01\n\
          \  2.26570785e-01  2.09463954e-01 -7.55226612e-02  2.52261162e-01\n -1.64674968e-01\
          \ -1.93853915e-01  1.33539736e-01 -7.48581886e-02\n -1.94763005e-01  1.58244133e-01\
          \  1.42674565e-01 -6.35127425e-02\n  1.82332516e-01 -4.37873602e-02 -5.23767471e-02\
          \  5.62581420e-02\n  1.79683089e-01 -1.13860965e-01 -4.89493310e-02  6.31783009e-02\n\
          \  7.70660639e-02  2.83241272e-04  1.46117926e-01 -1.19563445e-01\n -3.17812085e-01\
          \  9.13752317e-02  4.62356210e-02 -2.41753280e-01\n -3.35998654e-01  7.37867951e-02\
          \  1.04967535e-01  1.77428722e-01\n  3.38545561e-01  1.25526845e-01 -5.96841574e-02\
          \ -9.68309045e-02\n  5.82889318e-02  2.68777668e-01  2.40321636e-01  3.02538872e-02\n\
          \ -1.49101645e-01  1.07387424e-01 -1.72864646e-01  2.70506561e-01]"
    num_agent_steps_sampled: 164000
    num_agent_steps_trained: 1956048
    num_steps_sampled: 164000
    num_steps_trained: 1956048
    num_target_updates: 324
  iterations_since_restore: 164
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.18095238095238
    ram_util_percent: 31.91428571428571
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2189.429197072983
  time_this_iter_s: 14.103873491287231
  time_total_s: 2189.429197072983
  timers:
    learn_throughput: 4931.55
    learn_time_ms: 9.733
    update_time_ms: 2.953
  timestamp: 1629282885
  timesteps_since_restore: 0
  timesteps_total: 164000
  training_iteration: 164
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    164 |          2189.43 | 164000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 165000
  custom_metrics: {}
  date: 2021-08-18_10-34-58
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 164800
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06044742837548256
          max_q: -0.10359787940979004
          mean_q: -0.481058806180954
          mean_td_error: 0.042559511959552765
          min_q: -0.6261584758758545
        model: {}
        td_error: "[-0.08578205  0.19550097  0.27653617  0.22030497 -0.20373833  0.10138005\n\
          \ -0.08743137 -0.08570948 -0.36763403  0.22488272 -0.126786    0.28076923\n\
          \  0.18331414 -0.14678863 -0.17430204  0.3761117   0.07708418 -0.07906079\n\
          \  0.00980651  0.0077216   0.2228769   0.22553706  0.12472451  0.19933933\n\
          \ -0.07972443 -0.01278204  0.05186957 -0.1502821   0.15980154  0.09036314\n\
          \  0.21648723 -0.51009107  0.02019215  0.304124    0.16798133  0.02907592\n\
          \  0.10956013  0.05428237  0.02660787 -0.08682007 -0.05370331 -0.1213856\n\
          \ -0.00708932 -0.04165071  0.00721607  0.08151782  0.23761207  0.18103647]"
    num_agent_steps_sampled: 165000
    num_agent_steps_trained: 1968048
    num_steps_sampled: 165000
    num_steps_trained: 1968048
    num_target_updates: 326
  iterations_since_restore: 165
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.4421052631579
    ram_util_percent: 31.905263157894733
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2202.439052581787
  time_this_iter_s: 13.009855508804321
  time_total_s: 2202.439052581787
  timers:
    learn_throughput: 4926.844
    learn_time_ms: 9.743
    update_time_ms: 2.724
  timestamp: 1629282898
  timesteps_since_restore: 0
  timesteps_total: 165000
  training_iteration: 165
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    165 |          2202.44 | 165000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 166000
  custom_metrics: {}
  date: 2021-08-18_10-35-12
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 165808
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12.611075401306152
          max_q: 7255174.0
          mean_q: 302298.5
          mean_td_error: 14.448944091796875
          min_q: -0.6500295996665955
        model: {}
        td_error: "[ 3.54545116e-01  1.20958686e-01 -1.43179029e-01 -1.66571289e-01\n\
          \  4.14490700e-02 -1.73097819e-01 -8.76234770e-02  2.22908735e-01\n -2.15924323e-01\
          \  1.65287554e-01 -2.41910905e-01 -1.89422667e-02\n  1.23664141e-02  8.52379799e-02\
          \ -2.94823050e-02  1.03039145e-02\n  1.42273068e-01  4.53590602e-02 -1.92129612e-02\
          \  3.46500000e+02\n  1.17733836e-01 -7.91966617e-02 -1.17566586e-02  3.23694348e-02\n\
          \ -4.20388579e-02 -2.74851322e-01 -5.25955558e-01  1.98648334e-01\n  3.70240733e-02\
          \  2.04980552e-01  1.06061339e-01 -1.30472362e-01\n  2.59318650e-01  1.05402052e-01\
          \  4.01366949e-01  1.33799911e-01\n -1.39128745e-01 -1.44158125e-01  3.46500000e+02\
          \ -1.26229703e-01\n -8.80784690e-02 -7.78805912e-02  1.33046746e-01  8.92096758e-02\n\
          \  8.70097280e-02  9.75197554e-02 -1.53291434e-01  2.34106421e-01]"
    num_agent_steps_sampled: 166000
    num_agent_steps_trained: 1980048
    num_steps_sampled: 166000
    num_steps_trained: 1980048
    num_target_updates: 328
  iterations_since_restore: 166
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.50500000000002
    ram_util_percent: 31.914999999999992
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2216.2306151390076
  time_this_iter_s: 13.791562557220459
  time_total_s: 2216.2306151390076
  timers:
    learn_throughput: 4836.71
    learn_time_ms: 9.924
    update_time_ms: 3.029
  timestamp: 1629282912
  timesteps_since_restore: 0
  timesteps_total: 166000
  training_iteration: 166
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    166 |          2216.23 | 166000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 167000
  custom_metrics: {}
  date: 2021-08-18_10-35-26
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 166816
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 23.5662784576416
          max_q: 7254452.5
          mean_q: 453402.84375
          mean_td_error: -23.385740280151367
          min_q: -0.6072876453399658
        model: {}
        td_error: "[-3.74000000e+02  9.16123986e-02  3.91613245e-02 -7.99362361e-02\n\
          \ -9.87996757e-02  1.02510452e-01 -1.14594072e-01  1.17164850e-01\n  1.08047247e-01\
          \ -1.94751710e-01  1.24674380e-01 -1.10119551e-01\n  1.07197165e-01 -1.20594323e-01\
          \ -3.74000000e+02 -1.93995416e-01\n  2.13658750e-01  6.48325682e-03 -1.12662703e-01\
          \  1.83358252e-01\n -1.88860536e-01 -2.10105747e-01 -1.22191459e-01 -2.12712675e-01\n\
          \ -2.81985998e-02 -2.03146309e-01  6.87336028e-02 -1.15844548e-01\n -3.74000000e+02\
          \  2.13829756e-01  1.16267443e-01 -4.08426434e-01\n  2.40351677e-01  1.42027080e-01\
          \  1.86757505e-01  2.42046118e-02\n -8.31262767e-02 -6.25738502e-02 -1.90553278e-01\
          \  2.66537488e-01\n  2.75177062e-02 -2.02372238e-01  6.27067089e-02  4.15390134e-02\n\
          \ -3.10675085e-01  3.58420193e-01 -1.43242359e-01  1.49173856e-01]"
    num_agent_steps_sampled: 167000
    num_agent_steps_trained: 1992048
    num_steps_sampled: 167000
    num_steps_trained: 1992048
    num_target_updates: 330
  iterations_since_restore: 167
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.414999999999985
    ram_util_percent: 31.904999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2230.3447806835175
  time_this_iter_s: 14.114165544509888
  time_total_s: 2230.3447806835175
  timers:
    learn_throughput: 4937.755
    learn_time_ms: 9.721
    update_time_ms: 2.949
  timestamp: 1629282926
  timesteps_since_restore: 0
  timesteps_total: 167000
  training_iteration: 167
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    167 |          2230.34 | 167000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 168000
  custom_metrics: {}
  date: 2021-08-18_10-35-42
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 167824
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 10.129778861999512
          max_q: 7255584.0
          mean_q: 302315.5625
          mean_td_error: 31.48993682861328
          min_q: -0.6420918703079224
        model: {}
        td_error: "[ 1.20805800e-01 -1.43040717e-01  1.01835966e-01  3.11352074e-01\n\
          \ -1.69764161e-01  2.33551264e-01 -1.38337612e-01  1.22300267e-01\n -2.29198158e-01\
          \  1.44537210e-01 -2.67783523e-01 -2.00684965e-02\n -1.94662362e-01 -1.02616519e-01\
          \  1.11838818e-01 -1.11116976e-01\n -5.36626637e-01 -1.29300833e-01  1.00207865e-01\
          \ -7.78939724e-02\n -1.55317038e-01  1.25797540e-01  7.56500000e+02 -5.90464771e-01\n\
          \  2.65786171e-01  5.38876653e-02  1.29341483e-01 -1.25932693e-02\n  1.73417568e-01\
          \  7.38783479e-02  7.56500000e+02 -1.07215077e-01\n -3.13185453e-02  3.42920423e-02\
          \  9.86762047e-02 -7.68288076e-02\n  1.09996676e-01  1.91482484e-01 -3.79969418e-01\
          \ -8.24227333e-02\n -2.34336555e-01 -1.62059009e-01 -5.99717274e-02  4.84920859e-01\n\
          \  7.48705864e-03 -3.50224048e-01 -1.01151794e-01 -1.40544176e-02]"
    num_agent_steps_sampled: 168000
    num_agent_steps_trained: 2004048
    num_steps_sampled: 168000
    num_steps_trained: 2004048
    num_target_updates: 332
  iterations_since_restore: 168
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.104545454545466
    ram_util_percent: 31.972727272727273
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2245.6852555274963
  time_this_iter_s: 15.340474843978882
  time_total_s: 2245.6852555274963
  timers:
    learn_throughput: 4841.188
    learn_time_ms: 9.915
    update_time_ms: 2.786
  timestamp: 1629282942
  timesteps_since_restore: 0
  timesteps_total: 168000
  training_iteration: 168
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    168 |          2245.69 | 168000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 169000
  custom_metrics: {}
  date: 2021-08-18_10-35-58
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 168832
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03367717191576958
          max_q: 0.452201783657074
          mean_q: -0.45783016085624695
          mean_td_error: 0.02149379625916481
          min_q: -0.6649353504180908
        model: {}
        td_error: "[ 0.0578354   0.09218812  0.1670987  -0.07059702 -0.12236834  0.21335846\n\
          \ -0.20643233  0.03477037 -0.05190831 -0.01503462  0.00252587  0.0463267\n\
          \ -0.05646408 -0.15977946  0.09916472  0.11519259  0.00584012  0.06299967\n\
          \  0.2775826   0.04187381  0.31793582 -0.22763658  0.17506444 -0.18332067\n\
          \  0.2870633  -0.03264353  0.0161323  -0.32625693  0.34279865  0.19174647\n\
          \  0.15224928 -0.10603487 -0.00501353  0.24629033  0.19329768 -0.13979676\n\
          \ -0.14651567 -0.30599117  0.20136088 -0.08081359  0.07249022 -0.05579662\n\
          \ -0.07224351 -0.00778723 -0.14858007 -0.12780768  0.2112788   0.05605948]"
    num_agent_steps_sampled: 169000
    num_agent_steps_trained: 2016048
    num_steps_sampled: 169000
    num_steps_trained: 2016048
    num_target_updates: 334
  iterations_since_restore: 169
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.6090909090909
    ram_util_percent: 32.00454545454546
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2261.0800178050995
  time_this_iter_s: 15.39476227760315
  time_total_s: 2261.0800178050995
  timers:
    learn_throughput: 5025.25
    learn_time_ms: 9.552
    update_time_ms: 2.882
  timestamp: 1629282958
  timesteps_since_restore: 0
  timesteps_total: 169000
  training_iteration: 169
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    169 |          2261.08 | 169000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 170000
  custom_metrics: {}
  date: 2021-08-18_10-36-14
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 169840
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04245323687791824
          max_q: 0.041699349880218506
          mean_q: -0.473659485578537
          mean_td_error: 0.012380193918943405
          min_q: -0.6934843063354492
        model: {}
        td_error: "[ 0.0615055  -0.05353844 -0.19079316 -0.3016482   0.08790523  0.14309198\n\
          \ -0.18274215 -0.29687205  0.20084202 -0.01834893 -0.09674841 -0.13854615\n\
          \  0.17022067  0.08614784  0.06089395  0.10856491  0.08847734  0.04614353\n\
          \  0.11419803  0.06927299  0.29233915 -0.3468427   0.10349703 -0.12987414\n\
          \  0.1808038   0.06097168  0.11119592  0.05340302 -0.15969908 -0.3015409\n\
          \  0.14082026  0.23398292  0.18586278 -0.02435064 -0.01101202 -0.24962896\n\
          \  0.00171441  0.03840145  0.16541582 -0.14940712  0.13466853  0.20101452\n\
          \  0.02027065  0.31830722  0.06311426 -0.28355935  0.1395576  -0.15320328]"
    num_agent_steps_sampled: 170000
    num_agent_steps_trained: 2028048
    num_steps_sampled: 170000
    num_steps_trained: 2028048
    num_target_updates: 336
  iterations_since_restore: 170
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.645833333333336
    ram_util_percent: 32.00833333333333
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2277.1398334503174
  time_this_iter_s: 16.059815645217896
  time_total_s: 2277.1398334503174
  timers:
    learn_throughput: 4828.126
    learn_time_ms: 9.942
    update_time_ms: 2.951
  timestamp: 1629282974
  timesteps_since_restore: 0
  timesteps_total: 170000
  training_iteration: 170
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    170 |          2277.14 | 170000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 171000
  custom_metrics: {}
  date: 2021-08-18_10-36-30
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 170848
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07946647703647614
          max_q: -0.09829562902450562
          mean_q: -0.4823265075683594
          mean_td_error: 0.04712919518351555
          min_q: -0.6651273369789124
        model: {}
        td_error: "[ 0.12237799  0.17254347 -0.15291831  0.1511786   0.32712305  0.25083244\n\
          \ -0.11400378  0.10373214  0.14120126  0.14629906 -0.04728997  0.18793315\n\
          \ -0.15296125 -0.01882309 -0.0450176   0.17095882 -0.01735806  0.2156269\n\
          \  0.15836912  0.18970811  0.26354736  0.2665277  -0.10798943  0.40198725\n\
          \ -0.25023934  0.16559345 -0.12948237 -0.06776157 -0.0633181  -0.50894165\n\
          \  0.13216859  0.06513739 -0.06933594  0.26586807 -0.02651972  0.1821397\n\
          \ -0.00464612  0.14595824  0.03177363  0.16974604 -0.03414786 -0.03355706\n\
          \ -0.22040814 -0.11169958 -0.04224825  0.07496732  0.13028073 -0.15271127]"
    num_agent_steps_sampled: 171000
    num_agent_steps_trained: 2040048
    num_steps_sampled: 171000
    num_steps_trained: 2040048
    num_target_updates: 338
  iterations_since_restore: 171
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.06363636363635
    ram_util_percent: 32.06363636363637
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2293.011257171631
  time_this_iter_s: 15.871423721313477
  time_total_s: 2293.011257171631
  timers:
    learn_throughput: 4897.575
    learn_time_ms: 9.801
    update_time_ms: 2.908
  timestamp: 1629282990
  timesteps_since_restore: 0
  timesteps_total: 171000
  training_iteration: 171
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    171 |          2293.01 | 171000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 172000
  custom_metrics: {}
  date: 2021-08-18_10-36-46
  done: false
  episode_len_mean: 7299.636363636364
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3627241.947640258
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 22
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 171856
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1068069115281105
          max_q: -0.06436002254486084
          mean_q: -0.5736860036849976
          mean_td_error: -0.0771104097366333
          min_q: -0.7749309539794922
        model: {}
        td_error: "[-0.16111174  0.1804145   0.05104497 -0.18763453 -0.23964536 -0.30668426\n\
          \ -0.08945096  0.14262968 -0.1702882   0.2816955  -0.07244927 -0.08559194\n\
          \ -0.00897199  0.45092696 -0.3512653  -0.32582974  0.15069324 -0.23944992\n\
          \ -0.30781716  0.11244309 -0.01049691 -0.2668771   0.01278359 -0.23666728\n\
          \  0.11957526 -0.04677093 -0.05705932  0.1020636  -0.12558155 -0.21981913\n\
          \ -0.2751628   0.09718239 -0.09198457  0.12588346  0.09739423 -0.0927425\n\
          \ -0.2090885  -0.05499518 -0.13950223 -0.18942702 -0.23220056 -0.24376452\n\
          \ -0.1241402  -0.2433261  -0.22340697 -0.1968419   0.16255349  0.03746182]"
    num_agent_steps_sampled: 172000
    num_agent_steps_trained: 2052048
    num_steps_sampled: 172000
    num_steps_trained: 2052048
    num_target_updates: 340
  iterations_since_restore: 172
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.525
    ram_util_percent: 32.10833333333334
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049222589869104015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.174895381603083
    mean_inference_ms: 1.5836462910530884
    mean_raw_obs_processing_ms: 0.14332221240339957
  time_since_restore: 2309.3350024223328
  time_this_iter_s: 16.323745250701904
  time_total_s: 2309.3350024223328
  timers:
    learn_throughput: 4886.591
    learn_time_ms: 9.823
    update_time_ms: 2.841
  timestamp: 1629283006
  timesteps_since_restore: 0
  timesteps_total: 172000
  training_iteration: 172
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    172 |          2309.34 | 172000 | 3.62724e+06 |          7.25468e+06 |             -198.044 |            7299.64 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 173000
  custom_metrics: {}
  date: 2021-08-18_10-37-01
  done: false
  episode_len_mean: 7504.173913043478
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3784955.0237068334
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 172864
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07026278227567673
          max_q: -0.06280279159545898
          mean_q: -0.5330178737640381
          mean_td_error: 0.047645650804042816
          min_q: -0.7008106708526611
        model: {}
        td_error: "[-0.23891932  0.04568249  0.05251229  0.14733529  0.06476253  0.17677009\n\
          \  0.12441558  0.06878603  0.09652334  0.10933989  0.10501391 -0.06628656\n\
          \  0.1972186  -0.24299204  0.21106523  0.1703775  -0.18882023  0.21438658\n\
          \ -0.15570486 -0.17310551  0.12692124 -0.15398324  0.17537838  0.1692276\n\
          \ -0.16753265 -0.03044581 -0.04123056  0.3070994   0.14989358  0.30652434\n\
          \  0.1334849   0.15739924 -0.03436929  0.05326939  0.10981262 -0.15460733\n\
          \  0.1461612  -0.10378066  0.30223024  0.08366591 -0.07509643 -0.204977\n\
          \ -0.3785482   0.20517445  0.2861837  -0.19547126  0.10108995  0.29515666]"
    num_agent_steps_sampled: 173000
    num_agent_steps_trained: 2064048
    num_steps_sampled: 173000
    num_steps_trained: 2064048
    num_target_updates: 342
  iterations_since_restore: 173
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.87619047619048
    ram_util_percent: 32.076190476190476
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049226577834524006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.201123574849232
    mean_inference_ms: 1.5843001281676816
    mean_raw_obs_processing_ms: 0.14339554484788883
  time_since_restore: 2323.637200117111
  time_this_iter_s: 14.302197694778442
  time_total_s: 2323.637200117111
  timers:
    learn_throughput: 5138.989
    learn_time_ms: 9.34
    update_time_ms: 2.649
  timestamp: 1629283021
  timesteps_since_restore: 0
  timesteps_total: 173000
  training_iteration: 173
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    173 |          2323.64 | 173000 | 3.78496e+06 |          7.25468e+06 |             -198.044 |            7504.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 174000
  custom_metrics: {}
  date: 2021-08-18_10-37-13
  done: false
  episode_len_mean: 7504.173913043478
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3784955.0237068334
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 23
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 173872
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.11895451694726944
          max_q: 0.3459908962249756
          mean_q: -0.49963808059692383
          mean_td_error: 0.0811573937535286
          min_q: -0.7671722173690796
        model: {}
        td_error: "[ 0.06090522  0.23530668  0.2743495   0.31386483  0.19417936  0.1210736\n\
          \  0.0074653   0.11406088  0.07783049  0.11357659 -0.13587105  0.1481939\n\
          \ -0.05285794  0.3499611  -0.31117833  0.11591268  0.21514356 -0.3132583\n\
          \  0.52822673 -0.30877754  0.08463216  0.26769656  0.00649339  0.16859037\n\
          \ -0.02913508  0.28193766 -0.01400191 -0.12060262 -0.05296063  0.3352961\n\
          \  0.1045381  -0.2487762  -0.04912227  0.29593498  0.0329836   0.11898065\n\
          \ -0.08726484 -0.03677255 -0.16620892  0.19905269  0.20110524  0.0832755\n\
          \  0.2209292   0.17545444  0.14742327  0.3160166   0.17292762 -0.26097566]"
    num_agent_steps_sampled: 174000
    num_agent_steps_trained: 2076048
    num_steps_sampled: 174000
    num_steps_trained: 2076048
    num_target_updates: 344
  iterations_since_restore: 174
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.5
    ram_util_percent: 32.00625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049226577834524006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.201123574849232
    mean_inference_ms: 1.5843001281676816
    mean_raw_obs_processing_ms: 0.14339554484788883
  time_since_restore: 2335.1461787223816
  time_this_iter_s: 11.508978605270386
  time_total_s: 2335.1461787223816
  timers:
    learn_throughput: 4496.657
    learn_time_ms: 10.675
    update_time_ms: 2.961
  timestamp: 1629283033
  timesteps_since_restore: 0
  timesteps_total: 174000
  training_iteration: 174
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    174 |          2335.15 | 174000 | 3.78496e+06 |          7.25468e+06 |             -198.044 |            7504.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 175000
  custom_metrics: {}
  date: 2021-08-18_10-37-25
  done: false
  episode_len_mean: 7504.173913043478
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3784955.0237068334
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 23
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 174880
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.18712043762207
          max_q: 7255154.0
          mean_q: 151148.484375
          mean_td_error: 6.866486549377441
          min_q: -0.8077179193496704
        model: {}
        td_error: "[ 8.95551741e-02  2.00648308e-02 -1.10944033e-01  5.50904274e-02\n\
          \  1.96375668e-01  3.28500000e+02  7.51480460e-02 -2.39232183e-02\n  1.31894410e-01\
          \ -2.21374333e-02  3.57179582e-01 -2.12764204e-01\n  1.65521681e-01 -9.21431184e-02\
          \  2.92276144e-01  6.28925562e-02\n  2.26267308e-01  3.43163610e-02  1.47942424e-01\
          \ -1.03782296e-01\n  1.80183113e-01 -9.96659398e-02  2.37741649e-01 -7.02276826e-02\n\
          \ -1.45950377e-01 -2.61178851e-01  1.71599984e-01 -1.49752557e-01\n -2.15009034e-01\
          \ -7.43270814e-02  2.23137736e-01 -2.06633210e-01\n  2.29805708e-01 -2.56555766e-01\
          \  1.90421999e-01  8.91495347e-02\n -2.67275572e-02  1.44097626e-01 -4.69824672e-02\
          \  5.18530607e-03\n -1.73267841e-01 -4.47247177e-02  1.03099227e-01  6.80845976e-02\n\
          \ -2.29386836e-01  1.88614666e-01  1.73851609e-01 -2.02069342e-01]"
    num_agent_steps_sampled: 175000
    num_agent_steps_trained: 2088048
    num_steps_sampled: 175000
    num_steps_trained: 2088048
    num_target_updates: 346
  iterations_since_restore: 175
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.62777777777777
    ram_util_percent: 32.00555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049226577834524006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.201123574849232
    mean_inference_ms: 1.5843001281676816
    mean_raw_obs_processing_ms: 0.14339554484788883
  time_since_restore: 2347.53236413002
  time_this_iter_s: 12.38618540763855
  time_total_s: 2347.53236413002
  timers:
    learn_throughput: 3621.457
    learn_time_ms: 13.254
    update_time_ms: 5.575
  timestamp: 1629283045
  timesteps_since_restore: 0
  timesteps_total: 175000
  training_iteration: 175
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    175 |          2347.53 | 175000 | 3.78496e+06 |          7.25468e+06 |             -198.044 |            7504.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 176000
  custom_metrics: {}
  date: 2021-08-18_10-37-38
  done: false
  episode_len_mean: 7504.173913043478
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3784955.0237068334
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 23
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 175888
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.084999084472656
          max_q: 7254914.0
          mean_q: 151143.453125
          mean_td_error: 1.8498525619506836
          min_q: -0.8434785008430481
        model: {}
        td_error: "[ 4.54252958e-03  2.24751234e-02  1.52664959e-01  1.21000588e-01\n\
          \ -2.34992623e-01 -2.22112000e-01 -4.11695242e-02  2.34873652e-01\n -4.38002348e-02\
          \  2.14086473e-01  9.29890275e-02 -8.81075859e-02\n  2.85740018e-01  1.63183093e-01\
          \  1.24766707e-01  1.30771935e-01\n  2.89059281e-01  1.81626558e-01 -8.50059390e-02\
          \  7.96956420e-02\n  4.16052341e-02  1.98074520e-01  4.53586102e-01  2.65147328e-01\n\
          \  2.53047943e-01 -1.85148776e-01  4.14920449e-02 -1.74377888e-01\n  2.90980160e-01\
          \  1.23530805e-01 -3.88452411e-02  2.53694355e-01\n -1.43317103e-01  1.16306841e-01\
          \  8.55000000e+01  1.83759868e-01\n -1.41875893e-01  1.66814268e-01 -1.47784501e-01\
          \  3.20438087e-01\n -1.62286043e-01  1.02578044e-01 -1.12385511e-01 -1.27150059e-01\n\
          \ -2.67185688e-01  2.49108493e-01  1.15724504e-01  2.35104978e-01]"
    num_agent_steps_sampled: 176000
    num_agent_steps_trained: 2100048
    num_steps_sampled: 176000
    num_steps_trained: 2100048
    num_target_updates: 348
  iterations_since_restore: 176
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.44736842105263
    ram_util_percent: 32.0
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049226577834524006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.201123574849232
    mean_inference_ms: 1.5843001281676816
    mean_raw_obs_processing_ms: 0.14339554484788883
  time_since_restore: 2360.2001297473907
  time_this_iter_s: 12.667765617370605
  time_total_s: 2360.2001297473907
  timers:
    learn_throughput: 4625.592
    learn_time_ms: 10.377
    update_time_ms: 2.858
  timestamp: 1629283058
  timesteps_since_restore: 0
  timesteps_total: 176000
  training_iteration: 176
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    176 |           2360.2 | 176000 | 3.78496e+06 |          7.25468e+06 |             -198.044 |            7504.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 177000
  custom_metrics: {}
  date: 2021-08-18_10-37-51
  done: false
  episode_len_mean: 7504.173913043478
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3784955.0237068334
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 23
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 176896
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04619954898953438
          max_q: -0.04535907506942749
          mean_q: -0.8029664754867554
          mean_td_error: 0.021097710356116295
          min_q: -1.0427749156951904
        model: {}
        td_error: "[ 0.04176113 -0.27156538  0.07817578  0.05352914  0.19039589  0.08805144\n\
          \  0.01592332  0.2975672   0.29337764 -0.05695009  0.06628108  0.01476711\n\
          \ -0.01215744  0.16789156  0.00706881  0.17029303 -0.27485508  0.20512944\n\
          \  0.13642359  0.16271734 -0.2564078   0.00315601 -0.30611944  0.08676088\n\
          \ -0.19594097  0.2336694  -0.12593395 -0.23259288 -0.24902928  0.01766008\n\
          \  0.11299795  0.00818425 -0.13798556  0.0028708  -0.40615353  0.15719634\n\
          \  0.07730633 -0.36832383  0.22590011  0.16583174  0.04166102  0.10214078\n\
          \  0.0827108   0.16254932  0.2980051   0.11684632  0.19811314 -0.17620856]"
    num_agent_steps_sampled: 177000
    num_agent_steps_trained: 2112048
    num_steps_sampled: 177000
    num_steps_trained: 2112048
    num_target_updates: 350
  iterations_since_restore: 177
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.75
    ram_util_percent: 32.00555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049226577834524006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.201123574849232
    mean_inference_ms: 1.5843001281676816
    mean_raw_obs_processing_ms: 0.14339554484788883
  time_since_restore: 2373.0663781166077
  time_this_iter_s: 12.866248369216919
  time_total_s: 2373.0663781166077
  timers:
    learn_throughput: 5037.585
    learn_time_ms: 9.528
    update_time_ms: 2.699
  timestamp: 1629283071
  timesteps_since_restore: 0
  timesteps_total: 177000
  training_iteration: 177
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    177 |          2373.07 | 177000 | 3.78496e+06 |          7.25468e+06 |             -198.044 |            7504.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 178000
  custom_metrics: {}
  date: 2021-08-18_10-38-05
  done: false
  episode_len_mean: 7504.173913043478
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3784955.0237068334
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 23
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 177904
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0685783326625824
          max_q: -0.2863194942474365
          mean_q: -0.7103862166404724
          mean_td_error: 0.027634790167212486
          min_q: -0.926352322101593
        model: {}
        td_error: "[ 0.03062153  0.31065005 -0.03699654 -0.22926602 -0.1766274   0.24234223\n\
          \ -0.01909646 -0.20118731  0.24675107  0.39662057  0.040326    0.06424266\n\
          \  0.14335573  0.11223447  0.15335971  0.0518989  -0.10371029  0.19003463\n\
          \ -1.2426211   0.2839263  -0.01420248  0.07300192  0.23207593  0.15522367\n\
          \ -0.148435   -0.18341136  0.24273312  0.25476372 -0.17762458 -0.09345788\n\
          \  0.07778019 -0.1085484  -0.35229945 -0.08409935 -0.04128969  0.20704055\n\
          \  0.14852774  0.21667773  0.3054458   0.06815094  0.3358764  -0.03948736\n\
          \  0.10577005 -0.00673455  0.21598566 -0.3775184   0.08428127 -0.02661526]"
    num_agent_steps_sampled: 178000
    num_agent_steps_trained: 2124048
    num_steps_sampled: 178000
    num_steps_trained: 2124048
    num_target_updates: 352
  iterations_since_restore: 178
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.01
    ram_util_percent: 32.005
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049226577834524006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.201123574849232
    mean_inference_ms: 1.5843001281676816
    mean_raw_obs_processing_ms: 0.14339554484788883
  time_since_restore: 2386.5492005348206
  time_this_iter_s: 13.48282241821289
  time_total_s: 2386.5492005348206
  timers:
    learn_throughput: 4963.123
    learn_time_ms: 9.671
    update_time_ms: 2.721
  timestamp: 1629283085
  timesteps_since_restore: 0
  timesteps_total: 178000
  training_iteration: 178
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    178 |          2386.55 | 178000 | 3.78496e+06 |          7.25468e+06 |             -198.044 |            7504.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 179000
  custom_metrics: {}
  date: 2021-08-18_10-38-19
  done: false
  episode_len_mean: 7504.173913043478
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3784955.0237068334
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 23
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 178912
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.039420854300260544
          max_q: 0.5224903225898743
          mean_q: -0.7769303321838379
          mean_td_error: -0.02311071753501892
          min_q: -1.0452284812927246
        model: {}
        td_error: "[-4.92894053e-02  4.79221344e-04 -6.73013926e-03 -3.16766500e-02\n\
          \  1.49952114e-01 -7.99785554e-02 -1.99338496e-01  1.20202363e-01\n -2.29166150e-02\
          \  1.42402411e-01  6.91964626e-02  1.34394765e-01\n -2.74653941e-01 -2.69220084e-01\
          \  1.81978285e-01  1.23289943e-01\n -1.22608483e-01  8.41305852e-02  9.32604074e-02\
          \  7.51124024e-02\n  2.28942096e-01 -7.13781118e-02 -3.68243277e-01  4.21489775e-01\n\
          \ -1.68003976e-01  1.56772733e-01 -2.00343192e-01  9.38203335e-02\n -4.44887280e-02\
          \ -1.21702671e-01 -2.18924284e-01  1.58138871e-02\n  4.82843518e-02  1.13660932e-01\
          \  1.50856018e-01  7.94214010e-02\n  1.98435307e-01 -1.73295438e-01  1.65852010e-01\
          \ -1.35679662e-01\n -1.33362055e-01  1.15406573e-01 -2.71039188e-01 -2.43083596e-01\n\
          \  5.21801710e-02 -3.07744741e-02 -7.81452060e-01 -1.06465936e-01]"
    num_agent_steps_sampled: 179000
    num_agent_steps_trained: 2136048
    num_steps_sampled: 179000
    num_steps_trained: 2136048
    num_target_updates: 354
  iterations_since_restore: 179
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.46842105263157
    ram_util_percent: 32.00526315789474
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049226577834524006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.201123574849232
    mean_inference_ms: 1.5843001281676816
    mean_raw_obs_processing_ms: 0.14339554484788883
  time_since_restore: 2399.937215566635
  time_this_iter_s: 13.388015031814575
  time_total_s: 2399.937215566635
  timers:
    learn_throughput: 4882.61
    learn_time_ms: 9.831
    update_time_ms: 2.856
  timestamp: 1629283099
  timesteps_since_restore: 0
  timesteps_total: 179000
  training_iteration: 179
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    179 |          2399.94 | 179000 | 3.78496e+06 |          7.25468e+06 |             -198.044 |            7504.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 180000
  custom_metrics: {}
  date: 2021-08-18_10-38-33
  done: false
  episode_len_mean: 7504.173913043478
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3784955.0237068334
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 23
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 179920
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.431980609893799
          max_q: 7254819.0
          mean_q: 151141.34375
          mean_td_error: -0.1530275195837021
          min_q: -1.043636679649353
        model: {}
        td_error: "[-0.23518413  0.10079873 -0.09689265  0.36374283 -0.05678749  0.18252248\n\
          \ -0.06871325  0.12585205  0.1649977  -0.14802146  0.04634017 -0.24135214\n\
          \ -0.10419941 -0.13031173  0.15537417  0.08721066  0.1464209  -0.15372515\n\
          \  0.02080554 -0.434497    0.22760159 -0.17394167 -0.16057557 -0.09416223\n\
          \  0.06741351 -0.04217404  0.22778457  0.23838407  0.08855522  0.04630792\n\
          \  0.10520679  0.33514237  0.11089545  0.13259548 -0.08913916 -0.07683992\n\
          \ -0.27202648  0.03220475  0.24019247  0.17648506  0.16412444  0.09057552\n\
          \ -8.5        -0.26542747 -0.1212682   0.24613416  0.2699998  -0.0737493 ]"
    num_agent_steps_sampled: 180000
    num_agent_steps_trained: 2148048
    num_steps_sampled: 180000
    num_steps_trained: 2148048
    num_target_updates: 356
  iterations_since_restore: 180
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.935
    ram_util_percent: 32.005
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049226577834524006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.201123574849232
    mean_inference_ms: 1.5843001281676816
    mean_raw_obs_processing_ms: 0.14339554484788883
  time_since_restore: 2413.4743387699127
  time_this_iter_s: 13.537123203277588
  time_total_s: 2413.4743387699127
  timers:
    learn_throughput: 5040.94
    learn_time_ms: 9.522
    update_time_ms: 2.812
  timestamp: 1629283113
  timesteps_since_restore: 0
  timesteps_total: 180000
  training_iteration: 180
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    180 |          2413.47 | 180000 | 3.78496e+06 |          7.25468e+06 |             -198.044 |            7504.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 181000
  custom_metrics: {}
  date: 2021-08-18_10-38-46
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 180928
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08349388837814331
          max_q: -0.39499080181121826
          mean_q: -0.7440283298492432
          mean_td_error: -0.0688454732298851
          min_q: -0.9778727889060974
        model: {}
        td_error: "[-0.86467624 -0.14510477  0.16209465  0.23861474  0.24518752  0.09189379\n\
          \  0.10825789 -0.22189826  0.11959624 -0.2709849   0.05287844 -0.20150298\n\
          \ -0.17150837  0.03358889  0.07030457 -0.04811478  0.01818794  0.22774833\n\
          \ -0.07854658 -0.35373852 -0.05731148  0.08263856 -0.2466836  -0.65748703\n\
          \  0.14009023  0.12218833  0.17011333  0.01838762 -0.06350803 -0.16831398\n\
          \ -0.66819364  0.02768528 -0.19674736  0.1398136  -0.11936057  0.13714314\n\
          \  0.01668549  0.18154895  0.1673091   0.06799954 -0.35013264  0.18385875\n\
          \ -0.07595021 -0.9213836   0.04094326 -0.27055156 -0.21708763  0.19944584]"
    num_agent_steps_sampled: 181000
    num_agent_steps_trained: 2160048
    num_steps_sampled: 181000
    num_steps_trained: 2160048
    num_target_updates: 358
  iterations_since_restore: 181
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.03684210526315
    ram_util_percent: 32.00526315789474
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2426.3795580863953
  time_this_iter_s: 12.905219316482544
  time_total_s: 2426.3795580863953
  timers:
    learn_throughput: 4281.085
    learn_time_ms: 11.212
    update_time_ms: 3.815
  timestamp: 1629283126
  timesteps_since_restore: 0
  timesteps_total: 181000
  training_iteration: 181
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    181 |          2426.38 | 181000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 182000
  custom_metrics: {}
  date: 2021-08-18_10-38-56
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 181936
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 13.789388656616211
          max_q: 7255163.0
          mean_q: 302298.125
          mean_td_error: 13.90115737915039
          min_q: -0.8847861886024475
        model: {}
        td_error: "[-2.23112985e-01 -3.46488953e-02  3.12047839e-01 -1.28343612e-01\n\
          \  9.80542004e-02  2.03337133e-01 -1.00882113e-01 -4.06541467e-01\n  1.79054141e-01\
          \  8.56863856e-02 -2.88665295e-01  2.93132067e-02\n -8.08301270e-01 -7.51630425e-01\
          \  3.33972156e-01 -2.22341061e-01\n  1.12101316e-01 -1.57516599e-02  4.86509621e-01\
          \  7.09818006e-02\n  3.35500000e+02  4.86328423e-01  2.50355043e-02 -7.15106010e-01\n\
          \ -1.29304826e-01  2.30773687e-02  3.62961233e-01  3.35500000e+02\n  1.06143117e-01\
          \  6.73694015e-02 -2.65159786e-01 -3.52042198e-01\n  1.00350857e-01 -2.65332460e-01\
          \ -8.32408667e-01 -4.05038059e-01\n -2.77004808e-01  3.99840862e-01 -9.34599638e-02\
          \ -1.01023495e-01\n -6.01232648e-02 -1.03487849e-01 -2.44670823e-01 -9.40682888e-02\n\
          \  3.62371862e-01 -4.03193474e-01  5.39852977e-02 -3.21345657e-01]"
    num_agent_steps_sampled: 182000
    num_agent_steps_trained: 2172048
    num_steps_sampled: 182000
    num_steps_trained: 2172048
    num_target_updates: 360
  iterations_since_restore: 182
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.233333333333334
    ram_util_percent: 32.0
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2436.726477622986
  time_this_iter_s: 10.346919536590576
  time_total_s: 2436.726477622986
  timers:
    learn_throughput: 3706.225
    learn_time_ms: 12.951
    update_time_ms: 3.757
  timestamp: 1629283136
  timesteps_since_restore: 0
  timesteps_total: 182000
  training_iteration: 182
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    182 |          2436.73 | 182000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 183000
  custom_metrics: {}
  date: 2021-08-18_10-39-08
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 182944
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.888937950134277
          max_q: 7255248.0
          mean_q: 151150.640625
          mean_td_error: 8.759623527526855
          min_q: -0.5534892082214355
        model: {}
        td_error: "[ 3.8759060e-02  8.0661774e-03 -4.8610231e-01  2.4074429e-01\n  3.8535964e-01\
          \ -6.0798943e-02 -3.5058999e-01 -2.4395418e-01\n -9.0437770e-02  2.4414027e-01\
          \  1.1398369e-01 -3.3305407e-02\n -1.7772752e-01  4.2000000e+02  3.8858348e-01\
          \  2.5023258e-01\n -1.7734045e-01  6.1962843e-02  1.9354546e-01 -1.9318824e-01\n\
          \  3.7948936e-01  8.6193651e-02  3.8859397e-02  5.0063163e-02\n -2.9615757e-01\
          \  9.9484444e-02  2.4640858e-03 -1.4540237e-01\n -8.0226541e-02  8.4047318e-02\
          \  9.5095515e-02  2.4409097e-01\n -6.1335683e-02 -7.7006310e-02 -1.0805133e-01\
          \  4.6737015e-02\n  7.1891069e-02 -9.6426153e-01  1.5656745e-01  3.0448431e-01\n\
          \  3.0168587e-01 -1.7620207e-01 -2.2723353e-01  2.0143801e-01\n -9.4211161e-02\
          \  2.3725814e-01  2.3361039e-01 -5.3399593e-02]"
    num_agent_steps_sampled: 183000
    num_agent_steps_trained: 2184048
    num_steps_sampled: 183000
    num_steps_trained: 2184048
    num_target_updates: 362
  iterations_since_restore: 183
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.99375
    ram_util_percent: 32.0
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2447.9104659557343
  time_this_iter_s: 11.183988332748413
  time_total_s: 2447.9104659557343
  timers:
    learn_throughput: 2414.547
    learn_time_ms: 19.88
    update_time_ms: 6.76
  timestamp: 1629283148
  timesteps_since_restore: 0
  timesteps_total: 183000
  training_iteration: 183
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    183 |          2447.91 | 183000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 184000
  custom_metrics: {}
  date: 2021-08-18_10-39-20
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 183952
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.09919119626283646
          max_q: 1.5727421045303345
          mean_q: -0.03366165608167648
          mean_td_error: -0.09559853374958038
          min_q: -0.4513413906097412
        model: {}
        td_error: "[ 0.32364714  0.01608658 -0.77328086 -0.00264716 -0.16191491 -0.9075432\n\
          \ -0.11695686 -0.13042665 -0.03554547  0.24019456  0.14028844  0.3659503\n\
          \ -0.11828366 -0.30890858  0.10849363  0.22973311 -0.24746294 -0.4541886\n\
          \  0.54288006 -0.49308136 -0.12022886 -0.0079772   0.10776359 -0.1918715\n\
          \ -0.0903879  -0.02458566  0.23645383 -0.03818387 -0.5627736  -0.90777194\n\
          \  0.12730104 -0.02587888  0.05380794  0.0907028  -1.0353398   0.1555866\n\
          \  0.10606043 -0.99141234 -0.05583429  0.12666959 -0.1487895  -0.01175395\n\
          \ -0.10382786 -0.0060496  -0.00226897  0.06002796  0.0838694   0.37092936]"
    num_agent_steps_sampled: 184000
    num_agent_steps_trained: 2196048
    num_steps_sampled: 184000
    num_steps_trained: 2196048
    num_target_updates: 364
  iterations_since_restore: 184
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.12941176470588
    ram_util_percent: 32.0
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2459.8718523979187
  time_this_iter_s: 11.961386442184448
  time_total_s: 2459.8718523979187
  timers:
    learn_throughput: 5054.457
    learn_time_ms: 9.497
    update_time_ms: 2.783
  timestamp: 1629283160
  timesteps_since_restore: 0
  timesteps_total: 184000
  training_iteration: 184
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    184 |          2459.87 | 184000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 185000
  custom_metrics: {}
  date: 2021-08-18_10-39-32
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 184960
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.09405700117349625
          max_q: 0.8461096286773682
          mean_q: -0.002642326056957245
          mean_td_error: 0.08283095061779022
          min_q: -0.2638733386993408
        model: {}
        td_error: "[-0.14089018  0.24505043  0.15396135  0.16686568  0.19804516  0.14617994\n\
          \ -0.19571786  0.23336244 -0.24083614 -0.09455059  0.13069993  0.09043115\n\
          \  0.08032495  0.10622065  0.15240926 -0.21423435 -0.19578043  0.3317706\n\
          \  0.10139276  0.24488309  0.04173224 -0.04875568  0.23649782  0.50491506\n\
          \  0.17638385  0.26023465 -0.17915648  0.13726337  0.21166538  0.34757555\n\
          \  0.08698651  0.01556861 -0.13919242  0.10269473 -0.03642973  0.03271297\n\
          \ -0.13208023  0.24157983 -0.03101194  0.2503407   0.03816107  0.1709134\n\
          \  0.19977944  0.147228    0.03577214 -0.07047217 -0.22244643  0.29783738]"
    num_agent_steps_sampled: 185000
    num_agent_steps_trained: 2208048
    num_steps_sampled: 185000
    num_steps_trained: 2208048
    num_target_updates: 366
  iterations_since_restore: 185
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.62777777777777
    ram_util_percent: 32.0
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2471.947240114212
  time_this_iter_s: 12.075387716293335
  time_total_s: 2471.947240114212
  timers:
    learn_throughput: 4985.812
    learn_time_ms: 9.627
    update_time_ms: 2.732
  timestamp: 1629283172
  timesteps_since_restore: 0
  timesteps_total: 185000
  training_iteration: 185
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    185 |          2471.95 | 185000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 186000
  custom_metrics: {}
  date: 2021-08-18_10-39-46
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 185968
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03389543294906616
          max_q: 1.1417291164398193
          mean_q: 0.19921694695949554
          mean_td_error: 0.028336718678474426
          min_q: -0.07966792583465576
        model: {}
        td_error: "[ 0.23387082  0.21683063 -0.01808245 -0.35353437  0.18825503  0.21233013\n\
          \  0.04467665  0.07479925  0.05223354 -0.08018813 -0.09267384  0.05613153\n\
          \ -0.02770619  0.2065049  -0.1538969  -0.1571427   0.1526877   0.07675433\n\
          \  0.06114949 -0.12177999  0.148354   -0.07096621 -0.17311901 -0.17334452\n\
          \  0.33861467  0.01318228 -0.07943259  0.5190464   0.12549827 -0.00157702\n\
          \  0.16344514  0.18339443 -0.13120562  0.16056387 -0.8538448   0.26055285\n\
          \ -0.8119265   0.0806521   0.05581999 -0.00322593  0.05276866  0.11327623\n\
          \  0.3734317   0.6354241  -0.15053087 -0.09227228  0.03109545  0.07526834]"
    num_agent_steps_sampled: 186000
    num_agent_steps_trained: 2220048
    num_steps_sampled: 186000
    num_steps_trained: 2220048
    num_target_updates: 368
  iterations_since_restore: 186
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.46842105263158
    ram_util_percent: 32.0
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2485.02837061882
  time_this_iter_s: 13.081130504608154
  time_total_s: 2485.02837061882
  timers:
    learn_throughput: 4901.558
    learn_time_ms: 9.793
    update_time_ms: 2.749
  timestamp: 1629283186
  timesteps_since_restore: 0
  timesteps_total: 186000
  training_iteration: 186
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    186 |          2485.03 | 186000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 187000
  custom_metrics: {}
  date: 2021-08-18_10-39-59
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 186976
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.467397212982178
          max_q: 7255764.5
          mean_q: 151161.8125
          mean_td_error: 19.528514862060547
          min_q: -0.13402462005615234
        model: {}
        td_error: "[-1.44630224e-02 -6.01838231e-02  5.59138358e-02  3.39746475e-03\n\
          \  2.59813249e-01 -1.74745589e-01  2.72428930e-01 -1.89542055e-01\n -2.68398374e-01\
          \  9.37000000e+02  3.98389190e-01  2.27587402e-01\n -7.09648579e-02 -2.78618544e-01\
          \  2.28594244e-02  1.21652514e-01\n  1.80723369e-01  1.21208280e-01  2.67986923e-01\
          \ -4.79609370e-02\n  3.07675749e-01 -2.57929713e-01  2.01908886e-01 -5.04516885e-02\n\
          \ -3.28389645e-01  9.78294611e-02  2.63942719e-01  2.17981815e-01\n  1.43496454e-01\
          \  2.27580890e-01  2.03310370e-01 -3.18963647e-01\n  6.39201328e-02 -1.11612633e-01\
          \ -1.34451494e-01 -1.05950102e-01\n  8.99491459e-02 -1.32754385e-01  4.05312777e-02\
          \  1.72776818e-01\n -3.08696508e-01 -1.87026754e-01  4.91146669e-02  1.16560627e-02\n\
          \  1.27930135e-01 -9.16116595e-01  2.13348493e-02  1.52988866e-01]"
    num_agent_steps_sampled: 187000
    num_agent_steps_trained: 2232048
    num_steps_sampled: 187000
    num_steps_trained: 2232048
    num_target_updates: 370
  iterations_since_restore: 187
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.0578947368421
    ram_util_percent: 32.0
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2498.32817029953
  time_this_iter_s: 13.299799680709839
  time_total_s: 2498.32817029953
  timers:
    learn_throughput: 5021.778
    learn_time_ms: 9.558
    update_time_ms: 2.773
  timestamp: 1629283199
  timesteps_since_restore: 0
  timesteps_total: 187000
  training_iteration: 187
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    187 |          2498.33 | 187000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 188000
  custom_metrics: {}
  date: 2021-08-18_10-40-13
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 187984
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03864866867661476
          max_q: 1.161958932876587
          mean_q: 0.053577542304992676
          mean_td_error: 0.01105466391891241
          min_q: -0.3619334101676941
        model: {}
        td_error: "[ 0.12905431  0.11398196  0.1718092  -0.12638265 -0.08399144 -0.08008566\n\
          \  0.2964794   0.23113301  0.2505901   0.16053885 -0.0148569  -0.08930883\n\
          \  0.01633862 -0.09967165 -0.9255342  -0.07952347  0.08476439 -0.14526889\n\
          \ -0.03105884  0.06706282  0.03048676 -0.03389573  0.16959956  0.12003016\n\
          \ -0.10236043 -0.09584591  0.17309925 -0.03010798 -0.26036114  0.03945638\n\
          \ -0.29897472 -0.30638552  0.14134842  0.38613668 -0.12392831  0.33208865\n\
          \ -0.0312137   0.16036656  0.12311423  0.12939185 -0.04896614 -0.21858174\n\
          \ -0.01417349  0.0228753   0.16527939  0.24636316 -0.27318102  0.28289336]"
    num_agent_steps_sampled: 188000
    num_agent_steps_trained: 2244048
    num_steps_sampled: 188000
    num_steps_trained: 2244048
    num_target_updates: 372
  iterations_since_restore: 188
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.804999999999986
    ram_util_percent: 32.0
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2512.254387140274
  time_this_iter_s: 13.926216840744019
  time_total_s: 2512.254387140274
  timers:
    learn_throughput: 3438.858
    learn_time_ms: 13.958
    update_time_ms: 4.29
  timestamp: 1629283213
  timesteps_since_restore: 0
  timesteps_total: 188000
  training_iteration: 188
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    188 |          2512.25 | 188000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 189000
  custom_metrics: {}
  date: 2021-08-18_10-40-28
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 188992
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.12230952829122543
          max_q: 1.9464747905731201
          mean_q: 0.013159758411347866
          mean_td_error: -0.1376536786556244
          min_q: -0.2883673310279846
        model: {}
        td_error: "[ 0.13977008  0.17191286  0.03404388 -0.12196714 -0.43483108 -0.03632939\n\
          \ -0.03481387 -0.66091704  0.05946463 -0.06903442 -0.370706   -0.15054405\n\
          \ -0.24364078 -0.1167484  -0.1975154   0.48210192 -1.0605474  -1.1001495\n\
          \ -0.37463987 -1.0347179  -0.34108698 -0.10844227  0.10029165  0.08465181\n\
          \ -0.0404778  -0.21823457 -0.1280083   0.0132934   0.40725434  0.28814515\n\
          \ -0.2075766   0.03343415 -0.91369516  0.05384149  0.18515372  0.14319839\n\
          \ -0.0655536  -0.18756346 -0.44782245 -0.43454432 -0.248474    0.13812073\n\
          \  0.04994839  0.14027593 -0.43396917  0.08276372  0.16204208  0.40546638]"
    num_agent_steps_sampled: 189000
    num_agent_steps_trained: 2256048
    num_steps_sampled: 189000
    num_steps_trained: 2256048
    num_target_updates: 374
  iterations_since_restore: 189
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.0090909090909
    ram_util_percent: 32.0
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2527.012992143631
  time_this_iter_s: 14.758605003356934
  time_total_s: 2527.012992143631
  timers:
    learn_throughput: 4815.734
    learn_time_ms: 9.967
    update_time_ms: 2.768
  timestamp: 1629283228
  timesteps_since_restore: 0
  timesteps_total: 189000
  training_iteration: 189
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    189 |          2527.01 | 189000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 190000
  custom_metrics: {}
  date: 2021-08-18_10-40-44
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 190000
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 23.422443389892578
          max_q: 7255228.0
          mean_q: 604602.25
          mean_td_error: 33.36474609375
          min_q: -0.2742753028869629
        model: {}
        td_error: "[-1.7942324e-01  3.5018869e-02  4.0050000e+02 -1.5822524e-01\n -1.0672302e+00\
          \  1.5999825e-01  1.5697032e-03 -5.5659473e-02\n  4.0050000e+02 -2.4028093e-01\
          \  3.3271223e-02 -2.7519166e-02\n  1.5947193e-01 -2.3831606e-01  3.0979285e-01\
          \  9.7261518e-03\n -1.8420935e-02  4.9561429e-01  1.1153138e-01  3.2686231e-01\n\
          \ -9.5616564e-02  2.6629993e-01 -8.0740541e-02  4.0825203e-01\n -1.9615890e-01\
          \ -1.2898859e-01  1.1753118e-01  3.6615625e-01\n  6.7811310e-02 -3.1420049e-01\
          \  2.7632207e-01  1.9529700e-01\n  2.3020238e-01 -2.6296490e-01 -2.2514835e-01\
          \  8.3691299e-02\n -4.5146748e-02  4.0050000e+02 -3.3641571e-01  3.1401837e-01\n\
          \  1.0930821e-01 -2.3718326e-01 -5.6332040e-01  1.9376874e-01\n  4.0050000e+02\
          \  1.5385084e-01 -2.5544354e-01 -1.9136715e-01]"
    num_agent_steps_sampled: 190000
    num_agent_steps_trained: 2268048
    num_steps_sampled: 190000
    num_steps_trained: 2268048
    num_target_updates: 376
  iterations_since_restore: 190
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.64545454545455
    ram_util_percent: 32.00454545454546
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2542.0910274982452
  time_this_iter_s: 15.078035354614258
  time_total_s: 2542.0910274982452
  timers:
    learn_throughput: 4933.0
    learn_time_ms: 9.73
    update_time_ms: 2.822
  timestamp: 1629283244
  timesteps_since_restore: 0
  timesteps_total: 190000
  training_iteration: 190
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    190 |          2542.09 | 190000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 191000
  custom_metrics: {}
  date: 2021-08-18_10-41-00
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 190504
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.034241002053022385
          max_q: 0.385936975479126
          mean_q: 0.061605870723724365
          mean_td_error: -0.022508889436721802
          min_q: -0.23306256532669067
        model: {}
        td_error: "[ 1.79404780e-01 -3.80852371e-02 -1.81862637e-01  3.01777840e-01\n\
          \  1.71180546e-01 -1.22352719e-01  4.64396141e-02  2.07108647e-01\n  7.67135620e-02\
          \  7.27678314e-02 -7.46826530e-02 -3.89371440e-02\n  3.12799454e-01  1.95339143e-01\
          \  1.37004092e-01 -1.89979188e-03\n  1.36457860e-01 -8.22509527e-02 -1.60891667e-01\
          \ -1.17484736e+00\n  4.24730480e-02  1.24319889e-01 -1.16677359e-02 -1.78328484e-01\n\
          \ -1.24305815e-01 -3.08650672e-01 -1.27680078e-01  1.55128881e-01\n  1.81238800e-01\
          \ -9.70953479e-02 -1.48075998e-01  1.93028569e-01\n -4.44415927e-01  1.90526232e-01\
          \ -8.24415684e-03 -1.86104029e-01\n  1.09729171e-03  1.31430164e-01 -1.67192191e-01\
          \ -1.54465586e-01\n  7.12639987e-02 -1.04442090e-01 -2.39802688e-01  2.13858277e-01\n\
          \ -1.05922356e-01  8.47595185e-02 -5.46862185e-03 -1.88729763e-02]"
    num_agent_steps_sampled: 191000
    num_agent_steps_trained: 2280048
    num_steps_sampled: 191000
    num_steps_trained: 2280048
    num_target_updates: 377
  iterations_since_restore: 191
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.52727272727272
    ram_util_percent: 32.00454545454546
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2557.8281738758087
  time_this_iter_s: 15.737146377563477
  time_total_s: 2557.8281738758087
  timers:
    learn_throughput: 5022.655
    learn_time_ms: 9.557
    update_time_ms: 2.933
  timestamp: 1629283260
  timesteps_since_restore: 0
  timesteps_total: 191000
  training_iteration: 191
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    191 |          2557.83 | 191000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 192000
  custom_metrics: {}
  date: 2021-08-18_10-41-15
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 191512
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06870045512914658
          max_q: 1.8383398056030273
          mean_q: 0.1590757966041565
          mean_td_error: -0.0003938277659472078
          min_q: -0.1308714747428894
        model: {}
        td_error: "[-0.31889892  0.06936294  0.18310077 -0.23789716 -0.01310737 -0.0889989\n\
          \  0.00861952  0.06360202  0.22097823  0.146279    0.4106973   0.17887495\n\
          \  0.04388329  0.01303624 -0.750035   -0.09084129 -0.94958776 -0.17836079\n\
          \  0.13027307 -0.43586785 -0.25363147  0.29447383  0.35920727  0.01166444\n\
          \ -0.98682606  0.16258118  0.05488774  0.13899915  0.36824524 -0.06875986\n\
          \ -0.02320099  0.20455639 -0.2599603   0.25263786  0.4089974   0.19231294\n\
          \  0.1557975   0.11310633  0.21976638 -0.05883332 -0.06275098  0.18135536\n\
          \ -0.00582981 -0.06749091  0.1322199  -0.17789876 -0.02656481  0.3169222 ]"
    num_agent_steps_sampled: 192000
    num_agent_steps_trained: 2292048
    num_steps_sampled: 192000
    num_steps_trained: 2292048
    num_target_updates: 379
  iterations_since_restore: 192
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.17391304347825
    ram_util_percent: 32.10000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2573.2436821460724
  time_this_iter_s: 15.415508270263672
  time_total_s: 2573.2436821460724
  timers:
    learn_throughput: 4919.307
    learn_time_ms: 9.757
    update_time_ms: 2.701
  timestamp: 1629283275
  timesteps_since_restore: 0
  timesteps_total: 192000
  training_iteration: 192
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    192 |          2573.24 | 192000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 193000
  custom_metrics: {}
  date: 2021-08-18_10-41-33
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 192520
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02989509142935276
          max_q: 1.9366531372070312
          mean_q: 0.11716097593307495
          mean_td_error: -0.02330903336405754
          min_q: -0.2023005485534668
        model: {}
        td_error: "[ 0.66022086 -0.9139093  -0.32456875 -0.02765727 -0.06670633  0.21260798\n\
          \  0.09281757 -0.23299578  0.04462284 -0.7239513   0.4352407   0.18127462\n\
          \  0.12849121  0.21118131  0.10470794  0.12321247  0.03586505 -0.9075482\n\
          \  0.10992789  0.19313261 -0.09835994  0.20727569  0.1303249   0.04982722\n\
          \ -0.254163   -0.04651749 -0.19338913  0.08957493 -0.2800269  -0.04342958\n\
          \ -0.1970318   0.11559337 -0.1819841  -0.06666192  0.03476784  0.17569582\n\
          \  0.19651751  0.22809361 -0.11604413  0.2938677  -0.06944609 -0.18653345\n\
          \ -0.01160217 -0.16411898 -0.1800285   0.10912257 -0.13031244  0.13418879]"
    num_agent_steps_sampled: 193000
    num_agent_steps_trained: 2304048
    num_steps_sampled: 193000
    num_steps_trained: 2304048
    num_target_updates: 381
  iterations_since_restore: 193
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.087999999999994
    ram_util_percent: 32.108000000000004
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2590.4893748760223
  time_this_iter_s: 17.24569272994995
  time_total_s: 2590.4893748760223
  timers:
    learn_throughput: 4847.867
    learn_time_ms: 9.901
    update_time_ms: 3.01
  timestamp: 1629283293
  timesteps_since_restore: 0
  timesteps_total: 193000
  training_iteration: 193
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    193 |          2590.49 | 193000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 194000
  custom_metrics: {}
  date: 2021-08-18_10-41-50
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 193528
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12.085010528564453
          max_q: 7254646.0
          mean_q: 302277.21875
          mean_td_error: -7.400234222412109
          min_q: -0.2470831274986267
        model: {}
        td_error: "[-1.8050000e+02  1.3044444e-01 -2.2482800e-01  1.5019286e-01\n -1.7087284e-01\
          \ -7.8117102e-03  1.7817035e-01 -1.9328743e-01\n  1.4298399e-01  8.0337077e-02\
          \  1.7842120e-01  1.4107504e-01\n  2.1624708e-01  2.9045820e-01  2.9491448e-01\
          \ -2.0106718e-02\n  3.5446662e-01 -1.1686087e-01  5.8010183e-02  3.5268322e-01\n\
          \  1.3700622e-01 -2.2793794e-01 -1.9724879e-01 -1.8050000e+02\n  2.0083715e-01\
          \  2.7963519e-03  2.6889455e-01 -1.0913014e-03\n  1.0532148e+00  3.1715775e-01\
          \ -1.7866099e-01  1.4184390e-01\n -1.2229872e-01  2.2604395e-01  2.1562329e-01\
          \  2.9608212e-02\n  4.5677528e-02  2.7374631e-01  3.8873926e-01 -1.4309533e-01\n\
          \  1.4449175e-01  3.3723450e-01  1.9573738e-01  2.2271118e-01\n  3.6965019e-01\
          \  3.3193558e-01  6.3528657e-02 -1.4200278e-01]"
    num_agent_steps_sampled: 194000
    num_agent_steps_trained: 2316048
    num_steps_sampled: 194000
    num_steps_trained: 2316048
    num_target_updates: 383
  iterations_since_restore: 194
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.65833333333333
    ram_util_percent: 32.15833333333334
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2607.1920115947723
  time_this_iter_s: 16.70263671875
  time_total_s: 2607.1920115947723
  timers:
    learn_throughput: 4945.992
    learn_time_ms: 9.705
    update_time_ms: 3.314
  timestamp: 1629283310
  timesteps_since_restore: 0
  timesteps_total: 194000
  training_iteration: 194
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    194 |          2607.19 | 194000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 195000
  custom_metrics: {}
  date: 2021-08-18_10-42-08
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 194536
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04719296097755432
          max_q: 1.4743088483810425
          mean_q: 0.12888695299625397
          mean_td_error: -0.008612538687884808
          min_q: -0.17077630758285522
        model: {}
        td_error: "[-0.18998891  0.08711005 -0.08835194  0.11000308  0.20268998 -0.75918174\n\
          \ -0.400332    0.02368315  0.37497252 -0.08669972  0.16141742  0.20749587\n\
          \ -0.1972208   0.03473248  0.04835024 -0.5626204   0.01082343 -0.05366256\n\
          \  0.3624695   0.43091643 -0.14653994 -0.00429328 -0.03369679 -0.23891681\n\
          \  0.28021058  0.4274891  -0.16486248 -0.08481503  0.36566347 -0.02915393\n\
          \  0.18840411  0.4126443   0.22555742 -0.94157994  0.01124322 -0.76201624\n\
          \  0.34469795  0.17665151  0.06125937 -0.24158162  0.29978544  0.27160552\n\
          \  0.43666744  0.08621281 -0.40515244  0.295083   -0.9055016  -0.05507278]"
    num_agent_steps_sampled: 195000
    num_agent_steps_trained: 2328048
    num_steps_sampled: 195000
    num_steps_trained: 2328048
    num_target_updates: 385
  iterations_since_restore: 195
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.23076923076924
    ram_util_percent: 32.20384615384616
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2625.328384399414
  time_this_iter_s: 18.136372804641724
  time_total_s: 2625.328384399414
  timers:
    learn_throughput: 4885.548
    learn_time_ms: 9.825
    update_time_ms: 2.852
  timestamp: 1629283328
  timesteps_since_restore: 0
  timesteps_total: 195000
  training_iteration: 195
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    195 |          2625.33 | 195000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 196000
  custom_metrics: {}
  date: 2021-08-18_10-42-27
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 195544
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.916627407073975
          max_q: 7255213.0
          mean_q: 151150.375
          mean_td_error: 8.0399169921875
          min_q: -0.07278555631637573
        model: {}
        td_error: "[ 2.49794692e-01 -1.64881676e-01 -1.04031302e-01  3.85000000e+02\n\
          \ -8.43541324e-01 -3.76670778e-01 -1.55282915e-01  1.31619632e-01\n  3.73115689e-01\
          \  3.01723659e-01  1.07259601e-02 -6.85908645e-02\n -1.76352710e-02  2.08121613e-01\
          \  4.42973971e-01  5.31695560e-02\n  2.40143895e-01  2.83823282e-01  6.05697259e-02\
          \ -4.43585813e-02\n  3.51896822e-01 -8.12875479e-03 -7.47217536e-02  2.79102445e-01\n\
          \  2.28903875e-01  1.41355127e-01 -1.16343200e-01 -2.25173101e-01\n  4.28557247e-02\
          \  2.70806909e-01 -5.28673172e-01 -9.38965455e-02\n  1.45154655e-01 -1.06242940e-01\
          \  5.67385927e-02  1.75054312e-01\n  1.44955382e-01  3.02100182e-01 -1.22213066e-01\
          \  7.71550387e-02\n  2.02439979e-01  9.88899395e-02  1.69436678e-01  9.16959792e-02\n\
          \ -1.09847911e-01 -9.83739436e-01  2.67264962e-01 -3.41584563e-01]"
    num_agent_steps_sampled: 196000
    num_agent_steps_trained: 2340048
    num_steps_sampled: 196000
    num_steps_trained: 2340048
    num_target_updates: 387
  iterations_since_restore: 196
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.53076923076923
    ram_util_percent: 32.20769230769231
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2643.7649829387665
  time_this_iter_s: 18.436598539352417
  time_total_s: 2643.7649829387665
  timers:
    learn_throughput: 4882.633
    learn_time_ms: 9.831
    update_time_ms: 2.794
  timestamp: 1629283347
  timesteps_since_restore: 0
  timesteps_total: 196000
  training_iteration: 196
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    196 |          2643.76 | 196000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 197000
  custom_metrics: {}
  date: 2021-08-18_10-42-45
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 196552
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03971802815794945
          max_q: 0.4755473732948303
          mean_q: 0.04994342848658562
          mean_td_error: -0.0075977882370352745
          min_q: -0.21144747734069824
        model: {}
        td_error: "[ 0.12426819 -0.02674251  0.00689316  0.23637219  0.12521997 -0.10644965\n\
          \ -0.13016596  0.2531242  -0.0179774   0.19761539 -0.07261637 -0.00586934\n\
          \  0.3524703  -0.6597604   0.09164448  0.01803206 -0.0898314   0.06259841\n\
          \  0.29019296  0.04061113  0.01117457  0.37468392  0.18648227 -1.0718237\n\
          \  0.2568131   0.05928759  0.09706008  0.08100382 -0.29568526  0.22140914\n\
          \ -0.5241667  -0.0130915  -0.03399841  0.12279013 -0.18960041 -0.24028604\n\
          \ -0.08508968  0.05484676 -0.12442553  0.22472967 -0.00678135 -0.21151847\n\
          \  0.16293237  0.00164147 -0.0862065   0.17599669  0.0346222  -0.2371234 ]"
    num_agent_steps_sampled: 197000
    num_agent_steps_trained: 2352048
    num_steps_sampled: 197000
    num_steps_trained: 2352048
    num_target_updates: 389
  iterations_since_restore: 197
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.32962962962962
    ram_util_percent: 32.20000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2662.168925523758
  time_this_iter_s: 18.403942584991455
  time_total_s: 2662.168925523758
  timers:
    learn_throughput: 4832.287
    learn_time_ms: 9.933
    update_time_ms: 3.047
  timestamp: 1629283365
  timesteps_since_restore: 0
  timesteps_total: 197000
  training_iteration: 197
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    197 |          2662.17 | 197000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 198000
  custom_metrics: {}
  date: 2021-08-18_10-43-06
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 197560
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.481105804443359
          max_q: 7253055.0
          mean_q: 151105.328125
          mean_td_error: -36.9681396484375
          min_q: -0.27617549896240234
        model: {}
        td_error: "[ 2.29949832e-01  1.96727753e-01 -1.07096501e-01 -3.19157764e-02\n\
          \  2.30980173e-01 -3.92095298e-02  3.03009748e-02 -9.82046574e-02\n  1.42275631e-01\
          \  5.00348657e-02 -3.04103047e-01  1.41706780e-01\n -1.52773291e-01  1.65074378e-01\
          \  1.95132822e-01 -1.12251818e-01\n  7.22224042e-02 -1.75288334e-01 -4.50828731e-01\
          \ -2.29028583e-01\n -2.82905996e-04 -1.34403795e-01  6.36964291e-02 -2.20545322e-01\n\
          \  1.45457774e-01 -1.12042412e-01 -1.77300000e+03 -1.17689356e-01\n  8.72341096e-02\
          \  1.52609810e-01  1.46282285e-01  6.00220561e-02\n  2.15590388e-01 -1.02271095e-01\
          \  8.76478553e-02  9.15418118e-02\n -9.91066992e-01  9.56367850e-02  9.58863795e-02\
          \  2.65092105e-01\n -3.00325513e-01 -1.36077657e-01  2.79960632e-01 -2.48257518e-02\n\
          \ -4.65260327e-01 -1.95222139e-01 -4.32123467e-02 -1.67864978e-01]"
    num_agent_steps_sampled: 198000
    num_agent_steps_trained: 2364048
    num_steps_sampled: 198000
    num_steps_trained: 2364048
    num_target_updates: 391
  iterations_since_restore: 198
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.606896551724134
    ram_util_percent: 32.29655172413792
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2682.0347323417664
  time_this_iter_s: 19.865806818008423
  time_total_s: 2682.0347323417664
  timers:
    learn_throughput: 4855.689
    learn_time_ms: 9.885
    update_time_ms: 2.903
  timestamp: 1629283386
  timesteps_since_restore: 0
  timesteps_total: 198000
  training_iteration: 198
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    198 |          2682.03 | 198000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 199000
  custom_metrics: {}
  date: 2021-08-18_10-43-25
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 198568
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04325408115983009
          max_q: 0.8774027228355408
          mean_q: -0.06094270944595337
          mean_td_error: 0.0350395105779171
          min_q: -0.2745528221130371
        model: {}
        td_error: "[ 0.14666864  0.16675216 -0.06319858  0.18576849 -0.8232129   0.00823137\n\
          \ -0.33673552 -0.04163935 -0.07686207 -0.21026856  0.14248216  0.11850113\n\
          \ -0.09757979  0.22054845  0.3158505   0.21285701 -0.06719176 -0.07226908\n\
          \ -0.05665263 -0.00776283  0.32103273  0.03621295  0.14612362  0.358215\n\
          \ -0.13944554  0.32230604  0.1941784   0.06134097 -0.07716298  0.4811722\n\
          \ -0.09066869  0.01623347  0.09951425  0.25168306  0.20600462 -0.07174937\n\
          \  0.28706026 -0.07565809  0.02763983 -0.1027213  -0.06753024 -0.04611943\n\
          \  0.2859898  -0.8718334   0.15750918  0.17301416 -0.03491902  0.17018718]"
    num_agent_steps_sampled: 199000
    num_agent_steps_trained: 2376048
    num_steps_sampled: 199000
    num_steps_trained: 2376048
    num_target_updates: 393
  iterations_since_restore: 199
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.47142857142857
    ram_util_percent: 32.30357142857142
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2701.5991127490997
  time_this_iter_s: 19.564380407333374
  time_total_s: 2701.5991127490997
  timers:
    learn_throughput: 4761.148
    learn_time_ms: 10.082
    update_time_ms: 3.122
  timestamp: 1629283405
  timesteps_since_restore: 0
  timesteps_total: 199000
  training_iteration: 199
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    199 |           2701.6 | 199000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 200000
  custom_metrics: {}
  date: 2021-08-18_10-43-46
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 199576
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.043390918523073196
          max_q: 0.9911199808120728
          mean_q: -0.07533469796180725
          mean_td_error: -0.025665968656539917
          min_q: -0.357158362865448
        model: {}
        td_error: "[-0.05261795 -0.00293778 -0.6724984   0.1166313   0.20770806  0.13296038\n\
          \ -0.16206756  0.03821307 -0.02292046 -0.11183718  0.10466036 -0.05661005\n\
          \  0.14895812 -0.933835   -0.22470474  0.17820016 -0.13681749 -0.32807183\n\
          \  0.33193243  0.22351143  0.05196238 -0.26945055 -0.0411137   0.12315232\n\
          \  0.07348544  0.00421689  0.00159237 -0.12567645  0.02107479  0.03145918\n\
          \  0.25592977  0.22128016  0.03339064  0.33604652 -0.9265471   0.0074081\n\
          \ -0.08903445 -0.13928992  0.0968276  -0.28388143  0.11774553  0.41447937\n\
          \  0.24275635  0.01942661 -0.1451828  -0.07078606  0.01941873  0.00948639]"
    num_agent_steps_sampled: 200000
    num_agent_steps_trained: 2388048
    num_steps_sampled: 200000
    num_steps_trained: 2388048
    num_target_updates: 395
  iterations_since_restore: 200
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.69655172413793
    ram_util_percent: 32.30344827586206
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2721.6295301914215
  time_this_iter_s: 20.030417442321777
  time_total_s: 2721.6295301914215
  timers:
    learn_throughput: 4835.397
    learn_time_ms: 9.927
    update_time_ms: 3.208
  timestamp: 1629283426
  timesteps_since_restore: 0
  timesteps_total: 200000
  training_iteration: 200
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    200 |          2721.63 | 200000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 201000
  custom_metrics: {}
  date: 2021-08-18_10-44-06
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 200584
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04146818444132805
          max_q: 0.46725600957870483
          mean_q: -0.09310013055801392
          mean_td_error: -0.028865760192275047
          min_q: -0.29628342390060425
        model: {}
        td_error: "[-0.06611807  0.26187384  0.09339827 -0.05494739 -0.10143299  0.13205907\n\
          \  0.00520191  0.08544585 -0.05527648 -0.32667983 -0.09231394 -0.08862387\n\
          \  0.11234188 -0.1661971   0.20230258 -0.12590489  0.22562927 -0.15805957\n\
          \  0.13852394 -0.24873596 -0.26568818  0.00386129  0.04108144  0.27319473\n\
          \  0.00707349 -0.27540454  0.1104216  -0.40722734  0.04169834  0.24735945\n\
          \ -0.1564604  -0.2250371   0.1222899  -0.29443464  0.00752568  0.02235793\n\
          \ -0.16117729 -0.19183388  0.10434994  0.04266182  0.06860065 -0.36767703\n\
          \  0.12430283  0.10116696  0.13480365 -0.1697655   0.02228558 -0.1183724 ]"
    num_agent_steps_sampled: 201000
    num_agent_steps_trained: 2400048
    num_steps_sampled: 201000
    num_steps_trained: 2400048
    num_target_updates: 397
  iterations_since_restore: 201
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.8344827586207
    ram_util_percent: 32.32758620689654
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2742.174827337265
  time_this_iter_s: 20.545297145843506
  time_total_s: 2742.174827337265
  timers:
    learn_throughput: 4610.36
    learn_time_ms: 10.411
    update_time_ms: 3.003
  timestamp: 1629283446
  timesteps_since_restore: 0
  timesteps_total: 201000
  training_iteration: 201
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    201 |          2742.17 | 201000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 202000
  custom_metrics: {}
  date: 2021-08-18_10-44-28
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 201592
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.258224010467529
          max_q: 7256632.0
          mean_q: 151179.8125
          mean_td_error: 37.58421325683594
          min_q: -0.3111823797225952
        model: {}
        td_error: "[-1.67146415e-01  2.07326859e-01 -8.41454327e-01 -1.84522688e-01\n\
          \ -5.86602092e-02 -1.85323477e-01  2.85770118e-01 -1.11664481e-01\n  2.96116471e-02\
          \ -7.34240860e-02 -1.36429831e-01 -7.03107476e-01\n  1.30875945e-01 -2.50369236e-02\
          \  3.14495325e-01  3.88706625e-02\n -5.80471814e-01 -6.90900907e-03 -1.22157604e-01\
          \  1.03816569e-01\n  1.80450000e+03  8.20918977e-02  1.57663882e-01  1.05434641e-01\n\
          \  1.86221242e-01 -3.13751176e-02 -9.86149907e-02  1.58113688e-01\n  2.45359510e-01\
          \  1.22526646e-01 -3.69100273e-02 -5.84248602e-02\n  8.83794725e-02 -2.45418489e-01\
          \  3.21111083e-03 -1.52911171e-01\n  5.06056249e-02  6.28906190e-02  1.85820326e-01\
          \  1.18193239e-01\n  7.99554139e-02  1.44363761e-01 -1.93322182e-01  2.42631763e-01\n\
          \ -2.83123702e-02 -1.24349967e-02  2.29951352e-01  2.22121418e-01]"
    num_agent_steps_sampled: 202000
    num_agent_steps_trained: 2412048
    num_steps_sampled: 202000
    num_steps_trained: 2412048
    num_target_updates: 399
  iterations_since_restore: 202
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.99354838709678
    ram_util_percent: 32.40322580645161
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2763.456684589386
  time_this_iter_s: 21.28185725212097
  time_total_s: 2763.456684589386
  timers:
    learn_throughput: 4629.326
    learn_time_ms: 10.369
    update_time_ms: 3.111
  timestamp: 1629283468
  timesteps_since_restore: 0
  timesteps_total: 202000
  training_iteration: 202
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    202 |          2763.46 | 202000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 203000
  custom_metrics: {}
  date: 2021-08-18_10-44-51
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 202600
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.701531887054443
          max_q: 7253890.0
          mean_q: 151122.703125
          mean_td_error: -19.5913143157959
          min_q: -0.1884469985961914
        model: {}
        td_error: "[-2.38638252e-01 -8.36806059e-01  1.87866569e-01  1.42700285e-01\n\
          \  4.55325544e-02  2.17346311e-01 -2.08375752e-02  1.69257805e-01\n  1.80424750e-03\
          \  2.23279923e-01 -8.93945158e-01  1.17033124e-01\n  1.04632817e-01  1.72070801e-01\
          \  1.89424396e-01  1.18945286e-01\n  4.50803414e-02 -7.01042712e-02 -2.90866703e-01\
          \  3.30300480e-01\n -1.79109126e-01  2.12889329e-01  7.84223974e-02 -2.40431607e-01\n\
          \ -1.50405109e-01 -1.03214276e+00 -1.10745288e-01  2.98588932e-01\n  6.36088550e-02\
          \  2.11812198e-01  2.54970849e-01 -1.44978142e+00\n -6.19086996e-02 -9.37500000e+02\
          \ -4.16106582e-01 -2.33786687e-01\n  2.14150827e-02  3.24421048e-01 -1.63829923e-01\
          \ -3.11452776e-01\n  7.83598572e-02 -5.02114296e-02  2.16027021e-01  1.41118884e-01\n\
          \  1.38233602e-03 -1.19163796e-01 -3.48928422e-01  3.67809296e-01]"
    num_agent_steps_sampled: 203000
    num_agent_steps_trained: 2424048
    num_steps_sampled: 203000
    num_steps_trained: 2424048
    num_target_updates: 401
  iterations_since_restore: 203
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.881818181818176
    ram_util_percent: 32.406060606060606
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2786.042179107666
  time_this_iter_s: 22.58549451828003
  time_total_s: 2786.042179107666
  timers:
    learn_throughput: 4563.697
    learn_time_ms: 10.518
    update_time_ms: 3.046
  timestamp: 1629283491
  timesteps_since_restore: 0
  timesteps_total: 203000
  training_iteration: 203
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    203 |          2786.04 | 203000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 204000
  custom_metrics: {}
  date: 2021-08-18_10-45-13
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 203608
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.032937031239271164
          max_q: 0.5725833773612976
          mean_q: 0.07876548171043396
          mean_td_error: -0.026407381519675255
          min_q: -0.15358281135559082
        model: {}
        td_error: "[-0.24948592  0.10737236  0.16951035 -0.09988943  0.13588673 -0.19455235\n\
          \ -0.04556109  0.18212208  0.02710127 -0.11116302 -0.00765128  0.30772558\n\
          \ -0.09482348 -0.13051254  0.04992401 -0.15908803  0.02625858 -0.42702755\n\
          \  0.03462511  0.16805819  0.24015307 -0.9327214  -0.87990946 -0.05277249\n\
          \ -0.7896206   0.0646359   0.07534763  0.39413714 -0.14514345 -0.19452436\n\
          \  0.13065217  0.22532755 -0.19682997 -0.14139017  0.06638458  0.6849758\n\
          \ -0.2886003   0.22018418 -0.37873662 -0.07279009 -0.10329521  0.10967962\n\
          \  0.10648213  0.55029976 -0.0801627   0.29270908  0.05122919  0.08791519]"
    num_agent_steps_sampled: 204000
    num_agent_steps_trained: 2436048
    num_steps_sampled: 204000
    num_steps_trained: 2436048
    num_target_updates: 403
  iterations_since_restore: 204
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.72258064516128
    ram_util_percent: 32.41612903225806
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2808.0646271705627
  time_this_iter_s: 22.02244806289673
  time_total_s: 2808.0646271705627
  timers:
    learn_throughput: 4585.808
    learn_time_ms: 10.467
    update_time_ms: 3.073
  timestamp: 1629283513
  timesteps_since_restore: 0
  timesteps_total: 204000
  training_iteration: 204
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    204 |          2808.06 | 204000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 205000
  custom_metrics: {}
  date: 2021-08-18_10-45-36
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 204616
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 9.603919982910156
          max_q: 7255880.0
          mean_q: 151164.09375
          mean_td_error: 21.89847183227539
          min_q: -0.27479737997055054
        model: {}
        td_error: "[ 1.3649485e-01  2.5563806e-01 -1.3098282e-01  3.1884116e-01\n  2.3484659e-01\
          \ -9.6849307e-02 -9.9306726e-01 -9.2836224e-02\n -1.0241207e-01 -1.4329094e-01\
          \  4.3853879e-02  1.5838593e-01\n  1.0510000e+03  1.5227050e-03  2.3635964e-01\
          \  3.5064340e-01\n -9.4274931e-02 -4.0831767e-02 -9.1545707e-01 -4.0057018e-02\n\
          \ -4.1832760e-02  1.5408349e-01  2.6629019e-01  8.4561139e-02\n  2.5097966e-01\
          \  2.3399788e-01 -1.6222307e-01 -1.3336152e-02\n -1.4462978e-01  6.0234636e-02\
          \ -5.7516411e-02 -6.1779648e-02\n  3.9472342e-02  1.8679678e-02 -9.8703355e-02\
          \  1.6560042e-01\n -2.6732823e-01  4.9999833e-02  1.6085619e-01  1.2640482e-01\n\
          \  9.2308015e-02  1.9370854e-01 -2.4583192e-01 -1.8304831e-01\n  1.7156136e-01\
          \  5.2011117e-02 -2.8322250e-01  4.7877079e-01]"
    num_agent_steps_sampled: 205000
    num_agent_steps_trained: 2448048
    num_steps_sampled: 205000
    num_steps_trained: 2448048
    num_target_updates: 405
  iterations_since_restore: 205
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.347058823529416
    ram_util_percent: 32.5
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2831.0433220863342
  time_this_iter_s: 22.978694915771484
  time_total_s: 2831.0433220863342
  timers:
    learn_throughput: 4636.426
    learn_time_ms: 10.353
    update_time_ms: 3.024
  timestamp: 1629283536
  timesteps_since_restore: 0
  timesteps_total: 205000
  training_iteration: 205
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    205 |          2831.04 | 205000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 206000
  custom_metrics: {}
  date: 2021-08-18_10-46-00
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 205624
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.09469837695360184
          max_q: 2.6390433311462402
          mean_q: 0.00450114905834198
          mean_td_error: 0.044238489121198654
          min_q: -0.36581265926361084
        model: {}
        td_error: "[-0.065162    0.17718266 -1.1457919   0.32353687 -0.28745073  0.16338588\n\
          \  0.4044966   0.10829481  0.02192991  0.21616882 -0.03818922 -0.18991183\n\
          \  0.239378   -0.02173257 -1.1457919   0.42394042  0.21189967 -0.03305808\n\
          \  0.37687436  0.20589703  0.03439333  0.34897166 -0.20100276 -0.14497271\n\
          \ -0.12383544  0.01839188  0.06674081  0.08524688  0.16191262  0.07132724\n\
          \ -0.06558436 -0.00984871  0.11717096  0.11859518  1.0933602   0.28387022\n\
          \  0.09006205 -0.06023458 -0.03561306 -0.98858845  0.21711808 -0.07187177\n\
          \ -0.0817318   0.31810308  0.04387635  0.28777504  0.41616762  0.18775102]"
    num_agent_steps_sampled: 206000
    num_agent_steps_trained: 2460048
    num_steps_sampled: 206000
    num_steps_trained: 2460048
    num_target_updates: 407
  iterations_since_restore: 206
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.65757575757575
    ram_util_percent: 32.50606060606061
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2854.328171491623
  time_this_iter_s: 23.284849405288696
  time_total_s: 2854.328171491623
  timers:
    learn_throughput: 4666.3
    learn_time_ms: 10.287
    update_time_ms: 3.364
  timestamp: 1629283560
  timesteps_since_restore: 0
  timesteps_total: 206000
  training_iteration: 206
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    206 |          2854.33 | 206000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 207000
  custom_metrics: {}
  date: 2021-08-18_10-46-24
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 206632
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 9.879223823547363
          max_q: 7252318.0
          mean_q: 151089.8125
          mean_td_error: -52.35997772216797
          min_q: -0.4215596318244934
        model: {}
        td_error: "[-3.07468683e-01  1.02030027e+00 -1.77512676e-01  2.53385961e-01\n\
          \ -9.73579049e-01  8.42650235e-02  4.76869941e-02  2.98027217e-01\n -9.09864008e-02\
          \ -9.33868468e-01 -6.54227659e-02 -2.45055959e-01\n  5.36011457e-02 -1.13190234e-01\
          \ -6.21248782e-02  2.69573539e-01\n  1.97935134e-01  1.63931698e-01 -1.12027273e-01\
          \ -3.98566008e-01\n -2.30354369e-01  1.11413956e-01  2.86091939e-02  1.93209648e-01\n\
          \ -1.45798743e-01 -9.58615482e-01 -4.35240418e-01  3.45597208e-01\n -2.50912666e-01\
          \ -2.22144112e-01  3.12382758e-01  3.24538946e-02\n -2.50800000e+03  1.85521603e-01\
          \  5.84072173e-02 -9.85402465e-02\n -2.47385994e-01 -1.12590194e-01 -2.11976320e-02\
          \ -8.49812776e-02\n -1.43395376e+00 -4.05461788e-01 -9.26275194e-01  9.21069384e-02\n\
          \ -4.98421788e-02  1.07258797e-01 -4.38320637e-03 -2.68202759e-02]"
    num_agent_steps_sampled: 207000
    num_agent_steps_trained: 2472048
    num_steps_sampled: 207000
    num_steps_trained: 2472048
    num_target_updates: 409
  iterations_since_restore: 207
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.18571428571428
    ram_util_percent: 32.57714285714285
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2878.247186422348
  time_this_iter_s: 23.919014930725098
  time_total_s: 2878.247186422348
  timers:
    learn_throughput: 4510.772
    learn_time_ms: 10.641
    update_time_ms: 3.141
  timestamp: 1629283584
  timesteps_since_restore: 0
  timesteps_total: 207000
  training_iteration: 207
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    207 |          2878.25 | 207000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 208000
  custom_metrics: {}
  date: 2021-08-18_10-46-49
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 207640
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 185.65513610839844
          max_q: 661911.0625
          mean_q: 13790.0888671875
          mean_td_error: -2590541.0
          min_q: -0.021249115467071533
        model: {}
        td_error: "[ 6.44095242e-03 -1.44250989e-01 -6.54762350e+06  1.35088995e-01\n\
          \ -6.54762350e+06 -1.55706286e-01 -6.54762350e+06 -1.40168265e-01\n -6.54762350e+06\
          \ -6.54762350e+06 -1.12669957e+00 -1.71025544e-01\n  3.24488059e-02  1.19785756e-01\
          \ -6.54762350e+06 -6.54762350e+06\n -6.54762350e+06  2.45897263e-01  1.80855393e-01\
          \  3.92060816e-01\n -6.54762350e+06  7.63123482e-03  5.88798125e+04 -6.54762350e+06\n\
          \ -5.04992902e-03  4.28909659e-02 -6.54762350e+06 -6.54762350e+06\n -1.27390265e-01\
          \ -6.54762350e+06  3.58825624e-02 -6.54762350e+06\n  2.32783854e-02  2.50768930e-01\
          \ -6.54762350e+06  1.41528994e-02\n  1.93751559e-01 -6.54762350e+06  4.11631078e-01\
          \ -6.54762350e+06\n -7.87495434e-01 -6.54762350e+06 -6.54762350e+06 -2.88606361e-02\n\
          \ -2.07396746e-01  1.36906981e-01 -2.56764591e-02  4.66621816e-01]"
    num_agent_steps_sampled: 208000
    num_agent_steps_trained: 2484048
    num_steps_sampled: 208000
    num_steps_trained: 2484048
    num_target_updates: 411
  iterations_since_restore: 208
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.18857142857143
    ram_util_percent: 32.60285714285714
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2903.070866584778
  time_this_iter_s: 24.82368016242981
  time_total_s: 2903.070866584778
  timers:
    learn_throughput: 4362.676
    learn_time_ms: 11.002
    update_time_ms: 3.057
  timestamp: 1629283609
  timesteps_since_restore: 0
  timesteps_total: 208000
  training_iteration: 208
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    208 |          2903.07 | 208000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 209000
  custom_metrics: {}
  date: 2021-08-18_10-47-17
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 208648
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.2459886521100998
          max_q: 2.2573626041412354
          mean_q: 0.2668163776397705
          mean_td_error: 0.15535968542099
          min_q: 0.01996058225631714
        model: {}
        td_error: "[ 0.36477137 -0.00159699 -0.09719822  0.04134217  0.22165802  0.02972514\n\
          \  0.4098301   0.43268    -0.03659722  0.49574417  0.39053315 -0.08401415\n\
          \ -0.79706526  0.25650716  0.34323058  0.09893361 -0.10516563  0.00346845\n\
          \  0.10237361 -0.520934    0.05652809  0.33327287  0.60062563  0.19753492\n\
          \ -0.05707803  0.16048223  0.03841951  0.09116203  0.3460865   0.09699239\n\
          \  0.16105546  0.30656675  0.3584018   0.13595268  0.27962875 -0.17781037\n\
          \  0.51442945  0.2975411   0.15093118  0.4528312   0.15667413  0.23846234\n\
          \  0.28116065  0.16542009  0.11774844  0.1555212   0.07606085  0.374437  ]"
    num_agent_steps_sampled: 209000
    num_agent_steps_trained: 2496048
    num_steps_sampled: 209000
    num_steps_trained: 2496048
    num_target_updates: 413
  iterations_since_restore: 209
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.36410256410257
    ram_util_percent: 32.6948717948718
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2930.3519492149353
  time_this_iter_s: 27.28108263015747
  time_total_s: 2930.3519492149353
  timers:
    learn_throughput: 4754.997
    learn_time_ms: 10.095
    update_time_ms: 2.988
  timestamp: 1629283637
  timesteps_since_restore: 0
  timesteps_total: 209000
  training_iteration: 209
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    209 |          2930.35 | 209000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 210000
  custom_metrics: {}
  date: 2021-08-18_10-47-44
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 209656
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0448438860476017
          max_q: 1.4067332744598389
          mean_q: 0.09037032723426819
          mean_td_error: -0.0017288265516981483
          min_q: -0.2484336495399475
        model: {}
        td_error: "[-0.11190543  0.24909171  0.13520703  0.17068699  0.20335543  0.44879317\n\
          \ -0.05162297  0.07878377 -0.33074802  0.4212756   0.15647542 -0.24898869\n\
          \  0.02483043  0.12474075  0.06654105  0.13937256 -0.03172508  0.03598508\n\
          \ -0.15620196 -0.13958494  0.24477956 -0.11227694 -0.00103825 -0.2422896\n\
          \  0.05587532  0.05432084 -0.16524538 -0.22472733  0.14657302  0.18567929\n\
          \  0.43747753 -0.8890644  -0.05195804  0.02451134 -0.04647078  0.00345581\n\
          \ -0.12871951 -0.13566019  0.11597107 -0.06403874  0.07167785  0.07181536\n\
          \  0.04723742 -0.710042    0.02690381 -0.02099842  0.12018001 -0.08127439]"
    num_agent_steps_sampled: 210000
    num_agent_steps_trained: 2508048
    num_steps_sampled: 210000
    num_steps_trained: 2508048
    num_target_updates: 415
  iterations_since_restore: 210
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.5625
    ram_util_percent: 32.71
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2957.556854724884
  time_this_iter_s: 27.20490550994873
  time_total_s: 2957.556854724884
  timers:
    learn_throughput: 4366.84
    learn_time_ms: 10.992
    update_time_ms: 3.18
  timestamp: 1629283664
  timesteps_since_restore: 0
  timesteps_total: 210000
  training_iteration: 210
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    210 |          2957.56 | 210000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 211000
  custom_metrics: {}
  date: 2021-08-18_10-48-12
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 210664
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04745476692914963
          max_q: 1.6387786865234375
          mean_q: 0.005989658646285534
          mean_td_error: -0.01203500758856535
          min_q: -0.2314053773880005
        model: {}
        td_error: "[ 0.13596171 -0.14209697  0.01862385  0.074407   -0.25631958  0.07994826\n\
          \  0.02564621  0.03688853 -0.2099911  -0.05136345 -0.13257517 -0.05739899\n\
          \  0.13691978 -0.18330033 -0.07866053  0.04451036  0.27030012 -0.03655891\n\
          \  0.07245801  0.11050901 -0.27433085 -0.25633085  0.2748393  -0.23688352\n\
          \  0.19696037 -0.09102948  0.28806448  0.32046005  0.24256372  0.09278212\n\
          \  0.06018893  0.2997141  -0.7733035  -0.13144533  0.03438361 -0.15986696\n\
          \ -0.12811854  0.22290832  0.26560947  0.08268458  0.08817273  0.035678\n\
          \ -1.1568015   0.11526701  0.25387967  0.08321345  0.08093667 -0.26578435]"
    num_agent_steps_sampled: 211000
    num_agent_steps_trained: 2520048
    num_steps_sampled: 211000
    num_steps_trained: 2520048
    num_target_updates: 417
  iterations_since_restore: 211
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.84250000000001
    ram_util_percent: 32.8
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 2985.4008910655975
  time_this_iter_s: 27.8440363407135
  time_total_s: 2985.4008910655975
  timers:
    learn_throughput: 4671.834
    learn_time_ms: 10.274
    update_time_ms: 2.972
  timestamp: 1629283692
  timesteps_since_restore: 0
  timesteps_total: 211000
  training_iteration: 211
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    211 |           2985.4 | 211000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 212000
  custom_metrics: {}
  date: 2021-08-18_10-48-42
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 211672
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 14.631248474121094
          max_q: 7254855.5
          mean_q: 151142.8125
          mean_td_error: 0.622382640838623
          min_q: -0.23983824253082275
        model: {}
        td_error: "[ 5.79825863e-02  1.56722069e-02 -2.07061663e-01 -1.59065530e-01\n\
          \  1.90546170e-01  3.49903941e-01  8.73501450e-02  1.02781236e-01\n -3.61574441e-02\
          \  2.14956835e-01  2.99266458e-01  2.29870379e-01\n -1.44079268e-01  2.80666918e-01\
          \ -2.85662711e-02 -8.53042006e-02\n -1.68167293e-01 -6.12932928e-02  1.17971033e-01\
          \  2.54895389e-01\n -1.22451603e-01 -1.37710765e-01  2.85305977e-02  1.17922224e-01\n\
          \ -2.15699732e-01  2.80000000e+01  4.05172944e-01  2.46504575e-01\n  4.14262712e-02\
          \  3.90569791e-02  1.92864031e-01  3.19093913e-02\n  1.83815509e-01  2.43515164e-01\
          \ -3.68770868e-01 -1.09406888e-01\n  2.44845405e-01  1.40453070e-01 -2.28841782e-01\
          \  1.29638404e-01\n  6.33977801e-02  1.39470994e-01 -1.10970289e-01 -1.81818128e-01\n\
          \ -2.09159687e-01 -8.31123516e-02 -8.21800679e-02  1.63796946e-01]"
    num_agent_steps_sampled: 212000
    num_agent_steps_trained: 2532048
    num_steps_sampled: 212000
    num_steps_trained: 2532048
    num_target_updates: 419
  iterations_since_restore: 212
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.86666666666667
    ram_util_percent: 32.804761904761904
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 3014.534910917282
  time_this_iter_s: 29.13401985168457
  time_total_s: 3014.534910917282
  timers:
    learn_throughput: 4517.736
    learn_time_ms: 10.625
    update_time_ms: 3.313
  timestamp: 1629283722
  timesteps_since_restore: 0
  timesteps_total: 212000
  training_iteration: 212
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    212 |          3014.53 | 212000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 213000
  custom_metrics: {}
  date: 2021-08-18_10-49-11
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 212680
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.021289533004164696
          max_q: 0.6215350031852722
          mean_q: 0.05228709429502487
          mean_td_error: 0.0027388236485421658
          min_q: -0.12795501947402954
        model: {}
        td_error: "[ 1.10377058e-01  3.27811331e-01  2.39148974e-01 -1.11095935e-01\n\
          \ -8.42906535e-04  5.82057908e-02  1.30718559e-01  5.23648411e-03\n -2.39642799e-01\
          \ -1.04269177e-01  2.53923714e-01  8.12108517e-02\n -3.53106916e-01 -2.88502932e-01\
          \  1.52164519e-01  2.75395811e-03\n -1.00896764e+00  5.46612740e-02  1.82438388e-01\
          \  3.56043369e-01\n -1.80816904e-01 -1.03661984e-01  1.52309030e-01 -9.37670469e-04\n\
          \  1.15770563e-01 -1.32803202e-01 -4.34984751e-02 -1.36862174e-01\n  5.70831820e-02\
          \  9.38622057e-02  2.34043628e-01 -2.50143826e-01\n  1.65707916e-01  5.67408651e-02\
          \  1.02837041e-01 -7.14529753e-02\n  1.84397712e-01 -2.04383522e-01  1.75434530e-01\
          \  1.07164443e-01\n -1.12598330e-01 -7.79483169e-02 -2.21331179e-01  2.30492368e-01\n\
          \ -6.21183217e-03  1.44672319e-01 -3.03376913e-02  3.56699228e-02]"
    num_agent_steps_sampled: 213000
    num_agent_steps_trained: 2544048
    num_steps_sampled: 213000
    num_steps_trained: 2544048
    num_target_updates: 421
  iterations_since_restore: 213
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.973809523809514
    ram_util_percent: 32.87380952380953
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 3044.0457355976105
  time_this_iter_s: 29.51082468032837
  time_total_s: 3044.0457355976105
  timers:
    learn_throughput: 4549.568
    learn_time_ms: 10.55
    update_time_ms: 3.153
  timestamp: 1629283751
  timesteps_since_restore: 0
  timesteps_total: 213000
  training_iteration: 213
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    213 |          3044.05 | 213000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 214000
  custom_metrics: {}
  date: 2021-08-18_10-49-43
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 213688
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07104282081127167
          max_q: 0.9769330024719238
          mean_q: 0.0988587737083435
          mean_td_error: 0.007259468547999859
          min_q: -0.09196221828460693
        model: {}
        td_error: "[-0.17645526  0.07380937 -0.15518701 -0.02198976 -0.0656288   0.05137303\n\
          \ -0.09493376  0.23103976 -0.7822327  -0.17381573 -0.1708064   0.12018537\n\
          \ -0.01239051  0.15377139  0.24673533  0.5867289   0.06879632  0.5267788\n\
          \ -0.0228831   0.09081     0.060141    0.03984407  0.28946692 -0.10206963\n\
          \  0.03260201 -0.19707365  0.04661871 -0.0181581   0.15985583  0.41795203\n\
          \  0.17568517 -1.0465518  -0.02158904 -0.02993095  0.21524017  0.17831421\n\
          \  0.17388989 -0.01343535 -0.06999387 -0.1658438   0.1985802  -0.19977765\n\
          \ -0.10639094 -0.08343679  0.03489723  0.01365647 -0.01816602 -0.089577  ]"
    num_agent_steps_sampled: 214000
    num_agent_steps_trained: 2556048
    num_steps_sampled: 214000
    num_steps_trained: 2556048
    num_target_updates: 423
  iterations_since_restore: 214
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.525000000000006
    ram_util_percent: 32.90454545454546
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 3074.86590719223
  time_this_iter_s: 30.82017159461975
  time_total_s: 3074.86590719223
  timers:
    learn_throughput: 4618.864
    learn_time_ms: 10.392
    update_time_ms: 3.19
  timestamp: 1629283783
  timesteps_since_restore: 0
  timesteps_total: 214000
  training_iteration: 214
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    214 |          3074.87 | 214000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 215000
  custom_metrics: {}
  date: 2021-08-18_10-50-14
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 214696
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.021878637373447418
          max_q: 0.38943731784820557
          mean_q: 0.1665731966495514
          mean_td_error: -0.007641598582267761
          min_q: 0.02233409881591797
        model: {}
        td_error: "[ 0.28790167 -0.04684626 -0.23149729  0.10827413  0.10437857  0.30478474\n\
          \  0.12490486 -0.22383803  0.28979915  0.3110566   0.02301148  0.161666\n\
          \ -0.05808321  0.22587115  0.1068519  -0.0541054   0.259896   -0.18090081\n\
          \ -0.08419167 -1.0528936  -0.01750414 -0.45596892 -0.02335045  0.2102133\n\
          \ -0.1293355   0.00883141  0.07129519 -0.2400685   0.11841503  0.22443315\n\
          \ -0.70068246 -0.00110053  0.21369493 -0.0715256   0.0321749  -0.21675324\n\
          \ -0.10845521 -0.13527346  0.21625468  0.21229087 -0.01399028  0.05290428\n\
          \ -0.07432736 -0.25161704  0.2687394   0.17366225  0.04280174 -0.14859506]"
    num_agent_steps_sampled: 215000
    num_agent_steps_trained: 2568048
    num_steps_sampled: 215000
    num_steps_trained: 2568048
    num_target_updates: 425
  iterations_since_restore: 215
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.43913043478261
    ram_util_percent: 32.94565217391305
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 3106.546587705612
  time_this_iter_s: 31.680680513381958
  time_total_s: 3106.546587705612
  timers:
    learn_throughput: 4735.715
    learn_time_ms: 10.136
    update_time_ms: 3.014
  timestamp: 1629283814
  timesteps_since_restore: 0
  timesteps_total: 215000
  training_iteration: 215
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    215 |          3106.55 | 215000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 216000
  custom_metrics: {}
  date: 2021-08-18_10-50-47
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 215704
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0694078654050827
          max_q: 0.708101212978363
          mean_q: 0.1577373892068863
          mean_td_error: 0.06240932270884514
          min_q: 0.012248635292053223
        model: {}
        td_error: "[ 0.01791394 -0.10162884 -0.02102937 -0.07294564 -0.03151917 -0.06703231\n\
          \  0.36656237  0.0046494   0.28745398  0.21627377  0.12636757  0.16040185\n\
          \  0.2802894   0.10369361 -0.1496501   0.23588893 -0.02263117  0.12736668\n\
          \ -0.23854679 -0.10396633 -0.01283991  0.16968867  0.20116371 -0.13744557\n\
          \  0.04471788  0.21152344 -0.19272855 -0.02468958  0.19273269 -0.22243714\n\
          \  0.13375825 -0.06187143 -0.07281426  0.13733144  0.08667918  0.18346618\n\
          \ -0.16870767  0.09145137  0.10753733  0.3115471  -0.05871905  0.05242343\n\
          \  0.10036787 -0.16147482  0.17281862  0.44361317  0.18439409  0.16624919]"
    num_agent_steps_sampled: 216000
    num_agent_steps_trained: 2580048
    num_steps_sampled: 216000
    num_steps_trained: 2580048
    num_target_updates: 427
  iterations_since_restore: 216
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.2804347826087
    ram_util_percent: 33.004347826086956
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 3138.9321196079254
  time_this_iter_s: 32.38553190231323
  time_total_s: 3138.9321196079254
  timers:
    learn_throughput: 4744.162
    learn_time_ms: 10.118
    update_time_ms: 3.006
  timestamp: 1629283847
  timesteps_since_restore: 0
  timesteps_total: 216000
  training_iteration: 216
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    216 |          3138.93 | 216000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 217000
  custom_metrics: {}
  date: 2021-08-18_10-51-20
  done: false
  episode_len_mean: 7520.541666666667
  episode_media: {}
  episode_reward_max: 7254680.063226188
  episode_reward_mean: 3929524.747571226
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 216712
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05000906437635422
          max_q: 0.2753186821937561
          mean_q: 0.08750687539577484
          mean_td_error: -0.013161197304725647
          min_q: -0.05165457725524902
        model: {}
        td_error: "[-0.07659662  0.24487945 -1.0594583   0.2625268   0.23378974  0.1570279\n\
          \ -0.25308466 -0.04769087 -0.06731513 -0.16212955  0.31993544  0.17609456\n\
          \  0.0344354  -1.044962    0.1057604   0.20629916  0.07922073 -0.22546434\n\
          \  0.12469642 -0.05308156  0.1518158  -0.15187189 -0.01069794  0.21851514\n\
          \ -0.12946726  0.08606066 -0.12787345  0.13848226  0.11233507  0.18986027\n\
          \ -0.17257188  0.12235349  0.03729659  0.11420575 -0.20577419 -0.00618774\n\
          \  0.17089623 -0.11850563  0.23216487  0.19105332  0.35169876  0.05557702\n\
          \  0.08203108 -0.02826573 -1.062727    0.11893445 -0.09606253  0.15010399]"
    num_agent_steps_sampled: 217000
    num_agent_steps_trained: 2592048
    num_steps_sampled: 217000
    num_steps_trained: 2592048
    num_target_updates: 429
  iterations_since_restore: 217
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.07500000000001
    ram_util_percent: 33.00416666666667
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923018754427614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.224035947596955
    mean_inference_ms: 1.5849390521235291
    mean_raw_obs_processing_ms: 0.14345655363682372
  time_since_restore: 3171.832466840744
  time_this_iter_s: 32.9003472328186
  time_total_s: 3171.832466840744
  timers:
    learn_throughput: 4656.705
    learn_time_ms: 10.308
    update_time_ms: 3.147
  timestamp: 1629283880
  timesteps_since_restore: 0
  timesteps_total: 217000
  training_iteration: 217
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    217 |          3171.83 | 217000 | 3.92952e+06 |          7.25468e+06 |             -198.044 |            7520.54 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 218000
  custom_metrics: {}
  date: 2021-08-18_10-51-45
  done: false
  episode_len_mean: 8703.88
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4062537.2766114986
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 217720
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.380002498626709
          max_q: 7255563.0
          mean_q: 151157.609375
          mean_td_error: 15.242315292358398
          min_q: -0.09642386436462402
        model: {}
        td_error: "[ 5.50902002e-02  8.21904987e-02  2.25616544e-01 -1.40095308e-01\n\
          \ -1.82845429e-01 -3.16174105e-02 -2.82911360e-01  1.15831479e-01\n  1.35350585e-01\
          \ -2.51616955e-01  1.92800313e-01  2.88590908e-01\n -2.81075925e-01 -7.21683800e-02\
          \ -2.59432197e-01  7.53448457e-02\n  3.75610627e-02 -9.01522160e-01 -2.44134605e-01\
          \ -6.68457896e-02\n -1.54106155e-01 -2.83030629e-01 -4.63053226e-01  8.67908001e-02\n\
          \  6.79050386e-02  7.35500000e+02  2.70082831e-01 -2.25458682e-01\n -9.78312492e-02\
          \  2.08995622e-02 -1.63973331e-01  2.39839911e-01\n -3.40505362e-01 -7.50454217e-02\
          \ -1.05983116e-01  9.13117155e-02\n -1.52810067e-01 -1.75729975e-01  7.33921900e-02\
          \ -9.91754979e-02\n  8.59890133e-02  2.68957391e-02 -3.42502534e-01 -4.98180240e-02\n\
          \  2.83865705e-02 -9.00306329e-02 -6.16996408e-01  8.15054178e-02]"
    num_agent_steps_sampled: 218000
    num_agent_steps_trained: 2604048
    num_steps_sampled: 218000
    num_steps_trained: 2604048
    num_target_updates: 431
  iterations_since_restore: 218
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 58.980000000000004
    ram_util_percent: 32.8542857142857
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923783214067405
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.294179353184446
    mean_inference_ms: 1.5854443619447207
    mean_raw_obs_processing_ms: 0.1435566706426502
  time_since_restore: 3196.4088096618652
  time_this_iter_s: 24.576342821121216
  time_total_s: 3196.4088096618652
  timers:
    learn_throughput: 5005.883
    learn_time_ms: 9.589
    update_time_ms: 2.731
  timestamp: 1629283905
  timesteps_since_restore: 0
  timesteps_total: 218000
  training_iteration: 218
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    218 |          3196.41 | 218000 | 4.06254e+06 |          7.25484e+06 |             -198.044 |            8703.88 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 219000
  custom_metrics: {}
  date: 2021-08-18_10-51-58
  done: false
  episode_len_mean: 8703.88
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4062537.2766114986
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 25
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 218728
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10224702954292297
          max_q: 0.9411457777023315
          mean_q: 0.12023971974849701
          mean_td_error: -233.86447143554688
          min_q: -0.09162777662277222
        model: {}
        td_error: "[-1.2958512e-01 -1.5528384e-01  2.0284902e-01  1.5451485e-01\n  2.1413842e-01\
          \  8.3600748e-01 -8.5524380e-02  2.2607884e-01\n -1.0529505e-01  1.6178817e-01\
          \  1.7816189e-01  5.6977242e-01\n  3.7971303e-01 -3.4767505e-02 -6.9724530e-02\
          \ -8.0425575e-02\n -9.4904840e-02 -1.5536961e-01  1.2790498e-01 -1.7460552e-01\n\
          \  2.1254972e-01 -4.1392750e-01 -8.7321061e-01 -3.0885516e-02\n -1.3673410e-01\
          \  2.5532284e-01 -2.2305585e-03 -5.6141982e+03\n  2.5019586e-02 -1.4818515e-01\
          \  3.6644101e-01  2.0167933e-01\n  8.2069433e-01 -1.5821290e-01  3.7575629e-02\
          \  1.5214187e-01\n -9.5352247e-02  2.0496336e-01 -3.2104086e-02 -1.2216583e-01\n\
          \  1.7683451e-01  2.3523213e-01  1.1709598e-01  2.6523292e-01\n -1.6169459e-01\
          \ -5.6141982e+03  8.1253484e-02 -4.0635884e-02]"
    num_agent_steps_sampled: 219000
    num_agent_steps_trained: 2616048
    num_steps_sampled: 219000
    num_steps_trained: 2616048
    num_target_updates: 433
  iterations_since_restore: 219
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 67.30000000000001
    ram_util_percent: 32.111111111111114
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923783214067405
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.294179353184446
    mean_inference_ms: 1.5854443619447207
    mean_raw_obs_processing_ms: 0.1435566706426502
  time_since_restore: 3208.6433959007263
  time_this_iter_s: 12.234586238861084
  time_total_s: 3208.6433959007263
  timers:
    learn_throughput: 3667.612
    learn_time_ms: 13.088
    update_time_ms: 3.358
  timestamp: 1629283918
  timesteps_since_restore: 0
  timesteps_total: 219000
  training_iteration: 219
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    219 |          3208.64 | 219000 | 4.06254e+06 |          7.25484e+06 |             -198.044 |            8703.88 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 220000
  custom_metrics: {}
  date: 2021-08-18_10-52-09
  done: false
  episode_len_mean: 8703.88
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4062537.2766114986
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 25
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 219736
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03053993172943592
          max_q: 1.6968235969543457
          mean_q: 0.14026501774787903
          mean_td_error: -1288.378662109375
          min_q: -0.09389185905456543
        model: {}
        td_error: "[-8.80015343e-02 -6.24616407e-02 -1.38937145e-01 -2.11863488e-01\n\
          \  3.63497674e-01  1.40419811e-01  1.30342424e-01 -2.20928282e-01\n -4.29939926e-02\
          \ -2.72750556e-02  2.10388482e-01 -1.16501316e-01\n  9.29440707e-02  1.39746249e-01\
          \  2.38612235e-01  8.31769556e-02\n -8.28693509e-02 -2.11219385e-01 -3.09213477e+04\
          \  9.11183879e-02\n -7.60852993e-01 -1.18736893e-01  6.92167953e-02 -4.96569872e-02\n\
          \ -7.90445805e-01  2.64897868e-02 -1.73336357e-01  2.84198582e-01\n  5.48450053e-02\
          \  1.94970846e-01 -2.43434608e-01 -2.06522644e-03\n  1.55534893e-02  2.15166420e-01\
          \ -1.38392523e-01  2.81572014e-01\n -1.30573779e-01  1.09947875e-01  1.45421654e-01\
          \  3.89356583e-01\n  1.14413813e-01  1.22532628e-01  3.52078736e-01  2.82802433e-01\n\
          \  1.48857057e-01  9.68712866e-02 -2.65179127e-01 -3.09213477e+04]"
    num_agent_steps_sampled: 220000
    num_agent_steps_trained: 2628048
    num_steps_sampled: 220000
    num_steps_trained: 2628048
    num_target_updates: 435
  iterations_since_restore: 220
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.33125
    ram_util_percent: 32.10625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923783214067405
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.294179353184446
    mean_inference_ms: 1.5854443619447207
    mean_raw_obs_processing_ms: 0.1435566706426502
  time_since_restore: 3219.930258512497
  time_this_iter_s: 11.28686261177063
  time_total_s: 3219.930258512497
  timers:
    learn_throughput: 5027.798
    learn_time_ms: 9.547
    update_time_ms: 2.855
  timestamp: 1629283929
  timesteps_since_restore: 0
  timesteps_total: 220000
  training_iteration: 220
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    220 |          3219.93 | 220000 | 4.06254e+06 |          7.25484e+06 |             -198.044 |            8703.88 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 221000
  custom_metrics: {}
  date: 2021-08-18_10-52-22
  done: false
  episode_len_mean: 8703.88
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4062537.2766114986
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 25
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 220744
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 9.971023559570312
          max_q: 7256488.0
          mean_q: 302354.1875
          mean_td_error: -13879.275390625
          min_q: -0.07522118091583252
        model: {}
        td_error: "[ 6.94897547e-02  1.69633836e-01 -8.36908125e+04 -8.36908125e+04\n\
          \ -2.42214262e-01  3.73827100e-01 -8.36908125e+04 -8.36908125e+04\n -8.36908125e+04\
          \  1.66100000e+03  1.35523364e-01 -1.30322129e-01\n  1.14072546e-01 -1.35028863e+00\
          \  1.66100000e+03 -8.36908125e+04\n  1.73896402e-01 -8.02332535e-02  1.30544618e-01\
          \ -1.40630081e-01\n -3.75783980e-01  2.74340868e-01 -1.04632884e-01 -9.18374509e-02\n\
          \ -5.07608503e-02  4.20167297e-03 -6.17605031e-01 -1.04613818e-01\n  1.70480162e-01\
          \  5.91346994e-02  1.34058759e-01  2.01128632e-01\n  6.10463656e-02  1.73840195e-01\
          \ -2.28846312e-01 -8.36908125e+04\n  6.00294322e-02 -1.24374837e-01 -8.36908125e+04\
          \  1.74696848e-01\n  2.08804771e-01  6.14376962e-02  2.19704121e-01  1.19809464e-01\n\
          \  1.73823297e-01 -9.12914038e-01  1.88437641e-01  4.55539674e-01]"
    num_agent_steps_sampled: 221000
    num_agent_steps_trained: 2640048
    num_steps_sampled: 221000
    num_steps_trained: 2640048
    num_target_updates: 437
  iterations_since_restore: 221
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.57222222222223
    ram_util_percent: 32.111111111111114
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923783214067405
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.294179353184446
    mean_inference_ms: 1.5854443619447207
    mean_raw_obs_processing_ms: 0.1435566706426502
  time_since_restore: 3232.322687625885
  time_this_iter_s: 12.392429113388062
  time_total_s: 3232.322687625885
  timers:
    learn_throughput: 3717.84
    learn_time_ms: 12.911
    update_time_ms: 3.831
  timestamp: 1629283942
  timesteps_since_restore: 0
  timesteps_total: 221000
  training_iteration: 221
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    221 |          3232.32 | 221000 | 4.06254e+06 |          7.25484e+06 |             -198.044 |            8703.88 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 222000
  custom_metrics: {}
  date: 2021-08-18_10-52-35
  done: false
  episode_len_mean: 8703.88
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4062537.2766114986
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 25
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 221752
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1071116253733635
          max_q: 1.0607495307922363
          mean_q: 0.15605683624744415
          mean_td_error: 0.06026989966630936
          min_q: -0.0492861270904541
        model: {}
        td_error: "[ 2.8982830e-01  9.8118901e-02  5.4637098e-01 -3.0104035e-01\n  9.2010304e-02\
          \  6.4925432e-01 -2.3145698e-02 -1.5572126e+00\n  1.6817597e-01  3.3209962e-01\
          \  2.5175697e-01  4.7435485e-02\n  6.7493707e-02  3.5469276e-01  1.6411668e-01\
          \ -7.6404762e-01\n -6.9984794e-04  4.1321635e-02 -4.6482116e-02  5.1004577e-01\n\
          \ -2.1470499e-01  1.9896477e-03  1.0760409e-01  1.6732863e-01\n  6.9646269e-02\
          \  1.5919390e-01 -7.8323573e-02 -6.3910313e-02\n -1.7170832e-01  3.4594321e-01\
          \  2.4536836e-01  2.2983210e-01\n  2.0139872e-01  2.4238190e-01  7.9296552e-02\
          \  1.6788536e-01\n  8.5028313e-02  3.8999629e-01 -3.9854743e-02  3.2789528e-01\n\
          \ -2.5603095e-01 -4.6278811e-01  1.1899184e-01  2.2522734e-01\n  9.4090536e-02\
          \ -1.1002290e-01 -1.3421185e-01  2.4531908e-01]"
    num_agent_steps_sampled: 222000
    num_agent_steps_trained: 2652048
    num_steps_sampled: 222000
    num_steps_trained: 2652048
    num_target_updates: 439
  iterations_since_restore: 222
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.88947368421052
    ram_util_percent: 32.11052631578948
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923783214067405
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.294179353184446
    mean_inference_ms: 1.5854443619447207
    mean_raw_obs_processing_ms: 0.1435566706426502
  time_since_restore: 3245.0060217380524
  time_this_iter_s: 12.683334112167358
  time_total_s: 3245.0060217380524
  timers:
    learn_throughput: 5136.538
    learn_time_ms: 9.345
    update_time_ms: 2.589
  timestamp: 1629283955
  timesteps_since_restore: 0
  timesteps_total: 222000
  training_iteration: 222
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    222 |          3245.01 | 222000 | 4.06254e+06 |          7.25484e+06 |             -198.044 |            8703.88 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 223000
  custom_metrics: {}
  date: 2021-08-18_10-52-48
  done: false
  episode_len_mean: 8703.88
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4062537.2766114986
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 25
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 222760
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.568411350250244
          max_q: 7255138.5
          mean_q: 151149.40625
          mean_td_error: -34791.6015625
          min_q: -0.11715221405029297
        model: {}
        td_error: "[-4.53915000e-01  3.49529386e-02  4.27000880e-01 -2.84167707e-01\n\
          \  2.10082769e-01  3.33396941e-02  4.92591038e-03  1.34498775e-02\n -2.08788500e+05\
          \  1.79080367e-01  1.51374131e-01 -2.08788500e+05\n -2.08788500e+05  6.81062639e-02\
          \ -2.08788500e+05 -2.94444226e-02\n  1.41431898e-01 -2.08788500e+05 -4.05889302e-01\
          \  3.03939700e-01\n -9.03601944e-02  3.11000000e+02  1.96205765e-01 -1.96101665e-02\n\
          \  1.61109596e-01 -1.79040521e-01  2.98332095e-01  1.89252794e-01\n  6.12926483e-03\
          \ -3.47282529e-01  1.60441980e-01 -2.08788500e+05\n -2.08788500e+05 -3.41378510e-01\
          \ -2.08788500e+05  2.27534771e-03\n  3.47089350e-01 -1.87173247e-01 -2.27556840e-01\
          \  1.91962436e-01\n -3.93426716e-01 -2.68464684e-02 -3.69956568e-02  1.21691525e-02\n\
          \ -1.00756325e-01 -1.52931899e-01  2.33822078e-01  9.42029357e-02]"
    num_agent_steps_sampled: 223000
    num_agent_steps_trained: 2664048
    num_steps_sampled: 223000
    num_steps_trained: 2664048
    num_target_updates: 441
  iterations_since_restore: 223
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.98421052631579
    ram_util_percent: 32.1421052631579
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923783214067405
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.294179353184446
    mean_inference_ms: 1.5854443619447207
    mean_raw_obs_processing_ms: 0.1435566706426502
  time_since_restore: 3257.973232269287
  time_this_iter_s: 12.967210531234741
  time_total_s: 3257.973232269287
  timers:
    learn_throughput: 5074.906
    learn_time_ms: 9.458
    update_time_ms: 2.675
  timestamp: 1629283968
  timesteps_since_restore: 0
  timesteps_total: 223000
  training_iteration: 223
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    223 |          3257.97 | 223000 | 4.06254e+06 |          7.25484e+06 |             -198.044 |            8703.88 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 224000
  custom_metrics: {}
  date: 2021-08-18_10-53-02
  done: false
  episode_len_mean: 8703.88
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4062537.2766114986
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 25
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 223768
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05254829302430153
          max_q: 5.080366134643555
          mean_q: 0.6984742879867554
          mean_td_error: -29745.68359375
          min_q: -0.1309162974357605
        model: {}
        td_error: "[-2.37965422e+05  1.48077935e-01  6.34775162e-02 -1.45133913e-01\n\
          \ -6.63460851e-01  9.43654105e-02 -1.06262334e-01 -2.37965422e+05\n -8.45503733e-02\
          \ -2.02444851e-01  1.22375667e-01  1.23583056e-01\n  3.41088831e-01  1.05349503e-01\
          \ -4.36070412e-02 -2.37965422e+05\n -9.77442414e-02  3.81890148e-01  5.15083224e-02\
          \ -9.97512937e-02\n  4.10595983e-02  3.80192518e-01  1.94960535e-02 -3.15439761e-01\n\
          \ -2.37965422e+05 -4.90407161e-02 -2.37965422e+05 -1.49335265e-01\n  3.56195539e-01\
          \  2.05654919e-01  1.37157530e-01  6.98099360e-02\n  1.92173392e-01 -9.12294149e-01\
          \  8.02634954e-02  6.22228235e-02\n  1.29709765e-01 -1.25205800e-01 -4.59670275e-01\
          \  9.78494734e-02\n  3.45747530e-01 -1.02614850e-01 -2.69703627e-01 -2.90825218e-03\n\
          \ -2.37965422e+05 -3.56245525e-02 -1.11850306e-01  1.57635078e-01]"
    num_agent_steps_sampled: 224000
    num_agent_steps_trained: 2676048
    num_steps_sampled: 224000
    num_steps_trained: 2676048
    num_target_updates: 443
  iterations_since_restore: 224
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.19473684210527
    ram_util_percent: 32.16315789473685
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923783214067405
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.294179353184446
    mean_inference_ms: 1.5854443619447207
    mean_raw_obs_processing_ms: 0.1435566706426502
  time_since_restore: 3271.544222354889
  time_this_iter_s: 13.570990085601807
  time_total_s: 3271.544222354889
  timers:
    learn_throughput: 5074.612
    learn_time_ms: 9.459
    update_time_ms: 2.817
  timestamp: 1629283982
  timesteps_since_restore: 0
  timesteps_total: 224000
  training_iteration: 224
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    224 |          3271.54 | 224000 | 4.06254e+06 |          7.25484e+06 |             -198.044 |            8703.88 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 225000
  custom_metrics: {}
  date: 2021-08-18_10-53-16
  done: false
  episode_len_mean: 8703.88
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4062537.2766114986
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 25
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 224776
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1357036530971527
          max_q: 6.308106422424316
          mean_q: 1.045705795288086
          mean_td_error: -45488.5703125
          min_q: -0.2049342393875122
        model: {}
        td_error: "[ 8.8257708e-02  2.0240542e-01  1.8180066e-01  2.0187667e-01\n -2.7293203e+05\
          \  2.7395284e-01 -5.8833119e-02 -4.6586305e-01\n -8.9914143e-02  2.4816181e-01\
          \ -1.6297860e-01  1.5348956e-01\n  4.4952220e-01  1.5780047e-01  7.8324825e-03\
          \  8.6726025e-03\n  3.0881080e-01 -7.1315907e-02 -2.3871072e-02  1.5006319e-02\n\
          \ -2.7293203e+05  3.0405349e-01 -2.7293203e+05  1.1034444e-02\n -2.7293203e+05\
          \  9.7546026e-02  3.4563929e-02  1.4351690e-01\n -2.7293203e+05  2.0644626e-01\
          \  3.0403206e-01  4.2304799e-02\n  3.9190370e-01  2.9752153e-01  2.7203357e-01\
          \  2.1959466e-01\n  1.5836436e-01  1.9690931e-01  2.9643983e-01 -2.2981808e-02\n\
          \ -2.7293203e+05  1.6520253e-01  4.0140790e-01  2.3570082e-01\n -2.7293203e+05\
          \ -1.5329201e-02 -2.7293203e+05 -2.3983081e-01]"
    num_agent_steps_sampled: 225000
    num_agent_steps_trained: 2688048
    num_steps_sampled: 225000
    num_steps_trained: 2688048
    num_target_updates: 445
  iterations_since_restore: 225
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.23333333333331
    ram_util_percent: 32.157142857142865
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923783214067405
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.294179353184446
    mean_inference_ms: 1.5854443619447207
    mean_raw_obs_processing_ms: 0.1435566706426502
  time_since_restore: 3285.440667629242
  time_this_iter_s: 13.896445274353027
  time_total_s: 3285.440667629242
  timers:
    learn_throughput: 5083.838
    learn_time_ms: 9.442
    update_time_ms: 2.86
  timestamp: 1629283996
  timesteps_since_restore: 0
  timesteps_total: 225000
  training_iteration: 225
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    225 |          3285.44 | 225000 | 4.06254e+06 |          7.25484e+06 |             -198.044 |            8703.88 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 226000
  custom_metrics: {}
  date: 2021-08-18_10-53-30
  done: false
  episode_len_mean: 8686.192307692309
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4185310.265589856
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 225784
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.052047617733478546
          max_q: 10.276784896850586
          mean_q: 2.3450493812561035
          mean_td_error: -77625.2734375
          min_q: -0.23266464471817017
        model: {}
        td_error: "[ 2.79110909e-01  1.25053495e-01 -1.64121985e-01 -2.16944933e-01\n\
          \  1.61948428e-01  2.28124261e-01 -1.36890829e-01 -3.36342250e+05\n  1.39533341e-01\
          \ -1.68243378e-01 -4.48061705e-01  8.97136033e-02\n -3.36342250e+05 -3.36342250e+05\
          \  1.61144108e-01 -3.36342250e+05\n -3.15993190e-01  1.75431758e-01 -1.14936016e-01\
          \  1.42638326e-01\n -1.06319040e-02  1.88388020e-01  2.97958136e-01  7.17477053e-02\n\
          \ -3.36342250e+05 -5.20210415e-02 -3.70068014e-01  5.07347822e-01\n -2.72534281e-01\
          \  1.12867072e-01 -2.62457383e+04  1.39642283e-01\n -3.42862383e-02 -3.36342250e+05\
          \  1.49525553e-02 -3.36342250e+05\n -1.65411234e-01  1.07424445e-01  2.22712472e-01\
          \ -3.36342250e+05\n -3.36342250e+05 -3.36342250e+05 -8.27804446e-01 -1.51544642e+00\n\
          \ -3.36342250e+05  1.01049572e-01 -1.20663381e+00  2.88113475e-01]"
    num_agent_steps_sampled: 226000
    num_agent_steps_trained: 2700048
    num_steps_sampled: 226000
    num_steps_trained: 2700048
    num_target_updates: 447
  iterations_since_restore: 226
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.084999999999994
    ram_util_percent: 32.20000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924356649104282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.356772218880407
    mean_inference_ms: 1.5858133526234504
    mean_raw_obs_processing_ms: 0.1436412486520849
  time_since_restore: 3299.5868537425995
  time_this_iter_s: 14.146186113357544
  time_total_s: 3299.5868537425995
  timers:
    learn_throughput: 5033.253
    learn_time_ms: 9.537
    update_time_ms: 3.045
  timestamp: 1629284010
  timesteps_since_restore: 0
  timesteps_total: 226000
  training_iteration: 226
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    226 |          3299.59 | 226000 | 4.18531e+06 |          7.25484e+06 |             -198.044 |            8686.19 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 227000
  custom_metrics: {}
  date: 2021-08-18_10-53-42
  done: false
  episode_len_mean: 8686.192307692309
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4185310.265589856
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 26
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 226792
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.211701393127441
          max_q: 7256533.5
          mean_q: 151179.796875
          mean_td_error: -39577.171875
          min_q: -0.1271759271621704
        model: {}
        td_error: "[-3.6115503e+05  4.2535633e-01 -3.6115503e+05  1.2112055e-01\n -3.6115503e+05\
          \ -1.0557928e+00 -8.3983719e-01  3.6289448e-01\n  4.5000666e-01  1.9467968e-01\
          \  3.5835126e-01  3.3360878e-01\n  1.7060000e+03  2.6727331e-01  3.8332582e-01\
          \ -2.0987140e-01\n -1.7335087e-02 -3.0730495e-01  3.7607491e-01 -7.3496237e-02\n\
          \ -4.1040668e-01  2.8118888e-01  9.4810948e-03  1.3322243e-01\n -1.0227796e+00\
          \ -4.3991353e-02  3.2283616e-01 -1.0355890e-02\n  2.6491898e-01  3.4168857e-01\
          \ -4.7819160e+04 -2.4354100e-02\n -3.6115503e+05  3.2515243e-02 -3.1595230e-03\
          \  7.1153454e-02\n -3.6115503e+05  3.0534968e-01  1.1409290e+00  2.2660702e-01\n\
          \  1.9968897e-01  1.3766265e-01  1.3450646e-01 -4.7819160e+04\n  4.9501300e-02\
          \  1.9224417e-01 -1.3531907e-01  3.9668211e-01]"
    num_agent_steps_sampled: 227000
    num_agent_steps_trained: 2712048
    num_steps_sampled: 227000
    num_steps_trained: 2712048
    num_target_updates: 449
  iterations_since_restore: 227
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.16470588235294
    ram_util_percent: 32.2
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924356649104282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.356772218880407
    mean_inference_ms: 1.5858133526234504
    mean_raw_obs_processing_ms: 0.1436412486520849
  time_since_restore: 3310.937201499939
  time_this_iter_s: 11.350347757339478
  time_total_s: 3310.937201499939
  timers:
    learn_throughput: 5047.044
    learn_time_ms: 9.511
    update_time_ms: 2.766
  timestamp: 1629284022
  timesteps_since_restore: 0
  timesteps_total: 227000
  training_iteration: 227
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    227 |          3310.94 | 227000 | 4.18531e+06 |          7.25484e+06 |             -198.044 |            8686.19 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 228000
  custom_metrics: {}
  date: 2021-08-18_10-53-54
  done: false
  episode_len_mean: 8686.192307692309
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4185310.265589856
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 26
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 227800
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.572475910186768
          max_q: 7255681.5
          mean_q: 151164.21875
          mean_td_error: -72883.1328125
          min_q: -0.17675089836120605
        model: {}
        td_error: "[ 2.6968268e-01 -9.5163888e-01  2.2400796e-02 -3.9802019e+05\n  3.1973556e-02\
          \  8.8798881e-02  5.1548541e-02  1.5473092e-01\n -7.8610927e-03 -5.7596952e-02\
          \  5.0482661e-02  9.1932043e-03\n  5.2055538e-01  3.4934364e-02 -3.9802019e+05\
          \  1.5458992e-01\n -1.3427168e-02 -3.9802019e+05  2.9152766e-02 -1.6831832e-01\n\
          \ -4.8755282e-01 -7.8770609e+04 -3.9802019e+05 -2.1986626e-01\n -3.7118945e-02\
          \ -3.9802019e+05  1.2573263e-01 -7.8770609e+04\n -2.4272945e-02 -5.8443263e-02\
          \  8.5350000e+02  2.9373914e-01\n -3.9802019e+05 -7.8770609e+04 -2.3686545e-01\
          \ -4.8667036e-02\n  2.1198165e-01  1.7182618e-01  1.2530357e-01  9.4205499e-02\n\
          \ -3.9802019e+05  1.6778441e-01 -3.9802019e+05  8.4327437e-02\n -7.8770609e+04\
          \ -6.5618038e-02 -4.3341793e-02 -1.0472761e-01]"
    num_agent_steps_sampled: 228000
    num_agent_steps_trained: 2724048
    num_steps_sampled: 228000
    num_steps_trained: 2724048
    num_target_updates: 451
  iterations_since_restore: 228
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.28235294117647
    ram_util_percent: 32.182352941176475
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924356649104282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.356772218880407
    mean_inference_ms: 1.5858133526234504
    mean_raw_obs_processing_ms: 0.1436412486520849
  time_since_restore: 3322.7153747081757
  time_this_iter_s: 11.778173208236694
  time_total_s: 3322.7153747081757
  timers:
    learn_throughput: 5130.503
    learn_time_ms: 9.356
    update_time_ms: 2.722
  timestamp: 1629284034
  timesteps_since_restore: 0
  timesteps_total: 228000
  training_iteration: 228
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    228 |          3322.72 | 228000 | 4.18531e+06 |          7.25484e+06 |             -198.044 |            8686.19 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 229000
  custom_metrics: {}
  date: 2021-08-18_10-54-07
  done: false
  episode_len_mean: 8686.192307692309
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4185310.265589856
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 26
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 228808
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.056199125945568085
          max_q: 36.11876678466797
          mean_q: 3.3012187480926514
          mean_td_error: -49276.1015625
          min_q: -0.3566405177116394
        model: {}
        td_error: "[-3.91066819e-02  1.34414345e-01  1.73638046e-01 -1.18649062e+05\n\
          \ -1.79968029e-03 -4.83142823e-01  2.69479871e-01  2.74763286e-01\n -2.01340646e-01\
          \  2.60523051e-01 -1.37435019e-01  2.98946142e-01\n  2.28281334e-01  3.12680334e-01\
          \  9.42054912e-02 -1.02841124e-01\n -1.66181326e-01  1.07319981e-01  1.45930454e-01\
          \  1.11281805e-01\n -4.24461626e-03  1.18179679e-01 -1.40100718e-02  1.04535893e-01\n\
          \ -4.43004531e+05 -4.43004531e+05 -1.18649062e+05 -1.59088910e-01\n -2.51939237e-01\
          \  1.32613167e-01  3.22719783e-01 -8.81144255e-02\n  2.68015236e-01  7.58860782e-02\
          \ -4.19057459e-02 -7.37899691e-02\n -1.18649062e+05 -4.43004531e+05  3.64516705e-01\
          \  8.24113655e+00\n  1.32155776e-01 -1.07956231e-01 -1.18649062e+05 -4.43004531e+05\n\
          \  2.74255097e-01  2.55569309e-01 -1.18649062e+05 -3.86496484e-02]"
    num_agent_steps_sampled: 229000
    num_agent_steps_trained: 2736048
    num_steps_sampled: 229000
    num_steps_trained: 2736048
    num_target_updates: 453
  iterations_since_restore: 229
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.25555555555555
    ram_util_percent: 32.20000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924356649104282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.356772218880407
    mean_inference_ms: 1.5858133526234504
    mean_raw_obs_processing_ms: 0.1436412486520849
  time_since_restore: 3335.00691819191
  time_this_iter_s: 12.29154348373413
  time_total_s: 3335.00691819191
  timers:
    learn_throughput: 4920.209
    learn_time_ms: 9.756
    update_time_ms: 2.795
  timestamp: 1629284047
  timesteps_since_restore: 0
  timesteps_total: 229000
  training_iteration: 229
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    229 |          3335.01 | 229000 | 4.18531e+06 |          7.25484e+06 |             -198.044 |            8686.19 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 230000
  custom_metrics: {}
  date: 2021-08-18_10-54-19
  done: false
  episode_len_mean: 8686.192307692309
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4185310.265589856
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 26
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 229816
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.748952865600586
          max_q: 7255304.0
          mean_q: 151159.03125
          mean_td_error: -77922.1171875
          min_q: -0.02688884735107422
        model: {}
        td_error: "[ 2.23111466e-01 -1.52795609e+05 -4.21907008e-01 -4.70659062e+05\n\
          \ -4.54946852e+00 -1.92657262e-01 -3.67390037e-01 -4.70659062e+05\n  5.29702604e-02\
          \  1.52159125e-01  1.74013853e-01 -1.16004407e+00\n -2.02369094e-01 -6.64745718e-02\
          \ -2.34707594e-01  3.71808320e-01\n -3.09239924e-02 -1.97290152e-01 -4.37838346e-01\
          \  4.76500000e+02\n -1.52795609e+05 -7.37118721e-02  2.93002903e-01 -1.52795609e+05\n\
          \ -4.70659062e+05 -3.59020531e-02  2.84618139e-02  2.75861353e-01\n -2.48436332e-02\
          \ -1.95871383e-01 -1.25276059e-01 -2.40814745e-01\n -2.19802523e+00  8.04013461e-02\
          \  7.04758018e-02  8.17303434e-02\n -1.34600699e-02 -1.52795609e+05 -4.70659062e+05\
          \ -1.52795609e+05\n -2.03894228e-02 -5.20610213e-01  1.18112475e-01 -4.70659062e+05\n\
          \ -7.22184241e-01  2.49278843e-02 -1.52795609e+05 -4.70659062e+05]"
    num_agent_steps_sampled: 230000
    num_agent_steps_trained: 2748048
    num_steps_sampled: 230000
    num_steps_trained: 2748048
    num_target_updates: 455
  iterations_since_restore: 230
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.5
    ram_util_percent: 32.20000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924356649104282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.356772218880407
    mean_inference_ms: 1.5858133526234504
    mean_raw_obs_processing_ms: 0.1436412486520849
  time_since_restore: 3347.418864250183
  time_this_iter_s: 12.411946058273315
  time_total_s: 3347.418864250183
  timers:
    learn_throughput: 5005.796
    learn_time_ms: 9.589
    update_time_ms: 2.826
  timestamp: 1629284059
  timesteps_since_restore: 0
  timesteps_total: 230000
  training_iteration: 230
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    230 |          3347.42 | 230000 | 4.18531e+06 |          7.25484e+06 |             -198.044 |            8686.19 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 231000
  custom_metrics: {}
  date: 2021-08-18_10-54-33
  done: false
  episode_len_mean: 8686.192307692309
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4185310.265589856
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 26
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 230824
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04473381116986275
          max_q: 72.87106323242188
          mean_q: 6.774086952209473
          mean_td_error: -52301.9140625
          min_q: 0.0033440589904785156
        model: {}
        td_error: "[ 2.8381866e-01 -2.2616827e-01  1.2678833e-01 -1.5154955e+05\n -2.5706303e-01\
          \ -1.5154955e+05 -1.5154955e+05 -7.1994126e-02\n -6.4469349e-01 -4.3818581e+05\
          \ -1.5154955e+05  4.3840373e-01\n -1.5057099e-01 -1.4401978e-01  1.3703772e-01\
          \  2.2459066e-01\n -1.2640524e-01  6.4454049e-02 -1.9809923e-01 -2.3687042e-02\n\
          \  1.3618638e+01  2.1421342e-01 -2.7328901e+00  2.5787205e-01\n -6.3986778e-02\
          \  4.3223381e-02  3.2216460e-02  2.2453654e-01\n -3.5114199e-01  2.7996790e-01\
          \  7.2548956e-02  1.2943811e+00\n  3.0181593e-01  1.4477693e-01 -1.7929977e-01\
          \ -1.3981816e+01\n -4.3818581e+05 -1.0049075e-01  1.9916528e-01  8.9943886e-02\n\
          \  2.2936791e-01 -4.3818581e+05  1.2261659e-02 -1.5154955e+05\n -4.3818581e+05\
          \  2.0556171e-01 -5.1155835e-02  1.4387304e-01]"
    num_agent_steps_sampled: 231000
    num_agent_steps_trained: 2760048
    num_steps_sampled: 231000
    num_steps_trained: 2760048
    num_target_updates: 457
  iterations_since_restore: 231
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.54210526315791
    ram_util_percent: 32.20000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924356649104282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.356772218880407
    mean_inference_ms: 1.5858133526234504
    mean_raw_obs_processing_ms: 0.1436412486520849
  time_since_restore: 3360.5917971134186
  time_this_iter_s: 13.172932863235474
  time_total_s: 3360.5917971134186
  timers:
    learn_throughput: 4694.164
    learn_time_ms: 10.225
    update_time_ms: 2.88
  timestamp: 1629284073
  timesteps_since_restore: 0
  timesteps_total: 231000
  training_iteration: 231
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    231 |          3360.59 | 231000 | 4.18531e+06 |          7.25484e+06 |             -198.044 |            8686.19 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 232000
  custom_metrics: {}
  date: 2021-08-18_10-54-47
  done: false
  episode_len_mean: 8686.192307692309
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4185310.265589856
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 26
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 231832
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06666602939367294
          max_q: 92.437255859375
          mean_q: 13.724655151367188
          mean_td_error: -69788.28125
          min_q: 0.11143600940704346
        model: {}
        td_error: "[-2.94196486e-01 -4.69380062e+05  4.24687564e-02  1.27862290e-01\n\
          \ -1.74917340e-01 -4.69380062e+05 -1.35395259e-01  2.17683509e-01\n -4.69380062e+05\
          \  1.74540639e-01 -7.93892741e-02 -2.25108832e-01\n  1.77739367e-01 -4.93690073e-02\
          \ -2.20678896e-01  5.16046435e-02\n -2.27073610e-01 -2.59326577e-01  1.69878989e-01\
          \ -4.69380062e+05\n -2.01062292e-01 -8.76185894e-01 -7.53192604e-02 -6.41732422e+04\n\
          \  2.60397017e-01 -7.66407847e-02  8.60607177e-02 -2.37893176e+00\n  1.96804762e-01\
          \ -5.31787574e-02  1.04991466e-01 -4.27914143e-01\n  1.90270007e-01 -4.69380062e+05\
          \ -4.69380062e+05  1.27169162e-01\n -3.42049599e-01  8.05336684e-02  1.46564931e-01\
          \  4.26307023e-01\n -2.38027871e-01  2.31636867e-01  7.51512796e-02 -4.69380062e+05\n\
          \  1.82584316e-01 -9.42917764e-02  1.68154523e-01 -3.73922437e-01]"
    num_agent_steps_sampled: 232000
    num_agent_steps_trained: 2772048
    num_steps_sampled: 232000
    num_steps_trained: 2772048
    num_target_updates: 459
  iterations_since_restore: 232
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.220000000000006
    ram_util_percent: 32.20000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924356649104282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.356772218880407
    mean_inference_ms: 1.5858133526234504
    mean_raw_obs_processing_ms: 0.1436412486520849
  time_since_restore: 3374.22540640831
  time_this_iter_s: 13.633609294891357
  time_total_s: 3374.22540640831
  timers:
    learn_throughput: 4666.03
    learn_time_ms: 10.287
    update_time_ms: 3.017
  timestamp: 1629284087
  timesteps_since_restore: 0
  timesteps_total: 232000
  training_iteration: 232
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    232 |          3374.23 | 232000 | 4.18531e+06 |          7.25484e+06 |             -198.044 |            8686.19 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 233000
  custom_metrics: {}
  date: 2021-08-18_10-55-00
  done: false
  episode_len_mean: 8686.192307692309
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4185310.265589856
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 26
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 232840
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05917634069919586
          max_q: 86.04801940917969
          mean_q: 2.1313114166259766
          mean_td_error: 1.2614259719848633
          min_q: 0.07936441898345947
        model: {}
        td_error: "[ 3.0854046e-03 -1.5545940e-01 -3.6716336e-01 -1.8809462e-01\n -1.5826768e-01\
          \ -2.7623019e-01 -2.3484051e-02 -1.0963464e-01\n  1.4109497e-01  2.5726387e-01\
          \  1.3994753e-02  9.0952039e-02\n -2.9190910e-01 -3.1085920e-01  1.5637042e-01\
          \ -1.3462645e-01\n -2.9132217e-01  3.1526715e-02 -8.8253260e-02 -1.2098616e-01\n\
          \ -1.1843881e-01  2.2560938e-01  2.4453118e-02  4.0157005e-02\n  1.3657987e-01\
          \ -2.1540582e-02 -5.3345408e+00 -3.0007765e-02\n -3.7671208e-02  3.2594866e-01\
          \ -2.1615028e-02 -1.7090315e-01\n -1.0109526e-01 -1.2508938e-01 -1.3794730e+00\
          \  1.5530080e-01\n  2.3830168e-01  2.7700353e-01  1.2858005e-01 -3.2466602e-01\n\
          \  6.8518021e+01  3.6603451e-02  1.4355285e-01  1.4094374e-01\n -1.3118982e-03\
          \ -1.3791323e-01 -1.7664039e-01 -3.9705217e-02]"
    num_agent_steps_sampled: 233000
    num_agent_steps_trained: 2784048
    num_steps_sampled: 233000
    num_steps_trained: 2784048
    num_target_updates: 461
  iterations_since_restore: 233
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.56842105263158
    ram_util_percent: 32.20000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924356649104282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.356772218880407
    mean_inference_ms: 1.5858133526234504
    mean_raw_obs_processing_ms: 0.1436412486520849
  time_since_restore: 3387.8652267456055
  time_this_iter_s: 13.639820337295532
  time_total_s: 3387.8652267456055
  timers:
    learn_throughput: 4692.326
    learn_time_ms: 10.229
    update_time_ms: 2.818
  timestamp: 1629284100
  timesteps_since_restore: 0
  timesteps_total: 233000
  training_iteration: 233
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    233 |          3387.87 | 233000 | 4.18531e+06 |          7.25484e+06 |             -198.044 |            8686.19 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 234000
  custom_metrics: {}
  date: 2021-08-18_10-55-14
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 233848
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04390338808298111
          max_q: 1.014751672744751
          mean_q: 0.35253119468688965
          mean_td_error: 0.03813828155398369
          min_q: 0.14674949645996094
        model: {}
        td_error: "[ 0.03298575  0.16510515  0.1690487   0.22889824  0.3150525   0.2687298\n\
          \ -0.1117492   0.17263031 -0.01143998  0.06481022  0.02808213  0.08580068\n\
          \  0.18270451 -0.0888671  -0.00344753 -0.2951817   0.04379332 -0.11802867\n\
          \  0.31596732 -0.18178159  0.19703245 -0.10530129  0.01132828 -0.14198193\n\
          \  0.1765598  -0.18082237 -0.06635734  0.09023947 -0.09343521 -0.08078194\n\
          \  0.11062923 -0.24430144 -0.34879643 -0.32109666  0.59778064  0.07604192\n\
          \  0.42198512  0.08947167  0.21852404 -0.15883362 -0.05780369  0.03729373\n\
          \  0.25434712  0.27949706 -0.10057825  0.01951998 -0.07530755 -0.03732833]"
    num_agent_steps_sampled: 234000
    num_agent_steps_trained: 2796048
    num_steps_sampled: 234000
    num_steps_trained: 2796048
    num_target_updates: 463
  iterations_since_restore: 234
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.32500000000002
    ram_util_percent: 32.18000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3401.394690513611
  time_this_iter_s: 13.529463768005371
  time_total_s: 3401.394690513611
  timers:
    learn_throughput: 5055.383
    learn_time_ms: 9.495
    update_time_ms: 2.677
  timestamp: 1629284114
  timesteps_since_restore: 0
  timesteps_total: 234000
  training_iteration: 234
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    234 |          3401.39 | 234000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 235000
  custom_metrics: {}
  date: 2021-08-18_10-55-26
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 234856
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.810478210449219
          max_q: 7254404.0
          mean_q: 151133.96875
          mean_td_error: -8.680761337280273
          min_q: 0.37791216373443604
        model: {}
        td_error: "[-5.71943521e-02  1.96604788e-01  2.41041243e-01 -1.28053367e-01\n\
          \  1.38626039e-01 -1.38756335e-02  8.26125145e-02 -1.46034300e-01\n -1.50311172e-01\
          \  3.29897761e-01  1.64677024e-01  2.61522949e-01\n  1.81236506e-01 -3.14879894e-01\
          \  1.62998378e-01  4.29387987e-01\n  1.67475104e-01 -8.76027346e-02  3.55812430e-01\
          \ -2.19931364e-01\n  2.78894305e-01  2.75877386e-01  1.17583185e-01 -5.90397120e-02\n\
          \  3.29581022e-01  4.36838955e-01 -1.53272688e-01  2.50862837e-02\n  4.48522031e-01\
          \  2.89898634e-01  6.34288788e-02 -4.21500000e+02\n -4.91002202e-02 -1.63726807e-02\
          \  9.41771269e-02  1.98565871e-01\n  4.11594540e-01  1.29173577e-01  3.38025808e-01\
          \ -4.15693521e-02\n  2.30670869e-01 -3.88934851e-01  4.39470053e-01 -1.33620441e-01\n\
          \  2.46029556e-01  1.94164425e-01 -4.99558449e-01  2.33184695e-02]"
    num_agent_steps_sampled: 235000
    num_agent_steps_trained: 2808048
    num_steps_sampled: 235000
    num_steps_trained: 2808048
    num_target_updates: 465
  iterations_since_restore: 235
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.43529411764706
    ram_util_percent: 32.11176470588236
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3412.7648837566376
  time_this_iter_s: 11.370193243026733
  time_total_s: 3412.7648837566376
  timers:
    learn_throughput: 4607.395
    learn_time_ms: 10.418
    update_time_ms: 3.139
  timestamp: 1629284126
  timesteps_since_restore: 0
  timesteps_total: 235000
  training_iteration: 235
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    235 |          3412.76 | 235000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 236000
  custom_metrics: {}
  date: 2021-08-18_10-55-38
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 235864
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.09543940424919128
          max_q: 2.520686388015747
          mean_q: 0.4219549596309662
          mean_td_error: -0.03611908480525017
          min_q: 0.1437585949897766
        model: {}
        td_error: "[-0.23230004 -0.36675358 -0.33687264  0.03095436  0.21516657  1.2989322\n\
          \ -0.32741004  0.00826317  0.01619115  0.10213295 -0.10717607 -0.13979563\n\
          \ -0.13534307 -0.13965201  0.23592447 -0.22189635  0.15811467  0.09119099\n\
          \  0.14133829  0.11505464  0.12725808 -0.12148833  0.16115049  0.16878012\n\
          \ -0.22364289 -0.17187792 -0.3992145  -0.12872529  0.00228786 -0.5011286\n\
          \  0.05378807 -0.25300467  0.22369507 -0.13709718 -0.1773982   0.0194197\n\
          \  0.21034202 -0.21813059  0.01369375  0.09495819 -0.27644205 -0.15180498\n\
          \ -0.2743526   0.10218103 -0.6971744  -0.02867299  0.32592204  0.11689873]"
    num_agent_steps_sampled: 236000
    num_agent_steps_trained: 2820048
    num_steps_sampled: 236000
    num_steps_trained: 2820048
    num_target_updates: 467
  iterations_since_restore: 236
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 67.3529411764706
    ram_util_percent: 32.10588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3424.624925851822
  time_this_iter_s: 11.860042095184326
  time_total_s: 3424.624925851822
  timers:
    learn_throughput: 5069.705
    learn_time_ms: 9.468
    update_time_ms: 2.735
  timestamp: 1629284138
  timesteps_since_restore: 0
  timesteps_total: 236000
  training_iteration: 236
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    236 |          3424.62 | 236000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 237000
  custom_metrics: {}
  date: 2021-08-18_10-55-51
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 236872
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03440548852086067
          max_q: 0.8741481304168701
          mean_q: 0.3591345250606537
          mean_td_error: 0.033526547253131866
          min_q: 0.2507759928703308
        model: {}
        td_error: "[ 0.16013701  0.08310503  0.16860226 -0.13114285 -0.12376538 -0.13495794\n\
          \  0.16443992 -0.12103248  0.30818182 -0.15380085  0.11515948 -0.27435136\n\
          \ -0.0043456   0.18163572  0.2351783   0.35016555  0.02053079 -0.09566671\n\
          \  0.23934478  0.05846015  0.10588157 -0.15266079 -0.12291241  0.20927818\n\
          \ -0.1562736   0.10617191  0.18065825 -0.08294371 -0.21054101  0.1168282\n\
          \  0.08338599  0.15836555  0.35442436 -0.2323556  -0.06377548 -0.10718742\n\
          \  0.01366709 -0.05072135  0.2037547  -0.15223461  0.03678706 -0.16671348\n\
          \  0.06086661 -0.01591185  0.18506972  0.03482392  0.20533228  0.02233243]"
    num_agent_steps_sampled: 237000
    num_agent_steps_trained: 2832048
    num_steps_sampled: 237000
    num_steps_trained: 2832048
    num_target_updates: 469
  iterations_since_restore: 237
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.90555555555555
    ram_util_percent: 32.10555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3436.678624153137
  time_this_iter_s: 12.053698301315308
  time_total_s: 3436.678624153137
  timers:
    learn_throughput: 5124.144
    learn_time_ms: 9.367
    update_time_ms: 2.798
  timestamp: 1629284151
  timesteps_since_restore: 0
  timesteps_total: 237000
  training_iteration: 237
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    237 |          3436.68 | 237000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 238000
  custom_metrics: {}
  date: 2021-08-18_10-56-03
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 237880
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02608216553926468
          max_q: 0.8570359349250793
          mean_q: 0.36469098925590515
          mean_td_error: -0.004115584306418896
          min_q: 0.2125799059867859
        model: {}
        td_error: "[ 0.2794913   0.16772994  0.07911974  0.13919815 -0.05890855 -0.09453598\n\
          \  0.34105995 -0.13578814  0.02167225  0.09552437  0.0851604  -0.1680578\n\
          \  0.05635682 -0.2873695  -0.18140113  0.01727211 -0.03415194 -0.01048383\n\
          \  0.08175066 -0.00227535  0.08591296  0.31032687 -0.1470083   0.2640133\n\
          \  0.19826166  0.00429422  0.13563165  0.10255846  0.12987955 -0.00832093\n\
          \ -0.14456156  0.26993787 -0.06629416  0.18848318 -0.29786032  0.10616906\n\
          \ -0.24147218  0.1939344  -0.23872912 -0.3356552   0.06012198 -0.7732952\n\
          \  0.07887836 -0.3122769  -0.04793167 -0.01792413 -0.1377863   0.05180091]"
    num_agent_steps_sampled: 238000
    num_agent_steps_trained: 2844048
    num_steps_sampled: 238000
    num_steps_trained: 2844048
    num_target_updates: 471
  iterations_since_restore: 238
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.78235294117647
    ram_util_percent: 32.10588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3448.7296698093414
  time_this_iter_s: 12.051045656204224
  time_total_s: 3448.7296698093414
  timers:
    learn_throughput: 5071.863
    learn_time_ms: 9.464
    update_time_ms: 2.702
  timestamp: 1629284163
  timesteps_since_restore: 0
  timesteps_total: 238000
  training_iteration: 238
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    238 |          3448.73 | 238000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 239000
  custom_metrics: {}
  date: 2021-08-18_10-56-16
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 238888
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 10.892361640930176
          max_q: 7255357.0
          mean_q: 302306.84375
          mean_td_error: 22.11756706237793
          min_q: 0.15627062320709229
        model: {}
        td_error: "[-2.94651091e-02 -2.12674469e-01 -1.61283672e-01  5.30500000e+02\n\
          \  1.56578615e-01  9.05312300e-02 -2.76648283e-01  1.98854506e-02\n -1.65538996e-01\
          \  2.21046537e-01 -1.00239635e-01  4.16961014e-02\n  3.94631356e-01 -4.01622653e-01\
          \  4.17192429e-02  1.40381292e-01\n  3.07562470e-01 -5.72089255e-02 -1.51273966e-01\
          \  1.07834265e-01\n  1.33140832e-01 -1.06483698e-04  3.83936167e-02  2.33702004e-01\n\
          \ -1.55547976e-01  2.93976367e-02 -1.45988822e-01  5.20832688e-02\n  2.59148777e-02\
          \  1.05758935e-01  5.30500000e+02  8.99061710e-02\n -9.50171649e-02  1.57162249e-02\
          \  4.18309271e-02  1.10003337e-01\n -7.00276196e-02  2.60668218e-01  1.79540411e-01\
          \ -1.75450921e-01\n -1.41358495e-01  1.14827156e-01  1.08825207e-01  1.78310841e-01\n\
          \ -1.60731792e-01  9.70282704e-02  1.07768685e-01 -3.01313937e-01]"
    num_agent_steps_sampled: 239000
    num_agent_steps_trained: 2856048
    num_steps_sampled: 239000
    num_steps_trained: 2856048
    num_target_updates: 473
  iterations_since_restore: 239
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.78947368421052
    ram_util_percent: 32.10526315789474
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3461.6097617149353
  time_this_iter_s: 12.880091905593872
  time_total_s: 3461.6097617149353
  timers:
    learn_throughput: 4788.554
    learn_time_ms: 10.024
    update_time_ms: 2.795
  timestamp: 1629284176
  timesteps_since_restore: 0
  timesteps_total: 239000
  training_iteration: 239
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    239 |          3461.61 | 239000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 240000
  custom_metrics: {}
  date: 2021-08-18_10-56-30
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 239896
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 14.658027648925781
          max_q: 7255133.5
          mean_q: 302297.625
          mean_td_error: 12.824789047241211
          min_q: 0.1848609447479248
        model: {}
        td_error: "[ 2.84207880e-01  1.91080138e-01  2.91864514e-01 -2.28956699e-01\n\
          \  3.07000000e+02 -2.23330259e-02  1.26666725e-02 -2.28184640e-01\n  1.24031737e-01\
          \  1.93576604e-01  1.64235577e-01  5.12016565e-02\n  2.20198154e-01 -8.40275884e-02\
          \  4.50105816e-02  2.44490862e-01\n -9.09599066e-02  3.98617387e-02  1.08168453e-01\
          \  1.82324052e-01\n -1.05379581e-01 -1.11119926e-01  1.52228460e-01  1.76014856e-01\n\
          \  2.56999463e-01  9.12088901e-02  9.20644104e-02 -4.21062827e-01\n -6.74620271e-02\
          \ -1.30721867e-01  1.95919454e-01 -2.87480235e-01\n -1.74409807e-01 -1.16928130e-01\
          \  1.44139588e-01  1.21721089e-01\n  1.44852459e-01  1.74339607e-01  9.78801250e-02\
          \  3.07000000e+02\n -1.00849485e+00  1.13890022e-01  2.76373714e-01  3.03338557e-01\n\
          \  4.08229470e-01  1.36233747e-01 -2.48919785e-01 -1.22024417e-01]"
    num_agent_steps_sampled: 240000
    num_agent_steps_trained: 2868048
    num_steps_sampled: 240000
    num_steps_trained: 2868048
    num_target_updates: 475
  iterations_since_restore: 240
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.999999999999986
    ram_util_percent: 32.105000000000004
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3475.059822320938
  time_this_iter_s: 13.450060606002808
  time_total_s: 3475.059822320938
  timers:
    learn_throughput: 4857.482
    learn_time_ms: 9.882
    update_time_ms: 2.921
  timestamp: 1629284190
  timesteps_since_restore: 0
  timesteps_total: 240000
  training_iteration: 240
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    240 |          3475.06 | 240000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 241000
  custom_metrics: {}
  date: 2021-08-18_10-56-44
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 240904
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 16.9578857421875
          max_q: 7254802.0
          mean_q: 453425.3125
          mean_td_error: -1.5679386854171753
          min_q: -0.04645884037017822
        model: {}
        td_error: "[-6.41661882e-02 -1.13758743e-01  7.26285428e-02 -1.37336284e-01\n\
          \ -1.06919125e-01 -1.36104822e-01 -1.40502036e-01 -2.17497349e-03\n -3.70939076e-02\
          \ -2.45000000e+01 -2.09661014e-02 -1.03609562e-02\n -4.86317277e-03 -2.13075757e-01\
          \  1.94275141e-01 -2.45000000e+01\n  1.57238528e-01 -9.80466008e-02  1.23289220e-01\
          \ -2.42762208e-01\n  5.54858446e-02 -3.40447426e-02 -1.54573798e-01  1.46485388e-01\n\
          \ -6.24585152e-03  1.12622261e-01 -1.52228862e-01 -2.45000000e+01\n -2.21338630e-01\
          \ -3.81104708e-01 -4.35383141e-01  5.24200201e-02\n  1.86186999e-01 -8.73426646e-02\
          \ -1.35962069e-01  9.52292681e-02\n -2.07266361e-01  7.00908601e-02  1.24057308e-01\
          \ -1.00864321e-02\n  2.35384032e-02  1.64187938e-01  2.06656009e-02 -3.92292440e-02\n\
          \  9.59392190e-02  4.48473543e-02 -9.53430533e-02 -2.11963058e-01]"
    num_agent_steps_sampled: 241000
    num_agent_steps_trained: 2880048
    num_steps_sampled: 241000
    num_steps_trained: 2880048
    num_target_updates: 477
  iterations_since_restore: 241
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.28
    ram_util_percent: 32.11000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3488.8955686092377
  time_this_iter_s: 13.83574628829956
  time_total_s: 3488.8955686092377
  timers:
    learn_throughput: 4822.737
    learn_time_ms: 9.953
    update_time_ms: 3.011
  timestamp: 1629284204
  timesteps_since_restore: 0
  timesteps_total: 241000
  training_iteration: 241
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    241 |           3488.9 | 241000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 242000
  custom_metrics: {}
  date: 2021-08-18_10-56-59
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 241912
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0724795013666153
          max_q: 0.9099193811416626
          mean_q: 0.1896064281463623
          mean_td_error: -0.07443136721849442
          min_q: -0.021152853965759277
        model: {}
        td_error: "[ 0.08014244  0.13651064 -0.0505043   0.23897448 -0.10861048  0.01658335\n\
          \  0.01321325 -0.05185464 -0.28630084 -0.10187221 -0.20951486 -0.43651733\n\
          \  0.00840992 -0.17145014  0.02041999  0.2925102  -0.5621354  -0.15168308\n\
          \ -0.17984326  0.09140143 -0.4178698  -0.38022545  0.10178398  0.09664016\n\
          \ -0.24593157 -0.09846792 -0.26099554  0.17990468 -0.02255765 -0.11619729\n\
          \ -0.2198624  -0.21692598 -0.04678349 -0.15591425  0.07840405 -0.04995245\n\
          \  0.02732734  0.16317526  0.07175361  0.11314453 -0.03051443 -0.32245904\n\
          \  0.14676419 -0.09584749 -0.01991285 -0.41237783 -0.22485614  0.19816913]"
    num_agent_steps_sampled: 242000
    num_agent_steps_trained: 2892048
    num_steps_sampled: 242000
    num_steps_trained: 2892048
    num_target_updates: 479
  iterations_since_restore: 242
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.45238095238095
    ram_util_percent: 32.104761904761915
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3503.456579685211
  time_this_iter_s: 14.56101107597351
  time_total_s: 3503.456579685211
  timers:
    learn_throughput: 4986.936
    learn_time_ms: 9.625
    update_time_ms: 2.81
  timestamp: 1629284219
  timesteps_since_restore: 0
  timesteps_total: 242000
  training_iteration: 242
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    242 |          3503.46 | 242000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 243000
  custom_metrics: {}
  date: 2021-08-18_10-57-15
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 242920
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02989184483885765
          max_q: 1.0393024682998657
          mean_q: 0.2293703556060791
          mean_td_error: 0.004261493682861328
          min_q: -0.0170285701751709
        model: {}
        td_error: "[-0.40118128 -0.20885345  0.17172146  0.23476294  0.06638747 -0.03366718\n\
          \ -0.33261037  0.41315264 -0.18321908  0.19401264 -0.09201571 -0.03064115\n\
          \  0.27797237 -0.19504184 -0.12113065  0.05857216  0.12817335  0.0970434\n\
          \ -0.0989846  -0.23927283  0.02025893 -0.23525685 -0.10701978  0.13222307\n\
          \ -0.32210895  0.21832849  0.10209315 -0.18872836  0.05080018  0.10011452\n\
          \  0.28896445 -0.13342565  0.01539947 -0.08507387 -0.14343682  0.19992575\n\
          \ -0.15997183  0.09036548  0.25767308 -0.12603611  0.21656843  0.1097444\n\
          \ -0.01042677 -0.22209257  0.40593985  0.12026621  0.06402907 -0.15974551]"
    num_agent_steps_sampled: 243000
    num_agent_steps_trained: 2904048
    num_steps_sampled: 243000
    num_steps_trained: 2904048
    num_target_updates: 481
  iterations_since_restore: 243
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.89545454545454
    ram_util_percent: 32.20000000000002
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3518.8333237171173
  time_this_iter_s: 15.376744031906128
  time_total_s: 3518.8333237171173
  timers:
    learn_throughput: 4647.6
    learn_time_ms: 10.328
    update_time_ms: 2.83
  timestamp: 1629284235
  timesteps_since_restore: 0
  timesteps_total: 243000
  training_iteration: 243
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    243 |          3518.83 | 243000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 244000
  custom_metrics: {}
  date: 2021-08-18_10-57-30
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 243928
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.022953448817133904
          max_q: 0.6165059208869934
          mean_q: 0.28990939259529114
          mean_td_error: 0.0013420486357063055
          min_q: 0.14339518547058105
        model: {}
        td_error: "[ 0.12917012  0.13105525 -0.11500138  0.14475581 -0.11709809  0.09660731\n\
          \ -0.2791862   0.05348957 -0.14713097  0.32672164 -0.2613355  -0.15125662\n\
          \  0.17619073  0.15896848 -0.06245944  0.12326311  0.00534347  0.17527722\n\
          \  0.08989991 -0.10828757 -0.3007896   0.23917262  0.07060285  0.09350234\n\
          \ -0.12512457 -0.07788119  0.01771103  0.09093896  0.14546116 -0.08756632\n\
          \ -0.0151806   0.03272367  0.2879597  -0.06919959 -0.07762149  0.12564743\n\
          \ -0.00517225  0.15173343 -0.19611412 -0.32090753 -0.36051154 -0.20073527\n\
          \  0.09652358  0.06197208 -0.1645692   0.22184446  0.08279997 -0.02178854]"
    num_agent_steps_sampled: 244000
    num_agent_steps_trained: 2916048
    num_steps_sampled: 244000
    num_steps_trained: 2916048
    num_target_updates: 483
  iterations_since_restore: 244
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.92173913043479
    ram_util_percent: 32.20869565217392
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3534.263166666031
  time_this_iter_s: 15.429842948913574
  time_total_s: 3534.263166666031
  timers:
    learn_throughput: 4819.55
    learn_time_ms: 9.959
    update_time_ms: 3.094
  timestamp: 1629284250
  timesteps_since_restore: 0
  timesteps_total: 244000
  training_iteration: 244
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    244 |          3534.26 | 244000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 245000
  custom_metrics: {}
  date: 2021-08-18_10-57-46
  done: false
  episode_len_mean: 8656.851851851852
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4298989.765623159
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 27
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 244936
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.021790647879242897
          max_q: 0.750864565372467
          mean_q: 0.24902141094207764
          mean_td_error: -0.00023382529616355896
          min_q: 0.08939790725708008
        model: {}
        td_error: "[-0.26907814 -0.12743968  0.01023261  0.09399053 -0.10880733  0.12471606\n\
          \ -0.39234203 -0.22176123  0.04564595  0.22363038  0.08918254  0.10471487\n\
          \ -0.18074197  0.1719586   0.2097336  -0.23506752 -0.15233672 -0.02671491\n\
          \ -0.13984388 -0.00209165  0.31599057 -0.1452024   0.05952418 -0.04808481\n\
          \ -0.5106594   0.08299147  0.08821689  0.23110259  0.03050849  0.12059939\n\
          \  0.15036866  0.41111243  0.16073658  0.44061    -0.23903751  0.06610441\n\
          \  0.00591233 -0.37158978 -0.23917863 -0.01426975  0.08359542 -0.03790715\n\
          \  0.2465514  -0.0066756   0.18270026  0.05777389 -0.18054003 -0.17005771]"
    num_agent_steps_sampled: 245000
    num_agent_steps_trained: 2928048
    num_steps_sampled: 245000
    num_steps_trained: 2928048
    num_target_updates: 485
  iterations_since_restore: 245
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.01739130434783
    ram_util_percent: 32.20000000000002
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924717823734609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.412578991941702
    mean_inference_ms: 1.5860928748045355
    mean_raw_obs_processing_ms: 0.1437112466439372
  time_since_restore: 3550.149906873703
  time_this_iter_s: 15.88674020767212
  time_total_s: 3550.149906873703
  timers:
    learn_throughput: 4840.873
    learn_time_ms: 9.916
    update_time_ms: 2.95
  timestamp: 1629284266
  timesteps_since_restore: 0
  timesteps_total: 245000
  training_iteration: 245
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    245 |          3550.15 | 245000 | 4.29899e+06 |          7.25484e+06 |             -198.044 |            8656.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 246000
  custom_metrics: {}
  date: 2021-08-18_10-58-02
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 245944
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06436782330274582
          max_q: 1.0508196353912354
          mean_q: 0.2715909779071808
          mean_td_error: 0.06612785905599594
          min_q: 0.08241719007492065
        model: {}
        td_error: "[ 0.23964399 -0.18940783 -0.04910205 -0.22796923  0.01219139  0.643993\n\
          \  0.03136897  0.20040408  0.21527237 -0.06816381  0.02325691 -0.054407\n\
          \  0.21086735  0.07112139 -0.17338425  0.19582899  0.15869129  0.1738606\n\
          \ -0.12403741 -0.10390818 -0.12587708  0.10938875  0.11048763 -0.24526852\n\
          \  0.11349092 -0.21987084 -0.15559998 -0.3581962   0.18745947  0.3760643\n\
          \ -0.12934464  0.19321321  0.2498063   0.20221348 -0.41629177  0.1942751\n\
          \  0.22639889  0.18326753  0.26010904  0.3001773   0.12201895 -0.1347754\n\
          \  0.04268245  0.34284538 -0.05886123 -0.00515807  0.14498912  0.4783725 ]"
    num_agent_steps_sampled: 246000
    num_agent_steps_trained: 2940048
    num_steps_sampled: 246000
    num_steps_trained: 2940048
    num_target_updates: 487
  iterations_since_restore: 246
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.1
    ram_util_percent: 32.27272727272727
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3565.1990461349487
  time_this_iter_s: 15.049139261245728
  time_total_s: 3565.1990461349487
  timers:
    learn_throughput: 5119.167
    learn_time_ms: 9.377
    update_time_ms: 2.592
  timestamp: 1629284282
  timesteps_since_restore: 0
  timesteps_total: 246000
  training_iteration: 246
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    246 |           3565.2 | 246000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 247000
  custom_metrics: {}
  date: 2021-08-18_10-58-13
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 246952
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10765235871076584
          max_q: 1.1221776008605957
          mean_q: 0.1406756490468979
          mean_td_error: 0.1056150421500206
          min_q: -0.053414881229400635
        model: {}
        td_error: "[ 0.3250587   0.13562894  0.54286635  0.19538045  0.33496076  0.26249784\n\
          \ -0.3864665   0.04876658  0.29871532 -0.06322992  0.2907189   0.05983677\n\
          \ -0.12866627 -0.03062731  0.13078001  0.28495276  0.31634882  0.0651826\n\
          \ -0.02035213  0.43443665  0.15959361 -0.06111801  0.25768262  0.19624686\n\
          \  0.08447732 -0.08369869 -0.1915428   0.01521638 -0.13196689  0.01018697\n\
          \  0.1743581   0.09164178 -0.21127728  0.4373405   0.29245305 -0.26739204\n\
          \  0.27674466  0.2662912  -0.22044957  0.10301769 -0.11171122  0.12403271\n\
          \  0.17205073  0.41491145 -0.06882077  0.12480563  0.1401695  -0.02051082]"
    num_agent_steps_sampled: 247000
    num_agent_steps_trained: 2952048
    num_steps_sampled: 247000
    num_steps_trained: 2952048
    num_target_updates: 489
  iterations_since_restore: 247
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.599999999999994
    ram_util_percent: 32.199999999999996
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3575.8400785923004
  time_this_iter_s: 10.641032457351685
  time_total_s: 3575.8400785923004
  timers:
    learn_throughput: 4904.555
    learn_time_ms: 9.787
    update_time_ms: 2.629
  timestamp: 1629284293
  timesteps_since_restore: 0
  timesteps_total: 247000
  training_iteration: 247
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    247 |          3575.84 | 247000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 248000
  custom_metrics: {}
  date: 2021-08-18_10-58-25
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 247960
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0474664568901062
          max_q: 0.5733519196510315
          mean_q: 0.2530016005039215
          mean_td_error: 0.03952696546912193
          min_q: 0.06435942649841309
        model: {}
        td_error: "[-0.01082548 -0.38455385  0.09017389 -0.01119275 -0.00075001  0.06512718\n\
          \ -0.2987045   0.23201837 -0.25547004  0.28086266 -0.03403281  0.05095027\n\
          \  0.05288804  0.10680947  0.15373966  0.16436055 -0.2842471   0.14385977\n\
          \ -0.1938822   0.22937626 -0.07921252  0.12605803  0.23788993 -0.07690841\n\
          \ -0.49546748  0.22527306  0.0028885   0.57808375 -0.05671515  0.252696\n\
          \  0.29109502 -0.06135267  0.2351009  -0.0898928   0.2113546  -0.0356289\n\
          \  0.07758898  0.05893393  0.02001622  0.02954369  0.18638645  0.20459485\n\
          \  0.1781328  -0.21458656 -0.29130334  0.14756502 -0.18340772  0.32206073]"
    num_agent_steps_sampled: 248000
    num_agent_steps_trained: 2964048
    num_steps_sampled: 248000
    num_steps_trained: 2964048
    num_target_updates: 491
  iterations_since_restore: 248
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.45555555555555
    ram_util_percent: 32.20555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3588.1289694309235
  time_this_iter_s: 12.288890838623047
  time_total_s: 3588.1289694309235
  timers:
    learn_throughput: 4727.23
    learn_time_ms: 10.154
    update_time_ms: 3.028
  timestamp: 1629284305
  timesteps_since_restore: 0
  timesteps_total: 248000
  training_iteration: 248
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    248 |          3588.13 | 248000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 249000
  custom_metrics: {}
  date: 2021-08-18_10-58-37
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 248968
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07236875593662262
          max_q: 0.7508010864257812
          mean_q: 0.15021225810050964
          mean_td_error: -0.05913744121789932
          min_q: -0.058302462100982666
        model: {}
        td_error: "[-1.83906913e-01 -6.00857288e-02  1.54332370e-02  1.17266499e-01\n\
          \  1.18241861e-01  1.25301212e-01  1.71915531e-01 -1.20211691e-01\n  2.29804069e-01\
          \ -1.82219386e-01 -2.08993539e-01  1.60466194e-01\n  1.89266026e-01 -2.19451338e-01\
          \  1.47004992e-01 -2.36542523e-01\n -1.18107125e-01 -1.44453585e-01 -8.37180912e-02\
          \ -2.13908225e-01\n -2.71466434e-01  1.29748374e-01 -8.33583623e-02 -1.29023761e-01\n\
          \ -1.32524312e-01 -1.93747103e-01  1.00632489e-01 -1.95445776e-01\n -2.10905761e-01\
          \ -3.30284238e-05 -2.39767134e-01 -4.56829011e-01\n -1.21477097e-02 -3.50513875e-01\
          \  9.47354287e-02 -2.88420618e-02\n  2.53255427e-01  7.84147084e-02 -1.05469912e-01\
          \ -1.45071596e-01\n -3.27565670e-01  1.49345398e-02  3.32520962e-01 -4.56829011e-01\n\
          \  9.80822444e-02  3.11982334e-02  1.56643540e-01 -2.92323709e-01]"
    num_agent_steps_sampled: 249000
    num_agent_steps_trained: 2976048
    num_steps_sampled: 249000
    num_steps_trained: 2976048
    num_target_updates: 493
  iterations_since_restore: 249
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.905882352941184
    ram_util_percent: 32.20588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3599.876847743988
  time_this_iter_s: 11.747878313064575
  time_total_s: 3599.876847743988
  timers:
    learn_throughput: 4488.797
    learn_time_ms: 10.693
    update_time_ms: 2.834
  timestamp: 1629284317
  timesteps_since_restore: 0
  timesteps_total: 249000
  training_iteration: 249
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    249 |          3599.88 | 249000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 250000
  custom_metrics: {}
  date: 2021-08-18_10-58-49
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 249976
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06931314617395401
          max_q: 0.42791277170181274
          mean_q: 0.17370492219924927
          mean_td_error: 0.061381082981824875
          min_q: 0.03185361623764038
        model: {}
        td_error: "[-0.08892418  0.37503922  0.1734616  -0.03044733  0.08298242 -0.06339914\n\
          \  0.18987203 -0.05806738 -0.05788967  0.05355456  0.1519687  -0.04895101\n\
          \  0.18927416  0.04622994  0.03302383  0.02346826  0.00232014 -0.01618773\n\
          \ -0.12880832  0.24536751  0.06786662  0.18363163  0.16661522 -0.09842262\n\
          \ -0.08922312  0.23683359 -0.0206407  -0.07712644  0.15256643  0.2747748\n\
          \  0.29516864  0.33501494 -0.02381837 -0.07916138  0.17336364 -0.37094396\n\
          \  0.0352696   0.03679495  0.17778814  0.04355305 -0.40082592  0.03665057\n\
          \  0.24076529  0.2234773  -0.10471974  0.05929571  0.2582907   0.1395659 ]"
    num_agent_steps_sampled: 250000
    num_agent_steps_trained: 2988048
    num_steps_sampled: 250000
    num_steps_trained: 2988048
    num_target_updates: 495
  iterations_since_restore: 250
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.876470588235286
    ram_util_percent: 32.2
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3611.632977962494
  time_this_iter_s: 11.75613021850586
  time_total_s: 3611.632977962494
  timers:
    learn_throughput: 4977.036
    learn_time_ms: 9.644
    update_time_ms: 2.854
  timestamp: 1629284329
  timesteps_since_restore: 0
  timesteps_total: 250000
  training_iteration: 250
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    250 |          3611.63 | 250000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 251000
  custom_metrics: {}
  date: 2021-08-18_10-59-03
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 250984
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04066300392150879
          max_q: 0.7249172925949097
          mean_q: 0.10813431441783905
          mean_td_error: -0.03867385536432266
          min_q: -0.046826064586639404
        model: {}
        td_error: "[-0.05941319 -0.2685305  -0.39493436  0.0298769   0.17065778 -0.11557975\n\
          \  0.087658   -0.15669847 -0.0664943  -0.19644901 -0.0667837  -0.26101995\n\
          \ -0.28027803  0.1588812   0.03885496 -0.04786086 -0.02512372  0.17139557\n\
          \ -0.14713234 -0.08489107  0.20869218 -0.23309273 -0.17914505  0.05281605\n\
          \ -0.00767206  0.15075287  0.00079614 -0.12973714  0.08988599 -0.15497702\n\
          \  0.04270149  0.03489326  0.2096029  -0.00587231 -0.03919996 -0.24637252\n\
          \  0.20177966 -0.16925333  0.10703565 -0.05800419 -0.22518897  0.00872037\n\
          \  0.03885703 -0.0749962   0.26295942 -0.25937477  0.09962176 -0.06870879]"
    num_agent_steps_sampled: 251000
    num_agent_steps_trained: 3000048
    num_steps_sampled: 251000
    num_steps_trained: 3000048
    num_target_updates: 497
  iterations_since_restore: 251
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.38421052631578
    ram_util_percent: 32.20526315789475
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3624.7205736637115
  time_this_iter_s: 13.087595701217651
  time_total_s: 3624.7205736637115
  timers:
    learn_throughput: 5000.822
    learn_time_ms: 9.598
    update_time_ms: 2.847
  timestamp: 1629284343
  timesteps_since_restore: 0
  timesteps_total: 251000
  training_iteration: 251
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    251 |          3624.72 | 251000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 252000
  custom_metrics: {}
  date: 2021-08-18_10-59-16
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 251992
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04369410127401352
          max_q: 0.740200936794281
          mean_q: 0.15513759851455688
          mean_td_error: -0.04321512579917908
          min_q: -0.06362640857696533
        model: {}
        td_error: "[ 0.06880082  0.34813058 -0.18152644 -0.5740441  -0.08535662  0.02208535\n\
          \  0.21923026  0.20242728 -0.18640113 -0.18227625 -0.60806805 -0.2651529\n\
          \  0.32038653 -0.06527847  0.00420378 -0.41216975 -0.2217477  -0.2246232\n\
          \ -0.06783099 -0.20250595  0.13782422  0.18327239  0.05690257 -0.01854271\n\
          \ -0.20636207  0.03815395 -0.07751679 -0.08127095  0.17796555  0.23862302\n\
          \ -0.5465314  -0.05111584 -0.06795388  0.09869022 -0.13191196 -0.31538653\n\
          \  0.09107621 -0.06106784  0.09932519 -0.2681135   0.18513499  0.04863856\n\
          \ -0.02170076  0.09626608  0.15791948  0.18231103  0.12369108 -0.05092943]"
    num_agent_steps_sampled: 252000
    num_agent_steps_trained: 3012048
    num_steps_sampled: 252000
    num_steps_trained: 3012048
    num_target_updates: 499
  iterations_since_restore: 252
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.095000000000006
    ram_util_percent: 32.20500000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3638.1588456630707
  time_this_iter_s: 13.43827199935913
  time_total_s: 3638.1588456630707
  timers:
    learn_throughput: 4981.063
    learn_time_ms: 9.636
    update_time_ms: 2.967
  timestamp: 1629284356
  timesteps_since_restore: 0
  timesteps_total: 252000
  training_iteration: 252
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    252 |          3638.16 | 252000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 253000
  custom_metrics: {}
  date: 2021-08-18_10-59-30
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 253000
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.030022501945495605
          max_q: 0.6958115100860596
          mean_q: 0.18001127243041992
          mean_td_error: -0.013034079223871231
          min_q: -0.011874794960021973
        model: {}
        td_error: "[ 0.1153526   0.1754407  -0.01560708 -0.24614567 -0.2446095  -0.1403366\n\
          \ -0.26584014  0.20246495 -0.09410638 -1.0640634   0.22013903  0.14897604\n\
          \  0.04165883  0.24648245  0.15092093  0.31537953 -0.16509986  0.25142577\n\
          \  0.12359871  0.01972341 -0.17067721 -0.11311121 -0.2363481   0.12218235\n\
          \  0.09545539  0.10279825 -0.2485897  -0.2162947   0.30374286  0.06251006\n\
          \ -0.20151907 -0.3909465  -0.09775519 -0.03516    -0.13990974  0.10546856\n\
          \ -0.08089551 -0.01900518 -0.10937434  0.10433277  0.162952    0.1524825\n\
          \ -0.00114697  0.16077892 -0.06725074 -0.19197585  0.36922824  0.1766381 ]"
    num_agent_steps_sampled: 253000
    num_agent_steps_trained: 3024048
    num_steps_sampled: 253000
    num_steps_trained: 3024048
    num_target_updates: 501
  iterations_since_restore: 253
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.78947368421051
    ram_util_percent: 32.20526315789474
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3651.3879539966583
  time_this_iter_s: 13.229108333587646
  time_total_s: 3651.3879539966583
  timers:
    learn_throughput: 4778.563
    learn_time_ms: 10.045
    update_time_ms: 2.798
  timestamp: 1629284370
  timesteps_since_restore: 0
  timesteps_total: 253000
  training_iteration: 253
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    253 |          3651.39 | 253000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 254000
  custom_metrics: {}
  date: 2021-08-18_10-59-44
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 253504
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02918255515396595
          max_q: 0.8359360098838806
          mean_q: 0.11650492250919342
          mean_td_error: -0.01197037659585476
          min_q: -0.10369604825973511
        model: {}
        td_error: "[ 0.08683511  0.2469086  -0.02073918 -0.2367233   0.1081692  -0.23054472\n\
          \  0.09271765  0.2337318  -0.2043072  -0.10883111 -0.02141786 -0.04772495\n\
          \  0.07553883 -0.09924977  0.03410313  0.2181257  -0.40743893 -0.08074091\n\
          \  0.15076256  0.01557457  0.16827124  0.05347189  0.18240532 -0.07270676\n\
          \ -0.683138   -0.47056133  0.16524641  0.1350775  -0.18199319  0.32951462\n\
          \ -0.12946904  0.21714008 -0.04584338  0.17227446 -0.18199319 -0.18322554\n\
          \ -0.08762775 -0.29119977  0.044842    0.16776185  0.03915712  0.00680476\n\
          \  0.19446488 -0.08736029  0.15044516  0.06242254 -0.32634845  0.27283967]"
    num_agent_steps_sampled: 254000
    num_agent_steps_trained: 3036048
    num_steps_sampled: 254000
    num_steps_trained: 3036048
    num_target_updates: 502
  iterations_since_restore: 254
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.065
    ram_util_percent: 32.20500000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3665.325841665268
  time_this_iter_s: 13.93788766860962
  time_total_s: 3665.325841665268
  timers:
    learn_throughput: 4745.236
    learn_time_ms: 10.115
    update_time_ms: 2.809
  timestamp: 1629284384
  timesteps_since_restore: 0
  timesteps_total: 254000
  training_iteration: 254
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    254 |          3665.33 | 254000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 255000
  custom_metrics: {}
  date: 2021-08-18_10-59-58
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 254512
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.09455975890159607
          max_q: 0.919387698173523
          mean_q: 0.17218002676963806
          mean_td_error: 0.07167892903089523
          min_q: -0.06898778676986694
        model: {}
        td_error: "[ 0.26003113  0.01413205 -0.12163714  0.23515661  0.14714378  0.26421028\n\
          \ -0.22137266  0.2483021   0.16512236  0.03033022  0.22679344  0.22089785\n\
          \  0.33595368  0.15316808  0.16755764  0.24724355  0.29744655 -0.31245977\n\
          \ -0.17873585  0.24087402  0.3403012   0.06190757  0.23896796  0.2469381\n\
          \  0.13555963  0.02498127 -0.08865853  0.19489928  0.00187056  0.20166549\n\
          \  0.27472752  0.17828771  0.30819285  0.16546509 -0.24759674 -0.09000524\n\
          \ -0.34042722  0.2626474  -0.3531807  -0.3225798   0.07701808  0.21091238\n\
          \ -0.28406423 -0.05100907 -0.4726997   0.05383322  0.12633891  0.16613752]"
    num_agent_steps_sampled: 255000
    num_agent_steps_trained: 3048048
    num_steps_sampled: 255000
    num_steps_trained: 3048048
    num_target_updates: 504
  iterations_since_restore: 255
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.73809523809524
    ram_util_percent: 32.23809523809523
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3679.16162109375
  time_this_iter_s: 13.835779428482056
  time_total_s: 3679.16162109375
  timers:
    learn_throughput: 4884.375
    learn_time_ms: 9.827
    update_time_ms: 2.867
  timestamp: 1629284398
  timesteps_since_restore: 0
  timesteps_total: 255000
  training_iteration: 255
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    255 |          3679.16 | 255000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 256000
  custom_metrics: {}
  date: 2021-08-18_11-00-14
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 255520
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06968729197978973
          max_q: 0.9535918235778809
          mean_q: 0.17822353541851044
          mean_td_error: 0.05658312141895294
          min_q: -0.08297258615493774
        model: {}
        td_error: "[-0.1864407   0.3672575   0.14288226 -0.06418175 -0.02599458 -0.3027287\n\
          \ -0.00963009 -0.05248058  0.27195007 -0.03588516  0.06924974  0.16163605\n\
          \ -0.06232624 -0.10605723 -0.13024156  0.00468829  0.2774155  -0.01314925\n\
          \  0.14416392 -0.10311401  0.13178778  0.05201437 -0.06713256  0.06310432\n\
          \  0.03790811  0.13998552  0.42176256  0.0968228   0.23140135 -0.13392892\n\
          \  0.026972    0.19135416  0.2142713  -0.00084396  0.23466441 -0.3459803\n\
          \ -0.02497641  0.12794691  0.36594552  0.13151081 -0.43962014  0.31626475\n\
          \  0.06354728 -0.05753155 -0.16283631  0.28210145  0.06280863  0.40965247]"
    num_agent_steps_sampled: 256000
    num_agent_steps_trained: 3060048
    num_steps_sampled: 256000
    num_steps_trained: 3060048
    num_target_updates: 506
  iterations_since_restore: 256
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.24285714285715
    ram_util_percent: 32.309523809523796
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3694.2081944942474
  time_this_iter_s: 15.046573400497437
  time_total_s: 3694.2081944942474
  timers:
    learn_throughput: 4899.292
    learn_time_ms: 9.797
    update_time_ms: 2.934
  timestamp: 1629284414
  timesteps_since_restore: 0
  timesteps_total: 256000
  training_iteration: 256
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    256 |          3694.21 | 256000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 257000
  custom_metrics: {}
  date: 2021-08-18_11-00-28
  done: false
  episode_len_mean: 8776.392857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4404551.645403624
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 256528
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.026990661397576332
          max_q: 0.5563015937805176
          mean_q: 0.05837059020996094
          mean_td_error: 0.011471513658761978
          min_q: -0.12755721807479858
        model: {}
        td_error: "[ 0.01295871 -0.13487026  0.12966427  0.01137675 -0.41580844 -0.21864744\n\
          \  0.21987519  0.08677229 -0.07459687 -0.10701698 -0.06700267  0.21242175\n\
          \  0.06570775  0.35738117  0.07410747 -0.0818464  -0.09305014  0.04473339\n\
          \  0.05479841 -0.16944161 -0.05947673 -0.06194949  0.13236573 -0.24422789\n\
          \ -0.0264865   0.4292525   0.05517107 -0.03510959 -0.10641477  0.00457299\n\
          \  0.06467898  0.23201366 -0.10616759  0.18641981 -0.07858534  0.16207694\n\
          \ -0.1415475   0.1197861   0.28935564 -0.10896873 -0.15349367 -0.06328483\n\
          \  0.11952308 -0.17306    -0.01798986 -0.06787595  0.09409787  0.1984404 ]"
    num_agent_steps_sampled: 257000
    num_agent_steps_trained: 3072048
    num_steps_sampled: 257000
    num_steps_trained: 3072048
    num_target_updates: 508
  iterations_since_restore: 257
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.43333333333333
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924937847127
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.462822742604908
    mean_inference_ms: 1.586313825829245
    mean_raw_obs_processing_ms: 0.14377090742127993
  time_since_restore: 3708.560380220413
  time_this_iter_s: 14.352185726165771
  time_total_s: 3708.560380220413
  timers:
    learn_throughput: 4858.361
    learn_time_ms: 9.88
    update_time_ms: 3.256
  timestamp: 1629284428
  timesteps_since_restore: 0
  timesteps_total: 257000
  training_iteration: 257
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    257 |          3708.56 | 257000 | 4.40455e+06 |          7.25484e+06 |             -198.044 |            8776.39 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 258000
  custom_metrics: {}
  date: 2021-08-18_11-00-43
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 257536
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08058343827724457
          max_q: 0.7432686686515808
          mean_q: 0.021289829164743423
          mean_td_error: -0.07767286896705627
          min_q: -0.22877347469329834
        model: {}
        td_error: "[-0.11463936 -0.02790668  0.07224763 -0.46456057  0.12010992 -0.17553589\n\
          \ -0.2077991   0.00840112 -0.07171588  0.00759671 -0.23582527  0.20548195\n\
          \ -0.6661496  -0.23095638 -0.16019353 -0.01784277 -0.15491521 -0.30182528\n\
          \  0.07250959  0.1221368  -0.0055567   0.20213044 -0.02423739 -0.08993915\n\
          \  0.17685989  0.02427533 -0.13853842 -0.2765107  -0.17576662 -0.15955734\n\
          \ -0.62677246  0.45285913  0.17380816 -0.12471458 -0.022026    0.05355006\n\
          \ -0.13902612 -0.01285314  0.06110555  0.3158908   0.07203142 -0.25300932\n\
          \  0.02743584  0.1118962   0.01928064  0.13398746 -0.31023216 -0.9732865 ]"
    num_agent_steps_sampled: 258000
    num_agent_steps_trained: 3084048
    num_steps_sampled: 258000
    num_steps_trained: 3084048
    num_target_updates: 510
  iterations_since_restore: 258
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.85238095238095
    ram_util_percent: 32.30476190476189
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3723.1443223953247
  time_this_iter_s: 14.583942174911499
  time_total_s: 3723.1443223953247
  timers:
    learn_throughput: 4754.953
    learn_time_ms: 10.095
    update_time_ms: 2.797
  timestamp: 1629284443
  timesteps_since_restore: 0
  timesteps_total: 258000
  training_iteration: 258
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    258 |          3723.14 | 258000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 259000
  custom_metrics: {}
  date: 2021-08-18_11-00-55
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 258544
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06440317630767822
          max_q: 0.5180552005767822
          mean_q: -0.03196340054273605
          mean_td_error: -0.07112811505794525
          min_q: -0.2410333752632141
        model: {}
        td_error: "[ 0.18095297 -0.4274962  -0.07038036  0.03397466  0.08268912 -0.1840022\n\
          \  0.0833343   0.20152694  0.229469   -0.0079373  -0.08923651  0.0062861\n\
          \ -0.21708843  0.14771989  0.24627747  0.03676564  0.35631275  0.29865444\n\
          \  0.03099756 -0.26892573 -0.21333107 -0.4402238  -0.9798779   0.19263446\n\
          \ -0.12860858 -0.03512166 -0.06168313 -0.18806611  0.12731093 -0.15439655\n\
          \ -0.4494392  -0.17600065  0.09785187  0.26507753 -0.13782993 -0.27058873\n\
          \ -0.25252885  0.14484693 -0.21756667 -0.42446515  0.18533039  0.13059947\n\
          \  0.10744584  0.04183795 -0.37775406 -0.26708955 -0.3724779  -0.22992954]"
    num_agent_steps_sampled: 259000
    num_agent_steps_trained: 3096048
    num_steps_sampled: 259000
    num_steps_trained: 3096048
    num_target_updates: 512
  iterations_since_restore: 259
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.970588235294116
    ram_util_percent: 32.25294117647059
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3734.4017481803894
  time_this_iter_s: 11.257425785064697
  time_total_s: 3734.4017481803894
  timers:
    learn_throughput: 4865.394
    learn_time_ms: 9.866
    update_time_ms: 2.825
  timestamp: 1629284455
  timesteps_since_restore: 0
  timesteps_total: 259000
  training_iteration: 259
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    259 |           3734.4 | 259000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 260000
  custom_metrics: {}
  date: 2021-08-18_11-01-06
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 259552
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05194149166345596
          max_q: 1.014168620109558
          mean_q: -0.06825990974903107
          mean_td_error: 0.04729412496089935
          min_q: -0.3533167839050293
        model: {}
        td_error: "[ 0.40706563 -0.07996559  0.09195931  0.09763631 -0.29819375  0.19171119\n\
          \ -0.19709224 -0.45348832  0.37601236 -0.22871327  0.15128937  0.24484831\n\
          \ -0.05841237  0.15731937  0.09535982  0.12692305  0.02252556  0.6291616\n\
          \ -0.07237576 -0.1115505   0.14000076 -0.09571704 -0.06712009 -0.05793661\n\
          \ -0.06971079  0.5075591   0.24595639  0.36150903  0.17184418  0.3662886\n\
          \ -0.2097876   0.20991254 -0.05859713  0.15251207 -0.22664142  0.0280525\n\
          \ -0.04524523  0.04202807 -0.01269925 -0.35112202  0.07796195  0.2353814\n\
          \  0.14566979  0.22925043  0.15107039 -0.7794915   0.12344998 -0.03628036]"
    num_agent_steps_sampled: 260000
    num_agent_steps_trained: 3108048
    num_steps_sampled: 260000
    num_steps_trained: 3108048
    num_target_updates: 514
  iterations_since_restore: 260
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.150000000000006
    ram_util_percent: 32.2
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3745.751399040222
  time_this_iter_s: 11.349650859832764
  time_total_s: 3745.751399040222
  timers:
    learn_throughput: 4895.67
    learn_time_ms: 9.805
    update_time_ms: 2.68
  timestamp: 1629284466
  timesteps_since_restore: 0
  timesteps_total: 260000
  training_iteration: 260
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    260 |          3745.75 | 260000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 261000
  custom_metrics: {}
  date: 2021-08-18_11-01-19
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 260560
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.036080118268728256
          max_q: 0.47888004779815674
          mean_q: -0.12697476148605347
          mean_td_error: -0.015499912202358246
          min_q: -0.34052133560180664
        model: {}
        td_error: "[ 0.13687542  0.17616439 -0.3267378  -0.05024609  0.23641726  0.15777764\n\
          \  0.20747784  0.20177303  0.12575611 -0.11365432  0.04186039 -0.1604403\n\
          \ -0.40724403 -0.31683663 -0.21298838  0.14367509  0.04242152  0.01903905\n\
          \  0.08836073 -0.09050423 -0.29696536  0.05476043 -0.27479827  0.02707213\n\
          \ -0.11057131 -0.57440066  0.03772622 -0.07684934  0.02764243 -0.13623405\n\
          \ -0.36698532  0.10475808  0.10054624 -0.08649395  0.18917003  0.1886405\n\
          \  0.03462836  0.23182732  0.17292506  0.07164523  0.16483235  0.25873035\n\
          \ -0.4495105  -0.06722847  0.18630826  0.03277737 -0.20286994  0.11597431]"
    num_agent_steps_sampled: 261000
    num_agent_steps_trained: 3120048
    num_steps_sampled: 261000
    num_steps_trained: 3120048
    num_target_updates: 516
  iterations_since_restore: 261
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.58333333333334
    ram_util_percent: 32.21666666666667
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3757.962364912033
  time_this_iter_s: 12.210965871810913
  time_total_s: 3757.962364912033
  timers:
    learn_throughput: 4261.89
    learn_time_ms: 11.263
    update_time_ms: 3.137
  timestamp: 1629284479
  timesteps_since_restore: 0
  timesteps_total: 261000
  training_iteration: 261
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    261 |          3757.96 | 261000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 262000
  custom_metrics: {}
  date: 2021-08-18_11-01-31
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 261568
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0497271753847599
          max_q: 0.9096375107765198
          mean_q: 0.07241636514663696
          mean_td_error: 0.03856385126709938
          min_q: -0.20328885316848755
        model: {}
        td_error: "[-0.09819632  0.02826428  0.02917881  0.3327417  -0.28772634  0.07130885\n\
          \  0.18038902  0.44917426  0.26984632 -0.2201865  -0.03104967  0.1345559\n\
          \  0.16892436  0.26453125  0.21325245  0.01538695 -0.13682914 -0.09859849\n\
          \ -0.0740291  -0.02024822 -0.05087535  0.3655644   0.1607779   0.20543493\n\
          \  0.2405935  -0.59560305 -0.03899007  0.06080189 -0.04050232 -0.00169633\n\
          \ -0.04134319  0.31079933 -0.05166645  0.00098795  0.09316152  0.10570312\n\
          \ -0.166704    0.05310068  0.18067166 -0.16175617  0.4099774  -0.14829004\n\
          \ -0.35395086 -0.18510959  0.15338612  0.24392132 -0.30299026  0.21497038]"
    num_agent_steps_sampled: 262000
    num_agent_steps_trained: 3132048
    num_steps_sampled: 262000
    num_steps_trained: 3132048
    num_target_updates: 518
  iterations_since_restore: 262
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.32222222222222
    ram_util_percent: 32.20000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3770.17276763916
  time_this_iter_s: 12.210402727127075
  time_total_s: 3770.17276763916
  timers:
    learn_throughput: 4980.508
    learn_time_ms: 9.638
    update_time_ms: 2.708
  timestamp: 1629284491
  timesteps_since_restore: 0
  timesteps_total: 262000
  training_iteration: 262
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    262 |          3770.17 | 262000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 263000
  custom_metrics: {}
  date: 2021-08-18_11-01-44
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 262576
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 10.854104042053223
          max_q: 7254741.0
          mean_q: 151140.46875
          mean_td_error: -1.838331937789917
          min_q: -0.2827543616294861
        model: {}
        td_error: "[-2.6429248e-01  4.3453731e-02 -5.2332461e-01  2.8573713e-01\n  2.6277450e-01\
          \ -2.4934730e-01  1.2650639e-02 -5.1859558e-02\n  2.8230211e-01  2.2839987e-01\
          \  8.2866192e-02  1.1326498e-01\n  6.7262486e-02 -1.8183815e-01  3.0486870e-01\
          \ -2.8283149e-02\n  1.9395600e-01  1.1147307e-01 -6.6361830e-02  1.9811672e-01\n\
          \  3.3615416e-01 -1.3670751e-01  6.6326112e-03  2.6288360e-01\n -1.5709813e-01\
          \ -1.0152235e-01  2.8085649e-01  1.5819168e-01\n -3.1112412e-01  2.4597377e-01\
          \ -1.4489187e-01 -4.2096788e-01\n -8.8414347e-01  3.9505869e-02  2.8655935e-02\
          \  2.0805192e-01\n  9.6049234e-02  1.2056421e-01  1.2005338e-01 -1.3684100e-01\n\
          \ -2.8903779e-01 -9.1452593e-01  4.2398989e-02 -2.5773880e-01\n -8.7000000e+01\
          \ -1.5013847e-01  9.3429774e-02 -1.9641480e-01]"
    num_agent_steps_sampled: 263000
    num_agent_steps_trained: 3144048
    num_steps_sampled: 263000
    num_steps_trained: 3144048
    num_target_updates: 520
  iterations_since_restore: 263
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.93684210526315
    ram_util_percent: 32.26842105263158
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3782.975224494934
  time_this_iter_s: 12.802456855773926
  time_total_s: 3782.975224494934
  timers:
    learn_throughput: 4872.164
    learn_time_ms: 9.852
    update_time_ms: 2.804
  timestamp: 1629284504
  timesteps_since_restore: 0
  timesteps_total: 263000
  training_iteration: 263
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    263 |          3782.98 | 263000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 264000
  custom_metrics: {}
  date: 2021-08-18_11-01-58
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 263584
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.705413818359375
          max_q: 7254836.0
          mean_q: 151142.34375
          mean_td_error: 0.07623271644115448
          min_q: -0.3323709964752197
        model: {}
        td_error: "[-1.14250076e+00 -1.36522457e-01 -9.18333888e-01 -1.16087794e-01\n\
          \ -1.65542901e-01 -2.78013408e-01 -9.75865722e-02 -9.53596175e-01\n -1.69101864e-01\
          \  1.82312652e-01  8.00000000e+00 -5.39960712e-02\n  5.43544590e-02 -6.82470948e-02\
          \ -2.87353158e-01  4.37215716e-02\n  9.34904665e-02 -4.99241501e-02 -1.39607668e-01\
          \ -1.90123916e-02\n -2.40982234e-01  6.15727752e-02  4.70621735e-02 -1.33508801e-01\n\
          \  1.58336967e-01 -1.48119062e-01 -1.54142827e-01  2.56577373e-01\n -1.46577060e-02\
          \ -1.54440105e-02  1.06989875e-01 -2.42013931e-02\n  1.39309973e-01  2.10337952e-01\
          \ -7.30911642e-03  1.18392199e-01\n  7.22051412e-02  7.22584724e-02 -2.81683236e-01\
          \  1.64649338e-02\n -1.82851851e-01  1.34961545e-01  8.85450244e-02  3.86416167e-03\n\
          \  6.94571435e-03 -1.79741398e-01  8.29665065e-02 -3.13431203e-01]"
    num_agent_steps_sampled: 264000
    num_agent_steps_trained: 3156048
    num_steps_sampled: 264000
    num_steps_trained: 3156048
    num_target_updates: 522
  iterations_since_restore: 264
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.2578947368421
    ram_util_percent: 32.28947368421051
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3796.1309382915497
  time_this_iter_s: 13.1557137966156
  time_total_s: 3796.1309382915497
  timers:
    learn_throughput: 5014.985
    learn_time_ms: 9.571
    update_time_ms: 2.789
  timestamp: 1629284518
  timesteps_since_restore: 0
  timesteps_total: 264000
  training_iteration: 264
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    264 |          3796.13 | 264000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 265000
  custom_metrics: {}
  date: 2021-08-18_11-02-12
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 264592
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08377544581890106
          max_q: 0.7547013163566589
          mean_q: -0.013695690780878067
          mean_td_error: 0.0716530904173851
          min_q: -0.2716044783592224
        model: {}
        td_error: "[ 0.34157816  0.03573838  0.09680419  0.18841171  0.14410752 -0.17443599\n\
          \ -0.04562671  0.22054356  0.0114926   0.14266106  0.08046681  0.394141\n\
          \  0.21406323 -0.07960974  0.42250678 -0.18650651 -0.17212616  0.18570492\n\
          \ -0.1504165  -0.21361797  0.42534506 -0.031507   -0.08622532  0.05538148\n\
          \ -0.20239818  0.10736935 -0.15846859  0.29172203  0.36297423  0.19348097\n\
          \ -0.10606259 -0.00940204  0.05773517  0.06608585  0.0344141   0.05189808\n\
          \  0.02308828  0.2732938   0.30992347  0.15096216  0.09329611  0.3228721\n\
          \  0.6206299  -0.01301518 -0.38533515  0.15754268 -0.24286875 -0.37926388]"
    num_agent_steps_sampled: 265000
    num_agent_steps_trained: 3168048
    num_steps_sampled: 265000
    num_steps_trained: 3168048
    num_target_updates: 524
  iterations_since_restore: 265
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.81500000000001
    ram_util_percent: 32.214999999999996
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3810.1491355895996
  time_this_iter_s: 14.018197298049927
  time_total_s: 3810.1491355895996
  timers:
    learn_throughput: 4819.55
    learn_time_ms: 9.959
    update_time_ms: 2.86
  timestamp: 1629284532
  timesteps_since_restore: 0
  timesteps_total: 265000
  training_iteration: 265
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    265 |          3810.15 | 265000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 266000
  custom_metrics: {}
  date: 2021-08-18_11-02-27
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 265600
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.557555198669434
          max_q: 7254769.0
          mean_q: 151141.03125
          mean_td_error: -1.1348276138305664
          min_q: -0.30437225103378296
        model: {}
        td_error: "[ 3.69192868e-01  2.23883629e-01 -1.00862287e-01 -2.62057066e-01\n\
          \  1.81782126e-01 -8.83939862e-03  1.19462729e-01  2.97375977e-01\n  2.55190492e-01\
          \ -2.57499337e-01  3.26605976e-01  1.78963840e-02\n  2.86345750e-01  1.48258507e-01\
          \ -5.95000000e+01  2.05388516e-01\n  2.43808091e-01  1.32197350e-01 -2.75708437e-01\
          \ -1.18601754e-01\n -1.38777435e-01  2.99340010e-01 -2.05523133e-01  3.12038898e-01\n\
          \ -9.83881205e-02 -1.31815523e-01 -6.36060908e-02 -9.56204534e-03\n  6.26028538e-01\
          \ -8.12278837e-02  1.54132456e-01 -1.48017406e-02\n  3.20586979e-01  6.04738891e-02\
          \  1.22270703e-01  1.04613870e-01\n  7.00612366e-02  3.00832242e-01  1.39566809e-01\
          \ -1.11961454e-01\n -8.01298767e-03 -1.14262700e-02  5.76471567e-01  1.32262737e-01\n\
          \  1.70218498e-02  2.71520913e-01  2.24859118e-01  3.87482226e-01]"
    num_agent_steps_sampled: 266000
    num_agent_steps_trained: 3180048
    num_steps_sampled: 266000
    num_steps_trained: 3180048
    num_target_updates: 526
  iterations_since_restore: 266
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.44285714285715
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3824.4127955436707
  time_this_iter_s: 14.263659954071045
  time_total_s: 3824.4127955436707
  timers:
    learn_throughput: 4933.46
    learn_time_ms: 9.729
    update_time_ms: 2.683
  timestamp: 1629284547
  timesteps_since_restore: 0
  timesteps_total: 266000
  training_iteration: 266
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    266 |          3824.41 | 266000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 267000
  custom_metrics: {}
  date: 2021-08-18_11-02-41
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 266608
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 15.775547981262207
          max_q: 7255272.0
          mean_q: 302303.03125
          mean_td_error: 18.49030113220215
          min_q: -0.3100685477256775
        model: {}
        td_error: "[ 1.27771631e-01 -1.31622359e-01 -4.70221639e-02  5.52433021e-02\n\
          \  4.44500000e+02  9.12477821e-03  5.18592745e-02 -4.35896397e-01\n -3.90142202e-04\
          \  2.64706254e-01  1.77867383e-01  1.05374694e-01\n  1.29800528e-01  6.30474389e-02\
          \  4.44500000e+02 -2.97301769e-01\n -3.13538730e-01 -1.89075053e-01 -1.14940211e-01\
          \ -1.48083508e-01\n  1.10095739e-03  3.26789856e-01 -1.17437921e-01 -6.69097900e-02\n\
          \ -3.00938725e-01  1.70528412e-01 -1.88439265e-02 -2.53980994e-01\n  1.23814508e-01\
          \  2.29616791e-01 -4.36023593e-01 -4.34644073e-02\n -8.29794705e-01 -3.45457047e-02\
          \  2.29294926e-01  3.44536185e-01\n -2.04804808e-01 -7.36748427e-02 -3.18183154e-02\
          \  1.58375800e-01\n  6.93869293e-02 -2.02817917e-01 -3.63827944e-01  1.34675562e-01\n\
          \  2.25600690e-01  7.37873614e-02  2.01102912e-01 -8.22458044e-02]"
    num_agent_steps_sampled: 267000
    num_agent_steps_trained: 3192048
    num_steps_sampled: 267000
    num_steps_trained: 3192048
    num_target_updates: 528
  iterations_since_restore: 267
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.714285714285715
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3838.6948368549347
  time_this_iter_s: 14.282041311264038
  time_total_s: 3838.6948368549347
  timers:
    learn_throughput: 4857.447
    learn_time_ms: 9.882
    update_time_ms: 2.914
  timestamp: 1629284561
  timesteps_since_restore: 0
  timesteps_total: 267000
  training_iteration: 267
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    267 |          3838.69 | 267000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 268000
  custom_metrics: {}
  date: 2021-08-18_11-02-57
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 267616
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.021425457671284676
          max_q: 1.3997389078140259
          mean_q: -0.03334300220012665
          mean_td_error: 4.40611838712357e-05
          min_q: -0.3297092914581299
        model: {}
        td_error: "[-0.11200307  0.219275    0.24647778 -0.15780833 -0.08444747 -0.18395606\n\
          \ -0.03679363 -0.3180379   0.02164204  0.33763492 -0.11375157  0.56482214\n\
          \ -0.21925661 -0.22293659  0.1227826  -0.13719021 -0.05768791 -0.03858957\n\
          \  0.106023   -0.08940811 -0.25161165 -0.28629714  0.25487047  0.19353801\n\
          \ -0.28624207 -0.22266498  0.35831583  0.38464677 -0.11870259  0.09552726\n\
          \  0.06605707 -0.02931559 -0.19785836  0.03671262  0.06260848  0.13832341\n\
          \ -0.03116651 -0.35840493 -0.117293   -0.13764766  0.07590869 -0.10151236\n\
          \  0.16388026 -0.20082152  0.25157428  0.18486893  0.04787955  0.18015122]"
    num_agent_steps_sampled: 268000
    num_agent_steps_trained: 3204048
    num_steps_sampled: 268000
    num_steps_trained: 3204048
    num_target_updates: 530
  iterations_since_restore: 268
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.695454545454545
    ram_util_percent: 32.30454545454544
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3853.5048685073853
  time_this_iter_s: 14.810031652450562
  time_total_s: 3853.5048685073853
  timers:
    learn_throughput: 4893.718
    learn_time_ms: 9.808
    update_time_ms: 2.913
  timestamp: 1629284577
  timesteps_since_restore: 0
  timesteps_total: 268000
  training_iteration: 268
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    268 |           3853.5 | 268000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 269000
  custom_metrics: {}
  date: 2021-08-18_11-03-12
  done: false
  episode_len_mean: 8888.551724137931
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4502833.499559079
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 29
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 268624
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0742439553141594
          max_q: 0.6550450921058655
          mean_q: -0.15101520717144012
          mean_td_error: -0.07070843875408173
          min_q: -0.35200268030166626
        model: {}
        td_error: "[ 0.14986148  0.09594801 -0.02259642 -0.26787758  0.26210153  0.02671322\n\
          \  0.18582433  0.06265903 -0.24550427 -0.10841101 -0.25232404 -0.2050699\n\
          \ -0.12479992 -0.44696748 -0.23416817 -0.13788494  0.09684581 -0.04757398\n\
          \  0.15432091 -0.32337365 -0.05054292  0.09953953  0.02234544 -0.35448298\n\
          \ -0.22704297 -0.11321881 -0.12403747  0.02153018 -0.35471454 -0.33484256\n\
          \  0.19544199  0.10156015 -0.04513437  0.07681058 -0.15781657 -0.09141511\n\
          \  0.28793672 -0.41824645  0.06007904  0.12598819  0.14520863 -0.2371825\n\
          \ -0.35898718 -0.02606618 -0.06106526 -0.0250386   0.15004057 -0.31837416]"
    num_agent_steps_sampled: 269000
    num_agent_steps_trained: 3216048
    num_steps_sampled: 269000
    num_steps_trained: 3216048
    num_target_updates: 532
  iterations_since_restore: 269
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.32380952380953
    ram_util_percent: 32.309523809523796
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924972109650498
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.507541113035503
    mean_inference_ms: 1.5864700148501525
    mean_raw_obs_processing_ms: 0.1438189386629938
  time_since_restore: 3868.413958311081
  time_this_iter_s: 14.909089803695679
  time_total_s: 3868.413958311081
  timers:
    learn_throughput: 4829.145
    learn_time_ms: 9.94
    update_time_ms: 2.948
  timestamp: 1629284592
  timesteps_since_restore: 0
  timesteps_total: 269000
  training_iteration: 269
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    269 |          3868.41 | 269000 | 4.50283e+06 |          7.25484e+06 |             -198.044 |            8888.55 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 270000
  custom_metrics: {}
  date: 2021-08-18_11-03-27
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 269632
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03981318697333336
          max_q: 1.5501611232757568
          mean_q: -0.006569497287273407
          mean_td_error: -0.05124540627002716
          min_q: -0.3241494297981262
        model: {}
        td_error: "[ 0.0467304  -0.20987925 -0.03990258 -0.09736806 -0.01472837  0.04153471\n\
          \ -0.09480296  0.09563297 -0.30356383  0.11386998 -0.02118436  0.06157346\n\
          \  0.19700259 -0.11091748 -0.15037775  0.2820303   0.33755267  0.12099239\n\
          \  0.04341871  0.04143746 -0.0079716  -0.0559504  -0.3910306  -0.19678009\n\
          \  0.39213094  0.06937039  0.1423175  -0.35345933  0.0825139   0.05952504\n\
          \  0.31668478 -0.1964046   0.3472045  -0.06047984  0.27240315 -0.18980102\n\
          \ -0.02090301  0.09766659 -0.3731377  -0.23364359  0.20915017 -0.10213441\n\
          \ -1.015593   -0.06308416 -0.73664975  0.21257228 -1.1737921   0.17044544]"
    num_agent_steps_sampled: 270000
    num_agent_steps_trained: 3228048
    num_steps_sampled: 270000
    num_steps_trained: 3228048
    num_target_updates: 534
  iterations_since_restore: 270
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.627272727272725
    ram_util_percent: 32.3090909090909
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 3883.520234823227
  time_this_iter_s: 15.106276512145996
  time_total_s: 3883.520234823227
  timers:
    learn_throughput: 5047.12
    learn_time_ms: 9.51
    update_time_ms: 2.648
  timestamp: 1629284607
  timesteps_since_restore: 0
  timesteps_total: 270000
  training_iteration: 270
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    270 |          3883.52 | 270000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 271000
  custom_metrics: {}
  date: 2021-08-18_11-03-39
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 270640
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.794272422790527
          max_q: 7255109.0
          mean_q: 151147.953125
          mean_td_error: 5.844314098358154
          min_q: -0.43408524990081787
        model: {}
        td_error: "[-5.67874610e-02  1.91234767e-01  2.79466212e-02  2.72680968e-01\n\
          \  1.47577316e-01  5.19559085e-02 -2.82838941e-03 -1.17500566e-01\n -2.36333460e-02\
          \ -4.63959128e-02  4.08725142e-02  2.24383354e-01\n -3.51491362e-01 -1.96838915e-01\
          \  1.87675655e-01  3.28516960e-01\n -6.67129755e-02 -1.94692463e-01 -1.28823489e-01\
          \  8.88645649e-03\n -1.98851407e-01  2.14717895e-01  3.93314362e-01 -3.57403457e-02\n\
          \ -8.73995721e-02 -2.34135121e-01  1.75571650e-01 -3.25646251e-01\n  5.82779944e-02\
          \  7.01028109e-02 -1.52740002e-01 -6.95815012e-02\n  9.31248665e-02  1.96316093e-01\
          \ -9.92676020e-02  2.03836799e-01\n  1.38579637e-01 -1.29949951e+00  2.13841870e-01\
          \  2.81000000e+02\n -1.07773893e-01 -3.00232828e-01  1.00432038e-01 -8.44768882e-02\n\
          \  8.51292610e-02  2.32548118e-01  1.67785138e-01 -1.17155686e-01]"
    num_agent_steps_sampled: 271000
    num_agent_steps_trained: 3240048
    num_steps_sampled: 271000
    num_steps_trained: 3240048
    num_target_updates: 536
  iterations_since_restore: 271
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.00588235294117
    ram_util_percent: 32.3
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 3894.686388015747
  time_this_iter_s: 11.166153192520142
  time_total_s: 3894.686388015747
  timers:
    learn_throughput: 5101.189
    learn_time_ms: 9.41
    update_time_ms: 2.674
  timestamp: 1629284619
  timesteps_since_restore: 0
  timesteps_total: 271000
  training_iteration: 271
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    271 |          3894.69 | 271000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 272000
  custom_metrics: {}
  date: 2021-08-18_11-03-50
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 271648
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05065110698342323
          max_q: 1.5538921356201172
          mean_q: -0.14956964552402496
          mean_td_error: 0.022537244483828545
          min_q: -0.4115140438079834
        model: {}
        td_error: "[-0.2508797   0.19210571  0.15313607 -0.13729443  0.15553117 -0.3741399\n\
          \ -0.6403235  -0.1947417   0.6919507  -0.7673032   0.11616129 -0.0740709\n\
          \  0.27138618  0.54136324 -0.25425392 -0.05411193  0.20060736  0.2492038\n\
          \  0.26397225 -0.18182948 -0.01819766  0.10688269  0.1426714   0.09243119\n\
          \ -0.18992214 -0.35742402  0.67911446  0.00086784  0.09825593  0.12253171\n\
          \ -0.29524738 -0.10172641  0.01050326  0.14356083  0.2848909   0.05700842\n\
          \  0.17946625  0.17918903  0.08787492 -0.24986356  0.0843555   0.15287739\n\
          \  0.13287723  0.1203934  -0.01730438 -0.10647529 -0.29937923  0.1351065 ]"
    num_agent_steps_sampled: 272000
    num_agent_steps_trained: 3252048
    num_steps_sampled: 272000
    num_steps_trained: 3252048
    num_target_updates: 538
  iterations_since_restore: 272
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.21875
    ram_util_percent: 32.3
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 3905.968249320984
  time_this_iter_s: 11.281861305236816
  time_total_s: 3905.968249320984
  timers:
    learn_throughput: 4953.464
    learn_time_ms: 9.69
    update_time_ms: 2.632
  timestamp: 1629284630
  timesteps_since_restore: 0
  timesteps_total: 272000
  training_iteration: 272
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    272 |          3905.97 | 272000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 273000
  custom_metrics: {}
  date: 2021-08-18_11-04-03
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 272656
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 15.269756317138672
          max_q: 7257302.0
          mean_q: 453581.125
          mean_td_error: 154.58135986328125
          min_q: -0.6076018214225769
        model: {}
        td_error: "[-1.20547414e-03  2.80640572e-02 -1.95947438e-02  6.71653748e-02\n\
          \ -2.21236184e-01  2.85858810e-01  2.23351568e-01 -2.91407108e-01\n -1.49828807e-01\
          \  7.35924244e-02 -2.15437949e-01  8.78047347e-02\n -2.69162655e-03 -1.44331411e-01\
          \  5.98879457e-02 -5.67446947e-01\n  2.47400000e+03 -8.91022980e-02 -1.93078578e-01\
          \ -7.53088593e-02\n -2.98447013e-02  1.04256034e-01 -5.74331135e-02  2.47400000e+03\n\
          \ -3.10179591e-01 -2.37587795e-01 -3.55944782e-01  5.79238772e-01\n -4.74500000e-01\
          \ -6.09661564e-02  9.52996612e-02  2.47400000e+03\n -3.94934773e-01  5.13784289e-01\
          \ -4.20101583e-02  1.03654504e-01\n -7.61344731e-02 -2.48507559e-02  1.71636045e-01\
          \  2.18330801e-01\n -1.67700648e-01 -3.94881964e-02 -2.44908467e-01 -3.44872624e-02\n\
          \ -1.50396451e-01  3.36995721e-02 -2.46991456e-01  1.78166687e-01]"
    num_agent_steps_sampled: 273000
    num_agent_steps_trained: 3264048
    num_steps_sampled: 273000
    num_steps_trained: 3264048
    num_target_updates: 540
  iterations_since_restore: 273
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.30000000000001
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 3918.2101452350616
  time_this_iter_s: 12.241895914077759
  time_total_s: 3918.2101452350616
  timers:
    learn_throughput: 5071.965
    learn_time_ms: 9.464
    update_time_ms: 2.849
  timestamp: 1629284643
  timesteps_since_restore: 0
  timesteps_total: 273000
  training_iteration: 273
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    273 |          3918.21 | 273000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 274000
  custom_metrics: {}
  date: 2021-08-18_11-04-15
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 273664
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06424318999052048
          max_q: 1.0834128856658936
          mean_q: -0.16306160390377045
          mean_td_error: 0.0054308827966451645
          min_q: -0.5965715646743774
        model: {}
        td_error: "[-0.87818336 -0.24316403 -0.21523546 -0.10746425 -0.27723056  0.16344321\n\
          \ -0.03033945  0.24763137 -0.12978184  0.51940155 -0.2594196  -0.09714216\n\
          \ -0.1534487   0.11253534  0.27782255  0.06787923  0.10045636 -0.2593923\n\
          \ -0.20999378  0.09140146 -0.22724405  0.09244341  0.1372788   0.01750065\n\
          \  0.17215496  0.5274869   0.04270363  0.10729665  0.0644244  -0.14218625\n\
          \  0.1470496  -0.07043153  0.16583675 -0.31397164 -0.02581877  0.27315736\n\
          \ -0.02943027 -0.13292675  0.34513393  0.22887355 -0.19442987  0.03411001\n\
          \  0.4149168  -0.23493947 -0.40466702  0.29541743 -0.00830799  0.2594757 ]"
    num_agent_steps_sampled: 274000
    num_agent_steps_trained: 3276048
    num_steps_sampled: 274000
    num_steps_trained: 3276048
    num_target_updates: 542
  iterations_since_restore: 274
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.75
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 3930.3342525959015
  time_this_iter_s: 12.124107360839844
  time_total_s: 3930.3342525959015
  timers:
    learn_throughput: 5042.898
    learn_time_ms: 9.518
    update_time_ms: 2.763
  timestamp: 1629284655
  timesteps_since_restore: 0
  timesteps_total: 274000
  training_iteration: 274
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    274 |          3930.33 | 274000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 275000
  custom_metrics: {}
  date: 2021-08-18_11-04-29
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 274672
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.039842791855335236
          max_q: 1.4011523723602295
          mean_q: -0.23736566305160522
          mean_td_error: -0.0256514810025692
          min_q: -0.5728031992912292
        model: {}
        td_error: "[ 0.32660678  0.13874632  0.17752942 -0.35092857 -0.15620233  0.15974343\n\
          \  0.21620363 -0.01542413  0.08509667 -0.17412522  0.16491002  0.1442413\n\
          \ -0.03171998 -0.21561687 -0.36619037 -0.1432004   0.04854062 -0.18182479\n\
          \  0.14486808 -0.06835791 -0.19542325  0.08580005 -1.162574    0.20848411\n\
          \ -0.29612327  0.04167822 -0.16037732  0.14675102 -0.20160928  0.14888448\n\
          \  0.1653716   0.14007795  0.20019877 -0.2473584   0.08745778  0.16344431\n\
          \ -0.01438212 -0.08036926 -0.06583424 -0.25901303 -0.134796    0.30291063\n\
          \ -0.15586361 -0.11213532  0.20429748  0.03028136  0.02142584  0.00462893]"
    num_agent_steps_sampled: 275000
    num_agent_steps_trained: 3288048
    num_steps_sampled: 275000
    num_steps_trained: 3288048
    num_target_updates: 544
  iterations_since_restore: 275
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.973684210526315
    ram_util_percent: 32.30526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 3943.6210446357727
  time_this_iter_s: 13.286792039871216
  time_total_s: 3943.6210446357727
  timers:
    learn_throughput: 4674.22
    learn_time_ms: 10.269
    update_time_ms: 3.0
  timestamp: 1629284669
  timesteps_since_restore: 0
  timesteps_total: 275000
  training_iteration: 275
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    275 |          3943.62 | 275000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 276000
  custom_metrics: {}
  date: 2021-08-18_11-04-43
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 275680
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03081560507416725
          max_q: 1.751396656036377
          mean_q: -0.19717583060264587
          mean_td_error: -0.02662624791264534
          min_q: -0.5096638798713684
        model: {}
        td_error: "[ 0.05965531  0.12323141  0.0725517  -0.17351383  0.04579055 -0.10030252\n\
          \ -0.5198604  -0.8456277  -0.46814442 -0.16019388  0.22927749  0.4659434\n\
          \  0.45984727  0.3484264  -0.08644342  0.31592858  0.35160297  0.07953727\n\
          \ -0.03564502  0.17631906  0.22391358  0.05365145  0.07841259 -0.1383354\n\
          \  0.15427083 -0.8701872   0.14416665  0.19988114 -1.6543927  -0.06151493\n\
          \  0.00205648 -0.05832392 -0.05851665  0.12388381  0.20997638  0.05782485\n\
          \  0.01091161 -0.06979147 -0.12077942  0.04815517 -0.18711379  0.03028315\n\
          \  0.64335155  0.19982624 -0.13226032 -0.08933434 -0.48592344  0.12946796]"
    num_agent_steps_sampled: 276000
    num_agent_steps_trained: 3300048
    num_steps_sampled: 276000
    num_steps_trained: 3300048
    num_target_updates: 546
  iterations_since_restore: 276
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.42
    ram_util_percent: 32.30499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 3956.9323666095734
  time_this_iter_s: 13.31132197380066
  time_total_s: 3956.9323666095734
  timers:
    learn_throughput: 4926.53
    learn_time_ms: 9.743
    update_time_ms: 2.801
  timestamp: 1629284683
  timesteps_since_restore: 0
  timesteps_total: 276000
  training_iteration: 276
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    276 |          3956.93 | 276000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 277000
  custom_metrics: {}
  date: 2021-08-18_11-04-56
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 276688
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07469359785318375
          max_q: 0.7780629396438599
          mean_q: -0.4511347711086273
          mean_td_error: -0.09242789447307587
          min_q: -0.680184006690979
        model: {}
        td_error: "[ 0.1273911  -0.09149563 -0.05694532  0.00516528  0.2995001  -0.03145257\n\
          \  0.22240645  0.02451852  0.11247641 -0.28485215 -0.7555832   0.20786339\n\
          \  0.02007747 -0.69107103 -0.08073834 -0.22338554 -0.73959744  0.29333472\n\
          \  0.1590271   0.04137477 -1.2994742  -0.28959817 -0.09085256 -0.1606071\n\
          \ -0.11397636  0.22490102 -0.11196822 -0.16758299 -0.34721947 -0.13824296\n\
          \  0.07225013  0.36258358 -0.31302455  0.10755408  0.06448281 -0.18305397\n\
          \  0.05907279 -1.1026052   0.15343004 -0.15326989  0.18105239 -0.03896117\n\
          \  0.31691992 -0.1411626   0.16702765 -0.09403718  0.07180649 -0.02999735]"
    num_agent_steps_sampled: 277000
    num_agent_steps_trained: 3312048
    num_steps_sampled: 277000
    num_steps_trained: 3312048
    num_target_updates: 548
  iterations_since_restore: 277
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.90526315789474
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 3969.908969640732
  time_this_iter_s: 12.976603031158447
  time_total_s: 3969.908969640732
  timers:
    learn_throughput: 5062.884
    learn_time_ms: 9.481
    update_time_ms: 2.836
  timestamp: 1629284696
  timesteps_since_restore: 0
  timesteps_total: 277000
  training_iteration: 277
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    277 |          3969.91 | 277000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 278000
  custom_metrics: {}
  date: 2021-08-18_11-05-10
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 277696
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06450609117746353
          max_q: 0.7595470547676086
          mean_q: -0.31617283821105957
          mean_td_error: -0.027721649035811424
          min_q: -0.5979358553886414
        model: {}
        td_error: "[ 0.11821315  0.10098939 -0.1510922   0.03596514  0.3727036  -0.05451012\n\
          \ -0.5268893  -0.01680982 -0.02844747  0.34099448  0.29420847 -0.05289179\n\
          \  0.20329481  0.01868373 -0.09707043 -0.23407048  0.3490908  -0.32017547\n\
          \  0.15382355  0.08923143 -0.06146199 -0.0484997   0.19863063 -0.04979545\n\
          \ -0.6791138   0.02215731 -0.03343356 -0.25896004 -0.39915133  0.05682282\n\
          \  0.15301871 -0.2614379   0.18710792 -0.14424062 -0.32632992 -0.06870532\n\
          \ -0.10085063  0.44934934 -0.31959727  0.13875157 -0.01109058  0.08933759\n\
          \  0.09523174 -0.8712385   0.07132858  0.20438743 -0.1387769   0.18067944]"
    num_agent_steps_sampled: 278000
    num_agent_steps_trained: 3324048
    num_steps_sampled: 278000
    num_steps_trained: 3324048
    num_target_updates: 550
  iterations_since_restore: 278
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.22
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 3983.9507472515106
  time_this_iter_s: 14.041777610778809
  time_total_s: 3983.9507472515106
  timers:
    learn_throughput: 4324.443
    learn_time_ms: 11.1
    update_time_ms: 3.112
  timestamp: 1629284710
  timesteps_since_restore: 0
  timesteps_total: 278000
  training_iteration: 278
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    278 |          3983.95 | 278000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 279000
  custom_metrics: {}
  date: 2021-08-18_11-05-25
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 278704
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.034926287829875946
          max_q: 1.1508445739746094
          mean_q: -0.18453693389892578
          mean_td_error: 0.019818026572465897
          min_q: -0.5653055310249329
        model: {}
        td_error: "[ 0.00825664  0.01038688  0.07583064  0.1813497   0.16027302  0.01700008\n\
          \  0.16202304  0.12442216  0.46939746  0.11403909  0.14895362  0.00237089\n\
          \  0.18913144  0.09526578  0.11300832  0.28609282  0.01699117  0.17530736\n\
          \  0.0245997   0.18704778  0.22321194 -0.2443341  -0.18390614  0.031196\n\
          \ -0.24634382 -0.44807053  0.04914201 -0.10824236  0.06079757 -0.28351462\n\
          \  0.17287773 -0.14767984 -0.02739534 -0.23718652 -0.16784558 -0.9036443\n\
          \  0.11220735 -0.23124781 -0.04808396  0.0635187  -0.2198661   0.14496487\n\
          \ -0.19202614  0.30513203  0.17144173  0.25746244  0.15031666  0.33663583]"
    num_agent_steps_sampled: 279000
    num_agent_steps_trained: 3336048
    num_steps_sampled: 279000
    num_steps_trained: 3336048
    num_target_updates: 552
  iterations_since_restore: 279
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.47619047619047
    ram_util_percent: 32.30476190476189
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 3998.5082993507385
  time_this_iter_s: 14.557552099227905
  time_total_s: 3998.5082993507385
  timers:
    learn_throughput: 4833.041
    learn_time_ms: 9.932
    update_time_ms: 2.877
  timestamp: 1629284725
  timesteps_since_restore: 0
  timesteps_total: 279000
  training_iteration: 279
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    279 |          3998.51 | 279000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 280000
  custom_metrics: {}
  date: 2021-08-18_11-05-41
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 279712
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06503817439079285
          max_q: 2.0613279342651367
          mean_q: -0.17070317268371582
          mean_td_error: 0.059805065393447876
          min_q: -0.7073063850402832
        model: {}
        td_error: "[ 0.13918352  0.10069618  0.09715095 -0.07218364  0.39274925  0.13997713\n\
          \  0.3515943   0.28455412  0.11578819  0.2825122  -0.12272176  0.2548228\n\
          \  0.59861034 -0.11819154 -0.19477935  0.01422137  0.16069525  0.17118889\n\
          \  0.20554137 -0.2776277   0.2607559  -0.4348107   0.30517197  0.18525708\n\
          \ -0.13686097  0.25268495 -0.28843707 -0.07650098 -0.18682158 -0.18247005\n\
          \  0.44038388  0.38552785  0.19221193  0.26210195 -0.24521835  0.05945018\n\
          \ -0.16334039  0.02791172  0.33653158  0.03209832 -0.91354275  0.08887944\n\
          \  0.27452642 -0.03164428 -0.15886746  0.3247068  -0.18680245 -0.07602161]"
    num_agent_steps_sampled: 280000
    num_agent_steps_trained: 3348048
    num_steps_sampled: 280000
    num_steps_trained: 3348048
    num_target_updates: 554
  iterations_since_restore: 280
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.313636363636355
    ram_util_percent: 32.30454545454544
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 4014.1555273532867
  time_this_iter_s: 15.647228002548218
  time_total_s: 4014.1555273532867
  timers:
    learn_throughput: 4994.136
    learn_time_ms: 9.611
    update_time_ms: 2.839
  timestamp: 1629284741
  timesteps_since_restore: 0
  timesteps_total: 280000
  training_iteration: 280
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    280 |          4014.16 | 280000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 281000
  custom_metrics: {}
  date: 2021-08-18_11-05-57
  done: false
  episode_len_mean: 8992.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4594560.686053174
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 30
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 280720
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02606050670146942
          max_q: 1.3555681705474854
          mean_q: -0.1445409655570984
          mean_td_error: 0.008518213406205177
          min_q: -0.46980220079421997
        model: {}
        td_error: "[ 0.06452858  0.18892413 -0.21230513 -0.10362771  0.06598938  0.06759343\n\
          \ -0.17662632  0.18624079  0.16940671  0.37082982 -0.83126056 -0.07473052\n\
          \  0.00111893  0.18778038 -0.02449372 -0.13726005  0.10858196 -0.19546759\n\
          \  0.19321194 -0.09919915 -0.0846352  -0.29866102  0.27970934  0.12117684\n\
          \ -0.1487385   0.0191164   0.10163316 -0.04450008 -0.13243678 -0.08114481\n\
          \  0.1735875  -0.17555308  0.08349019  0.14075938 -0.15209293  0.07180554\n\
          \  0.45407042  0.15018716 -0.2016456  -0.3876331   0.29900724  0.1254226\n\
          \  0.14502189  0.1430546  -0.23785332  0.08843565  0.10584883  0.10220656]"
    num_agent_steps_sampled: 281000
    num_agent_steps_trained: 3360048
    num_steps_sampled: 281000
    num_steps_trained: 3360048
    num_target_updates: 556
  iterations_since_restore: 281
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.408695652173904
    ram_util_percent: 32.30434782608694
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049248771659528304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.547761221820888
    mean_inference_ms: 1.5865859000962734
    mean_raw_obs_processing_ms: 0.14385845929121413
  time_since_restore: 4029.844181537628
  time_this_iter_s: 15.68865418434143
  time_total_s: 4029.844181537628
  timers:
    learn_throughput: 4740.688
    learn_time_ms: 10.125
    update_time_ms: 2.977
  timestamp: 1629284757
  timesteps_since_restore: 0
  timesteps_total: 281000
  training_iteration: 281
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    281 |          4029.84 | 281000 | 4.59456e+06 |          7.25484e+06 |             -198.044 |             8992.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 282000
  custom_metrics: {}
  date: 2021-08-18_11-06-13
  done: false
  episode_len_mean: 9089.612903225807
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4680370.234460836
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 281728
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.048752326518297195
          max_q: 1.2317686080932617
          mean_q: -0.20104679465293884
          mean_td_error: 0.006465894635766745
          min_q: -0.5253094434738159
        model: {}
        td_error: "[ 0.20485643 -0.2634853  -0.01876064  0.32575053  0.46799517  0.1775192\n\
          \ -0.03336263 -0.01360974  0.21935546 -0.06310481 -0.2589407  -0.32907045\n\
          \ -0.40354672  0.21637446  0.25122517 -0.09941632  0.16348684 -0.20283133\n\
          \  0.17742988 -0.17823385  0.01621678 -0.28710088  0.10089236 -0.05098426\n\
          \  0.02142653 -0.1546325  -0.46655676  0.19401634  0.25029516  0.20583224\n\
          \  0.08534852  0.14268339  0.39449507 -1.224874    0.07591616 -0.7198005\n\
          \  0.39735043  0.34244698  0.13141894 -0.13944584  0.03431424  0.20615095\n\
          \ -0.1515662  -0.20307328 -0.20872977  0.24859595  0.5333434   0.1967527 ]"
    num_agent_steps_sampled: 282000
    num_agent_steps_trained: 3372048
    num_steps_sampled: 282000
    num_steps_trained: 3372048
    num_target_updates: 558
  iterations_since_restore: 282
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.73181818181819
    ram_util_percent: 32.38181818181817
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924791448491466
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.584092262345998
    mean_inference_ms: 1.5866616738668173
    mean_raw_obs_processing_ms: 0.14389396810386124
  time_since_restore: 4045.0384340286255
  time_this_iter_s: 15.194252490997314
  time_total_s: 4045.0384340286255
  timers:
    learn_throughput: 4684.814
    learn_time_ms: 10.246
    update_time_ms: 2.791
  timestamp: 1629284773
  timesteps_since_restore: 0
  timesteps_total: 282000
  training_iteration: 282
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    282 |          4045.04 | 282000 | 4.68037e+06 |          7.25484e+06 |             -198.044 |            9089.61 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 283000
  custom_metrics: {}
  date: 2021-08-18_11-06-24
  done: false
  episode_len_mean: 9089.612903225807
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4680370.234460836
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 31
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 282736
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.059791434556245804
          max_q: 1.5054538249969482
          mean_q: -0.2399015873670578
          mean_td_error: -0.03478540852665901
          min_q: -0.9776736497879028
        model: {}
        td_error: "[-0.15305434  0.09057987  0.0044536  -0.00452727 -0.0739736   0.20203938\n\
          \ -0.33416367 -0.10150798 -0.10231125  0.02036742 -0.14979234 -0.20296928\n\
          \  0.20660126 -0.1118027  -0.42607665 -1.1202222   0.03042501  0.22168308\n\
          \  0.00805116 -0.2961192  -0.23551226  0.47265804  0.09650731 -0.48598552\n\
          \ -0.30749288 -0.1167565   0.2461853   0.22312486  0.00288564  0.15648574\n\
          \  0.09134147 -0.1317867   0.07018125  0.22051626 -0.09355421 -0.44609493\n\
          \  0.20712459  0.30032712 -0.30355257  0.09011185 -0.14142826  0.23459345\n\
          \ -0.18651265  0.2817685  -0.10202938  0.13799793  0.1133067   0.22821009]"
    num_agent_steps_sampled: 283000
    num_agent_steps_trained: 3384048
    num_steps_sampled: 283000
    num_steps_trained: 3384048
    num_target_updates: 560
  iterations_since_restore: 283
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.71875000000001
    ram_util_percent: 32.3
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924791448491466
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.584092262345998
    mean_inference_ms: 1.5866616738668173
    mean_raw_obs_processing_ms: 0.14389396810386124
  time_since_restore: 4056.015464782715
  time_this_iter_s: 10.977030754089355
  time_total_s: 4056.015464782715
  timers:
    learn_throughput: 5004.315
    learn_time_ms: 9.592
    update_time_ms: 2.588
  timestamp: 1629284784
  timesteps_since_restore: 0
  timesteps_total: 283000
  training_iteration: 283
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    283 |          4056.02 | 283000 | 4.68037e+06 |          7.25484e+06 |             -198.044 |            9089.61 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 284000
  custom_metrics: {}
  date: 2021-08-18_11-06-36
  done: false
  episode_len_mean: 9089.612903225807
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4680370.234460836
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 31
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 283744
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07527056336402893
          max_q: 2.8694374561309814
          mean_q: -0.09226225316524506
          mean_td_error: 0.0681951642036438
          min_q: -0.6499145030975342
        model: {}
        td_error: "[-0.55964094  0.39456654  0.24825019  0.01733047  0.21452475  0.10518593\n\
          \  0.07095823 -0.06077567 -0.23184688  0.10693786  0.15925217 -0.02572849\n\
          \ -0.19811943  0.04186967 -0.3200264   0.32089084 -0.21056357 -0.5020771\n\
          \ -0.06503886 -0.22818072  0.36325264  0.24646914  0.56145704  0.23688412\n\
          \ -0.21743776  0.21878088 -0.12339771 -0.03265476  0.33066976  0.26406288\n\
          \  0.34539798  0.11524576  0.5209433   0.18744695 -0.09363285  0.03575331\n\
          \  0.18851832  0.34612858  0.08369756 -0.10490057  0.18335235 -0.10911709\n\
          \ -0.09320661  0.08900425 -0.03422424  0.0037625   0.1570113   0.32633197]"
    num_agent_steps_sampled: 284000
    num_agent_steps_trained: 3396048
    num_steps_sampled: 284000
    num_steps_trained: 3396048
    num_target_updates: 562
  iterations_since_restore: 284
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.46111111111111
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924791448491466
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.584092262345998
    mean_inference_ms: 1.5866616738668173
    mean_raw_obs_processing_ms: 0.14389396810386124
  time_since_restore: 4067.9425933361053
  time_this_iter_s: 11.927128553390503
  time_total_s: 4067.9425933361053
  timers:
    learn_throughput: 4803.968
    learn_time_ms: 9.992
    update_time_ms: 2.876
  timestamp: 1629284796
  timesteps_since_restore: 0
  timesteps_total: 284000
  training_iteration: 284
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    284 |          4067.94 | 284000 | 4.68037e+06 |          7.25484e+06 |             -198.044 |            9089.61 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 285000
  custom_metrics: {}
  date: 2021-08-18_11-06-49
  done: false
  episode_len_mean: 9089.612903225807
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4680370.234460836
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 31
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 284752
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04900885373353958
          max_q: 5.292169094085693
          mean_q: -0.06368076801300049
          mean_td_error: -0.06161556765437126
          min_q: -0.5332757830619812
        model: {}
        td_error: "[ 3.9792061e-04 -4.2185426e-01 -1.4203292e-01  4.1438043e-02\n -1.6808802e-01\
          \  2.5870532e-01  1.7113376e-01  1.6692895e-01\n -1.0368862e+00 -8.9647651e-02\
          \  2.7126968e-01 -2.6133326e-01\n -1.1136514e-01  1.1379194e-01 -1.2522277e-01\
          \  3.0204177e-01\n -1.8590483e-01  3.3165956e-01  1.4376298e-02 -2.0381752e-01\n\
          \  2.4424499e-01  4.4891715e-02 -9.5782101e-02 -3.4236956e-01\n  9.1333449e-02\
          \ -1.8625760e-01 -2.3391959e-01 -1.0688567e-01\n -1.5249862e-01 -1.3275820e-01\
          \ -1.4017320e-01  1.3541815e-01\n -1.6467741e-01  1.1282414e-01  1.0475665e-03\
          \  1.7549402e-01\n -6.0659587e-02 -4.2577875e-01  2.4238455e-01 -2.1692356e-01\n\
          \  6.5129548e-02 -9.9210262e-02 -1.3840914e-01 -1.1431339e+00\n -1.4918236e-01\
          \  3.9618111e-01  1.4331958e-01  2.5321293e-01]"
    num_agent_steps_sampled: 285000
    num_agent_steps_trained: 3408048
    num_steps_sampled: 285000
    num_steps_trained: 3408048
    num_target_updates: 564
  iterations_since_restore: 285
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.666666666666664
    ram_util_percent: 32.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924791448491466
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.584092262345998
    mean_inference_ms: 1.5866616738668173
    mean_raw_obs_processing_ms: 0.14389396810386124
  time_since_restore: 4080.1860122680664
  time_this_iter_s: 12.24341893196106
  time_total_s: 4080.1860122680664
  timers:
    learn_throughput: 3782.671
    learn_time_ms: 12.689
    update_time_ms: 3.48
  timestamp: 1629284809
  timesteps_since_restore: 0
  timesteps_total: 285000
  training_iteration: 285
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    285 |          4080.19 | 285000 | 4.68037e+06 |          7.25484e+06 |             -198.044 |            9089.61 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 286000
  custom_metrics: {}
  date: 2021-08-18_11-07-01
  done: false
  episode_len_mean: 8929.8125
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4760817.417131055
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 285760
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05346649885177612
          max_q: 3.276679039001465
          mean_q: -0.17190825939178467
          mean_td_error: -0.09175422042608261
          min_q: -0.6742621660232544
        model: {}
        td_error: "[-0.21381998  0.0987336  -0.11904779  0.23762766 -0.14761448 -0.52577305\n\
          \  0.22671515 -2.2964473   0.14963627 -0.7707814   0.13366723  0.24309528\n\
          \ -0.1632838  -0.14810054  0.08020476  0.22012436 -1.3431714   0.10445583\n\
          \  0.08367118  0.14496881  0.32204652  0.0023964   0.13925588 -0.08275017\n\
          \ -0.14686006  0.23263234 -0.17864633  0.11465573 -0.33493364  0.15122682\n\
          \ -0.14706948 -0.6355287  -0.07671905  0.03381091  0.19412762  0.01907057\n\
          \ -0.13447064 -0.06934282  0.20270753  0.28751472  0.20824015 -0.16294694\n\
          \ -0.3319176   0.05029692 -0.12045106 -0.14924933  0.08912079  0.12472029]"
    num_agent_steps_sampled: 286000
    num_agent_steps_trained: 3420048
    num_steps_sampled: 286000
    num_steps_trained: 3420048
    num_target_updates: 566
  iterations_since_restore: 286
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.7611111111111
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924662002063314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.617097067676212
    mean_inference_ms: 1.5867271535637872
    mean_raw_obs_processing_ms: 0.143925290191165
  time_since_restore: 4092.3325560092926
  time_this_iter_s: 12.146543741226196
  time_total_s: 4092.3325560092926
  timers:
    learn_throughput: 5045.286
    learn_time_ms: 9.514
    update_time_ms: 2.608
  timestamp: 1629284821
  timesteps_since_restore: 0
  timesteps_total: 286000
  training_iteration: 286
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    286 |          4092.33 | 286000 | 4.76082e+06 |          7.25484e+06 |             -198.044 |            8929.81 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 287000
  custom_metrics: {}
  date: 2021-08-18_11-07-14
  done: false
  episode_len_mean: 8929.8125
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4760817.417131055
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 32
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 286768
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1035984456539154
          max_q: 1.4290072917938232
          mean_q: -0.08081895112991333
          mean_td_error: -0.1163848266005516
          min_q: -0.6139391660690308
        model: {}
        td_error: "[-0.20441721  0.2388454   0.00256765  0.17245936 -0.29535812 -0.25711125\n\
          \ -0.9142345   0.3190644  -0.4551102  -0.11492867 -0.18216349  0.21788728\n\
          \ -0.33874533  0.1432926   0.2261048   0.22378969 -0.10175828 -0.35635412\n\
          \ -0.09714693 -0.05158958 -0.17459379 -1.1612389  -0.81367123  0.48181063\n\
          \  0.13507119  0.1877858  -0.07751784 -0.14921725  0.05197555 -0.17583363\n\
          \  0.15340206 -0.31321383 -0.02691485 -0.2537911   0.00994851 -0.059836\n\
          \ -0.00759496 -0.10067108  0.01991332 -0.11754283 -1.3984138   0.17545894\n\
          \  0.18389213  0.1520023   0.13403192 -0.5263866   0.18769696 -0.2781171 ]"
    num_agent_steps_sampled: 287000
    num_agent_steps_trained: 3432048
    num_steps_sampled: 287000
    num_steps_trained: 3432048
    num_target_updates: 568
  iterations_since_restore: 287
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.52222222222221
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924662002063314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.617097067676212
    mean_inference_ms: 1.5867271535637872
    mean_raw_obs_processing_ms: 0.143925290191165
  time_since_restore: 4104.894409894943
  time_this_iter_s: 12.561853885650635
  time_total_s: 4104.894409894943
  timers:
    learn_throughput: 5026.392
    learn_time_ms: 9.55
    update_time_ms: 2.717
  timestamp: 1629284834
  timesteps_since_restore: 0
  timesteps_total: 287000
  training_iteration: 287
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    287 |          4104.89 | 287000 | 4.76082e+06 |          7.25484e+06 |             -198.044 |            8929.81 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 288000
  custom_metrics: {}
  date: 2021-08-18_11-07-27
  done: false
  episode_len_mean: 8929.8125
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4760817.417131055
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 32
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 287776
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.09312422573566437
          max_q: 1.9246232509613037
          mean_q: -0.229813814163208
          mean_td_error: -0.06502664089202881
          min_q: -0.8150864243507385
        model: {}
        td_error: "[ 0.15643519  0.17535377 -0.1689039  -0.26767626 -0.4908859  -0.30910885\n\
          \ -0.2634864   0.04613775  0.25247133  0.16203481 -2.0355215   0.0331521\n\
          \ -0.20365351  0.2232224   0.32876688  0.14456826 -0.5068716   0.04695141\n\
          \  0.07948744 -0.34819806 -0.04677063  0.24346954 -0.1288841   0.26247877\n\
          \ -0.44593963 -0.27446282 -0.03652602  0.4222322   0.01551992 -0.70959544\n\
          \  0.07609367 -0.22549778  0.1911507  -0.16353917 -0.15066025  0.03166017\n\
          \ -0.1308217   0.04399461  0.03016588 -0.11696798  0.1341303   0.56769276\n\
          \  0.19145304  0.3671453  -0.18854775  0.2512746  -0.33877456 -0.0470275 ]"
    num_agent_steps_sampled: 288000
    num_agent_steps_trained: 3444048
    num_steps_sampled: 288000
    num_steps_trained: 3444048
    num_target_updates: 570
  iterations_since_restore: 288
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.6
    ram_util_percent: 32.3
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924662002063314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.617097067676212
    mean_inference_ms: 1.5867271535637872
    mean_raw_obs_processing_ms: 0.143925290191165
  time_since_restore: 4117.153827428818
  time_this_iter_s: 12.259417533874512
  time_total_s: 4117.153827428818
  timers:
    learn_throughput: 4914.24
    learn_time_ms: 9.768
    update_time_ms: 2.813
  timestamp: 1629284847
  timesteps_since_restore: 0
  timesteps_total: 288000
  training_iteration: 288
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    288 |          4117.15 | 288000 | 4.76082e+06 |          7.25484e+06 |             -198.044 |            8929.81 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 289000
  custom_metrics: {}
  date: 2021-08-18_11-07-39
  done: false
  episode_len_mean: 8929.8125
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4760817.417131055
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 32
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 288784
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.3112263679504395
          max_q: 7255666.0
          mean_q: 151159.78125
          mean_td_error: 17.485498428344727
          min_q: -0.42536860704421997
        model: {}
        td_error: "[-5.58899790e-02 -6.23517334e-01  1.87444419e-01  8.18247437e-01\n\
          \  2.16200709e-01  2.29851067e-01 -7.81664252e-02 -1.97337866e-02\n -1.25395969e-01\
          \ -2.47414112e-02 -7.69879073e-02 -7.99946308e-01\n -2.30614662e-01  4.06876504e-02\
          \  3.02952647e-01  1.88533768e-01\n -8.00579786e-03 -1.08969048e-01  2.47226655e-02\
          \  2.62506783e-01\n -6.03021085e-02  2.04089671e-01 -2.90142238e-01  3.19889069e-01\n\
          \  3.16999018e-01  7.88810402e-02 -2.70564198e-01 -2.18329608e-01\n -1.55699313e-01\
          \  2.31314659e-01  5.08014560e-02  2.70022035e-01\n  3.27807486e-01 -2.32701302e-02\
          \ -4.40038264e-01  4.59255457e-01\n  4.28524792e-01 -1.41872734e-01  5.12857437e-02\
          \ -3.66214991e-01\n -2.18846217e-01  2.52895534e-01 -1.39656216e-01  1.03803307e-01\n\
          \  2.80536443e-01  2.44185925e-01 -1.10603765e-01  8.38000000e+02]"
    num_agent_steps_sampled: 289000
    num_agent_steps_trained: 3456048
    num_steps_sampled: 289000
    num_steps_trained: 3456048
    num_target_updates: 572
  iterations_since_restore: 289
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.568421052631585
    ram_util_percent: 32.30526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924662002063314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.617097067676212
    mean_inference_ms: 1.5867271535637872
    mean_raw_obs_processing_ms: 0.143925290191165
  time_since_restore: 4129.648730993271
  time_this_iter_s: 12.494903564453125
  time_total_s: 4129.648730993271
  timers:
    learn_throughput: 4803.899
    learn_time_ms: 9.992
    update_time_ms: 3.087
  timestamp: 1629284859
  timesteps_since_restore: 0
  timesteps_total: 289000
  training_iteration: 289
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    289 |          4129.65 | 289000 | 4.76082e+06 |          7.25484e+06 |             -198.044 |            8929.81 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 290000
  custom_metrics: {}
  date: 2021-08-18_11-07-53
  done: false
  episode_len_mean: 8929.8125
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4760817.417131055
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 32
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 289792
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 17.471006393432617
          max_q: 7254210.0
          mean_q: 302258.6875
          mean_td_error: -25.83807945251465
          min_q: -0.7809574007987976
        model: {}
        td_error: "[-1.66764677e-01 -2.48052537e-01  1.55644238e-01 -2.43893534e-01\n\
          \  2.45593727e-01 -1.77479088e-01 -3.43546599e-01 -6.24338388e-02\n  1.80849075e-01\
          \ -2.62934029e-01 -5.76642156e-03  3.40623766e-01\n -1.02682412e-02 -4.87107038e-03\
          \  2.23282218e-01 -5.50590754e-01\n -2.22425833e-01 -4.77470040e-01 -1.12249807e-01\
          \ -6.18500000e+02\n -3.13185632e-01 -1.90361530e-01  1.48468375e-01  9.91538465e-02\n\
          \ -8.66232067e-02 -2.89397269e-01 -1.20000571e-01  5.40446863e-02\n -3.16411287e-01\
          \ -6.18500000e+02  1.42836869e-01  2.13125944e-01\n  6.88973069e-02 -1.92476606e+00\
          \  3.36343497e-02 -1.67981446e-01\n  1.47215962e-01 -2.25601852e-01 -2.47599185e-03\
          \  1.05321527e-01\n  1.66648537e-01  4.86037016e-01  1.14678890e-01  1.95470333e-01\n\
          \  6.49836957e-02 -2.59432495e-02  2.54312754e-01 -1.17091306e-01]"
    num_agent_steps_sampled: 290000
    num_agent_steps_trained: 3468048
    num_steps_sampled: 290000
    num_steps_trained: 3468048
    num_target_updates: 574
  iterations_since_restore: 290
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.76842105263158
    ram_util_percent: 32.30526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924662002063314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.617097067676212
    mean_inference_ms: 1.5867271535637872
    mean_raw_obs_processing_ms: 0.143925290191165
  time_since_restore: 4142.487363815308
  time_this_iter_s: 12.838632822036743
  time_total_s: 4142.487363815308
  timers:
    learn_throughput: 4920.161
    learn_time_ms: 9.756
    update_time_ms: 2.694
  timestamp: 1629284873
  timesteps_since_restore: 0
  timesteps_total: 290000
  training_iteration: 290
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    290 |          4142.49 | 290000 | 4.76082e+06 |          7.25484e+06 |             -198.044 |            8929.81 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 291000
  custom_metrics: {}
  date: 2021-08-18_11-08-06
  done: false
  episode_len_mean: 8929.8125
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4760817.417131055
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 32
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 290800
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05886662378907204
          max_q: 1.4988255500793457
          mean_q: 0.1268128603696823
          mean_td_error: 0.04577105492353439
          min_q: -0.26669633388519287
        model: {}
        td_error: "[ 0.15411438  0.18695255 -0.1682429  -0.21631724  0.13127246 -0.54022574\n\
          \  0.20834708 -0.10434341 -0.00885361  0.16782102 -0.1552437   0.22207719\n\
          \  0.15154368  0.2313632  -0.11581052  0.0894483   0.03515589 -0.24612848\n\
          \  0.19413733  0.41105312 -0.561108    0.08875523  0.18530118  0.05896658\n\
          \ -0.04953419 -1.1876419  -0.15219441 -0.05660522  0.08222021  0.3173387\n\
          \  0.24185795 -0.22245997  0.15549827  0.33285373 -0.26670915  0.13592467\n\
          \ -0.1034158   0.628139   -0.09136842  0.18696994  0.02144905 -0.00177144\n\
          \  0.9445161   0.32765198 -0.25587058  0.16044885  0.53484946  0.11482818]"
    num_agent_steps_sampled: 291000
    num_agent_steps_trained: 3480048
    num_steps_sampled: 291000
    num_steps_trained: 3480048
    num_target_updates: 576
  iterations_since_restore: 291
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.978947368421046
    ram_util_percent: 32.30526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924662002063314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.617097067676212
    mean_inference_ms: 1.5867271535637872
    mean_raw_obs_processing_ms: 0.143925290191165
  time_since_restore: 4155.976228952408
  time_this_iter_s: 13.48886513710022
  time_total_s: 4155.976228952408
  timers:
    learn_throughput: 5086.934
    learn_time_ms: 9.436
    update_time_ms: 2.785
  timestamp: 1629284886
  timesteps_since_restore: 0
  timesteps_total: 291000
  training_iteration: 291
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    291 |          4155.98 | 291000 | 4.76082e+06 |          7.25484e+06 |             -198.044 |            8929.81 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 292000
  custom_metrics: {}
  date: 2021-08-18_11-08-20
  done: false
  episode_len_mean: 8929.8125
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4760817.417131055
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 32
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 291808
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.061687301844358444
          max_q: 3.466672658920288
          mean_q: -0.0672304630279541
          mean_td_error: -0.11473378539085388
          min_q: -0.43933993577957153
        model: {}
        td_error: "[ 0.4026488  -0.00911736 -0.20857476  0.05677474 -0.24932472  0.16976637\n\
          \ -0.13859281  0.6354024  -0.2692312  -0.29110032  0.17915085 -0.08905265\n\
          \ -1.6375692   0.52257305 -0.30409592 -0.57561255 -0.15803348 -0.11414184\n\
          \ -0.40423346  0.11134332  0.08310057  0.10122952  0.07401094 -1.6329558\n\
          \  0.30044168 -0.14309347  0.22937801 -0.29326922  0.15458646  0.06910285\n\
          \  0.00212157 -0.1883256   0.18304086 -0.07644278  0.18455622 -2.0041795\n\
          \ -0.1831066   0.20948559 -0.5047651  -0.17482035  0.28222144  0.29952747\n\
          \ -0.21469155 -0.03117257 -0.15104668 -0.10428913  0.17691422  0.21623969]"
    num_agent_steps_sampled: 292000
    num_agent_steps_trained: 3492048
    num_steps_sampled: 292000
    num_steps_trained: 3492048
    num_target_updates: 578
  iterations_since_restore: 292
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.273684210526305
    ram_util_percent: 32.30526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924662002063314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.617097067676212
    mean_inference_ms: 1.5867271535637872
    mean_raw_obs_processing_ms: 0.143925290191165
  time_since_restore: 4169.116544961929
  time_this_iter_s: 13.140316009521484
  time_total_s: 4169.116544961929
  timers:
    learn_throughput: 5006.02
    learn_time_ms: 9.588
    update_time_ms: 2.928
  timestamp: 1629284900
  timesteps_since_restore: 0
  timesteps_total: 292000
  training_iteration: 292
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    292 |          4169.12 | 292000 | 4.76082e+06 |          7.25484e+06 |             -198.044 |            8929.81 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 293000
  custom_metrics: {}
  date: 2021-08-18_11-08-34
  done: false
  episode_len_mean: 8929.8125
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4760817.417131055
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 32
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 292816
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04527568817138672
          max_q: 1.244188904762268
          mean_q: -0.12974300980567932
          mean_td_error: -0.10728573799133301
          min_q: -0.5679968595504761
        model: {}
        td_error: "[ 1.90487802e-01 -1.06803477e-01  3.96256894e-02 -1.89378589e-01\n\
          \ -3.25510055e-01 -5.41971326e-01  2.60529995e-01  4.04163480e-01\n -1.88901663e-01\
          \  8.46004486e-02  7.10355639e-02  3.14743847e-01\n -4.15842533e-02  5.55377603e-02\
          \  2.73956358e-02 -2.28619576e-03\n -1.70247704e-01  9.39810723e-02 -1.24725774e-01\
          \  1.81938171e-01\n  8.38786066e-02 -3.19483519e-01 -3.45021844e-01 -1.88648969e-01\n\
          \  6.05794191e-02  2.18273163e-01 -5.84833443e-01  6.80102557e-02\n -7.26527154e-01\
          \  1.17347956e-01 -8.26666132e-02  1.21649653e-01\n  1.03932217e-01  1.22888684e-01\
          \ -2.53570080e-03 -9.78127569e-02\n -2.79905945e-01  2.05670416e-01  2.78208852e-01\
          \  1.32414073e-01\n  3.10454130e-01 -1.52305484e-01 -2.91058570e-01 -3.78435349e+00\n\
          \ -4.17911947e-01 -1.01262331e-01  8.70506167e-02  2.81623781e-01]"
    num_agent_steps_sampled: 293000
    num_agent_steps_trained: 3504048
    num_steps_sampled: 293000
    num_steps_trained: 3504048
    num_target_updates: 580
  iterations_since_restore: 293
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.08571428571429
    ram_util_percent: 32.30476190476189
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924662002063314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.617097067676212
    mean_inference_ms: 1.5867271535637872
    mean_raw_obs_processing_ms: 0.143925290191165
  time_since_restore: 4183.362040519714
  time_this_iter_s: 14.245495557785034
  time_total_s: 4183.362040519714
  timers:
    learn_throughput: 4780.549
    learn_time_ms: 10.041
    update_time_ms: 2.894
  timestamp: 1629284914
  timesteps_since_restore: 0
  timesteps_total: 293000
  training_iteration: 293
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    293 |          4183.36 | 293000 | 4.76082e+06 |          7.25484e+06 |             -198.044 |            8929.81 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 294000
  custom_metrics: {}
  date: 2021-08-18_11-08-48
  done: false
  episode_len_mean: 8900.0
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4836387.823395375
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 293824
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10692758858203888
          max_q: 1.4109413623809814
          mean_q: -0.23219852149486542
          mean_td_error: 0.1013009175658226
          min_q: -0.5634731650352478
        model: {}
        td_error: "[ 0.20345578  0.30494326 -0.17685764  0.9789202   0.23354888  0.0864259\n\
          \  0.06249848  0.11976188  0.09783351  0.20329401  0.34781492  0.06002843\n\
          \  0.16937178  0.22925273  0.38390166  0.30998456 -0.40376228  0.19763857\n\
          \ -0.03350079 -0.47185016  0.25411123  0.5666116   0.27059835  0.1408466\n\
          \ -0.15461007  0.1962392   0.17187095 -0.06283855 -0.14183086  0.04088414\n\
          \  0.17029968 -0.0514411   0.16457534  0.20453805 -0.44395018 -0.2589144\n\
          \  0.25075328  0.4407028   0.31999886  0.07447702  0.02082795 -0.12544549\n\
          \  0.09941322 -0.89124197 -0.01080835  0.26734945  0.24922925  0.19749397]"
    num_agent_steps_sampled: 294000
    num_agent_steps_trained: 3516048
    num_steps_sampled: 294000
    num_steps_trained: 3516048
    num_target_updates: 582
  iterations_since_restore: 294
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.120000000000005
    ram_util_percent: 32.30499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924517080368564
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.646991541968835
    mean_inference_ms: 1.5868142630644297
    mean_raw_obs_processing_ms: 0.1439528949176967
  time_since_restore: 4196.785931348801
  time_this_iter_s: 13.423890829086304
  time_total_s: 4196.785931348801
  timers:
    learn_throughput: 4993.95
    learn_time_ms: 9.612
    update_time_ms: 2.859
  timestamp: 1629284928
  timesteps_since_restore: 0
  timesteps_total: 294000
  training_iteration: 294
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    294 |          4196.79 | 294000 | 4.83639e+06 |          7.25484e+06 |             -198.044 |               8900 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 295000
  custom_metrics: {}
  date: 2021-08-18_11-09-01
  done: false
  episode_len_mean: 8900.0
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4836387.823395375
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 33
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 294832
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.818558692932129
          max_q: 7253718.0
          mean_q: 151118.828125
          mean_td_error: -23.072673797607422
          min_q: -1.1562459468841553
        model: {}
        td_error: "[ 2.20343590e-01  9.59418714e-02  1.01131797e-01 -1.61139265e-01\n\
          \  4.15473819e-01  1.88900828e-01  3.83725405e-01 -2.40060389e-02\n -2.21633315e-02\
          \  1.63169265e-01 -2.42866516e-01 -1.52233928e-01\n -6.73768580e-01 -2.30918840e-01\
          \ -2.41616070e-01 -7.97078609e-02\n  6.18100762e-02  1.16618097e-01  2.08886027e-01\
          \  2.93357641e-01\n -4.46989536e-02  2.47007489e-01  3.50366831e-01 -2.87633508e-01\n\
          \  3.92085016e-02 -2.13285863e-01 -1.33455813e-01 -4.98592854e-03\n  1.89359248e-01\
          \  1.09803736e-01  1.16265416e-01 -1.18309058e-01\n  2.29751408e-01  5.49846888e-02\
          \ -1.46005958e-01  1.45398259e-01\n -1.90986753e-01 -2.25688219e-02 -1.59441054e-01\
          \  1.64543390e-01\n -5.20758867e-01 -2.75524020e-01 -9.79286432e-02  1.97676897e-01\n\
          \ -1.10800000e+03 -9.94199514e-02  1.27849877e-01  4.33752418e-01]"
    num_agent_steps_sampled: 295000
    num_agent_steps_trained: 3528048
    num_steps_sampled: 295000
    num_steps_trained: 3528048
    num_target_updates: 584
  iterations_since_restore: 295
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.07058823529412
    ram_util_percent: 32.305882352941175
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924517080368564
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.646991541968835
    mean_inference_ms: 1.5868142630644297
    mean_raw_obs_processing_ms: 0.1439528949176967
  time_since_restore: 4208.844340085983
  time_this_iter_s: 12.058408737182617
  time_total_s: 4208.844340085983
  timers:
    learn_throughput: 3110.377
    learn_time_ms: 15.432
    update_time_ms: 3.786
  timestamp: 1629284941
  timesteps_since_restore: 0
  timesteps_total: 295000
  training_iteration: 295
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.0/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    295 |          4208.84 | 295000 | 4.83639e+06 |          7.25484e+06 |             -198.044 |               8900 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 296000
  custom_metrics: {}
  date: 2021-08-18_11-09-12
  done: false
  episode_len_mean: 8900.0
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4836387.823395375
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 33
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 295840
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03137869015336037
          max_q: 2.5657236576080322
          mean_q: -0.24186980724334717
          mean_td_error: 0.00833048950880766
          min_q: -0.7925662398338318
        model: {}
        td_error: "[-0.10198522  0.18449318 -0.28167373 -0.02431968  0.4879508  -0.64221686\n\
          \  0.12882608 -0.56792045  0.16417521  0.06678092  0.38042104 -0.24584894\n\
          \ -0.05340797  0.08713138 -0.62235826 -0.04573819  0.24187666  0.7593105\n\
          \  0.02252415  0.06166112 -0.32990283 -0.08498847  0.2818926  -0.27621245\n\
          \  0.24418032  0.25050366  0.02571717  0.36616707  0.19775578 -0.10874093\n\
          \ -0.19956613  0.14417511  0.12036622  0.31188893 -0.23745199 -0.49004006\n\
          \  0.13303375 -0.29326653 -0.295197    0.30450696 -0.15042081  0.20735198\n\
          \  0.26223266 -0.18638599 -0.18913782 -0.155821    0.34548682  0.20205475]"
    num_agent_steps_sampled: 296000
    num_agent_steps_trained: 3540048
    num_steps_sampled: 296000
    num_steps_trained: 3540048
    num_target_updates: 586
  iterations_since_restore: 296
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.970588235294116
    ram_util_percent: 32.305882352941175
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924517080368564
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.646991541968835
    mean_inference_ms: 1.5868142630644297
    mean_raw_obs_processing_ms: 0.1439528949176967
  time_since_restore: 4220.333427429199
  time_this_iter_s: 11.489087343215942
  time_total_s: 4220.333427429199
  timers:
    learn_throughput: 4971.948
    learn_time_ms: 9.654
    update_time_ms: 2.711
  timestamp: 1629284952
  timesteps_since_restore: 0
  timesteps_total: 296000
  training_iteration: 296
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    296 |          4220.33 | 296000 | 4.83639e+06 |          7.25484e+06 |             -198.044 |               8900 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 297000
  custom_metrics: {}
  date: 2021-08-18_11-09-25
  done: false
  episode_len_mean: 8900.0
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4836387.823395375
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 33
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 296848
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 13.324713706970215
          max_q: 7253765.5
          mean_q: 453360.1875
          mean_td_error: -66.45391082763672
          min_q: -0.582815945148468
        model: {}
        td_error: "[-7.34546185e-02 -1.58828855e-01  1.15696609e-01  1.95486754e-01\n\
          \ -1.06200000e+03 -1.06200000e+03  8.64299536e-02  3.07250261e-01\n -2.55873084e-01\
          \ -8.86717081e-01 -3.00956726e-01  2.67230332e-01\n -1.60242647e-01  4.43481088e-01\
          \  2.06360281e-01 -1.31689477e+00\n -5.18704653e-02  6.87647462e-02  1.70772314e-01\
          \ -3.79985794e-02\n -1.83418125e-01 -5.21360338e-01  6.16226792e-02 -1.06200000e+03\n\
          \  7.82260299e-03 -3.91360074e-01 -4.33656752e-01  1.24944896e-01\n  1.36490792e-01\
          \ -1.31763697e-01 -9.93113890e-02  1.15163743e-01\n  2.37898350e-01 -2.75365591e-01\
          \  1.93158329e-01  5.85781932e-02\n  5.95727861e-01 -1.33890957e-01  2.56695449e-01\
          \  1.66468740e-01\n  8.72503519e-02 -1.20787096e+00 -2.24176466e-01 -1.14684391e+00\n\
          \  1.89118624e-01  5.07614493e-01 -1.32303834e-02 -3.82735550e-01]"
    num_agent_steps_sampled: 297000
    num_agent_steps_trained: 3552048
    num_steps_sampled: 297000
    num_steps_trained: 3552048
    num_target_updates: 588
  iterations_since_restore: 297
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.85000000000001
    ram_util_percent: 32.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924517080368564
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.646991541968835
    mean_inference_ms: 1.5868142630644297
    mean_raw_obs_processing_ms: 0.1439528949176967
  time_since_restore: 4232.239633798599
  time_this_iter_s: 11.906206369400024
  time_total_s: 4232.239633798599
  timers:
    learn_throughput: 4937.67
    learn_time_ms: 9.721
    update_time_ms: 2.809
  timestamp: 1629284965
  timesteps_since_restore: 0
  timesteps_total: 297000
  training_iteration: 297
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    297 |          4232.24 | 297000 | 4.83639e+06 |          7.25484e+06 |             -198.044 |               8900 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 298000
  custom_metrics: {}
  date: 2021-08-18_11-09-38
  done: false
  episode_len_mean: 8900.0
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4836387.823395375
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 33
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 297856
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04099016636610031
          max_q: 2.040973663330078
          mean_q: -0.25013482570648193
          mean_td_error: 0.008131983689963818
          min_q: -0.5813160538673401
        model: {}
        td_error: "[ 0.30789393  0.23096007  0.1907463  -0.01127099 -0.03059185  0.11785489\n\
          \ -0.15098178  0.03439775 -0.2673648   0.02821174 -0.12870044 -0.07428208\n\
          \  0.14439082  0.13340947  0.21337983  0.00318134 -0.18137005  0.03596646\n\
          \  0.20316082  0.28155226 -0.19397864  0.26065505 -0.18609264 -0.17471015\n\
          \ -0.08127755 -0.09809652 -0.22223094  0.1829463  -0.09121272  0.1501416\n\
          \ -0.31447217  0.11727184  0.15216255 -0.2451621  -0.02724522  0.26434052\n\
          \ -0.41701198  0.16122222  0.18991232 -0.26171014  0.1628258  -0.19463073\n\
          \ -0.12523681 -0.17897719  0.01960632  0.19967186  0.19092375  0.0701569 ]"
    num_agent_steps_sampled: 298000
    num_agent_steps_trained: 3564048
    num_steps_sampled: 298000
    num_steps_trained: 3564048
    num_target_updates: 590
  iterations_since_restore: 298
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.07777777777777
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924517080368564
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.646991541968835
    mean_inference_ms: 1.5868142630644297
    mean_raw_obs_processing_ms: 0.1439528949176967
  time_since_restore: 4245.1536638736725
  time_this_iter_s: 12.914030075073242
  time_total_s: 4245.1536638736725
  timers:
    learn_throughput: 5128.948
    learn_time_ms: 9.359
    update_time_ms: 2.821
  timestamp: 1629284978
  timesteps_since_restore: 0
  timesteps_total: 298000
  training_iteration: 298
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    298 |          4245.15 | 298000 | 4.83639e+06 |          7.25484e+06 |             -198.044 |               8900 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 299000
  custom_metrics: {}
  date: 2021-08-18_11-09-51
  done: false
  episode_len_mean: 8900.0
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4836387.823395375
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 33
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 298864
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.037087514996528625
          max_q: 2.752091407775879
          mean_q: -0.21365022659301758
          mean_td_error: -0.00632666889578104
          min_q: -0.592691957950592
        model: {}
        td_error: "[-0.07628676 -0.22223419  0.31865048  0.30223572 -0.37075046 -0.02478693\n\
          \ -0.01529357  0.05102831  0.01970039 -0.15354586  0.14281344 -0.22141144\n\
          \  0.6478474  -0.24584295  0.16676664  0.14944816  0.48812956 -0.35426164\n\
          \ -0.01503959 -0.24229996 -0.13189182  0.17314273 -0.45954472  0.06425825\n\
          \  0.02584743  0.01144692  0.13360107  0.19384092  0.48082435 -0.18189824\n\
          \ -0.24560103 -0.30833206 -0.28116286 -0.04015574 -0.08911338 -0.05573386\n\
          \ -0.08126239  0.1741932  -0.2460326   0.12457418 -0.08627951  0.04796055\n\
          \ -0.08996487 -0.09166679  0.4768409  -0.23607706  0.15292305 -0.08328365]"
    num_agent_steps_sampled: 299000
    num_agent_steps_trained: 3576048
    num_steps_sampled: 299000
    num_steps_trained: 3576048
    num_target_updates: 592
  iterations_since_restore: 299
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.25789473684211
    ram_util_percent: 32.30526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924517080368564
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.646991541968835
    mean_inference_ms: 1.5868142630644297
    mean_raw_obs_processing_ms: 0.1439528949176967
  time_since_restore: 4257.956571102142
  time_this_iter_s: 12.802907228469849
  time_total_s: 4257.956571102142
  timers:
    learn_throughput: 4188.013
    learn_time_ms: 11.461
    update_time_ms: 3.208
  timestamp: 1629284991
  timesteps_since_restore: 0
  timesteps_total: 299000
  training_iteration: 299
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    299 |          4257.96 | 299000 | 4.83639e+06 |          7.25484e+06 |             -198.044 |               8900 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 300000
  custom_metrics: {}
  date: 2021-08-18_11-10-07
  done: false
  episode_len_mean: 8900.0
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4836387.823395375
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 33
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 299872
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.051737185567617416
          max_q: 2.3816072940826416
          mean_q: -0.23297333717346191
          mean_td_error: 0.015882832929491997
          min_q: -0.5477762818336487
        model: {}
        td_error: "[-0.31392425 -0.10290393  0.30010724 -0.25607195  0.2750941   0.17669189\n\
          \  0.02522957 -0.3188277  -0.08624893 -0.00743908  0.05179596 -0.01495776\n\
          \  0.50467694  0.59210557  0.5051363   0.17483479 -0.18299302  0.15058008\n\
          \  0.16456181 -0.15931213  0.06840137  0.01363575  0.2478447  -0.16246401\n\
          \  0.19147545 -0.5400587   0.00875747  0.03628191 -0.21934757  0.13471562\n\
          \  0.30210406 -0.3117128  -0.41493118 -0.07581872 -0.41109586 -0.7862766\n\
          \  0.19183153  0.1578944   0.21245068  0.25413585  0.12960285  0.15634018\n\
          \  0.16003317  0.1948973   0.42846817 -0.44150627 -0.14331655 -0.09810179]"
    num_agent_steps_sampled: 300000
    num_agent_steps_trained: 3588048
    num_steps_sampled: 300000
    num_steps_trained: 3588048
    num_target_updates: 594
  iterations_since_restore: 300
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.64782608695651
    ram_util_percent: 32.3086956521739
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924517080368564
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.646991541968835
    mean_inference_ms: 1.5868142630644297
    mean_raw_obs_processing_ms: 0.1439528949176967
  time_since_restore: 4273.868494510651
  time_this_iter_s: 15.9119234085083
  time_total_s: 4273.868494510651
  timers:
    learn_throughput: 4941.852
    learn_time_ms: 9.713
    update_time_ms: 2.96
  timestamp: 1629285007
  timesteps_since_restore: 0
  timesteps_total: 300000
  training_iteration: 300
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    300 |          4273.87 | 300000 | 4.83639e+06 |          7.25484e+06 |             -198.044 |               8900 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 301000
  custom_metrics: {}
  date: 2021-08-18_11-10-21
  done: false
  episode_len_mean: 8835.176470588236
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4907513.065378537
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 300880
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 9.491713523864746
          max_q: 7255181.0
          mean_q: 302299.0625
          mean_td_error: 14.85308837890625
          min_q: -1.1547492742538452
        model: {}
        td_error: "[ 3.54500000e+02  6.32206500e-02  3.54500000e+02 -5.26476264e-01\n\
          \ -5.86329460e-01  3.23752761e-02  2.02145636e-01  2.87605107e-01\n  9.48311448e-01\
          \  1.69912457e-01 -3.47762585e-01  2.18081117e-01\n  1.76763415e-01 -3.18275690e-02\
          \ -1.21903151e-01  3.58861178e-01\n -1.76109284e-01  1.79193199e-01 -1.15094185e-02\
          \  2.87783563e-01\n -1.25631094e-01  7.33240247e-02  1.32325888e-02  1.77846014e-01\n\
          \  8.41185868e-01 -1.93324104e-01 -2.85486989e-02  3.75135541e-02\n  8.85717869e-02\
          \  3.45818281e-01  4.10037935e-02  3.99447083e-02\n  4.35971200e-01  2.06780136e-01\
          \  4.48327839e-01  1.27019972e-01\n  3.63707125e-01 -4.88160253e-02  8.07461739e-02\
          \  9.83190536e-03\n  3.51558149e-01  8.82906318e-02 -4.40088809e-02 -4.77974713e-02\n\
          \ -1.67004943e-01 -9.06508565e-02 -1.24381304e-01 -7.46104866e-02]"
    num_agent_steps_sampled: 301000
    num_agent_steps_trained: 3600048
    num_steps_sampled: 301000
    num_steps_trained: 3600048
    num_target_updates: 596
  iterations_since_restore: 301
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.16499999999999
    ram_util_percent: 32.30499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924380464621607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.674100768046243
    mean_inference_ms: 1.5869159758282034
    mean_raw_obs_processing_ms: 0.14397830472609158
  time_since_restore: 4287.0246324539185
  time_this_iter_s: 13.156137943267822
  time_total_s: 4287.0246324539185
  timers:
    learn_throughput: 4623.372
    learn_time_ms: 10.382
    update_time_ms: 3.046
  timestamp: 1629285021
  timesteps_since_restore: 0
  timesteps_total: 301000
  training_iteration: 301
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    301 |          4287.02 | 301000 | 4.90751e+06 |          7.25484e+06 |             -198.044 |            8835.18 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 302000
  custom_metrics: {}
  date: 2021-08-18_11-10-33
  done: false
  episode_len_mean: 8835.176470588236
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4907513.065378537
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 34
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 301888
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.88653039932251
          max_q: 7254408.5
          mean_q: 151133.53125
          mean_td_error: -8.67455005645752
          min_q: -0.5609999299049377
        model: {}
        td_error: "[ 1.28375739e-02 -3.68865848e-01  3.45668554e-01  3.08725119e-01\n\
          \  2.33300507e-01 -1.46934986e-02 -1.85970068e-02  3.10433924e-01\n  2.47768164e-01\
          \  4.62770760e-02  6.89675212e-02  2.36276031e-01\n -4.19000000e+02  2.87737429e-01\
          \ -5.52594662e-03  4.96562235e-02\n -1.87195539e-02 -1.05258644e-01 -2.38636181e-01\
          \ -1.29211873e-01\n  1.51807189e-01 -1.78584486e-01  1.37412608e-01 -2.89003104e-01\n\
          \  2.09911764e-01  1.09084815e-01 -1.44788325e-02  2.33498573e-01\n  1.43596977e-01\
          \  3.64671111e-01  1.79894388e-01  3.11572373e-01\n  1.90636039e-01 -1.18199158e+00\
          \  2.00894430e-01 -9.31208730e-02\n  2.21773386e-02 -4.59162474e-01  4.74843860e-01\
          \  2.95794964e-01\n  5.11039257e-01 -1.58418417e-01  1.66374207e-01 -4.10074592e-02\n\
          \  1.50592029e-01 -1.35470688e-01  5.29530048e-02  1.79629773e-02]"
    num_agent_steps_sampled: 302000
    num_agent_steps_trained: 3612048
    num_steps_sampled: 302000
    num_steps_trained: 3612048
    num_target_updates: 598
  iterations_since_restore: 302
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.61176470588236
    ram_util_percent: 32.305882352941175
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924380464621607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.674100768046243
    mean_inference_ms: 1.5869159758282034
    mean_raw_obs_processing_ms: 0.14397830472609158
  time_since_restore: 4298.70592212677
  time_this_iter_s: 11.681289672851562
  time_total_s: 4298.70592212677
  timers:
    learn_throughput: 4572.331
    learn_time_ms: 10.498
    update_time_ms: 3.233
  timestamp: 1629285033
  timesteps_since_restore: 0
  timesteps_total: 302000
  training_iteration: 302
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    302 |          4298.71 | 302000 | 4.90751e+06 |          7.25484e+06 |             -198.044 |            8835.18 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 303000
  custom_metrics: {}
  date: 2021-08-18_11-10-45
  done: false
  episode_len_mean: 8835.176470588236
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4907513.065378537
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 34
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 302896
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03451165929436684
          max_q: 0.5462940335273743
          mean_q: -0.4016827940940857
          mean_td_error: 0.04104390740394592
          min_q: -0.7315783500671387
        model: {}
        td_error: "[ 0.05880505  0.18504608  0.47223157  0.04444629 -0.0888114  -0.02182737\n\
          \  0.16448575  0.16307962 -0.13060173  0.23260996  0.10304677  0.21445149\n\
          \  0.08002827 -0.2630524   0.16869193  0.01573482  0.06965575 -0.21488607\n\
          \  0.03733569  0.19675583 -0.14301991  0.14003557  0.1520353   0.0654974\n\
          \  0.19965956  0.3300475  -0.09406134 -0.06191835 -0.29938     0.06260175\n\
          \  0.18617642 -0.18315068  0.1757943  -0.23788446  0.26434088 -0.16366947\n\
          \ -0.15566841  0.22333354 -0.21402091 -0.18595576 -0.16103542 -0.12388074\n\
          \ -0.21211642 -0.33315375  0.3900565   0.2941433   0.22006291  0.3480124 ]"
    num_agent_steps_sampled: 303000
    num_agent_steps_trained: 3624048
    num_steps_sampled: 303000
    num_steps_trained: 3624048
    num_target_updates: 600
  iterations_since_restore: 303
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.16470588235292
    ram_util_percent: 32.3
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924380464621607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.674100768046243
    mean_inference_ms: 1.5869159758282034
    mean_raw_obs_processing_ms: 0.14397830472609158
  time_since_restore: 4310.862986326218
  time_this_iter_s: 12.157064199447632
  time_total_s: 4310.862986326218
  timers:
    learn_throughput: 4928.062
    learn_time_ms: 9.74
    update_time_ms: 2.796
  timestamp: 1629285045
  timesteps_since_restore: 0
  timesteps_total: 303000
  training_iteration: 303
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    303 |          4310.86 | 303000 | 4.90751e+06 |          7.25484e+06 |             -198.044 |            8835.18 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 304000
  custom_metrics: {}
  date: 2021-08-18_11-10-58
  done: false
  episode_len_mean: 8835.176470588236
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4907513.065378537
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 34
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 303904
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05798554793000221
          max_q: 2.36783504486084
          mean_q: -0.28918835520744324
          mean_td_error: -0.06196283921599388
          min_q: -0.7633746862411499
        model: {}
        td_error: "[ 0.14943379 -0.18231705 -0.35120586  0.268135    0.3363486  -0.29615325\n\
          \ -0.34861088  0.03154206  0.05391511  0.11383307  0.34658617 -0.00664347\n\
          \ -0.33583835  0.18204522 -0.12215117 -0.25126922 -0.03350142  0.0547592\n\
          \ -0.09049463  0.4336272   0.03591835  0.0123862   0.10031694 -0.25534028\n\
          \  0.35802352  0.10357621  0.07969001 -0.12785     0.11782953 -0.21250474\n\
          \  0.22987872 -0.03276438  0.09948164  0.08423889 -0.4360181   0.10085738\n\
          \ -0.01231748 -1.9772274   0.33127815 -0.31606516 -0.3924694   0.3096171\n\
          \ -0.13998562 -0.19228782 -0.27246046 -0.04591703 -0.31195927 -0.16418195]"
    num_agent_steps_sampled: 304000
    num_agent_steps_trained: 3636048
    num_steps_sampled: 304000
    num_steps_trained: 3636048
    num_target_updates: 602
  iterations_since_restore: 304
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.42777777777778
    ram_util_percent: 32.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924380464621607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.674100768046243
    mean_inference_ms: 1.5869159758282034
    mean_raw_obs_processing_ms: 0.14397830472609158
  time_since_restore: 4322.983450651169
  time_this_iter_s: 12.120464324951172
  time_total_s: 4322.983450651169
  timers:
    learn_throughput: 4865.7
    learn_time_ms: 9.865
    update_time_ms: 2.854
  timestamp: 1629285058
  timesteps_since_restore: 0
  timesteps_total: 304000
  training_iteration: 304
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    304 |          4322.98 | 304000 | 4.90751e+06 |          7.25484e+06 |             -198.044 |            8835.18 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 305000
  custom_metrics: {}
  date: 2021-08-18_11-11-11
  done: false
  episode_len_mean: 8835.176470588236
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4907513.065378537
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 34
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 304912
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.046199481934309006
          max_q: -0.03167039155960083
          mean_q: -0.4735468327999115
          mean_td_error: -0.03539804369211197
          min_q: -0.8987946510314941
        model: {}
        td_error: "[ 0.02366799 -0.3005343   0.20206195 -0.14682615  0.2558276   0.19705302\n\
          \ -0.3127844  -0.07084292  0.00508821 -0.21113464 -0.12427798 -0.33743727\n\
          \  0.19480097 -0.4566096   0.3473304  -0.29493994 -0.06105179 -0.10302749\n\
          \  0.2491836  -0.2654417   0.25840634 -0.2996214  -0.06902134 -0.02354628\n\
          \  0.30821568  0.20899594 -0.37444288 -1.0147258   0.01334041  0.06900555\n\
          \  0.09919125 -0.22904468  0.10566491  0.16106123  0.06244656  0.09146482\n\
          \  0.15941882 -0.05662775  0.16225559  0.17454666 -0.31224632  0.13292521\n\
          \  0.1485104   0.09121716 -0.06556505 -0.2755648   0.14201123 -0.15748313]"
    num_agent_steps_sampled: 305000
    num_agent_steps_trained: 3648048
    num_steps_sampled: 305000
    num_steps_trained: 3648048
    num_target_updates: 604
  iterations_since_restore: 305
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.05263157894737
    ram_util_percent: 32.30526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924380464621607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.674100768046243
    mean_inference_ms: 1.5869159758282034
    mean_raw_obs_processing_ms: 0.14397830472609158
  time_since_restore: 4335.9788501262665
  time_this_iter_s: 12.995399475097656
  time_total_s: 4335.9788501262665
  timers:
    learn_throughput: 4775.933
    learn_time_ms: 10.05
    update_time_ms: 3.07
  timestamp: 1629285071
  timesteps_since_restore: 0
  timesteps_total: 305000
  training_iteration: 305
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    305 |          4335.98 | 305000 | 4.90751e+06 |          7.25484e+06 |             -198.044 |            8835.18 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 306000
  custom_metrics: {}
  date: 2021-08-18_11-11-25
  done: false
  episode_len_mean: 8835.176470588236
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4907513.065378537
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 34
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 305920
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.466909885406494
          max_q: 7254188.5
          mean_q: 151128.546875
          mean_td_error: -13.299234390258789
          min_q: -0.8048895597457886
        model: {}
        td_error: "[-7.4751377e-02  2.0066410e-01  3.0602914e-01  4.8045504e-01\n -1.3091850e-01\
          \ -5.2988410e-02 -2.8820539e-01  9.2366636e-02\n  2.7917087e-01  2.4168932e-01\
          \ -5.5513024e-02 -3.5022795e-02\n  4.1878819e-03  3.2991081e-01  1.3951647e-01\
          \ -7.2237074e-02\n -4.0773213e-01 -3.5231817e-01 -6.7200959e-03  1.1956608e-01\n\
          \  1.4657821e-01 -1.3217881e-01 -5.2271008e-02  8.8576227e-02\n  1.0668936e-01\
          \  1.4420861e-01 -6.3850000e+02  2.2409481e-01\n -3.2346466e-01 -2.1105587e-01\
          \ -8.5788429e-02  1.8969285e-01\n -1.3027025e+00  1.5007675e-01 -4.8021376e-02\
          \ -1.9948159e-01\n  2.2815603e-01  1.4764071e-01 -1.8194857e-01  8.2229370e-01\n\
          \ -1.9819349e-01  1.3230962e-01 -4.0151078e-01 -1.6377687e-02\n  3.0669034e-02\
          \ -1.7464757e-03  1.6793948e-01 -4.5836270e-03]"
    num_agent_steps_sampled: 306000
    num_agent_steps_trained: 3660048
    num_steps_sampled: 306000
    num_steps_trained: 3660048
    num_target_updates: 606
  iterations_since_restore: 306
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.225
    ram_util_percent: 32.30499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924380464621607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.674100768046243
    mean_inference_ms: 1.5869159758282034
    mean_raw_obs_processing_ms: 0.14397830472609158
  time_since_restore: 4349.547621011734
  time_this_iter_s: 13.56877088546753
  time_total_s: 4349.547621011734
  timers:
    learn_throughput: 4787.62
    learn_time_ms: 10.026
    update_time_ms: 2.84
  timestamp: 1629285085
  timesteps_since_restore: 0
  timesteps_total: 306000
  training_iteration: 306
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    306 |          4349.55 | 306000 | 4.90751e+06 |          7.25484e+06 |             -198.044 |            8835.18 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 307000
  custom_metrics: {}
  date: 2021-08-18_11-11-39
  done: false
  episode_len_mean: 8835.176470588236
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4907513.065378537
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 34
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 306928
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06098072975873947
          max_q: 5.683544635772705
          mean_q: -0.38947996497154236
          mean_td_error: -0.05760672688484192
          min_q: -0.8113027215003967
        model: {}
        td_error: "[-0.21235399  0.9733739   0.15312433 -0.15032339 -0.44104835 -0.01419765\n\
          \  0.18216074  0.17130601  0.35539    -0.27247104 -0.35438085 -0.32106394\n\
          \  0.04157336 -0.20887303  0.08396924 -0.01827151 -0.16928324 -0.12977687\n\
          \ -0.266147    0.2841823   0.22726132 -0.21508557 -0.19914806  0.3197093\n\
          \  0.3044209  -0.1475823   0.44117856  0.06974924  0.08810735  0.14508194\n\
          \ -0.06143576 -0.23891693 -0.6395584  -0.22398329 -0.08152655 -0.12412328\n\
          \ -0.15369093 -0.42340696  0.07444483 -0.15407217 -0.7386014  -0.16038847\n\
          \  0.17256153  0.1682626  -0.39467293 -0.39648992 -0.09289193 -0.01721489]"
    num_agent_steps_sampled: 307000
    num_agent_steps_trained: 3672048
    num_steps_sampled: 307000
    num_steps_trained: 3672048
    num_target_updates: 608
  iterations_since_restore: 307
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.595000000000006
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924380464621607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.674100768046243
    mean_inference_ms: 1.5869159758282034
    mean_raw_obs_processing_ms: 0.14397830472609158
  time_since_restore: 4363.151326417923
  time_this_iter_s: 13.603705406188965
  time_total_s: 4363.151326417923
  timers:
    learn_throughput: 5089.866
    learn_time_ms: 9.431
    update_time_ms: 2.785
  timestamp: 1629285099
  timesteps_since_restore: 0
  timesteps_total: 307000
  training_iteration: 307
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    307 |          4363.15 | 307000 | 4.90751e+06 |          7.25484e+06 |             -198.044 |            8835.18 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 308000
  custom_metrics: {}
  date: 2021-08-18_11-11-54
  done: false
  episode_len_mean: 8835.176470588236
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4907513.065378537
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 34
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 307936
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03616214916110039
          max_q: 1.6364820003509521
          mean_q: -0.4805704355239868
          mean_td_error: 0.030147477984428406
          min_q: -1.0610694885253906
        model: {}
        td_error: "[ 0.17376488 -0.11354199  0.2808805   0.08223816 -0.13981831 -0.19684076\n\
          \ -0.51909965  0.10908145  0.08594322  0.24709803 -0.24582508  0.11086416\n\
          \ -0.15310764 -0.08530307  0.2860615   0.0517742   0.43614924  0.1567558\n\
          \ -0.11838913  0.16222489  0.14898807  0.17538565 -0.22214639  0.03600174\n\
          \  0.06683022  0.605619    0.02165771 -0.05248117 -0.2179482  -0.08638263\n\
          \ -0.24838299  0.20816928  0.15261132  0.18812913 -0.04036838 -0.06593353\n\
          \  0.25983006  0.05061007  0.13114357  0.07719699 -0.15866554  0.33193427\n\
          \  0.05269763 -0.36222827 -0.16945773 -0.07340077  0.01780409  0.00895542]"
    num_agent_steps_sampled: 308000
    num_agent_steps_trained: 3684048
    num_steps_sampled: 308000
    num_steps_trained: 3684048
    num_target_updates: 610
  iterations_since_restore: 308
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.03333333333333
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924380464621607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.674100768046243
    mean_inference_ms: 1.5869159758282034
    mean_raw_obs_processing_ms: 0.14397830472609158
  time_since_restore: 4377.710471868515
  time_this_iter_s: 14.559145450592041
  time_total_s: 4377.710471868515
  timers:
    learn_throughput: 4870.608
    learn_time_ms: 9.855
    update_time_ms: 2.852
  timestamp: 1629285114
  timesteps_since_restore: 0
  timesteps_total: 308000
  training_iteration: 308
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    308 |          4377.71 | 308000 | 4.90751e+06 |          7.25484e+06 |             -198.044 |            8835.18 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 309000
  custom_metrics: {}
  date: 2021-08-18_11-12-06
  done: false
  episode_len_mean: 8808.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4974574.197332795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 308944
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05563991889357567
          max_q: 0.36473286151885986
          mean_q: -0.6502700448036194
          mean_td_error: -0.07249787449836731
          min_q: -0.939517080783844
        model: {}
        td_error: "[ 0.16516191  0.10554761  0.21685565 -0.3280396  -0.30990332 -0.8158921\n\
          \ -0.4277168   0.20299226 -0.18535006 -0.23251456 -0.11434788  0.2411775\n\
          \ -0.5256456  -0.22474879 -0.22212005  0.14920461 -0.01591682  0.17879564\n\
          \  0.00668666 -0.07742184  0.0164414   0.20285144 -0.02315199 -0.17720369\n\
          \ -0.22317618 -0.17972618 -0.04120445 -0.11632788  0.02901208  0.02182508\n\
          \ -0.0760178   0.07879692 -0.27717072 -0.12007463  0.20879257 -0.05397099\n\
          \  0.1905021   0.07331359 -0.11115253 -0.7066781  -0.00351554 -0.27913713\n\
          \  0.32307756 -0.27200902 -0.0014931   0.29595625 -0.03824091 -0.00702059]"
    num_agent_steps_sampled: 309000
    num_agent_steps_trained: 3696048
    num_steps_sampled: 309000
    num_steps_trained: 3696048
    num_target_updates: 612
  iterations_since_restore: 309
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.34444444444445
    ram_util_percent: 32.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924217749779597
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.698576706660724
    mean_inference_ms: 1.5870071812596382
    mean_raw_obs_processing_ms: 0.14400152250403167
  time_since_restore: 4389.617754459381
  time_this_iter_s: 11.907282590866089
  time_total_s: 4389.617754459381
  timers:
    learn_throughput: 5033.656
    learn_time_ms: 9.536
    update_time_ms: 2.756
  timestamp: 1629285126
  timesteps_since_restore: 0
  timesteps_total: 309000
  training_iteration: 309
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    309 |          4389.62 | 309000 | 4.97457e+06 |          7.25484e+06 |             -198.044 |             8808.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 310000
  custom_metrics: {}
  date: 2021-08-18_11-12-18
  done: false
  episode_len_mean: 8808.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4974574.197332795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 35
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 309952
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 13.212276458740234
          max_q: 7255076.5
          mean_q: 302294.375
          mean_td_error: 10.399506568908691
          min_q: -0.9226751327514648
        model: {}
        td_error: "[ 7.91593790e-02  2.03065157e-01 -3.36955428e-01  2.29312837e-01\n\
          \ -6.63671315e-01  7.55919218e-02 -3.53838235e-01  1.60291731e-01\n  4.11256969e-01\
          \  6.60443306e-03  1.37088895e-02  1.23833656e-01\n  4.04130697e-01 -2.06026912e-01\
          \ -1.85646832e-01 -1.39949417e+00\n  1.54314220e-01  1.04997173e-01  3.45863104e-02\
          \  2.52825558e-01\n  7.07792044e-02 -3.82922888e-02  3.20393801e-01 -1.39638484e-01\n\
          \  6.17544055e-02 -6.43360138e-01  3.46658826e-02 -8.37568820e-01\n  2.51000000e+02\
          \  1.47726655e-01  1.03114128e-01  2.55766451e-01\n  3.43141019e-01  1.92082644e-01\
          \ -7.01664090e-02 -2.36709565e-01\n -6.94972336e-01  1.75931811e-01 -1.85129493e-01\
          \ -9.41353858e-01\n -1.06405854e-01 -3.64485383e-02  8.04734230e-02  3.49032104e-01\n\
          \  2.09543705e-02  3.83432508e-02  2.51000000e+02 -1.95858479e-01]"
    num_agent_steps_sampled: 310000
    num_agent_steps_trained: 3708048
    num_steps_sampled: 310000
    num_steps_trained: 3708048
    num_target_updates: 614
  iterations_since_restore: 310
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.231249999999996
    ram_util_percent: 32.30625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924217749779597
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.698576706660724
    mean_inference_ms: 1.5870071812596382
    mean_raw_obs_processing_ms: 0.14400152250403167
  time_since_restore: 4400.783968925476
  time_this_iter_s: 11.16621446609497
  time_total_s: 4400.783968925476
  timers:
    learn_throughput: 4853.535
    learn_time_ms: 9.89
    update_time_ms: 2.77
  timestamp: 1629285138
  timesteps_since_restore: 0
  timesteps_total: 310000
  training_iteration: 310
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    310 |          4400.78 | 310000 | 4.97457e+06 |          7.25484e+06 |             -198.044 |             8808.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 311000
  custom_metrics: {}
  date: 2021-08-18_11-12-30
  done: false
  episode_len_mean: 8808.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4974574.197332795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 35
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 310960
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04508070647716522
          max_q: 1.0035135746002197
          mean_q: -0.47408995032310486
          mean_td_error: 0.034391917288303375
          min_q: -0.9766823649406433
        model: {}
        td_error: "[ 0.16015577 -0.05919051  0.30473375  0.09628898 -0.1983453  -0.00530982\n\
          \  0.12767583 -0.16168457  0.22589283 -0.06971186 -0.7729198  -0.05852872\n\
          \ -0.00677395 -0.07386394  0.23946345 -0.14501923 -0.05943671 -0.03359902\n\
          \ -0.1832478   0.2087239   0.11321193  0.18136716 -0.14031398  0.40138847\n\
          \  0.05986753  0.26722592  0.33742297 -0.16076809 -0.28880686  0.25950736\n\
          \  0.08030492  0.21256036  0.23004717  0.15557015  0.21004307 -0.20719898\n\
          \  0.11001432 -0.3761254   0.16157472  0.383878   -0.1720503   0.04750407\n\
          \  0.19379383 -0.11415988  0.15430573 -0.09167635  0.09738231  0.00963855]"
    num_agent_steps_sampled: 311000
    num_agent_steps_trained: 3720048
    num_steps_sampled: 311000
    num_steps_trained: 3720048
    num_target_updates: 616
  iterations_since_restore: 311
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 67.30588235294118
    ram_util_percent: 32.311764705882354
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924217749779597
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.698576706660724
    mean_inference_ms: 1.5870071812596382
    mean_raw_obs_processing_ms: 0.14400152250403167
  time_since_restore: 4412.506331682205
  time_this_iter_s: 11.722362756729126
  time_total_s: 4412.506331682205
  timers:
    learn_throughput: 4188.893
    learn_time_ms: 11.459
    update_time_ms: 3.367
  timestamp: 1629285150
  timesteps_since_restore: 0
  timesteps_total: 311000
  training_iteration: 311
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    311 |          4412.51 | 311000 | 4.97457e+06 |          7.25484e+06 |             -198.044 |             8808.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 312000
  custom_metrics: {}
  date: 2021-08-18_11-12-42
  done: false
  episode_len_mean: 8808.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4974574.197332795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 35
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 311968
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.727858066558838
          max_q: 7254476.0
          mean_q: 151134.6875
          mean_td_error: -7.359979629516602
          min_q: -1.7073290348052979
        model: {}
        td_error: "[-1.96814835e-01  2.26798952e-01  2.19710231e-01  5.89340568e-01\n\
          \ -5.05247772e-01 -4.02676553e-01  8.55209231e-02 -1.23782516e-01\n -2.06188023e-01\
          \ -2.09729791e-01 -4.74133939e-02 -2.90720731e-01\n  3.60660553e-02 -2.47848064e-01\
          \ -4.20626640e-01 -3.38176191e-01\n -3.84503961e-01  8.99316072e-02 -3.12933505e-01\
          \  8.57936442e-02\n -1.26631796e-01  1.09509885e-01  1.75560474e-01 -5.96455336e-02\n\
          \ -1.93402946e-01  3.56339216e-02 -3.42426896e-02  3.48696709e-02\n  4.71013784e-03\
          \  1.85329914e-02  2.27707505e-01 -1.51437700e-01\n -2.92873800e-01 -1.82423830e-01\
          \ -1.78985894e-01 -2.59100199e-02\n -5.70757985e-01  2.67157555e-02 -1.65711820e-01\
          \ -3.88124108e-01\n -1.29604369e-01 -3.49500000e+02  2.04273999e-01 -3.47855747e-01\n\
          \  5.94138503e-02  5.83063900e-01  3.85419726e-02 -9.64452624e-02]"
    num_agent_steps_sampled: 312000
    num_agent_steps_trained: 3732048
    num_steps_sampled: 312000
    num_steps_trained: 3732048
    num_target_updates: 618
  iterations_since_restore: 312
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.92777777777778
    ram_util_percent: 32.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924217749779597
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.698576706660724
    mean_inference_ms: 1.5870071812596382
    mean_raw_obs_processing_ms: 0.14400152250403167
  time_since_restore: 4424.375652551651
  time_this_iter_s: 11.8693208694458
  time_total_s: 4424.375652551651
  timers:
    learn_throughput: 4923.602
    learn_time_ms: 9.749
    update_time_ms: 2.791
  timestamp: 1629285162
  timesteps_since_restore: 0
  timesteps_total: 312000
  training_iteration: 312
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    312 |          4424.38 | 312000 | 4.97457e+06 |          7.25484e+06 |             -198.044 |             8808.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 313000
  custom_metrics: {}
  date: 2021-08-18_11-12-55
  done: false
  episode_len_mean: 8808.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4974574.197332795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 35
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 312976
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05930003151297569
          max_q: 3.1917052268981934
          mean_q: -0.31389370560646057
          mean_td_error: 0.05556977912783623
          min_q: -0.9639506340026855
        model: {}
        td_error: "[-0.21570706 -0.09871693  0.3811006   1.6654072  -0.25670362 -0.2771771\n\
          \ -0.01507688  0.06308961 -0.11942324  0.2751274  -0.14493656 -0.11400157\n\
          \ -0.11919266  0.2639358   0.2659167  -0.13004941 -0.07868785  0.4276393\n\
          \  0.3889414   0.14149183  0.1819632  -0.16971815 -0.18982503  0.27679288\n\
          \  0.1779139   0.28615433  0.0802106  -0.18671882  0.27449256 -0.0327151\n\
          \  0.23975146  0.24283946 -0.6910552  -0.14062092  0.03884739 -0.16493946\n\
          \  0.2848873  -0.1185047   0.2822786   0.25223172 -0.23782873  0.24331963\n\
          \ -0.1952877   0.09370935 -0.33673704  0.17340964  0.11406362 -0.41454253]"
    num_agent_steps_sampled: 313000
    num_agent_steps_trained: 3744048
    num_steps_sampled: 313000
    num_steps_trained: 3744048
    num_target_updates: 620
  iterations_since_restore: 313
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.86666666666666
    ram_util_percent: 32.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924217749779597
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.698576706660724
    mean_inference_ms: 1.5870071812596382
    mean_raw_obs_processing_ms: 0.14400152250403167
  time_since_restore: 4436.663102149963
  time_this_iter_s: 12.287449598312378
  time_total_s: 4436.663102149963
  timers:
    learn_throughput: 4835.862
    learn_time_ms: 9.926
    update_time_ms: 2.825
  timestamp: 1629285175
  timesteps_since_restore: 0
  timesteps_total: 313000
  training_iteration: 313
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    313 |          4436.66 | 313000 | 4.97457e+06 |          7.25484e+06 |             -198.044 |             8808.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 314000
  custom_metrics: {}
  date: 2021-08-18_11-13-08
  done: false
  episode_len_mean: 8808.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4974574.197332795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 35
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 313984
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 11.566307067871094
          max_q: 7255951.0
          mean_q: 302331.1875
          mean_td_error: 46.898738861083984
          min_q: -1.0491259098052979
        model: {}
        td_error: "[ 3.3164668e-01 -8.1186891e-03 -9.2905760e-02 -7.9650342e-02\n  2.3349613e-01\
          \  1.5910256e-01 -7.4527806e-01 -1.2755185e-02\n -2.5514019e-01 -1.3004807e-01\
          \  1.2888753e-01  1.6147232e-01\n  8.4924877e-01  3.7668306e-01  1.7027557e-03\
          \ -3.9657128e-01\n -7.5295627e-02 -2.2362596e-01  3.9384490e-01  4.8165619e-02\n\
          \ -6.4641833e-03 -3.9900243e-02  8.2979739e-02  1.9878447e-02\n  2.4391741e-01\
          \  6.3638854e-01  3.4913373e-01 -1.3965312e-01\n  8.2887173e-02  2.2076628e-01\
          \ -1.7914030e-01 -4.4922495e-01\n -4.1600579e-01  1.1250000e+03  9.5851612e-01\
          \  7.4462891e-02\n  2.9091680e-01  1.1250000e+03 -3.9261368e-01 -5.1906973e-02\n\
          \ -1.5745771e-01  3.1534970e-01  3.1545806e-01  1.8383640e-01\n -1.3164788e-01\
          \ -5.5536938e-01 -5.3864300e-01 -2.4197614e-01]"
    num_agent_steps_sampled: 314000
    num_agent_steps_trained: 3756048
    num_steps_sampled: 314000
    num_steps_trained: 3756048
    num_target_updates: 622
  iterations_since_restore: 314
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.79473684210525
    ram_util_percent: 32.30526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924217749779597
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.698576706660724
    mean_inference_ms: 1.5870071812596382
    mean_raw_obs_processing_ms: 0.14400152250403167
  time_since_restore: 4449.6004021167755
  time_this_iter_s: 12.937299966812134
  time_total_s: 4449.6004021167755
  timers:
    learn_throughput: 5030.524
    learn_time_ms: 9.542
    update_time_ms: 2.728
  timestamp: 1629285188
  timesteps_since_restore: 0
  timesteps_total: 314000
  training_iteration: 314
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    314 |           4449.6 | 314000 | 4.97457e+06 |          7.25484e+06 |             -198.044 |             8808.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 315000
  custom_metrics: {}
  date: 2021-08-18_11-13-21
  done: false
  episode_len_mean: 8808.4
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 4974574.197332795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 35
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 314992
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0658843144774437
          max_q: 1.3139348030090332
          mean_q: -0.37125295400619507
          mean_td_error: -0.11218807101249695
          min_q: -0.9740210771560669
        model: {}
        td_error: "[-0.15455653 -0.21033397  0.2164194  -0.43717068 -0.34559885 -0.44906446\n\
          \  0.01220152  0.27147046  0.36378604 -0.1831426  -0.2269499  -0.21097097\n\
          \  0.14411658  0.56956196  0.47443712 -0.23016477  0.01499647 -0.9380284\n\
          \ -0.16330984 -0.10233404 -0.22904384 -0.19890577 -0.18325266 -0.24911821\n\
          \ -0.1395747  -0.12729383 -2.534289    0.31863612  0.1466071  -0.1949367\n\
          \ -0.3677066  -0.4020117   0.34080058 -0.14675397 -0.193901   -0.25549084\n\
          \  0.34770435  0.07991439 -0.21788403 -0.21991101 -0.09832671  0.15609759\n\
          \  0.25877303 -0.31326622  0.29756248  0.11891842  0.16464627  0.04161444]"
    num_agent_steps_sampled: 315000
    num_agent_steps_trained: 3768048
    num_steps_sampled: 315000
    num_steps_trained: 3768048
    num_target_updates: 624
  iterations_since_restore: 315
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.86842105263159
    ram_util_percent: 32.31052631578947
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924217749779597
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.698576706660724
    mean_inference_ms: 1.5870071812596382
    mean_raw_obs_processing_ms: 0.14400152250403167
  time_since_restore: 4462.829052448273
  time_this_iter_s: 13.228650331497192
  time_total_s: 4462.829052448273
  timers:
    learn_throughput: 4997.756
    learn_time_ms: 9.604
    update_time_ms: 2.752
  timestamp: 1629285201
  timesteps_since_restore: 0
  timesteps_total: 315000
  training_iteration: 315
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    315 |          4462.83 | 315000 | 4.97457e+06 |          7.25484e+06 |             -198.044 |             8808.4 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 316000
  custom_metrics: {}
  date: 2021-08-18_11-13-33
  done: false
  episode_len_mean: 8753.277777777777
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5037909.885496192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 316000
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05933742970228195
          max_q: 2.775561809539795
          mean_q: -0.36198484897613525
          mean_td_error: 0.07808060944080353
          min_q: -0.849686324596405
        model: {}
        td_error: "[ 0.32233447  0.11598313  0.26888442 -0.18807271 -0.17961845  0.10098833\n\
          \  0.12279308 -0.16448559 -0.27389395  0.17261672  0.39127493  0.2039823\n\
          \  0.3191116   0.08891976  0.07300156  0.01591152  0.17421806  0.17856348\n\
          \ -0.04873133  0.0453341   0.11723882  0.23224401  0.16229725  0.04687846\n\
          \ -0.03828695 -0.08262539 -0.14213279  0.19079876 -0.12417018  0.32172382\n\
          \  0.34006494 -0.16577959  0.12841642  0.23285002  0.20241982  0.27522135\n\
          \ -0.01372084 -0.10580671  0.35162354 -0.05178937  0.28250664  0.19588786\n\
          \ -0.26514518 -0.30417475  0.11260036  0.04909772 -0.03293798  0.09345353]"
    num_agent_steps_sampled: 316000
    num_agent_steps_trained: 3780048
    num_steps_sampled: 316000
    num_steps_trained: 3780048
    num_target_updates: 626
  iterations_since_restore: 316
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.181250000000006
    ram_util_percent: 32.3
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924068858636689
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7203980731629
    mean_inference_ms: 1.587091616064554
    mean_raw_obs_processing_ms: 0.1440210379727203
  time_since_restore: 4473.943097114563
  time_this_iter_s: 11.114044666290283
  time_total_s: 4473.943097114563
  timers:
    learn_throughput: 4993.566
    learn_time_ms: 9.612
    update_time_ms: 2.754
  timestamp: 1629285213
  timesteps_since_restore: 0
  timesteps_total: 316000
  training_iteration: 316
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    316 |          4473.94 | 316000 | 5.03791e+06 |          7.25484e+06 |             -198.044 |            8753.28 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 317000
  custom_metrics: {}
  date: 2021-08-18_11-13-45
  done: false
  episode_len_mean: 8753.277777777777
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5037909.885496192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 36
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 316504
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03903648257255554
          max_q: 4.400773525238037
          mean_q: -0.1883382797241211
          mean_td_error: 0.017604447901248932
          min_q: -0.8172116875648499
        model: {}
        td_error: "[ 0.20548195  0.08386713 -0.31040525  0.25366753  0.07367897 -0.02396372\n\
          \ -0.24197254 -0.08440149 -0.3260614   0.11771858  0.00190467  0.16381627\n\
          \  0.22797555  0.501927    0.09938884  0.23066294 -0.01722109 -0.01038384\n\
          \ -0.17738608 -0.55627054 -0.18189633 -0.18923885  0.20036066 -0.04253206\n\
          \ -0.2545677   0.15038747  0.42437094  0.1729846  -0.13930708  0.11749262\n\
          \  0.2538818   0.13410169 -0.11924136  0.28282553  0.10012704 -0.25567946\n\
          \  0.16244918 -0.43605423  0.25947714  0.22715253 -0.01276171 -0.24019039\n\
          \  0.02010059  0.12444335  0.09977472  0.10143045 -0.30488595 -0.02201521]"
    num_agent_steps_sampled: 317000
    num_agent_steps_trained: 3792048
    num_steps_sampled: 317000
    num_steps_trained: 3792048
    num_target_updates: 627
  iterations_since_restore: 317
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.01176470588236
    ram_util_percent: 32.305882352941175
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924068858636689
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7203980731629
    mean_inference_ms: 1.587091616064554
    mean_raw_obs_processing_ms: 0.1440210379727203
  time_since_restore: 4485.341146707535
  time_this_iter_s: 11.398049592971802
  time_total_s: 4485.341146707535
  timers:
    learn_throughput: 5197.617
    learn_time_ms: 9.235
    update_time_ms: 2.875
  timestamp: 1629285225
  timesteps_since_restore: 0
  timesteps_total: 317000
  training_iteration: 317
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    317 |          4485.34 | 317000 | 5.03791e+06 |          7.25484e+06 |             -198.044 |            8753.28 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 318000
  custom_metrics: {}
  date: 2021-08-18_11-13-57
  done: false
  episode_len_mean: 8753.277777777777
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5037909.885496192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 36
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 317512
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.149335861206055
          max_q: 7255871.0
          mean_q: 151163.53125
          mean_td_error: 21.675960540771484
          min_q: -0.8600366115570068
        model: {}
        td_error: "[-1.88792944e-02  4.17923927e-02 -9.88427460e-01  1.01830006e-01\n\
          \  1.04550000e+03 -6.52337909e-01  1.59217775e-01  1.43607080e-01\n  8.63575041e-02\
          \  5.78818321e-02 -2.68055737e-01 -4.27424312e-02\n  8.88824463e-02  2.14712203e-01\
          \ -2.61363387e-01 -1.01514161e-01\n  1.09897435e-01  2.91274786e-02 -3.50525081e-01\
          \ -2.32970476e+00\n  1.29496396e-01 -3.26307416e-02 -1.30507708e-01  1.18835509e-01\n\
          \ -6.30524397e-01  8.36680532e-02  5.98398447e-02  2.00017631e-01\n  3.49897683e-01\
          \  1.70441270e-01  2.25082874e-01 -2.39089131e-02\n -1.10194921e-01 -3.44335258e-01\
          \  2.61395454e-01  2.64505446e-01\n -4.16877270e-01 -1.36272103e-01  4.23492610e-01\
          \  1.95238054e-01\n  4.42968309e-01 -2.56094933e-02  8.94587636e-02  3.25628221e-01\n\
          \  1.25187814e-01  2.74571657e-01 -2.89963531e+00 -6.29191995e-02]"
    num_agent_steps_sampled: 318000
    num_agent_steps_trained: 3804048
    num_steps_sampled: 318000
    num_steps_trained: 3804048
    num_target_updates: 629
  iterations_since_restore: 318
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.870588235294115
    ram_util_percent: 32.305882352941175
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924068858636689
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7203980731629
    mean_inference_ms: 1.587091616064554
    mean_raw_obs_processing_ms: 0.1440210379727203
  time_since_restore: 4497.047823190689
  time_this_iter_s: 11.706676483154297
  time_total_s: 4497.047823190689
  timers:
    learn_throughput: 5067.739
    learn_time_ms: 9.472
    update_time_ms: 3.09
  timestamp: 1629285237
  timesteps_since_restore: 0
  timesteps_total: 318000
  training_iteration: 318
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    318 |          4497.05 | 318000 | 5.03791e+06 |          7.25484e+06 |             -198.044 |            8753.28 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 319000
  custom_metrics: {}
  date: 2021-08-18_11-14-11
  done: false
  episode_len_mean: 8753.277777777777
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5037909.885496192
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 36
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 318520
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.050018925219774246
          max_q: 2.51887583732605
          mean_q: -0.35872912406921387
          mean_td_error: 0.04970524460077286
          min_q: -0.93897545337677
        model: {}
        td_error: "[ 0.07065481  0.2737249   0.20380825 -0.06439835 -0.35893238 -0.29809278\n\
          \ -0.31552267  0.09310758 -0.05802137  0.23254478  0.35983467 -0.31993732\n\
          \ -0.08405903  0.3717326   0.24571282  0.04069316 -0.77954495  0.23305792\n\
          \ -0.31723022  0.2808531  -0.06061846 -0.00428897  0.10937142 -0.24913245\n\
          \  0.42786527 -0.13027832  0.13731349 -0.11899722 -0.25864238  0.16658479\n\
          \  0.1832391   0.07970989 -0.17346424  0.15646642 -0.04598337  0.32003856\n\
          \  0.02201968  0.06966949 -0.07381338  0.25867707  0.15512204  0.13677645\n\
          \ -0.24974793  0.21069837  0.5696291   0.20280081  0.4129771   0.32187396]"
    num_agent_steps_sampled: 319000
    num_agent_steps_trained: 3816048
    num_steps_sampled: 319000
    num_steps_trained: 3816048
    num_target_updates: 631
  iterations_since_restore: 319
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.45
    ram_util_percent: 32.30499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04924068858636689
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7203980731629
    mean_inference_ms: 1.587091616064554
    mean_raw_obs_processing_ms: 0.1440210379727203
  time_since_restore: 4510.650860548019
  time_this_iter_s: 13.603037357330322
  time_total_s: 4510.650860548019
  timers:
    learn_throughput: 4198.231
    learn_time_ms: 11.433
    update_time_ms: 5.352
  timestamp: 1629285251
  timesteps_since_restore: 0
  timesteps_total: 319000
  training_iteration: 319
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    319 |          4510.65 | 319000 | 5.03791e+06 |          7.25484e+06 |             -198.044 |            8753.28 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 320000
  custom_metrics: {}
  date: 2021-08-18_11-14-22
  done: false
  episode_len_mean: 8622.432432432432
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5097822.437052287
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 319528
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 3.97269606590271
          max_q: 7256814.0
          mean_q: 151183.1875
          mean_td_error: 41.296112060546875
          min_q: -1.3496118783950806
        model: {}
        td_error: "[ 2.16539264e-01  5.38533926e-03 -2.75136173e-01 -2.75960177e-01\n\
          \ -1.09345436e-01  3.70712876e-02  1.98800000e+03  2.67689347e-01\n  1.57048285e-01\
          \  3.72913241e-01  1.25959516e-02  1.41704679e-01\n  5.16998172e-02  1.09043956e-01\
          \ -4.40442294e-01 -3.14543366e-01\n  1.29049659e-01 -2.49148726e-01 -5.18867970e-02\
          \ -4.98917043e-01\n  3.12316000e-01  1.06837153e-01  8.43132138e-02  2.20456600e-01\n\
          \ -3.78403664e-01 -3.71530294e-01 -3.40890288e-01  2.03565955e-02\n -1.00173831e-01\
          \ -2.66138911e-02 -5.03358841e-02  1.91407144e-01\n -1.32637107e+00  3.27005982e-02\
          \ -9.77151930e-01  4.21359837e-02\n  1.09526336e-01 -4.44483459e-01  2.04891980e-01\
          \ -2.17952418e+00\n  1.93823457e-01 -5.90643287e-02  3.55806231e-01 -1.26433730e-01\n\
          \  6.38303161e-03 -7.75919557e-02 -1.71113014e-01 -3.23222488e-01]"
    num_agent_steps_sampled: 320000
    num_agent_steps_trained: 3828048
    num_steps_sampled: 320000
    num_steps_trained: 3828048
    num_target_updates: 633
  iterations_since_restore: 320
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.875
    ram_util_percent: 32.30625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923895896963919
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.740302016870359
    mean_inference_ms: 1.587160361770812
    mean_raw_obs_processing_ms: 0.14403798231052575
  time_since_restore: 4521.39745593071
  time_this_iter_s: 10.74659538269043
  time_total_s: 4521.39745593071
  timers:
    learn_throughput: 4913.916
    learn_time_ms: 9.768
    update_time_ms: 2.795
  timestamp: 1629285262
  timesteps_since_restore: 0
  timesteps_total: 320000
  training_iteration: 320
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    320 |           4521.4 | 320000 | 5.09782e+06 |          7.25484e+06 |             -198.044 |            8622.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 321000
  custom_metrics: {}
  date: 2021-08-18_11-14-34
  done: false
  episode_len_mean: 8622.432432432432
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5097822.437052287
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 37
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 320536
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.047479767352342606
          max_q: 7.175556182861328
          mean_q: -0.13719426095485687
          mean_td_error: -0.006766443606466055
          min_q: -0.714350700378418
        model: {}
        td_error: "[ 0.07345623  0.01198617 -0.09925416  0.11309463  0.15413302  0.06736737\n\
          \ -0.14530104 -0.33117718 -0.10543767  0.21986422  0.22742361  0.09267205\n\
          \  0.15503693 -0.19807196  0.09231204  0.19297582 -0.12310445  0.04295087\n\
          \ -0.67235875 -0.30835336 -0.11909708 -0.10267694  0.0207563  -0.23996782\n\
          \ -0.2082367   0.532538    0.6157929   0.03119057  0.29758477 -0.15850347\n\
          \ -0.0867725  -2.3483927   0.07270402 -0.0159243   0.0750137  -0.21426779\n\
          \  0.4351173   0.125862   -0.1166642   0.13667572  0.23073888  0.05073208\n\
          \  0.1446889   0.3987478   0.19984937  0.19245088 -0.12695801  0.39201474]"
    num_agent_steps_sampled: 321000
    num_agent_steps_trained: 3840048
    num_steps_sampled: 321000
    num_steps_trained: 3840048
    num_target_updates: 635
  iterations_since_restore: 321
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.638888888888886
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923895896963919
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.740302016870359
    mean_inference_ms: 1.587160361770812
    mean_raw_obs_processing_ms: 0.14403798231052575
  time_since_restore: 4533.293494939804
  time_this_iter_s: 11.896039009094238
  time_total_s: 4533.293494939804
  timers:
    learn_throughput: 5155.162
    learn_time_ms: 9.311
    update_time_ms: 2.812
  timestamp: 1629285274
  timesteps_since_restore: 0
  timesteps_total: 321000
  training_iteration: 321
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    321 |          4533.29 | 321000 | 5.09782e+06 |          7.25484e+06 |             -198.044 |            8622.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 322000
  custom_metrics: {}
  date: 2021-08-18_11-14-48
  done: false
  episode_len_mean: 8622.432432432432
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5097822.437052287
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 37
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 321544
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06509778648614883
          max_q: 1.1460201740264893
          mean_q: -0.3650646209716797
          mean_td_error: -0.08636422455310822
          min_q: -0.8685229420661926
        model: {}
        td_error: "[-0.21230078 -0.13716406 -0.15843493 -0.13155818 -0.22031999  0.5531371\n\
          \ -0.15185022 -0.3834473   0.27541777 -0.17454925  0.01419771  0.11932927\n\
          \ -1.0424719   0.1645742  -0.0696792  -0.00350577  0.04552072  0.11977792\n\
          \ -0.32692945 -0.04727554  0.00254571 -0.18797463 -0.06516814  0.24706495\n\
          \ -0.03463715 -0.04431665  0.1252948   0.08241081 -0.08460207 -0.1861378\n\
          \  0.03205276 -0.06281775 -0.24421602 -0.22202897  0.12283367 -0.37096816\n\
          \ -0.08887982  0.05752957  0.16716266 -0.32315633 -0.21323654 -0.82266366\n\
          \  0.3032481  -0.23205861 -0.24131349 -0.19143498  0.08987445  0.00764263]"
    num_agent_steps_sampled: 322000
    num_agent_steps_trained: 3852048
    num_steps_sampled: 322000
    num_steps_trained: 3852048
    num_target_updates: 637
  iterations_since_restore: 322
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.48947368421054
    ram_util_percent: 32.30526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923895896963919
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.740302016870359
    mean_inference_ms: 1.587160361770812
    mean_raw_obs_processing_ms: 0.14403798231052575
  time_since_restore: 4546.865523338318
  time_this_iter_s: 13.572028398513794
  time_total_s: 4546.865523338318
  timers:
    learn_throughput: 4945.639
    learn_time_ms: 9.706
    update_time_ms: 2.819
  timestamp: 1629285288
  timesteps_since_restore: 0
  timesteps_total: 322000
  training_iteration: 322
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    322 |          4546.87 | 322000 | 5.09782e+06 |          7.25484e+06 |             -198.044 |            8622.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 323000
  custom_metrics: {}
  date: 2021-08-18_11-15-02
  done: false
  episode_len_mean: 8622.432432432432
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5097822.437052287
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 37
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 322552
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0580097921192646
          max_q: 4.067651748657227
          mean_q: -0.4021589756011963
          mean_td_error: 0.07956556975841522
          min_q: -0.9439699649810791
        model: {}
        td_error: "[ 0.19709724  0.0210433   0.35512054 -0.13256691 -0.05507272  0.31980276\n\
          \  0.38692033  0.07746923  0.4792505   0.2187053   0.17421865 -0.19301358\n\
          \  0.0190379  -0.02951986  0.22855347  0.47102255  0.4516678  -0.35492036\n\
          \ -0.06130248 -0.15827113 -0.04142109 -0.32321078 -0.56102914 -0.0821631\n\
          \ -0.46845526  0.2646377   0.16962767  0.35144657  0.2808851   0.2541399\n\
          \ -0.16753237  0.19572729  0.21710992 -0.13648325  0.23344004  0.1733852\n\
          \ -0.04702336  0.20358998 -0.2435177   0.23229581 -0.20690268  0.29227006\n\
          \  0.13986117  0.24886274  0.23033327  0.16602129 -0.04891825  0.07692766]"
    num_agent_steps_sampled: 323000
    num_agent_steps_trained: 3864048
    num_steps_sampled: 323000
    num_steps_trained: 3864048
    num_target_updates: 639
  iterations_since_restore: 323
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.875
    ram_util_percent: 32.30499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923895896963919
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.740302016870359
    mean_inference_ms: 1.587160361770812
    mean_raw_obs_processing_ms: 0.14403798231052575
  time_since_restore: 4560.262499809265
  time_this_iter_s: 13.396976470947266
  time_total_s: 4560.262499809265
  timers:
    learn_throughput: 4938.857
    learn_time_ms: 9.719
    update_time_ms: 2.733
  timestamp: 1629285302
  timesteps_since_restore: 0
  timesteps_total: 323000
  training_iteration: 323
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    323 |          4560.26 | 323000 | 5.09782e+06 |          7.25484e+06 |             -198.044 |            8622.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 324000
  custom_metrics: {}
  date: 2021-08-18_11-15-16
  done: false
  episode_len_mean: 8622.432432432432
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5097822.437052287
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 37
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 323560
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.09362562000751495
          max_q: 1.4277437925338745
          mean_q: -0.6013016700744629
          mean_td_error: -0.1208246573805809
          min_q: -0.9445033073425293
        model: {}
        td_error: "[-0.3904286  -0.2759711  -0.20119601 -0.25040662 -0.31035146 -0.28428286\n\
          \ -0.3721828  -0.08052611 -0.1558395  -0.00646102 -0.4201967  -0.28249106\n\
          \  0.02951235  0.02662349 -0.28393823  0.17057651 -0.08600569 -0.0257234\n\
          \ -0.3312636   0.07701015 -0.09301764 -0.05076015  0.18543202 -0.09422269\n\
          \ -0.8538794   0.20248431 -0.0317834  -0.07025987  0.46978748 -0.0310536\n\
          \ -0.43221077  0.31593752 -0.30847666  0.33792531 -0.19560999 -0.17023474\n\
          \ -0.46265566 -0.02167255 -0.2733622  -0.11860865 -0.3510025   0.10281122\n\
          \  0.21850067 -0.37544852  0.0198504  -0.2720927   0.27617002 -0.26858813]"
    num_agent_steps_sampled: 324000
    num_agent_steps_trained: 3876048
    num_steps_sampled: 324000
    num_steps_trained: 3876048
    num_target_updates: 641
  iterations_since_restore: 324
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.02
    ram_util_percent: 32.30499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923895896963919
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.740302016870359
    mean_inference_ms: 1.587160361770812
    mean_raw_obs_processing_ms: 0.14403798231052575
  time_since_restore: 4574.40970993042
  time_this_iter_s: 14.147210121154785
  time_total_s: 4574.40970993042
  timers:
    learn_throughput: 4652.68
    learn_time_ms: 10.317
    update_time_ms: 2.965
  timestamp: 1629285316
  timesteps_since_restore: 0
  timesteps_total: 324000
  training_iteration: 324
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    324 |          4574.41 | 324000 | 5.09782e+06 |          7.25484e+06 |             -198.044 |            8622.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 325000
  custom_metrics: {}
  date: 2021-08-18_11-15-31
  done: false
  episode_len_mean: 8622.432432432432
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5097822.437052287
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 37
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 324568
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.020518925040960312
          max_q: 0.6815949082374573
          mean_q: -0.559820830821991
          mean_td_error: 0.0023049539886415005
          min_q: -1.0570151805877686
        model: {}
        td_error: "[-0.346575    0.13884181 -0.14008972  0.20939088 -0.12913257 -0.1618337\n\
          \  0.24076289  0.25415397 -0.38388893  0.3228358   0.08121109 -0.59326094\n\
          \  0.07338625 -0.25561035  0.19361913 -0.01992556 -0.02271312  0.11592448\n\
          \  0.12008178  0.04964262  0.11449458 -0.05492651 -0.14792669  0.1090827\n\
          \ -0.3838564   0.03439921  0.43561095 -0.19779024 -0.02097946 -0.04956126\n\
          \ -1.0055482  -0.15409574  0.11021698 -0.08265233  0.2788599   0.28273958\n\
          \ -0.08170348  0.06473428  0.1332075  -0.08538121  0.31807935  0.2463606\n\
          \ -0.06833196  0.12730855  0.02443123  0.5571853  -0.07485098 -0.06528914]"
    num_agent_steps_sampled: 325000
    num_agent_steps_trained: 3888048
    num_steps_sampled: 325000
    num_steps_trained: 3888048
    num_target_updates: 643
  iterations_since_restore: 325
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.9952380952381
    ram_util_percent: 32.309523809523796
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923895896963919
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.740302016870359
    mean_inference_ms: 1.587160361770812
    mean_raw_obs_processing_ms: 0.14403798231052575
  time_since_restore: 4588.53390288353
  time_this_iter_s: 14.124192953109741
  time_total_s: 4588.53390288353
  timers:
    learn_throughput: 4986.306
    learn_time_ms: 9.626
    update_time_ms: 2.755
  timestamp: 1629285331
  timesteps_since_restore: 0
  timesteps_total: 325000
  training_iteration: 325
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    325 |          4588.53 | 325000 | 5.09782e+06 |          7.25484e+06 |             -198.044 |            8622.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 326000
  custom_metrics: {}
  date: 2021-08-18_11-15-46
  done: false
  episode_len_mean: 8622.432432432432
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5097822.437052287
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 37
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 325576
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05779246613383293
          max_q: 3.3190717697143555
          mean_q: -0.7119591236114502
          mean_td_error: -0.07483769953250885
          min_q: -1.32981276512146
        model: {}
        td_error: "[-0.06553757 -0.04327452 -0.09307134 -0.40903443  0.1429416  -0.4440062\n\
          \  0.1140933   0.24098927 -0.35358244  0.13594866 -0.024939    0.17838532\n\
          \ -0.26430225 -0.24486184  0.07836407  0.17633003  0.01247835 -0.05873281\n\
          \ -0.25481415 -0.07423431 -0.01481336  0.33733296  0.03259045 -0.25328082\n\
          \ -0.24356347  0.21545166  0.01072264  0.06877357  0.3062507   0.10893083\n\
          \ -0.26064843  0.15725619  0.03212917 -0.29714108 -0.19662535 -0.30299753\n\
          \ -0.03832084 -0.11407238 -0.131163   -0.01432347 -0.3390382  -0.30634695\n\
          \ -0.1778577  -0.3802959  -0.35551146 -0.15343726  0.05359191 -0.08494228]"
    num_agent_steps_sampled: 326000
    num_agent_steps_trained: 3900048
    num_steps_sampled: 326000
    num_steps_trained: 3900048
    num_target_updates: 645
  iterations_since_restore: 326
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.713636363636354
    ram_util_percent: 32.39999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923895896963919
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.740302016870359
    mean_inference_ms: 1.587160361770812
    mean_raw_obs_processing_ms: 0.14403798231052575
  time_since_restore: 4603.856605291367
  time_this_iter_s: 15.322702407836914
  time_total_s: 4603.856605291367
  timers:
    learn_throughput: 4931.14
    learn_time_ms: 9.734
    update_time_ms: 2.808
  timestamp: 1629285346
  timesteps_since_restore: 0
  timesteps_total: 326000
  training_iteration: 326
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    326 |          4603.86 | 326000 | 5.09782e+06 |          7.25484e+06 |             -198.044 |            8622.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 327000
  custom_metrics: {}
  date: 2021-08-18_11-16-00
  done: false
  episode_len_mean: 8586.28947368421
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5154580.4701948045
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 326584
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.052493616938591
          max_q: 6.881433963775635
          mean_q: -0.16922156512737274
          mean_td_error: 0.005411182995885611
          min_q: -0.911798894405365
        model: {}
        td_error: "[ 0.327843   -0.19588852  0.08642125  0.45317078  0.28901422 -0.01708889\n\
          \ -0.08074854  0.7586715  -0.09390789 -0.40008086  0.43944857 -0.17093164\n\
          \  0.07988554 -0.44858122 -0.22457576  0.1719765  -0.16922563 -0.02572656\n\
          \ -0.03114831  0.23906243 -0.16657823 -1.0222974   0.36545587  0.06317204\n\
          \ -0.21011835  0.07244676  0.16891488 -0.09958839 -0.9083741  -0.06693137\n\
          \  0.24380732  0.29512686  0.42199898  0.188133    0.09878236 -0.00344956\n\
          \  0.03931808  0.37853995 -0.11726409 -0.14621568  0.05471198 -0.18862087\n\
          \  0.37154043 -0.06391168 -0.23360002  0.19345558 -0.7554904   0.29918283]"
    num_agent_steps_sampled: 327000
    num_agent_steps_trained: 3912048
    num_steps_sampled: 327000
    num_steps_trained: 3912048
    num_target_updates: 647
  iterations_since_restore: 327
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.225
    ram_util_percent: 32.344999999999985
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049237008903477195
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7588616731561615
    mean_inference_ms: 1.587218474218463
    mean_raw_obs_processing_ms: 0.14405253665825105
  time_since_restore: 4616.765743970871
  time_this_iter_s: 12.909138679504395
  time_total_s: 4616.765743970871
  timers:
    learn_throughput: 4780.197
    learn_time_ms: 10.041
    update_time_ms: 2.803
  timestamp: 1629285360
  timesteps_since_restore: 0
  timesteps_total: 327000
  training_iteration: 327
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    327 |          4616.77 | 327000 | 5.15458e+06 |          7.25484e+06 |             -198.044 |            8586.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 328000
  custom_metrics: {}
  date: 2021-08-18_11-16-13
  done: false
  episode_len_mean: 8586.28947368421
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5154580.4701948045
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 38
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 327592
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03708956390619278
          max_q: 2.0928733348846436
          mean_q: -0.323509156703949
          mean_td_error: 0.02495010755956173
          min_q: -0.8689157366752625
        model: {}
        td_error: "[ 0.3542137   0.04058474  0.02960956  0.21851426 -0.03690985 -0.06707138\n\
          \  0.02096486  0.13451415  0.22254932 -0.05314755 -0.09931061  0.02765831\n\
          \  0.18868768 -0.22822565 -0.30577928  0.2276721  -0.02845311  0.5876682\n\
          \  0.04965365  0.06626308 -0.05891524 -0.19531265  0.35847372 -0.06885004\n\
          \ -0.3170422   0.03256416  0.11339825 -0.12225223 -0.20392263  0.24915361\n\
          \ -0.15063274 -0.04978618 -0.188115   -0.43518335 -0.43680674  0.3853535\n\
          \  0.14148402  0.09338343  0.18734127 -0.21998125  0.064928    0.21150315\n\
          \ -0.2230976   0.16639966 -0.02829331  0.31977844  0.26259875 -0.0402199 ]"
    num_agent_steps_sampled: 328000
    num_agent_steps_trained: 3924048
    num_steps_sampled: 328000
    num_steps_trained: 3924048
    num_target_updates: 649
  iterations_since_restore: 328
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.72941176470589
    ram_util_percent: 32.305882352941175
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049237008903477195
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7588616731561615
    mean_inference_ms: 1.587218474218463
    mean_raw_obs_processing_ms: 0.14405253665825105
  time_since_restore: 4628.94602060318
  time_this_iter_s: 12.18027663230896
  time_total_s: 4628.94602060318
  timers:
    learn_throughput: 4985.405
    learn_time_ms: 9.628
    update_time_ms: 2.727
  timestamp: 1629285373
  timesteps_since_restore: 0
  timesteps_total: 328000
  training_iteration: 328
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    328 |          4628.95 | 328000 | 5.15458e+06 |          7.25484e+06 |             -198.044 |            8586.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 329000
  custom_metrics: {}
  date: 2021-08-18_11-16-25
  done: false
  episode_len_mean: 8586.28947368421
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5154580.4701948045
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 38
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 328600
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.914500713348389
          max_q: 7254949.0
          mean_q: 151144.234375
          mean_td_error: 2.4825551509857178
          min_q: -1.1172534227371216
        model: {}
        td_error: "[-2.64734328e-02 -4.63286161e-01 -4.87659574e-02 -2.05580831e-01\n\
          \ -2.07318574e-01 -2.56287038e-01 -1.10291243e-01 -3.12693119e-02\n  1.55235469e-01\
          \ -1.73009366e-01  2.63865352e-01  1.18801534e-01\n -3.00951689e-01 -8.19697976e-02\
          \ -2.77552307e-01  7.12239742e-03\n -2.76493311e-01  9.46012735e-02  2.90028453e-02\
          \ -9.14053917e-02\n -1.59916937e-01 -4.47388887e-02 -1.20945036e-01  5.21727800e-02\n\
          \ -1.81064546e-01 -1.98635817e-01 -2.52399921e-01 -2.57359147e-02\n -2.08468199e-01\
          \ -1.34364337e-01  5.25684953e-02  1.92916304e-01\n  1.22000000e+02 -5.14297903e-01\
          \  1.29365504e-01 -1.27650678e-01\n  1.18498415e-01  1.58409476e-02  1.30217493e-01\
          \  1.56623721e-02\n  2.49241352e-01 -4.10451889e-02  5.14987111e-03 -2.58749068e-01\n\
          \  4.13962007e-02  3.42156649e-01 -1.23889685e-01  9.13831666e-02]"
    num_agent_steps_sampled: 329000
    num_agent_steps_trained: 3936048
    num_steps_sampled: 329000
    num_steps_trained: 3936048
    num_target_updates: 651
  iterations_since_restore: 329
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.28333333333333
    ram_util_percent: 32.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049237008903477195
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7588616731561615
    mean_inference_ms: 1.587218474218463
    mean_raw_obs_processing_ms: 0.14405253665825105
  time_since_restore: 4641.292732715607
  time_this_iter_s: 12.346712112426758
  time_total_s: 4641.292732715607
  timers:
    learn_throughput: 5123.049
    learn_time_ms: 9.369
    update_time_ms: 2.679
  timestamp: 1629285385
  timesteps_since_restore: 0
  timesteps_total: 329000
  training_iteration: 329
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    329 |          4641.29 | 329000 | 5.15458e+06 |          7.25484e+06 |             -198.044 |            8586.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 330000
  custom_metrics: {}
  date: 2021-08-18_11-16-38
  done: false
  episode_len_mean: 8586.28947368421
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5154580.4701948045
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 38
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 329608
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05707131326198578
          max_q: 2.0693418979644775
          mean_q: -0.5490761995315552
          mean_td_error: -0.028080973774194717
          min_q: -1.0216585397720337
        model: {}
        td_error: "[-0.3224873   0.01653373 -0.04075348 -0.18289465  0.20744032  0.19884473\n\
          \ -0.01881117 -0.08883786  0.10927141  0.19873542 -0.26588    -0.06431139\n\
          \  0.17959416  0.42737752  0.215015    0.13209873  0.05408937 -0.1605416\n\
          \ -0.4047258  -0.05061603 -0.18660438 -0.16000181  0.27017707 -0.1755287\n\
          \  0.18699974 -0.11846536 -0.842597    0.08934724 -0.06979835  0.19527781\n\
          \  0.19259432 -0.18401206  0.53082263 -0.05447191 -0.6945857   0.24506027\n\
          \ -0.03472018 -0.05448592 -0.14252317 -0.23859662 -0.29105136  0.02576071\n\
          \ -0.38275516  0.32303882  0.24624991  0.02175868 -0.26185054  0.07793325]"
    num_agent_steps_sampled: 330000
    num_agent_steps_trained: 3948048
    num_steps_sampled: 330000
    num_steps_trained: 3948048
    num_target_updates: 653
  iterations_since_restore: 330
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.23684210526316
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049237008903477195
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7588616731561615
    mean_inference_ms: 1.587218474218463
    mean_raw_obs_processing_ms: 0.14405253665825105
  time_since_restore: 4654.061689853668
  time_this_iter_s: 12.768957138061523
  time_total_s: 4654.061689853668
  timers:
    learn_throughput: 4683.168
    learn_time_ms: 10.249
    update_time_ms: 3.547
  timestamp: 1629285398
  timesteps_since_restore: 0
  timesteps_total: 330000
  training_iteration: 330
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    330 |          4654.06 | 330000 | 5.15458e+06 |          7.25484e+06 |             -198.044 |            8586.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 331000
  custom_metrics: {}
  date: 2021-08-18_11-16-52
  done: false
  episode_len_mean: 8586.28947368421
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5154580.4701948045
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 38
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 330616
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.820972919464111
          max_q: 7254185.0
          mean_q: 151128.125
          mean_td_error: -13.332906723022461
          min_q: -1.282343864440918
        model: {}
        td_error: "[ 1.2251639e-01  1.6366041e-01 -6.4000000e+02 -2.3207837e-01\n -4.7723293e-02\
          \  4.8991996e-01 -5.3026676e-02  2.2264385e-01\n  1.4507031e-01  6.0712576e-02\
          \ -7.8706205e-02 -6.5676272e-02\n -3.4114921e-01  3.0868804e-01 -9.4391406e-02\
          \  2.4904978e-01\n -1.6018724e-01  4.2246222e-02 -2.5034422e-01 -3.0747837e-01\n\
          \ -1.8558794e-01 -1.2580097e-01 -1.1784668e-01 -1.5424514e-01\n -1.6176939e-02\
          \ -6.1606586e-02 -6.0363829e-02 -2.7278277e-01\n -2.7839863e-01 -1.4360712e-01\
          \  2.4246985e-01 -7.8093052e-02\n  1.5938044e-02  3.4803975e-01  2.2085834e-01\
          \ -9.1754317e-02\n  3.5170686e-01  1.5972239e-01 -3.2585621e-02  3.9769411e-02\n\
          \  4.8868841e-01  6.2556624e-02 -5.2473080e-01  1.2779284e-01\n -4.0102905e-01\
          \  3.3467770e-02 -4.8965096e-02  3.4933054e-01]"
    num_agent_steps_sampled: 331000
    num_agent_steps_trained: 3960048
    num_steps_sampled: 331000
    num_steps_trained: 3960048
    num_target_updates: 655
  iterations_since_restore: 331
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.15999999999999
    ram_util_percent: 32.30999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049237008903477195
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7588616731561615
    mean_inference_ms: 1.587218474218463
    mean_raw_obs_processing_ms: 0.14405253665825105
  time_since_restore: 4667.592419624329
  time_this_iter_s: 13.5307297706604
  time_total_s: 4667.592419624329
  timers:
    learn_throughput: 5011.353
    learn_time_ms: 9.578
    update_time_ms: 2.737
  timestamp: 1629285412
  timesteps_since_restore: 0
  timesteps_total: 331000
  training_iteration: 331
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    331 |          4667.59 | 331000 | 5.15458e+06 |          7.25484e+06 |             -198.044 |            8586.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 332000
  custom_metrics: {}
  date: 2021-08-18_11-17-08
  done: false
  episode_len_mean: 8586.28947368421
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5154580.4701948045
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 38
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 331624
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04521068558096886
          max_q: 2.275367021560669
          mean_q: -0.6940187215805054
          mean_td_error: -0.0545278862118721
          min_q: -1.2147235870361328
        model: {}
        td_error: "[-0.2644716   0.21628237  0.02949339 -0.08301596 -0.02971023 -0.28921896\n\
          \ -0.06989467  0.33043146 -0.04215962 -0.01000559 -0.14523691 -0.06957874\n\
          \ -0.49721098 -0.05275387  0.16038924 -0.10700798 -0.01417261  0.46694183\n\
          \ -0.89977884 -0.22612739 -0.18761647  0.17189944  0.368155   -0.30768\n \
          \ 0.07977681 -0.32299668 -0.14880681 -0.32586408 -0.15339708  0.0717724\n\
          \ -0.29100925  0.1881969   0.44648188 -0.21168077 -0.36223614  0.30335903\n\
          \  0.07713807  0.24754018  0.11240226 -0.01190197 -0.0550372  -0.34989762\n\
          \ -0.09035754  0.02451777 -0.06530011 -0.09718633  0.2120446  -0.34284902]"
    num_agent_steps_sampled: 332000
    num_agent_steps_trained: 3972048
    num_steps_sampled: 332000
    num_steps_trained: 3972048
    num_target_updates: 657
  iterations_since_restore: 332
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.33333333333333
    ram_util_percent: 32.30476190476189
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049237008903477195
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7588616731561615
    mean_inference_ms: 1.587218474218463
    mean_raw_obs_processing_ms: 0.14405253665825105
  time_since_restore: 4682.503726005554
  time_this_iter_s: 14.911306381225586
  time_total_s: 4682.503726005554
  timers:
    learn_throughput: 4938.542
    learn_time_ms: 9.719
    update_time_ms: 2.901
  timestamp: 1629285428
  timesteps_since_restore: 0
  timesteps_total: 332000
  training_iteration: 332
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    332 |           4682.5 | 332000 | 5.15458e+06 |          7.25484e+06 |             -198.044 |            8586.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 333000
  custom_metrics: {}
  date: 2021-08-18_11-17-21
  done: false
  episode_len_mean: 8586.28947368421
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5154580.4701948045
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 38
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 332632
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04067016392946243
          max_q: 5.906455039978027
          mean_q: -0.7880846858024597
          mean_td_error: 0.012545878998935223
          min_q: -1.8451054096221924
        model: {}
        td_error: "[ 0.03663665 -0.36892003  0.2726521   0.2717055  -0.1998983   0.22694641\n\
          \  0.02527547 -1.5255919   0.2657826   0.23660862  0.34293544  0.18533438\n\
          \  0.1192289   0.03198707  0.6987815   0.23059207 -0.53135145  0.24672186\n\
          \  0.23147452 -0.08579111 -0.2822764   0.25009835 -0.30521816  0.10790813\n\
          \  0.05928648  0.24490106 -0.31829637 -0.5126816  -0.22738475  0.17295527\n\
          \ -0.09995854 -0.08532566  0.14891613 -0.10888624  0.35711378 -0.10553777\n\
          \ -0.48353654 -0.195907    0.27595502  0.06113762  0.04772866 -0.14379251\n\
          \  0.02399129  0.31120574  0.35205066  0.31360245 -0.22161412  0.25465685]"
    num_agent_steps_sampled: 333000
    num_agent_steps_trained: 3984048
    num_steps_sampled: 333000
    num_steps_trained: 3984048
    num_target_updates: 659
  iterations_since_restore: 333
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.92999999999999
    ram_util_percent: 32.37499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049237008903477195
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.7588616731561615
    mean_inference_ms: 1.587218474218463
    mean_raw_obs_processing_ms: 0.14405253665825105
  time_since_restore: 4696.091574907303
  time_this_iter_s: 13.587848901748657
  time_total_s: 4696.091574907303
  timers:
    learn_throughput: 4642.616
    learn_time_ms: 10.339
    update_time_ms: 2.881
  timestamp: 1629285441
  timesteps_since_restore: 0
  timesteps_total: 333000
  training_iteration: 333
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    333 |          4696.09 | 333000 | 5.15458e+06 |          7.25484e+06 |             -198.044 |            8586.29 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 334000
  custom_metrics: {}
  date: 2021-08-18_11-17-33
  done: false
  episode_len_mean: 8541.102564102564
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5208428.338643137
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 333640
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.013110160827637
          max_q: 7254476.0
          mean_q: 151134.078125
          mean_td_error: -7.210881233215332
          min_q: -1.8272817134857178
        model: {}
        td_error: "[ 1.56170547e-01  2.79782653e-01  6.47632241e-01 -2.29630232e-01\n\
          \  2.17260003e-01 -2.21019775e-01 -3.62581134e-01 -1.23260975e-01\n  2.72415578e-01\
          \ -9.57536697e-03  2.00890481e-01 -1.62039578e-01\n  3.79248142e-01 -7.42108226e-02\
          \  2.01763511e-01 -1.12583637e-02\n -7.04234838e-02  1.62387967e-01  2.55515099e-01\
          \  6.98655844e-02\n  6.08578920e-02  2.75670528e-01 -1.26983404e-01  1.87364817e-02\n\
          \  3.83546531e-01 -2.10561991e-01  2.03869820e-01  1.80410385e-01\n -8.24353099e-02\
          \ -6.16596937e-02  9.85988379e-02 -3.09823811e-01\n -4.50664759e-02  1.31864190e-01\
          \  2.93321490e-01  4.45016146e-01\n  5.83225489e-02 -2.30232865e-01  1.87512994e-01\
          \  3.24409008e-02\n  4.64909077e-02  3.36446404e-01 -1.50271654e-02  2.50166953e-01\n\
          \ -3.50000000e+02  2.82638967e-01 -3.16698313e-01  4.11373019e-01]"
    num_agent_steps_sampled: 334000
    num_agent_steps_trained: 3996048
    num_steps_sampled: 334000
    num_steps_trained: 3996048
    num_target_updates: 661
  iterations_since_restore: 334
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.78823529411764
    ram_util_percent: 32.329411764705874
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923488891422461
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.775823556637271
    mean_inference_ms: 1.5872733548427032
    mean_raw_obs_processing_ms: 0.1440646740995977
  time_since_restore: 4707.59610915184
  time_this_iter_s: 11.504534244537354
  time_total_s: 4707.59610915184
  timers:
    learn_throughput: 4956.891
    learn_time_ms: 9.683
    update_time_ms: 2.696
  timestamp: 1629285453
  timesteps_since_restore: 0
  timesteps_total: 334000
  training_iteration: 334
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    334 |           4707.6 | 334000 | 5.20843e+06 |          7.25484e+06 |             -198.044 |             8541.1 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 335000
  custom_metrics: {}
  date: 2021-08-18_11-17-45
  done: false
  episode_len_mean: 8541.102564102564
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5208428.338643137
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 39
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 334648
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.045410457998514175
          max_q: 0.03612017631530762
          mean_q: -1.0188292264938354
          mean_td_error: -0.021947696805000305
          min_q: -1.492893934249878
        model: {}
        td_error: "[-0.08482707 -0.21955574 -0.00771737 -0.06279641 -0.18379343 -0.28590727\n\
          \  0.07540017  0.07059216  0.26729298 -0.11434603 -0.3078454  -0.08858466\n\
          \ -0.94825405 -0.21977752  0.01092565  0.33984876 -0.11172003  0.07921875\n\
          \  0.04829133  0.40912473 -0.14252305  0.18545413 -0.01694095 -0.03245664\n\
          \  0.3433659   0.21827173  0.03359699  0.3716612  -0.14325213  0.23950851\n\
          \  0.36443245  0.03145552  0.29452777 -0.17791212  0.0956552  -0.06825185\n\
          \  0.16342354 -0.03217286  0.11811262 -0.28427893 -0.03093505 -0.6783032\n\
          \ -0.6037733   0.23600686  0.29517674 -0.38477415  0.08602464 -0.2001586 ]"
    num_agent_steps_sampled: 335000
    num_agent_steps_trained: 4008048
    num_steps_sampled: 335000
    num_steps_trained: 4008048
    num_target_updates: 663
  iterations_since_restore: 335
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.07647058823529
    ram_util_percent: 32.305882352941175
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923488891422461
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.775823556637271
    mean_inference_ms: 1.5872733548427032
    mean_raw_obs_processing_ms: 0.1440646740995977
  time_since_restore: 4719.314485549927
  time_this_iter_s: 11.718376398086548
  time_total_s: 4719.314485549927
  timers:
    learn_throughput: 5037.472
    learn_time_ms: 9.529
    update_time_ms: 2.702
  timestamp: 1629285465
  timesteps_since_restore: 0
  timesteps_total: 335000
  training_iteration: 335
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    335 |          4719.31 | 335000 | 5.20843e+06 |          7.25484e+06 |             -198.044 |             8541.1 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 336000
  custom_metrics: {}
  date: 2021-08-18_11-17-58
  done: false
  episode_len_mean: 8541.102564102564
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5208428.338643137
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 39
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 335656
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 9.987444877624512
          max_q: 7254369.0
          mean_q: 151131.890625
          mean_td_error: -9.483478546142578
          min_q: -1.5779671669006348
        model: {}
        td_error: "[-3.37316751e-01  3.81620228e-01  1.80018306e-01  3.85151148e-01\n\
          \ -8.45468938e-02  3.10405254e-01  6.57216132e-01  2.73592770e-01\n  1.46043122e-01\
          \ -1.71888590e-01 -2.02143192e-02 -3.58684897e-01\n  2.68864036e-01  3.04337025e-01\
          \ -1.21163785e-01 -1.30620271e-01\n  1.70540690e-01 -4.56000000e+02  2.40313053e-01\
          \  1.44035339e-01\n -8.79777074e-02 -9.17757750e-02  2.37533987e-01 -6.72423661e-01\n\
          \  4.51638997e-01  1.74693048e-01 -1.77870631e-01 -1.71681643e-01\n  1.62604332e-01\
          \  8.02165270e-02 -2.78318584e-01  8.71090889e-02\n  2.02083588e-01  1.86815143e-01\
          \ -2.78796136e-01  6.62796497e-02\n -6.10316396e-02 -2.65049279e-01  3.83316159e-01\
          \ -1.61808729e-03\n -1.83433962e+00  1.28020048e-02  1.43315673e-01  1.99087620e-01\n\
          \  9.22107697e-03 -2.27510750e-01  1.45827532e-01  1.61215544e-01]"
    num_agent_steps_sampled: 336000
    num_agent_steps_trained: 4020048
    num_steps_sampled: 336000
    num_steps_trained: 4020048
    num_target_updates: 665
  iterations_since_restore: 336
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.7611111111111
    ram_util_percent: 32.29999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923488891422461
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.775823556637271
    mean_inference_ms: 1.5872733548427032
    mean_raw_obs_processing_ms: 0.1440646740995977
  time_since_restore: 4731.269663572311
  time_this_iter_s: 11.955178022384644
  time_total_s: 4731.269663572311
  timers:
    learn_throughput: 4930.934
    learn_time_ms: 9.734
    update_time_ms: 2.625
  timestamp: 1629285478
  timesteps_since_restore: 0
  timesteps_total: 336000
  training_iteration: 336
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    336 |          4731.27 | 336000 | 5.20843e+06 |          7.25484e+06 |             -198.044 |             8541.1 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 337000
  custom_metrics: {}
  date: 2021-08-18_11-18-11
  done: false
  episode_len_mean: 8424.7
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5259584.697626151
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 336664
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.458662986755371
          max_q: 7254493.0
          mean_q: 151134.59375
          mean_td_error: -6.90442419052124
          min_q: -1.5092227458953857
        model: {}
        td_error: "[ 2.6052344e-01 -3.1004429e-01  2.0753145e-01  3.8554001e-01\n -1.2551725e-01\
          \  7.2218180e-02  2.4553633e-01 -1.2124848e-01\n -5.4928386e-01 -7.5838423e-01\
          \ -1.0804021e-01 -3.9329448e-01\n -2.5711104e-01 -7.7250838e-02 -3.6781782e-01\
          \ -3.2512903e-02\n  9.0526938e-03  5.0667524e-02  2.8570533e-01 -4.8732281e-02\n\
          \ -1.4214921e-01  1.0023165e-01  1.1675179e-01  4.9352747e-01\n  2.4601579e-01\
          \ -1.7609358e-01  5.0841212e-02  2.5306237e-01\n  5.7841301e-01  3.7277895e-01\
          \  8.6878121e-02  2.9166436e-01\n  6.8330407e-02  2.5018597e-01 -9.0281963e-03\
          \ -3.3200000e+02\n -1.6073430e-01  9.7279787e-02 -9.7176802e-01 -4.9214876e-01\n\
          \  3.1393337e-01  3.8705671e-01 -2.5506777e-01  1.3930181e-01\n  2.5175440e-01\
          \  4.7313452e-02  1.6099569e-01  1.2081891e-01]"
    num_agent_steps_sampled: 337000
    num_agent_steps_trained: 4032048
    num_steps_sampled: 337000
    num_steps_trained: 4032048
    num_target_updates: 667
  iterations_since_restore: 337
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 67.06315789473686
    ram_util_percent: 32.31052631578947
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049233026100461943
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.79153963951404
    mean_inference_ms: 1.5873265437083883
    mean_raw_obs_processing_ms: 0.1440759934949864
  time_since_restore: 4744.489785432816
  time_this_iter_s: 13.22012186050415
  time_total_s: 4744.489785432816
  timers:
    learn_throughput: 4740.13
    learn_time_ms: 10.126
    update_time_ms: 2.961
  timestamp: 1629285491
  timesteps_since_restore: 0
  timesteps_total: 337000
  training_iteration: 337
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    337 |          4744.49 | 337000 | 5.25958e+06 |          7.25484e+06 |             -198.044 |             8424.7 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 338000
  custom_metrics: {}
  date: 2021-08-18_11-18-23
  done: false
  episode_len_mean: 8424.7
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5259584.697626151
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 40
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 337672
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1303154081106186
          max_q: 2.310746431350708
          mean_q: -1.018623948097229
          mean_td_error: -0.10175177454948425
          min_q: -1.870319128036499
        model: {}
        td_error: "[-0.4472311  -0.6180604  -0.10325849 -0.14042759  0.24605465  0.06979799\n\
          \ -0.49602973 -0.18149292 -0.15583599 -0.26795113 -0.303205   -0.17302418\n\
          \ -0.22830641 -0.26772594 -0.0999347   0.25258315  0.02188516 -0.13220364\n\
          \  0.15689385 -0.20367724  0.09358585  0.12294543  0.20849895  0.04952657\n\
          \ -0.2603678  -0.14999008 -0.2849276  -0.07942581  0.25687492 -0.45272982\n\
          \  0.18223643 -0.34214413 -0.28280407  0.15997612 -0.64469624  0.02708137\n\
          \  0.16122329  0.22744262  0.03803122 -0.02839035 -0.2196858   0.10279596\n\
          \  0.09757209 -0.4971581   0.48619926 -0.13323307 -0.2735659  -0.3778069 ]"
    num_agent_steps_sampled: 338000
    num_agent_steps_trained: 4044048
    num_steps_sampled: 338000
    num_steps_trained: 4044048
    num_target_updates: 669
  iterations_since_restore: 338
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.86874999999999
    ram_util_percent: 32.3
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049233026100461943
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.79153963951404
    mean_inference_ms: 1.5873265437083883
    mean_raw_obs_processing_ms: 0.1440759934949864
  time_since_restore: 4755.386210203171
  time_this_iter_s: 10.896424770355225
  time_total_s: 4755.386210203171
  timers:
    learn_throughput: 4898.958
    learn_time_ms: 9.798
    update_time_ms: 2.791
  timestamp: 1629285503
  timesteps_since_restore: 0
  timesteps_total: 338000
  training_iteration: 338
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    338 |          4755.39 | 338000 | 5.25958e+06 |          7.25484e+06 |             -198.044 |             8424.7 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 339000
  custom_metrics: {}
  date: 2021-08-18_11-18-34
  done: false
  episode_len_mean: 8424.7
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5259584.697626151
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 40
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 338680
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 26.614582061767578
          max_q: 7253462.0
          mean_q: 453340.59375
          mean_td_error: -85.1050033569336
          min_q: -1.8122525215148926
        model: {}
        td_error: "[ 6.3059974e-01  3.6420983e-01  3.5661936e-02  6.4738989e-02\n -4.1011715e-01\
          \  5.8570266e-02 -1.4752495e-01  1.5736997e-01\n -1.3625000e+03  2.7567434e-01\
          \ -1.0157287e-01  2.2177517e-01\n  1.9792676e-01  2.1780056e-01  8.6417913e-02\
          \ -2.2956300e-01\n  2.5254893e-01 -1.3625000e+03 -1.8417838e-01  1.4058161e-01\n\
          \  3.2917905e-01 -8.1955910e-02 -4.4244587e-02  9.4030440e-02\n -1.3625000e+03\
          \  1.1729616e-01 -1.2830400e-01  1.4478588e-01\n  1.4381719e-01  1.6667914e-01\
          \  2.1887481e-01  2.6270545e-01\n -3.2043517e-02  3.3082008e-02 -1.0036041e+00\
          \  4.6540189e-01\n  1.4329225e-01  9.0770006e-02  3.0226028e-01 -2.0259017e-01\n\
          \ -1.3312322e-01 -9.1939992e-01  2.8407460e-01  2.0971787e-01\n  3.9556420e-01\
          \  3.2004118e-02  1.8343234e-01 -2.4254990e-01]"
    num_agent_steps_sampled: 339000
    num_agent_steps_trained: 4056048
    num_steps_sampled: 339000
    num_steps_trained: 4056048
    num_target_updates: 671
  iterations_since_restore: 339
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.65625
    ram_util_percent: 32.30625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049233026100461943
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.79153963951404
    mean_inference_ms: 1.5873265437083883
    mean_raw_obs_processing_ms: 0.1440759934949864
  time_since_restore: 4766.280915975571
  time_this_iter_s: 10.894705772399902
  time_total_s: 4766.280915975571
  timers:
    learn_throughput: 4798.334
    learn_time_ms: 10.003
    update_time_ms: 2.699
  timestamp: 1629285514
  timesteps_since_restore: 0
  timesteps_total: 339000
  training_iteration: 339
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    339 |          4766.28 | 339000 | 5.25958e+06 |          7.25484e+06 |             -198.044 |             8424.7 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 340000
  custom_metrics: {}
  date: 2021-08-18_11-18-46
  done: false
  episode_len_mean: 8424.7
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5259584.697626151
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 40
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 339688
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06986870616674423
          max_q: 2.617199659347534
          mean_q: -0.7993569374084473
          mean_td_error: 0.048433125019073486
          min_q: -1.6280109882354736
        model: {}
        td_error: "[ 0.4454763   0.28799248 -0.86402184 -0.44484007 -0.241781    0.47166324\n\
          \  0.2967571   0.0865525  -0.11038935  0.33632183 -0.01358104 -0.10310256\n\
          \  0.1123358   0.1384573   0.25675213  0.36483145  0.19539225 -0.00872707\n\
          \ -0.0843612  -0.2906369  -0.16060454 -0.37282526  0.10914963  0.21250987\n\
          \ -0.15581292  0.22440743  0.22442198  0.08099593 -0.16573375 -0.21467412\n\
          \ -0.10601723 -0.02505159  0.07364547 -0.462416    0.3864274   0.3065911\n\
          \  0.41906542  0.4515846   0.34294438 -0.11811137  0.05850375  0.07559669\n\
          \  0.02643597 -0.18813115  0.2936498  -0.05446732  0.17249644  0.05911815]"
    num_agent_steps_sampled: 340000
    num_agent_steps_trained: 4068048
    num_steps_sampled: 340000
    num_steps_trained: 4068048
    num_target_updates: 673
  iterations_since_restore: 340
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.84705882352941
    ram_util_percent: 32.305882352941175
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049233026100461943
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.79153963951404
    mean_inference_ms: 1.5873265437083883
    mean_raw_obs_processing_ms: 0.1440759934949864
  time_since_restore: 4778.238498687744
  time_this_iter_s: 11.957582712173462
  time_total_s: 4778.238498687744
  timers:
    learn_throughput: 5073.87
    learn_time_ms: 9.46
    update_time_ms: 2.738
  timestamp: 1629285526
  timesteps_since_restore: 0
  timesteps_total: 340000
  training_iteration: 340
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    340 |          4778.24 | 340000 | 5.25958e+06 |          7.25484e+06 |             -198.044 |             8424.7 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 341000
  custom_metrics: {}
  date: 2021-08-18_11-18-59
  done: false
  episode_len_mean: 8424.7
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5259584.697626151
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 40
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 340696
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 15.067495346069336
          max_q: 7255096.0
          mean_q: 302294.75
          mean_td_error: 11.33789348602295
          min_q: -1.5710530281066895
        model: {}
        td_error: "[ 7.70095587e-02  8.19566846e-02  2.71500000e+02  3.00110579e-01\n\
          \  1.23507261e-01  4.52342391e-01  9.82607603e-02  3.11331928e-01\n  4.09045935e-01\
          \  1.21770382e-01 -5.04348278e-02 -4.01341379e-01\n -1.12845331e-01 -9.66714472e-02\
          \  3.30422103e-01  1.13910675e-01\n  2.72015452e-01  3.50667357e-01  3.80152583e-01\
          \  2.35812426e-01\n -1.44032502e+00 -1.29512012e-01  5.16859531e-01 -6.68704510e-04\n\
          \ -9.47191715e-02  6.24164343e-02 -1.30913615e-01 -1.23956919e-01\n  3.56459618e-03\
          \ -8.50876570e-02  1.53529406e-01 -1.32818520e-01\n  1.82981133e-01  8.92341137e-03\
          \ -4.38684225e-01  2.92021990e-01\n  2.71500000e+02 -3.56793761e-01 -3.40448797e-01\
          \ -1.13546252e-01\n -1.87947750e-02 -1.24696851e-01 -1.28654242e-02  3.59262943e-01\n\
          \ -1.81699276e-01  1.91262245e-01  8.14779997e-02  9.50525999e-02]"
    num_agent_steps_sampled: 341000
    num_agent_steps_trained: 4080048
    num_steps_sampled: 341000
    num_steps_trained: 4080048
    num_target_updates: 675
  iterations_since_restore: 341
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.800000000000004
    ram_util_percent: 32.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049233026100461943
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.79153963951404
    mean_inference_ms: 1.5873265437083883
    mean_raw_obs_processing_ms: 0.1440759934949864
  time_since_restore: 4790.269583463669
  time_this_iter_s: 12.031084775924683
  time_total_s: 4790.269583463669
  timers:
    learn_throughput: 4890.449
    learn_time_ms: 9.815
    update_time_ms: 2.806
  timestamp: 1629285539
  timesteps_since_restore: 0
  timesteps_total: 341000
  training_iteration: 341
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    341 |          4790.27 | 341000 | 5.25958e+06 |          7.25484e+06 |             -198.044 |             8424.7 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 342000
  custom_metrics: {}
  date: 2021-08-18_11-19-11
  done: false
  episode_len_mean: 8424.7
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5259584.697626151
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 40
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 341704
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.961985111236572
          max_q: 7255530.0
          mean_q: 151155.96875
          mean_td_error: 14.716440200805664
          min_q: -1.5164201259613037
        model: {}
        td_error: "[-3.36928815e-01  8.68907571e-02  2.34248996e-01  3.27089906e-01\n\
          \  1.74942374e-01  8.84172320e-02 -1.49581373e-01  7.05000000e+02\n -2.00722992e-01\
          \ -9.25064087e-04  5.17908692e-01 -2.20813215e-01\n -3.19000781e-01 -3.67346048e-01\
          \ -9.96881723e-02  2.26394534e-01\n -1.36495829e-01 -1.19927049e-01  1.12133026e-01\
          \  2.01659322e-01\n  2.05392241e-01 -1.54813051e-01 -3.53401184e-01  4.01382446e-02\n\
          \  3.39100361e-02  2.47763872e-01 -8.46381187e-02  5.24314165e-01\n -6.68408275e-02\
          \ -1.73696399e-01 -2.83465356e-01  2.87438810e-01\n -6.57559633e-02  6.40386343e-02\
          \ -1.07023716e-02  2.96586394e-01\n  1.28216565e-01 -5.73565960e-02 -2.58289516e-01\
          \  1.20584130e-01\n  2.27689862e-01  3.29465032e-01 -4.52280045e-04 -1.73195541e-01\n\
          \  4.59964275e-02  2.07010508e-01  1.85205102e-01  1.09724760e-01]"
    num_agent_steps_sampled: 342000
    num_agent_steps_trained: 4092048
    num_steps_sampled: 342000
    num_steps_trained: 4092048
    num_target_updates: 677
  iterations_since_restore: 342
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.36666666666667
    ram_util_percent: 32.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049233026100461943
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.79153963951404
    mean_inference_ms: 1.5873265437083883
    mean_raw_obs_processing_ms: 0.1440759934949864
  time_since_restore: 4802.775303602219
  time_this_iter_s: 12.505720138549805
  time_total_s: 4802.775303602219
  timers:
    learn_throughput: 4910.069
    learn_time_ms: 9.776
    update_time_ms: 2.765
  timestamp: 1629285551
  timesteps_since_restore: 0
  timesteps_total: 342000
  training_iteration: 342
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    342 |          4802.78 | 342000 | 5.25958e+06 |          7.25484e+06 |             -198.044 |             8424.7 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 343000
  custom_metrics: {}
  date: 2021-08-18_11-19-24
  done: false
  episode_len_mean: 8424.7
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5259584.697626151
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 40
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 342712
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0668046846985817
          max_q: 3.530688762664795
          mean_q: -0.8601149320602417
          mean_td_error: 0.03151361271739006
          min_q: -1.4103572368621826
        model: {}
        td_error: "[-0.35041565  0.5114536   0.46768677  0.14118695 -0.17333269  0.20204985\n\
          \  0.05714631  0.05288696  0.14633775  0.5217364  -0.11060697 -0.1442532\n\
          \  0.25385988  0.0880636  -0.18704963  0.07736486  0.00366342  0.33128977\n\
          \ -0.22571194  0.01844287 -0.73762697 -0.0469408  -0.27004576 -0.0611968\n\
          \ -0.1975779  -0.40005732  0.07217562  0.24502057  0.02439857 -0.10890004\n\
          \  0.06942832 -0.02807212  0.3268926   0.16117537 -0.6178991   0.13251078\n\
          \  0.23620522  0.0513826   0.1877706   0.31775904 -0.22770655 -0.17015737\n\
          \  0.14693367  0.25649166 -0.09033215  0.2973734   0.457129   -0.1952796 ]"
    num_agent_steps_sampled: 343000
    num_agent_steps_trained: 4104048
    num_steps_sampled: 343000
    num_steps_trained: 4104048
    num_target_updates: 679
  iterations_since_restore: 343
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.24736842105262
    ram_util_percent: 32.31052631578947
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049233026100461943
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.79153963951404
    mean_inference_ms: 1.5873265437083883
    mean_raw_obs_processing_ms: 0.1440759934949864
  time_since_restore: 4815.493568658829
  time_this_iter_s: 12.718265056610107
  time_total_s: 4815.493568658829
  timers:
    learn_throughput: 4662.982
    learn_time_ms: 10.294
    update_time_ms: 2.949
  timestamp: 1629285564
  timesteps_since_restore: 0
  timesteps_total: 343000
  training_iteration: 343
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    343 |          4815.49 | 343000 | 5.25958e+06 |          7.25484e+06 |             -198.044 |             8424.7 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 344000
  custom_metrics: {}
  date: 2021-08-18_11-19-38
  done: false
  episode_len_mean: 8424.7
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5259584.697626151
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 40
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 343720
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12.671485900878906
          max_q: 7255125.0
          mean_q: 151147.71875
          mean_td_error: 6.240177154541016
          min_q: -1.5303442478179932
        model: {}
        td_error: "[-8.6468339e-02  1.9177490e-01  1.3423848e-01  2.3527133e-01\n  3.2973897e-01\
          \  3.3401418e-01 -1.6489100e-01 -2.7883732e-01\n -8.5468113e-02 -4.7057986e-02\
          \ -3.3258295e-01 -3.0318606e-01\n  1.7081678e-02 -2.7110004e-01  5.8851242e-02\
          \  1.9084024e-01\n  1.0545349e-01  3.1597471e-01 -1.0404688e-01  3.0050000e+02\n\
          \  3.5285890e-01  1.5005761e-01  1.2166655e-01  2.7515578e-01\n -4.3655491e-01\
          \  3.0277205e-01 -1.7887896e-01 -1.1062765e-01\n -4.8577785e-02 -4.4682547e-01\
          \  2.5716841e-01 -2.6686859e-01\n -1.1770558e-01  4.5692694e-01  1.3246715e-01\
          \  1.0651350e-03\n  3.0750632e-02 -3.5641009e-01 -2.5660861e-01 -2.6990712e-01\n\
          \ -3.9869297e-01  1.5231764e-01  2.7515578e-01  7.6247871e-02\n  2.1460116e-01\
          \  1.6360199e-01  1.8136692e-01 -1.4676123e+00]"
    num_agent_steps_sampled: 344000
    num_agent_steps_trained: 4116048
    num_steps_sampled: 344000
    num_steps_trained: 4116048
    num_target_updates: 681
  iterations_since_restore: 344
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.785000000000004
    ram_util_percent: 32.30999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049233026100461943
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.79153963951404
    mean_inference_ms: 1.5873265437083883
    mean_raw_obs_processing_ms: 0.1440759934949864
  time_since_restore: 4828.830141782761
  time_this_iter_s: 13.336573123931885
  time_total_s: 4828.830141782761
  timers:
    learn_throughput: 3826.221
    learn_time_ms: 12.545
    update_time_ms: 5.545
  timestamp: 1629285578
  timesteps_since_restore: 0
  timesteps_total: 344000
  training_iteration: 344
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    344 |          4828.83 | 344000 | 5.25958e+06 |          7.25484e+06 |             -198.044 |             8424.7 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 345000
  custom_metrics: {}
  date: 2021-08-18_11-19-52
  done: false
  episode_len_mean: 8412.170731707318
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5308244.51749502
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 344728
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 9.161073684692383
          max_q: 7254790.0
          mean_q: 151140.4375
          mean_td_error: -0.8432275652885437
          min_q: -1.899381160736084
        model: {}
        td_error: "[-2.80293405e-01  1.25968143e-01  1.49602413e-01 -1.36377484e-01\n\
          \  1.35409951e-01 -1.79607868e-01 -1.05876803e+00 -5.80114663e-01\n  2.04070807e-02\
          \ -7.98373759e-01 -5.96823096e-02  2.00774550e-01\n  1.25539780e-01 -1.50746942e-01\
          \ -4.18108046e-01 -1.02495790e-01\n  6.22036457e-02  3.93490672e-01 -2.23158121e-01\
          \  4.01098967e-01\n -2.24954724e-01 -4.52762306e-01  1.62718773e-01 -8.98722410e-02\n\
          \ -7.46675730e-02  1.96968675e-01  1.81408644e-01 -2.48348713e-01\n -3.61882508e-01\
          \ -2.12270141e-01 -6.06234252e-01 -1.15112305e-01\n -1.00160480e-01 -1.12624452e-01\
          \  1.39615476e-01  1.57368183e-01\n  8.75627995e-03 -3.58599424e-01  1.73294544e-01\
          \ -6.56416416e-02\n  1.36130929e-01 -3.71589661e-01  1.78440452e-01 -3.48965108e-01\n\
          \ -3.45000000e+01 -1.40440583e-01 -5.82020402e-01 -4.70248401e-01]"
    num_agent_steps_sampled: 345000
    num_agent_steps_trained: 4128048
    num_steps_sampled: 345000
    num_steps_trained: 4128048
    num_target_updates: 683
  iterations_since_restore: 345
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.73157894736842
    ram_util_percent: 32.368421052631575
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923055601843503
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.805480474019107
    mean_inference_ms: 1.587370875758754
    mean_raw_obs_processing_ms: 0.1440851946681939
  time_since_restore: 4842.238506317139
  time_this_iter_s: 13.408364534378052
  time_total_s: 4842.238506317139
  timers:
    learn_throughput: 4950.333
    learn_time_ms: 9.696
    update_time_ms: 2.779
  timestamp: 1629285592
  timesteps_since_restore: 0
  timesteps_total: 345000
  training_iteration: 345
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    345 |          4842.24 | 345000 | 5.30824e+06 |          7.25484e+06 |             -198.044 |            8412.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 346000
  custom_metrics: {}
  date: 2021-08-18_11-20-04
  done: false
  episode_len_mean: 8412.170731707318
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5308244.51749502
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 41
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 345736
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.060270246118307114
          max_q: 5.381639003753662
          mean_q: -0.6074873208999634
          mean_td_error: -0.050379469990730286
          min_q: -1.7291064262390137
        model: {}
        td_error: "[-0.05172968  0.1295836   0.632766    0.20509607 -0.7119242  -3.665162\n\
          \  0.07980335  0.19292629 -0.05919814 -0.00834668 -0.01060915 -0.18319142\n\
          \  0.7864679   0.45540524  0.10520148 -0.19429493 -0.03064883  0.10188544\n\
          \  0.19074178 -0.12334013  0.3937807  -0.02674043  0.05703592  0.12358236\n\
          \  0.04195452 -0.11549455 -0.31331766  0.11565232  0.24785638  0.12562513\n\
          \ -0.07354379  0.19216096  0.03278697  0.13737166  0.03259927 -0.10807514\n\
          \  0.12280929 -0.23914304 -0.0666002  -0.36206424 -0.07433617  0.27932847\n\
          \ -0.01810086 -0.62663126  0.05526361 -0.04313344  0.02620113 -0.17647445]"
    num_agent_steps_sampled: 346000
    num_agent_steps_trained: 4140048
    num_steps_sampled: 346000
    num_steps_trained: 4140048
    num_target_updates: 685
  iterations_since_restore: 346
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.09411764705883
    ram_util_percent: 32.323529411764696
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923055601843503
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.805480474019107
    mean_inference_ms: 1.587370875758754
    mean_raw_obs_processing_ms: 0.1440851946681939
  time_since_restore: 4853.730554103851
  time_this_iter_s: 11.492047786712646
  time_total_s: 4853.730554103851
  timers:
    learn_throughput: 5084.737
    learn_time_ms: 9.44
    update_time_ms: 3.196
  timestamp: 1629285604
  timesteps_since_restore: 0
  timesteps_total: 346000
  training_iteration: 346
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    346 |          4853.73 | 346000 | 5.30824e+06 |          7.25484e+06 |             -198.044 |            8412.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 347000
  custom_metrics: {}
  date: 2021-08-18_11-20-16
  done: false
  episode_len_mean: 8412.170731707318
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5308244.51749502
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 41
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 346744
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.517987251281738
          max_q: 7256108.0
          mean_q: 151167.84375
          mean_td_error: 26.733022689819336
          min_q: -1.9512653350830078
        model: {}
        td_error: "[-2.48808801e-01  1.26391768e-01  6.19029999e-02 -9.68481302e-02\n\
          \  8.93142939e-01 -1.32062805e+00  2.33399868e-03 -8.03179741e-02\n  3.79513383e-01\
          \  6.34491444e-03  7.06825256e-02 -2.01552153e-01\n  1.08591318e-01  9.47940946e-02\
          \  2.48357296e-01  2.84831524e-01\n -4.10441160e-02  1.73315883e-01 -2.80483961e-01\
          \ -1.89760715e-01\n -2.49826908e-01  7.36705065e-02  2.17483640e-01 -1.16135776e-01\n\
          \ -4.46573377e-01  3.54576111e-02 -3.52625847e-02 -6.37284517e-02\n  1.91597700e-01\
          \  2.13036776e-01 -3.70810628e-01  2.22841859e-01\n  1.26023173e-01  9.75406170e-03\
          \  1.28350000e+03 -9.64940786e-02\n  1.61320210e-01  1.89247727e-01  1.21866226e-01\
          \  2.10205436e-01\n  3.80270839e-01 -6.12694740e-01  1.09243989e-01 -5.69902420e-01\n\
          \ -2.07508981e-01 -3.14389825e-01  3.82675052e-01  1.33082271e-01]"
    num_agent_steps_sampled: 347000
    num_agent_steps_trained: 4152048
    num_steps_sampled: 347000
    num_steps_trained: 4152048
    num_target_updates: 687
  iterations_since_restore: 347
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.61666666666666
    ram_util_percent: 32.39444444444444
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923055601843503
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.805480474019107
    mean_inference_ms: 1.587370875758754
    mean_raw_obs_processing_ms: 0.1440851946681939
  time_since_restore: 4865.806660890579
  time_this_iter_s: 12.076106786727905
  time_total_s: 4865.806660890579
  timers:
    learn_throughput: 3364.73
    learn_time_ms: 14.266
    update_time_ms: 4.997
  timestamp: 1629285616
  timesteps_since_restore: 0
  timesteps_total: 347000
  training_iteration: 347
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    347 |          4865.81 | 347000 | 5.30824e+06 |          7.25484e+06 |             -198.044 |            8412.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 348000
  custom_metrics: {}
  date: 2021-08-18_11-20-29
  done: false
  episode_len_mean: 8412.170731707318
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5308244.51749502
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 41
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 347752
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06302209943532944
          max_q: 0.9899827241897583
          mean_q: -1.020066261291504
          mean_td_error: -0.05777416378259659
          min_q: -1.9629312753677368
        model: {}
        td_error: "[ 0.07781959 -0.47838777 -0.02034307  0.21043754 -0.08413911  0.19111097\n\
          \  0.07945645  0.38268042 -0.30144775 -0.40984952 -0.23018348 -0.2066685\n\
          \ -0.1058166  -0.11538708  0.17257977 -0.2827742  -0.01674516 -0.20953631\n\
          \  0.11011207  0.15851963 -0.14221084 -0.21737826  0.07528114 -0.03418791\n\
          \ -0.86998975  0.1475972   0.44632864 -0.21458304 -0.36548996 -0.1828202\n\
          \  0.20674336  0.11037946 -0.03524518 -0.03574896 -0.0442822  -0.475639\n\
          \ -0.7715954  -0.21296978  0.06664318  0.10307956  0.15523958 -0.11754662\n\
          \  0.21153641  0.05958319 -0.06315577  0.07995486  0.05292463  0.372954  ]"
    num_agent_steps_sampled: 348000
    num_agent_steps_trained: 4164048
    num_steps_sampled: 348000
    num_steps_trained: 4164048
    num_target_updates: 689
  iterations_since_restore: 348
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.21111111111111
    ram_util_percent: 32.4
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04923055601843503
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.805480474019107
    mean_inference_ms: 1.587370875758754
    mean_raw_obs_processing_ms: 0.1440851946681939
  time_since_restore: 4878.088230133057
  time_this_iter_s: 12.281569242477417
  time_total_s: 4878.088230133057
  timers:
    learn_throughput: 5001.654
    learn_time_ms: 9.597
    update_time_ms: 2.816
  timestamp: 1629285629
  timesteps_since_restore: 0
  timesteps_total: 348000
  training_iteration: 348
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    348 |          4878.09 | 348000 | 5.30824e+06 |          7.25484e+06 |             -198.044 |            8412.17 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 349000
  custom_metrics: {}
  date: 2021-08-18_11-20-42
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 348760
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 42.33858108520508
          max_q: 7254952.0
          mean_q: 302288.75
          mean_td_error: 5.178508758544922
          min_q: -1.6311739683151245
        model: {}
        td_error: "[-2.2686183e+00 -4.9174345e-01  2.6665235e-01  1.0270488e-01\n  2.2152752e-01\
          \ -5.2400506e-01  5.2445769e-02  2.3474848e-01\n -4.7800374e-01  2.6590526e-01\
          \ -3.5503864e-02 -1.2335706e-01\n  2.8624421e-01 -2.8348368e-01 -2.8476954e-01\
          \ -4.8973161e-01\n -1.5061265e-01  1.1844301e-01 -2.2885296e-01 -1.6109419e-01\n\
          \  1.1060202e-01 -1.7139482e-01  1.2800000e+02  2.5934505e-01\n -2.4785644e-01\
          \ -7.2898275e-01  1.2800000e+02 -4.6366769e-01\n -1.5756631e-01 -2.8904879e-01\
          \  1.4497769e-01 -1.1273575e-01\n  1.6425538e-01 -9.6604824e-02 -2.3881882e-01\
          \  3.6095285e-01\n -1.7758689e+00 -9.7729921e-02  5.6732416e-02  1.7822266e-01\n\
          \ -2.0224023e-01  1.6609454e-01  6.5850139e-02 -2.1266854e-01\n  7.9464912e-02\
          \  4.7258234e-01 -6.6511917e-01 -5.9236646e-02]"
    num_agent_steps_sampled: 349000
    num_agent_steps_trained: 4176048
    num_steps_sampled: 349000
    num_steps_trained: 4176048
    num_target_updates: 691
  iterations_since_restore: 349
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.866666666666674
    ram_util_percent: 32.383333333333326
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 4890.208289146423
  time_this_iter_s: 12.1200590133667
  time_total_s: 4890.208289146423
  timers:
    learn_throughput: 5036.968
    learn_time_ms: 9.53
    update_time_ms: 2.764
  timestamp: 1629285642
  timesteps_since_restore: 0
  timesteps_total: 349000
  training_iteration: 349
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    349 |          4890.21 | 349000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 350000
  custom_metrics: {}
  date: 2021-08-18_11-20-54
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 349768
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 9.529078483581543
          max_q: 7254260.5
          mean_q: 151129.859375
          mean_td_error: -11.677701950073242
          min_q: -1.4789280891418457
        model: {}
        td_error: "[ 2.50366032e-02  2.09755778e-01  1.07037067e-01  7.26419687e-02\n\
          \  2.99719572e-01  5.66573143e-02 -1.20922327e-02  9.70824212e-02\n -2.08242416e-01\
          \  1.89467818e-01  8.46059322e-02  9.78708267e-02\n -1.24934912e-01  1.02294445e-01\
          \  1.75677299e-01  2.35944510e-01\n  5.33105373e-01 -2.87183404e-01 -2.90277272e-01\
          \  4.95915174e-01\n -2.06074595e-01  2.45060682e-01 -3.58521700e-01  2.50209570e-01\n\
          \ -1.29846454e-01 -4.53098297e-01 -9.96495485e-02  1.93146348e-01\n  2.59561539e-02\
          \  5.79470754e-01  2.70625830e-01 -5.64000000e+02\n  3.83190513e-02  3.14013958e-01\
          \ -8.23039412e-02 -3.01760435e-02\n -2.29974985e-02  3.03358138e-01 -5.62345982e-03\
          \ -1.61701620e-01\n  2.61807442e-01  1.17811441e-01  1.18599951e-01 -1.71182156e-02\n\
          \  9.28223133e-03  5.59124947e-02  6.09655380e-02  3.32824588e-01]"
    num_agent_steps_sampled: 350000
    num_agent_steps_trained: 4188048
    num_steps_sampled: 350000
    num_steps_trained: 4188048
    num_target_updates: 693
  iterations_since_restore: 350
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.68235294117648
    ram_util_percent: 32.305882352941175
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 4901.709943771362
  time_this_iter_s: 11.501654624938965
  time_total_s: 4901.709943771362
  timers:
    learn_throughput: 5080.067
    learn_time_ms: 9.449
    update_time_ms: 2.831
  timestamp: 1629285654
  timesteps_since_restore: 0
  timesteps_total: 350000
  training_iteration: 350
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    350 |          4901.71 | 350000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 351000
  custom_metrics: {}
  date: 2021-08-18_11-21-05
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 350776
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 11.867788314819336
          max_q: 7255806.0
          mean_q: 151161.828125
          mean_td_error: 20.50944709777832
          min_q: -2.0091474056243896
        model: {}
        td_error: "[ 2.52276301e-01  2.94130802e-01  2.38860130e-01  1.11032486e-01\n\
          \ -1.34724125e-01  5.86513281e-02  2.69889832e-04 -9.57202911e-03\n  3.96868527e-01\
          \ -7.91332603e-01 -1.95384026e-02  1.84581876e-01\n  5.55030942e-01  1.34115219e-02\
          \  3.43805790e-01 -4.32124138e-02\n -5.08782387e-01  3.34571242e-01 -1.10389590e-01\
          \  6.29006803e-01\n -2.13871002e-02 -8.09006393e-02 -1.27032697e-01 -3.37947547e-01\n\
          \  6.02243841e-02 -6.33710384e-01  5.23931980e-01  1.87449455e-01\n  2.48398542e-01\
          \  8.50987434e-03 -4.34976578e-01  3.27136338e-01\n  9.82000000e+02  4.16289866e-01\
          \  1.22051656e-01  3.07273954e-01\n -8.48531723e-02 -4.34959948e-01 -5.96646488e-01\
          \  3.08178663e-01\n  6.02229834e-02  3.03902030e-01  8.35458040e-02 -2.84962654e-02\n\
          \ -3.56119156e-01  4.91798401e-01  2.75252521e-01  7.13357925e-02]"
    num_agent_steps_sampled: 351000
    num_agent_steps_trained: 4200048
    num_steps_sampled: 351000
    num_steps_trained: 4200048
    num_target_updates: 695
  iterations_since_restore: 351
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.599999999999994
    ram_util_percent: 32.30625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 4912.794461250305
  time_this_iter_s: 11.084517478942871
  time_total_s: 4912.794461250305
  timers:
    learn_throughput: 4934.016
    learn_time_ms: 9.728
    update_time_ms: 2.795
  timestamp: 1629285665
  timesteps_since_restore: 0
  timesteps_total: 351000
  training_iteration: 351
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    351 |          4912.79 | 351000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 352000
  custom_metrics: {}
  date: 2021-08-18_11-21-18
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 351784
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 22.221662521362305
          max_q: 7253991.0
          mean_q: 302248.4375
          mean_td_error: -34.8619384765625
          min_q: -1.9725207090377808
        model: {}
        td_error: "[-8.6692983e-01  3.5890055e-01 -2.4224639e-01  3.5560131e-03\n  4.1225815e-01\
          \  1.1724162e-01  5.7604194e-02 -6.8690163e-01\n -5.1492035e-02  4.5892239e-02\
          \ -3.5650504e-01 -2.4812686e-01\n -3.9600396e-01  1.2984395e-01 -1.0113573e-01\
          \  1.3788605e-01\n -2.1129107e-01 -3.3135289e-01  2.5029218e-01  2.7245402e-01\n\
          \ -8.3350000e+02  2.3982835e-01  1.6997695e-01 -1.4527702e-01\n  3.6426413e-01\
          \ -1.3896683e-01  4.3495667e-01  1.5317619e-01\n -2.9153759e+00 -6.3775110e-01\
          \ -3.9012003e-01 -1.5955174e-01\n -1.9124627e-02 -9.1001391e-03 -1.8409729e-02\
          \  1.7957431e-01\n -8.1420004e-02 -2.3818183e-01 -6.1892390e-02 -1.2941226e-01\n\
          \ -1.9392836e-01 -8.3350000e+02 -4.3446946e-01  2.1093726e-01\n  3.8761497e-02\
          \ -1.4513135e-01 -6.9442004e-01 -4.5992672e-02]"
    num_agent_steps_sampled: 352000
    num_agent_steps_trained: 4212048
    num_steps_sampled: 352000
    num_steps_trained: 4212048
    num_target_updates: 697
  iterations_since_restore: 352
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.98421052631579
    ram_util_percent: 32.30526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 4925.878169536591
  time_this_iter_s: 13.0837082862854
  time_total_s: 4925.878169536591
  timers:
    learn_throughput: 4954.268
    learn_time_ms: 9.689
    update_time_ms: 2.883
  timestamp: 1629285678
  timesteps_since_restore: 0
  timesteps_total: 352000
  training_iteration: 352
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    352 |          4925.88 | 352000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 353000
  custom_metrics: {}
  date: 2021-08-18_11-21-32
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 352792
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0718814805150032
          max_q: 0.6781143546104431
          mean_q: -0.9993641376495361
          mean_td_error: -0.019821085035800934
          min_q: -1.7914860248565674
        model: {}
        td_error: "[ 0.0242604   0.02396393  0.49441314 -0.0780437  -0.4164443   0.15072286\n\
          \ -0.39229906  0.10345411  0.02964143 -0.25472808 -0.07541847 -0.2711798\n\
          \  0.12125266  0.34272242  0.13341844  0.21352315 -0.44651282  0.01479584\n\
          \ -0.02214265  0.2051884  -0.0882138  -0.48045582 -0.18570662 -0.14548877\n\
          \ -0.06825739 -0.17794502 -0.14379156  0.39503896 -0.47636318  0.03722782\n\
          \  0.28935784  0.18343109  0.40330255 -0.01311326  0.23024607  0.14323461\n\
          \  0.17023814  0.16644025  0.12951899 -0.12545812 -0.12106538 -0.66642475\n\
          \ -0.44416487  0.54486555 -0.18521911  0.40761614 -0.41490078 -0.2159496 ]"
    num_agent_steps_sampled: 353000
    num_agent_steps_trained: 4224048
    num_steps_sampled: 353000
    num_steps_trained: 4224048
    num_target_updates: 699
  iterations_since_restore: 353
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.575
    ram_util_percent: 32.30499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 4939.0244154930115
  time_this_iter_s: 13.146245956420898
  time_total_s: 4939.0244154930115
  timers:
    learn_throughput: 4498.737
    learn_time_ms: 10.67
    update_time_ms: 2.911
  timestamp: 1629285692
  timesteps_since_restore: 0
  timesteps_total: 353000
  training_iteration: 353
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    353 |          4939.02 | 353000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 354000
  custom_metrics: {}
  date: 2021-08-18_11-21-45
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 353800
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.58212947845459
          max_q: 7254971.5
          mean_q: 151144.296875
          mean_td_error: 3.1113462448120117
          min_q: -2.097738265991211
        model: {}
        td_error: "[ 1.9246459e-01 -1.3020134e-01 -4.4314885e-01  1.2113607e-01\n  9.3871593e-02\
          \ -1.6830575e-01  5.7041645e-03  3.0509114e-02\n -3.2985759e-01  1.9847846e-01\
          \ -8.7877870e-02  2.7980685e-02\n  1.2224394e-01 -1.4100111e-01  8.3737850e-02\
          \  4.5784593e-02\n  1.0863578e-01 -6.4362764e-02  3.2705736e-01  7.3096156e-02\n\
          \  2.7962291e-01  1.4042854e-04 -1.2078130e-01  7.3577046e-02\n  1.6303825e-01\
          \  1.8175614e-01 -1.4188021e-01 -6.2133312e-02\n -5.5565953e-02  6.1345714e-01\
          \  3.0722034e-01  1.9608974e-02\n -1.3885534e-01  3.6583650e-01 -8.8694572e-02\
          \ -2.3244880e-02\n -6.3940227e-02 -4.4323787e-02 -1.9404936e-01  3.2514906e-01\n\
          \  2.6994562e-01  2.0099878e-02  3.9124781e-01 -9.0200007e-02\n  1.4650000e+02\
          \  3.9629269e-01  6.0963702e-01 -2.1427727e-01]"
    num_agent_steps_sampled: 354000
    num_agent_steps_trained: 4236048
    num_steps_sampled: 354000
    num_steps_trained: 4236048
    num_target_updates: 701
  iterations_since_restore: 354
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.40555555555555
    ram_util_percent: 32.30555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 4951.718628406525
  time_this_iter_s: 12.694212913513184
  time_total_s: 4951.718628406525
  timers:
    learn_throughput: 4703.771
    learn_time_ms: 10.205
    update_time_ms: 2.934
  timestamp: 1629285705
  timesteps_since_restore: 0
  timesteps_total: 354000
  training_iteration: 354
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    354 |          4951.72 | 354000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 355000
  custom_metrics: {}
  date: 2021-08-18_11-22-00
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 354808
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 18.544189453125
          max_q: 7254753.0
          mean_q: 302280.46875
          mean_td_error: -3.105079412460327
          min_q: -1.8639883995056152
        model: {}
        td_error: "[-6.86891735e-01 -5.90450466e-02  2.19883680e-01  7.76188374e-02\n\
          \ -2.57074833e-01 -1.79468036e-01 -7.15000000e+01 -3.25153232e-01\n  3.22876275e-01\
          \ -7.55543113e-02 -9.86186266e-02 -4.45352674e-01\n -1.84843302e-01 -2.58766651e-01\
          \ -1.45832181e-01 -1.57843411e-01\n -3.56390357e-01 -1.44405246e-01  4.48959947e-01\
          \  1.06885076e-01\n  2.96139717e-03 -4.53495860e-01  1.50156260e-01 -1.56429291e-01\n\
          \  1.58184886e-01 -7.17531443e-02  5.19283712e-02 -2.97106934e+00\n  1.74342990e-01\
          \ -4.52632785e-01  1.94023728e-01  5.81717491e-02\n -1.62770867e-01  3.00070643e-01\
          \  1.79510951e-01  5.97176552e-02\n -7.15000000e+01 -1.44102275e-01  1.18451476e-01\
          \ -2.37506866e-01\n -1.00346804e-02  3.18149447e-01  4.72557545e-02  3.14470053e-01\n\
          \ -4.82698679e-01 -3.82725000e-02 -4.14752960e-01 -3.76686126e-01]"
    num_agent_steps_sampled: 355000
    num_agent_steps_trained: 4248048
    num_steps_sampled: 355000
    num_steps_trained: 4248048
    num_target_updates: 703
  iterations_since_restore: 355
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.74761904761906
    ram_util_percent: 32.30476190476189
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 4966.23765707016
  time_this_iter_s: 14.519028663635254
  time_total_s: 4966.23765707016
  timers:
    learn_throughput: 4607.185
    learn_time_ms: 10.419
    update_time_ms: 2.816
  timestamp: 1629285720
  timesteps_since_restore: 0
  timesteps_total: 355000
  training_iteration: 355
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    355 |          4966.24 | 355000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 356000
  custom_metrics: {}
  date: 2021-08-18_11-22-17
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 355816
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.24210432171821594
          max_q: 1.05978524684906
          mean_q: -1.246367335319519
          mean_td_error: -0.23503851890563965
          min_q: -2.1235251426696777
        model: {}
        td_error: "[ 0.29257354 -0.3210739  -0.22028303 -0.07724433 -0.47879136 -0.31234407\n\
          \ -0.99225104 -0.16719162 -0.04001629 -0.44640934 -0.17629647  0.09691978\n\
          \ -1.0387652  -0.45087254  0.2943387  -0.5699369  -0.38327873  0.16714776\n\
          \ -0.30844378  0.2391429  -0.36625075 -0.07394612 -0.1712215  -0.5488986\n\
          \ -0.17510486 -0.2711922  -0.15141308 -0.32622904 -0.17704046 -0.8593135\n\
          \ -0.39222032 -0.02678037 -0.05425137  0.03611994 -0.44110525 -0.20579949\n\
          \ -0.03637445 -0.4014665  -0.33782423 -0.5930375  -0.00606346  0.26112568\n\
          \  0.01482868 -0.44217086 -0.15665936  0.2104249  -0.3707465  -0.32616186]"
    num_agent_steps_sampled: 356000
    num_agent_steps_trained: 4260048
    num_steps_sampled: 356000
    num_steps_trained: 4260048
    num_target_updates: 705
  iterations_since_restore: 356
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.47916666666667
    ram_util_percent: 32.454166666666666
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 4982.638903617859
  time_this_iter_s: 16.401246547698975
  time_total_s: 4982.638903617859
  timers:
    learn_throughput: 3372.892
    learn_time_ms: 14.231
    update_time_ms: 3.274
  timestamp: 1629285737
  timesteps_since_restore: 0
  timesteps_total: 356000
  training_iteration: 356
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    356 |          4982.64 | 356000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 357000
  custom_metrics: {}
  date: 2021-08-18_11-22-35
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 356824
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 11.522589683532715
          max_q: 7254818.0
          mean_q: 151141.125
          mean_td_error: -0.12666645646095276
          min_q: -1.8741512298583984
        model: {}
        td_error: "[ 2.7610338e-01 -1.1584008e-01 -2.9560077e-01 -5.1641721e-01\n -1.3190281e-01\
          \  4.8198617e-01  7.6540124e-01  2.9911399e-03\n  1.4253962e-01  3.3499837e-02\
          \ -7.0000000e+00  7.0357323e-04\n  4.8936838e-01 -2.9003918e-02  6.9221973e-02\
          \ -2.4537086e-01\n -1.6905975e-01 -1.6526704e+00 -1.6958547e-01  2.2314394e-01\n\
          \  3.1971633e-01 -3.3009928e-01  7.3814845e-01  3.2589519e-01\n -6.9289088e-02\
          \  2.6268768e-01 -1.8505943e-01 -1.2345454e-01\n  2.1021998e-01 -4.0526688e-01\
          \  4.3183029e-01 -2.9279459e-01\n  1.2334454e-01  9.7679138e-02  2.9144263e-01\
          \  9.7579837e-02\n -2.7524257e-01  7.4477911e-02 -1.9626093e-01  2.0572019e-01\n\
          \  1.1657000e-02 -2.2734113e-01  2.5721562e-01  2.2632316e-01\n  3.3554888e-01\
          \  5.8290720e-02  1.3127863e-01 -3.3374536e-01]"
    num_agent_steps_sampled: 357000
    num_agent_steps_trained: 4272048
    num_steps_sampled: 357000
    num_steps_trained: 4272048
    num_target_updates: 707
  iterations_since_restore: 357
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 71.38888888888889
    ram_util_percent: 32.53703703703704
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 5000.529579162598
  time_this_iter_s: 17.89067554473877
  time_total_s: 5000.529579162598
  timers:
    learn_throughput: 4933.399
    learn_time_ms: 9.73
    update_time_ms: 2.838
  timestamp: 1629285755
  timesteps_since_restore: 0
  timesteps_total: 357000
  training_iteration: 357
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    357 |          5000.53 | 357000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 358000
  custom_metrics: {}
  date: 2021-08-18_11-22-50
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 357832
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 15.1867036819458
          max_q: 7254018.0
          mean_q: 302249.71875
          mean_td_error: -33.61114501953125
          min_q: -2.1436729431152344
        model: {}
        td_error: "[ 1.0671097e-01  4.3242931e-01  1.2303519e-01  1.8065631e-01\n -3.0364747e+00\
          \ -1.5487063e-01  4.6781135e-01 -4.3746880e-01\n  1.9925684e-03 -1.4929450e-01\
          \ -3.7494034e-01  7.3397219e-02\n  4.4725835e-01 -3.1434321e-01  2.2440577e-01\
          \  3.8840896e-01\n -2.5336987e-01 -8.0700000e+02 -2.6056302e-01 -4.8661745e-01\n\
          \  3.4337294e-01  4.2503071e-01 -3.3102691e-01 -4.6852469e-02\n -1.4504886e-01\
          \  8.1152081e-02 -8.0700000e+02  1.6862965e-01\n -2.2782826e-01  6.5979004e-01\
          \  1.3898325e-01 -4.1556084e-01\n -2.3618340e-01  3.7466586e-01 -1.1932850e-02\
          \  1.1859894e-02\n  3.6403739e-01  2.8775072e-01  1.9185376e-01 -1.7273700e-01\n\
          \  4.9722242e-01 -1.3896954e-01  4.2285228e-01  3.7124157e-02\n  5.5423582e-01\
          \  4.5300603e-02  2.4050236e-01  5.6876075e-01]"
    num_agent_steps_sampled: 358000
    num_agent_steps_trained: 4284048
    num_steps_sampled: 358000
    num_steps_trained: 4284048
    num_target_updates: 709
  iterations_since_restore: 358
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.3
    ram_util_percent: 32.5
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 5015.404039621353
  time_this_iter_s: 14.874460458755493
  time_total_s: 5015.404039621353
  timers:
    learn_throughput: 4978.661
    learn_time_ms: 9.641
    update_time_ms: 3.003
  timestamp: 1629285770
  timesteps_since_restore: 0
  timesteps_total: 358000
  training_iteration: 358
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    358 |           5015.4 | 358000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 359000
  custom_metrics: {}
  date: 2021-08-18_11-23-07
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 358840
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07453615963459015
          max_q: 4.888807773590088
          mean_q: -1.0754098892211914
          mean_td_error: 0.010296083055436611
          min_q: -1.9559390544891357
        model: {}
        td_error: "[ 0.27725768 -0.12712795 -0.01483238 -0.5147526   0.19333768 -0.2174021\n\
          \ -0.05696166 -0.49943316 -0.25182235  0.43032193 -0.09568727  0.21195304\n\
          \ -0.08705223 -0.00954902  0.43905056  0.12030661  0.28634155  0.11089325\n\
          \  0.279989    0.46504164 -0.31330502  0.07237363 -0.33482528 -0.26262355\n\
          \ -0.30387497  0.15337205  0.42534375 -0.48861015 -0.57338065  0.37138844\n\
          \ -0.07200384  0.48390675  0.39360607 -0.41785693 -0.3375635   0.715022\n\
          \  0.40014255 -0.09419441  0.32177913 -0.2592206   0.3311069   0.02864373\n\
          \ -0.50845206 -0.8539529  -0.0127331   0.66766524  0.33350217 -0.3109157 ]"
    num_agent_steps_sampled: 359000
    num_agent_steps_trained: 4296048
    num_steps_sampled: 359000
    num_steps_trained: 4296048
    num_target_updates: 711
  iterations_since_restore: 359
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.9
    ram_util_percent: 32.50833333333333
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 5031.750984668732
  time_this_iter_s: 16.34694504737854
  time_total_s: 5031.750984668732
  timers:
    learn_throughput: 4371.04
    learn_time_ms: 10.981
    update_time_ms: 3.053
  timestamp: 1629285787
  timesteps_since_restore: 0
  timesteps_total: 359000
  training_iteration: 359
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    359 |          5031.75 | 359000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 360000
  custom_metrics: {}
  date: 2021-08-18_11-23-23
  done: false
  episode_len_mean: 8304.42857142857
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5354588.404352854
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 359848
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.743652820587158
          max_q: 7254779.0
          mean_q: 151140.15625
          mean_td_error: -0.9693113565444946
          min_q: -2.3008005619049072
        model: {}
        td_error: "[ 3.8815308e-01  2.9530841e-01  2.1260011e-01  1.9442604e+00\n -1.6416681e-01\
          \  4.6423149e-01  3.1053901e-02  2.9209983e-01\n  1.0460085e-01 -1.7601023e+00\
          \ -3.0723214e-01  3.3275270e-01\n  2.1371245e-01  2.9403585e-01 -1.4780855e-01\
          \  4.9534726e-01\n  2.1974957e-01 -3.6345857e-01 -2.9640353e-01 -8.4817410e-04\n\
          \ -1.4701962e-01 -2.2554755e-02 -9.7827435e-02 -1.3125281e+00\n -2.1901786e-01\
          \  7.5133324e-01 -1.8435657e-01  1.7417407e-01\n -5.5039030e-01 -1.2203324e-01\
          \  1.5421736e-01  1.1918998e-01\n  3.3879876e-02  9.3135238e-02 -7.5375557e-01\
          \ -1.4780855e-01\n -5.9678537e-01  1.5425825e-01 -1.5772510e-01 -5.0527525e-01\n\
          \  1.3539886e-01 -4.3277681e-02  5.1772851e-01 -1.0386121e-01\n -3.8145971e-01\
          \ -5.1757693e-02 -1.0711193e-02 -4.5500000e+01]"
    num_agent_steps_sampled: 360000
    num_agent_steps_trained: 4308048
    num_steps_sampled: 360000
    num_steps_trained: 4308048
    num_target_updates: 713
  iterations_since_restore: 360
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.88695652173914
    ram_util_percent: 32.504347826086956
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922790107168825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.818214041725763
    mean_inference_ms: 1.5874115017959138
    mean_raw_obs_processing_ms: 0.14409311383869655
  time_since_restore: 5047.58274269104
  time_this_iter_s: 15.83175802230835
  time_total_s: 5047.58274269104
  timers:
    learn_throughput: 4855.443
    learn_time_ms: 9.886
    update_time_ms: 3.047
  timestamp: 1629285803
  timesteps_since_restore: 0
  timesteps_total: 360000
  training_iteration: 360
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    360 |          5047.58 | 360000 | 5.35459e+06 |          7.25484e+06 |             -198.044 |            8304.43 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 361000
  custom_metrics: {}
  date: 2021-08-18_11-23-41
  done: false
  episode_len_mean: 8390.46511627907
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5398775.55275467
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 360856
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08861026912927628
          max_q: 2.948127508163452
          mean_q: -0.9983174204826355
          mean_td_error: -0.003184886649250984
          min_q: -2.1626944541931152
        model: {}
        td_error: "[-0.25422704  0.14757681 -0.07929635  0.10078299 -0.3140926   0.15906829\n\
          \  0.32881665 -0.15715045  0.11698413  0.23925388 -0.3948977  -0.2820685\n\
          \ -0.48104107 -0.19535667 -0.11938715  0.37829018 -0.39869797  0.13322163\n\
          \ -0.09361291  0.23176587 -0.28542042  0.1818766   0.6680937  -0.25241065\n\
          \  0.13032019  0.07938101 -0.01328123 -0.06149942  0.07421136 -0.31854635\n\
          \  0.07140517 -0.04718232  0.2666278  -0.8561262  -0.39569378  0.31846035\n\
          \ -0.41014838  0.7898276  -0.18505776 -0.22154284 -0.15086961  0.2353698\n\
          \  0.5388715   0.03397167  0.13494492 -0.06922483  0.20743203  0.31740355]"
    num_agent_steps_sampled: 361000
    num_agent_steps_trained: 4320048
    num_steps_sampled: 361000
    num_steps_trained: 4320048
    num_target_updates: 715
  iterations_since_restore: 361
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.744
    ram_util_percent: 32.571999999999996
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922628235617232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.830508447526371
    mean_inference_ms: 1.5874936700029607
    mean_raw_obs_processing_ms: 0.14410321943410273
  time_since_restore: 5064.462048530579
  time_this_iter_s: 16.879305839538574
  time_total_s: 5064.462048530579
  timers:
    learn_throughput: 3734.799
    learn_time_ms: 12.852
    update_time_ms: 4.662
  timestamp: 1629285821
  timesteps_since_restore: 0
  timesteps_total: 361000
  training_iteration: 361
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    361 |          5064.46 | 361000 | 5.39878e+06 |          7.25484e+06 |             -198.044 |            8390.47 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 362000
  custom_metrics: {}
  date: 2021-08-18_11-23-52
  done: false
  episode_len_mean: 8390.46511627907
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5398775.55275467
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 43
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 361864
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.420639991760254
          max_q: 7254352.0
          mean_q: 151131.171875
          mean_td_error: -9.94326400756836
          min_q: -2.119595527648926
        model: {}
        td_error: "[-2.92209029e-01  1.50095367e+00 -4.02009249e-01  8.15145969e-02\n\
          \ -3.15221667e-01 -2.32785165e-01 -3.04171443e-01 -2.83747911e-01\n -1.05823398e-01\
          \ -1.24093652e-01 -3.55782628e-01 -1.20654106e-01\n  3.96744996e-01 -6.60860240e-02\
          \ -2.01948047e-01 -1.76932454e-01\n -2.13991165e-01  3.96274924e-01  2.16049671e-01\
          \ -1.26909018e-02\n -1.95977926e-01 -4.96072769e-01 -1.79949641e-01  1.64617538e-01\n\
          \ -6.53364658e-01 -3.29822123e-01  1.21215582e-01  5.19796789e-01\n  1.53998852e-01\
          \ -6.40810549e-01 -1.13894582e-01  3.85359645e-01\n -4.72500000e+02  4.04412270e-01\
          \  1.04357004e-01 -2.06626415e-01\n  1.94435954e-01  1.98381186e-01 -8.91456962e-01\
          \  1.81462109e-01\n -2.18950629e-01 -6.74155235e-01 -2.64960170e-01 -2.56655812e-01\n\
          \ -1.72368407e-01 -1.57581723e+00  6.64436162e-01 -3.81615877e-01]"
    num_agent_steps_sampled: 362000
    num_agent_steps_trained: 4332048
    num_steps_sampled: 362000
    num_steps_trained: 4332048
    num_target_updates: 717
  iterations_since_restore: 362
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.35625
    ram_util_percent: 32.4
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922628235617232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.830508447526371
    mean_inference_ms: 1.5874936700029607
    mean_raw_obs_processing_ms: 0.14410321943410273
  time_since_restore: 5074.960955142975
  time_this_iter_s: 10.49890661239624
  time_total_s: 5074.960955142975
  timers:
    learn_throughput: 3734.446
    learn_time_ms: 12.853
    update_time_ms: 4.722
  timestamp: 1629285832
  timesteps_since_restore: 0
  timesteps_total: 362000
  training_iteration: 362
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    362 |          5074.96 | 362000 | 5.39878e+06 |          7.25484e+06 |             -198.044 |            8390.47 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 363000
  custom_metrics: {}
  date: 2021-08-18_11-24-03
  done: false
  episode_len_mean: 8390.46511627907
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5398775.55275467
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 43
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 362872
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 10.141910552978516
          max_q: 7254940.0
          mean_q: 151143.5
          mean_td_error: 2.3095455169677734
          min_q: -2.5302343368530273
        model: {}
        td_error: "[-3.73494625e-02 -7.93752074e-02  4.91076708e-01 -3.45615685e-01\n\
          \  5.50475359e-01  3.10444832e-02  2.77634144e-01 -1.96647167e-01\n  7.07886815e-02\
          \ -1.98236525e-01  1.21843696e-01 -1.15617692e-01\n  1.15000000e+02  2.36014605e-01\
          \  4.76360321e-04 -2.69066691e-02\n -4.24419284e-01 -4.39822465e-01  3.49695921e-01\
          \  5.15677929e-02\n  3.91640902e-01 -3.92826915e-01 -4.04966712e-01 -2.24484801e-01\n\
          \  7.16133714e-02 -3.40724587e-01  2.03648686e-01 -2.71425009e-01\n -2.11876869e-01\
          \ -2.64430642e-01 -3.04739118e-01  5.08308783e-02\n -1.02399349e-01 -5.47944188e-01\
          \ -4.28070426e-01 -9.76232290e-02\n  1.16865039e-01  4.17364836e-01  1.13803029e-01\
          \ -3.73587549e-01\n -1.49216533e-01 -7.53950119e-01 -1.32732701e+00  2.28634000e-01\n\
          \ -1.84347630e-01  3.50478530e-01  5.71770668e-02 -8.05627108e-02]"
    num_agent_steps_sampled: 363000
    num_agent_steps_trained: 4344048
    num_steps_sampled: 363000
    num_steps_trained: 4344048
    num_target_updates: 719
  iterations_since_restore: 363
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.356249999999996
    ram_util_percent: 32.40625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922628235617232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.830508447526371
    mean_inference_ms: 1.5874936700029607
    mean_raw_obs_processing_ms: 0.14410321943410273
  time_since_restore: 5085.948436021805
  time_this_iter_s: 10.987480878829956
  time_total_s: 5085.948436021805
  timers:
    learn_throughput: 4967.053
    learn_time_ms: 9.664
    update_time_ms: 2.884
  timestamp: 1629285843
  timesteps_since_restore: 0
  timesteps_total: 363000
  training_iteration: 363
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    363 |          5085.95 | 363000 | 5.39878e+06 |          7.25484e+06 |             -198.044 |            8390.47 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 364000
  custom_metrics: {}
  date: 2021-08-18_11-24-15
  done: false
  episode_len_mean: 8390.46511627907
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5398775.55275467
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 43
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 363880
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.09055384248495102
          max_q: 5.391427516937256
          mean_q: -0.8817234039306641
          mean_td_error: 0.028642704710364342
          min_q: -1.9541740417480469
        model: {}
        td_error: "[ 0.29438937  0.05245006 -0.1026333  -0.58874315 -0.14516473  0.44543254\n\
          \ -0.139438    0.09822208  0.19961345 -0.16367215  0.05144823 -1.5018169\n\
          \ -0.04208052  0.27855098 -0.04215527 -0.03721654  0.09246659 -0.25304204\n\
          \  0.17362529 -0.65892285  0.48548406 -0.17420346  0.6640878   0.16574812\n\
          \ -0.6158331   0.20298612  0.47549748  0.450346    0.11523592 -0.41413325\n\
          \  0.5817647  -0.3998261   0.18186033 -0.17320037 -0.03357744 -0.05766416\n\
          \ -0.10224688 -0.13170397  0.28028798  0.23356915  0.43455422 -0.2605741\n\
          \  0.89878833 -0.07313854 -0.03824186  0.01114547  0.18697762  0.46954656]"
    num_agent_steps_sampled: 364000
    num_agent_steps_trained: 4356048
    num_steps_sampled: 364000
    num_steps_trained: 4356048
    num_target_updates: 721
  iterations_since_restore: 364
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.1888888888889
    ram_util_percent: 32.40555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922628235617232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.830508447526371
    mean_inference_ms: 1.5874936700029607
    mean_raw_obs_processing_ms: 0.14410321943410273
  time_since_restore: 5098.173371553421
  time_this_iter_s: 12.224935531616211
  time_total_s: 5098.173371553421
  timers:
    learn_throughput: 4995.176
    learn_time_ms: 9.609
    update_time_ms: 2.852
  timestamp: 1629285855
  timesteps_since_restore: 0
  timesteps_total: 364000
  training_iteration: 364
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    364 |          5098.17 | 364000 | 5.39878e+06 |          7.25484e+06 |             -198.044 |            8390.47 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 365000
  custom_metrics: {}
  date: 2021-08-18_11-24-28
  done: false
  episode_len_mean: 8390.46511627907
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5398775.55275467
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 43
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 364888
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.17525893449783325
          max_q: 5.0069379806518555
          mean_q: -0.7325669527053833
          mean_td_error: -0.11569871753454208
          min_q: -1.9561429023742676
        model: {}
        td_error: "[ 0.2042296  -0.08646739 -0.02802539 -0.2755819  -0.25501525  0.5232278\n\
          \  0.4347483  -0.3659171  -0.19069278  0.16749012 -0.502663    0.29268372\n\
          \ -1.0902029  -0.07440978 -0.01097596 -0.6653561  -0.0887934  -0.5850613\n\
          \ -0.17202312 -0.1583991  -0.3599695  -0.29610574 -0.01168334  0.0419122\n\
          \ -0.305027   -1.080637    0.01534426  0.07913804  0.26030034  0.10282886\n\
          \ -0.06753999 -0.29083526  0.23496878 -0.26747704  0.12144029 -0.2894795\n\
          \ -0.49348366  0.24860537  0.18016696 -0.06773949  0.16105962 -0.70158887\n\
          \  0.08767414 -0.57611346 -0.11423707 -0.22721547  0.5691161   0.42024392]"
    num_agent_steps_sampled: 365000
    num_agent_steps_trained: 4368048
    num_steps_sampled: 365000
    num_steps_trained: 4368048
    num_target_updates: 723
  iterations_since_restore: 365
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.477777777777774
    ram_util_percent: 32.4
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922628235617232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.830508447526371
    mean_inference_ms: 1.5874936700029607
    mean_raw_obs_processing_ms: 0.14410321943410273
  time_since_restore: 5110.581307888031
  time_this_iter_s: 12.407936334609985
  time_total_s: 5110.581307888031
  timers:
    learn_throughput: 5014.536
    learn_time_ms: 9.572
    update_time_ms: 2.787
  timestamp: 1629285868
  timesteps_since_restore: 0
  timesteps_total: 365000
  training_iteration: 365
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    365 |          5110.58 | 365000 | 5.39878e+06 |          7.25484e+06 |             -198.044 |            8390.47 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 366000
  custom_metrics: {}
  date: 2021-08-18_11-24-42
  done: false
  episode_len_mean: 8390.46511627907
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5398775.55275467
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 43
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 365896
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07744766771793365
          max_q: 5.2333526611328125
          mean_q: -0.8753201365470886
          mean_td_error: 0.025542259216308594
          min_q: -1.8969457149505615
        model: {}
        td_error: "[ 0.30735028  0.8916211   0.02035266  0.41363144  0.00324297 -0.49241638\n\
          \  0.09354949 -0.59305155 -0.821824   -0.13330585 -0.38260734 -0.04664081\n\
          \ -0.06196368  0.02776796  0.15033597 -0.05919373  0.33727813  0.6339275\n\
          \ -0.1905174  -0.00120628 -0.04864192  0.21649182  0.47665966  0.2515725\n\
          \  0.06633103  0.06579387  0.5066823   0.02750987  0.04856098 -0.80166173\n\
          \  0.28675056 -0.02948594 -0.16649258  0.51234627  0.22612274 -0.00210726\n\
          \  0.10630763 -0.10537004 -0.31196105  0.01887655 -0.49265826 -0.2837065\n\
          \  0.00893629  0.03189659 -0.04761279 -0.21151447  0.46144772  0.31862402]"
    num_agent_steps_sampled: 366000
    num_agent_steps_trained: 4380048
    num_steps_sampled: 366000
    num_steps_trained: 4380048
    num_target_updates: 725
  iterations_since_restore: 366
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.80526315789473
    ram_util_percent: 32.41052631578947
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922628235617232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.830508447526371
    mean_inference_ms: 1.5874936700029607
    mean_raw_obs_processing_ms: 0.14410321943410273
  time_since_restore: 5123.388901233673
  time_this_iter_s: 12.80759334564209
  time_total_s: 5123.388901233673
  timers:
    learn_throughput: 4906.755
    learn_time_ms: 9.782
    update_time_ms: 2.915
  timestamp: 1629285882
  timesteps_since_restore: 0
  timesteps_total: 366000
  training_iteration: 366
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    366 |          5123.39 | 366000 | 5.39878e+06 |          7.25484e+06 |             -198.044 |            8390.47 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 367000
  custom_metrics: {}
  date: 2021-08-18_11-24-56
  done: false
  episode_len_mean: 8390.46511627907
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5398775.55275467
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 43
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 366904
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05914278328418732
          max_q: 5.539261817932129
          mean_q: -0.5534163117408752
          mean_td_error: -0.007524795830249786
          min_q: -1.890084147453308
        model: {}
        td_error: "[ 5.9908676e-01  7.4253261e-02  4.2273128e-01  3.9976281e-01\n  2.1151894e-01\
          \  5.8054054e-01 -1.3049585e-01 -2.8592255e+00\n -5.1962137e-01 -2.5929999e-01\
          \ -2.8208494e-01 -1.2486911e-01\n -1.0850592e+00  4.9678677e-01 -3.5581806e-01\
          \  5.0013345e-01\n -2.9593781e-01  1.8264413e-01  4.8738074e-01  3.9590430e-01\n\
          \ -4.5056641e-02 -9.3405753e-02 -4.3583989e-01  2.7545810e-01\n -1.5512466e-01\
          \  2.1471494e-01  6.6735679e-01  5.3071165e-01\n  2.3807856e-01 -5.5943078e-01\
          \  2.3102282e-01 -2.8108954e-03\n  2.4624300e-01 -1.4572401e+00  3.0770648e-01\
          \  2.7439559e-01\n  2.6407790e-01  2.9340971e-01  1.6912448e-01  1.3991347e-01\n\
          \ -3.0405885e-01  4.9832845e-01 -8.0244541e-03 -5.4462194e-02\n -9.8959878e-02\
          \ -1.1481106e-01 -3.1125784e-02  2.1028745e-01]"
    num_agent_steps_sampled: 367000
    num_agent_steps_trained: 4392048
    num_steps_sampled: 367000
    num_steps_trained: 4392048
    num_target_updates: 727
  iterations_since_restore: 367
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.02500000000002
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922628235617232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.830508447526371
    mean_inference_ms: 1.5874936700029607
    mean_raw_obs_processing_ms: 0.14410321943410273
  time_since_restore: 5136.952138185501
  time_this_iter_s: 13.563236951828003
  time_total_s: 5136.952138185501
  timers:
    learn_throughput: 4743.0
    learn_time_ms: 10.12
    update_time_ms: 2.894
  timestamp: 1629285896
  timesteps_since_restore: 0
  timesteps_total: 367000
  training_iteration: 367
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    367 |          5136.95 | 367000 | 5.39878e+06 |          7.25484e+06 |             -198.044 |            8390.47 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 368000
  custom_metrics: {}
  date: 2021-08-18_11-25-10
  done: false
  episode_len_mean: 8390.46511627907
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5398775.55275467
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 43
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 367912
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 22.3945369720459
          max_q: 7255355.0
          mean_q: 302305.5625
          mean_td_error: 21.926071166992188
          min_q: -1.7804100513458252
        model: {}
        td_error: "[-6.74799621e-01 -8.66864920e-02 -4.97331142e-01 -4.45502996e-01\n\
          \  1.26152277e-01  5.30500000e+02 -1.73906684e-01 -2.73582458e-01\n -4.45571065e-01\
          \ -1.05089664e-01 -3.86623561e-01 -3.90501738e-01\n -1.60977840e-01 -2.32874155e-02\
          \ -3.35528970e-01  9.29361582e-02\n  7.06784725e-02 -1.90281749e-01 -7.36421645e-01\
          \  5.47415018e-03\n -7.85301924e-02 -4.58414733e-01  4.07971621e-01  4.02290821e-02\n\
          \  5.30500000e+02 -1.47189856e-01 -7.44988173e-02 -1.61516547e-01\n -6.37057543e-01\
          \ -2.83179760e-01 -1.01687312e+00  1.63168699e-01\n  6.16852045e-02 -5.04919529e-01\
          \  1.48223639e-01  4.49793458e-01\n -1.76795423e-01  1.15926385e-01 -3.80246341e-01\
          \ -6.28255129e-01\n -4.18811172e-01 -5.97875953e-01  3.67822409e-01 -7.79861212e-02\n\
          \ -1.93998635e-01  2.28316069e-01  2.96725035e-02 -9.44212675e-02]"
    num_agent_steps_sampled: 368000
    num_agent_steps_trained: 4404048
    num_steps_sampled: 368000
    num_steps_trained: 4404048
    num_target_updates: 729
  iterations_since_restore: 368
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.504999999999995
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922628235617232
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.830508447526371
    mean_inference_ms: 1.5874936700029607
    mean_raw_obs_processing_ms: 0.14410321943410273
  time_since_restore: 5150.585126161575
  time_this_iter_s: 13.632987976074219
  time_total_s: 5150.585126161575
  timers:
    learn_throughput: 4804.621
    learn_time_ms: 9.99
    update_time_ms: 2.99
  timestamp: 1629285910
  timesteps_since_restore: 0
  timesteps_total: 368000
  training_iteration: 368
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    368 |          5150.59 | 368000 | 5.39878e+06 |          7.25484e+06 |             -198.044 |            8390.47 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 369000
  custom_metrics: {}
  date: 2021-08-18_11-25-24
  done: false
  episode_len_mean: 8379.568181818182
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5440953.750942413
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 368920
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.678574562072754
          max_q: 7254183.0
          mean_q: 151127.90625
          mean_td_error: -13.408924102783203
          min_q: -1.8281903266906738
        model: {}
        td_error: "[ 4.17490005e-01  3.13634276e-01  4.84652996e-01 -5.83759546e-02\n\
          \ -2.04405785e-02 -2.22694218e-01 -3.13618600e-01  3.10418010e-01\n  8.03135335e-01\
          \ -2.78521180e-01 -3.39993596e-01  2.11908221e-02\n  1.35864735e-01  2.49028087e-01\
          \ -7.17708588e-01 -1.01214617e-01\n  3.92452478e-02  6.52222037e-02 -1.36721671e-01\
          \  1.20892584e-01\n  3.41484189e-01 -2.30503082e-01 -9.72889364e-02 -2.11190581e-01\n\
          \ -4.29388344e-01 -9.42517519e-02 -3.36991727e-01 -3.38774562e-01\n -5.44583797e-03\
          \  2.87262201e-02 -3.39826286e-01 -1.15652680e-01\n  2.48653769e-01  2.94498354e-02\
          \ -1.89270020e-01 -4.49687183e-01\n -1.84124589e-01 -6.41500000e+02  5.03956079e-02\
          \  1.76517248e-01\n -1.91774368e-02 -7.19804168e-02 -3.22868586e-01 -1.35981083e-01\n\
          \ -7.18946755e-01 -1.91088691e-02  4.40369844e-01  9.50863361e-02]"
    num_agent_steps_sampled: 369000
    num_agent_steps_trained: 4416048
    num_steps_sampled: 369000
    num_steps_trained: 4416048
    num_target_updates: 731
  iterations_since_restore: 369
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.31500000000001
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049224212456731725
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8415512672426795
    mean_inference_ms: 1.5875558330603219
    mean_raw_obs_processing_ms: 0.14411084218102924
  time_since_restore: 5164.647691488266
  time_this_iter_s: 14.062565326690674
  time_total_s: 5164.647691488266
  timers:
    learn_throughput: 5097.327
    learn_time_ms: 9.417
    update_time_ms: 2.717
  timestamp: 1629285924
  timesteps_since_restore: 0
  timesteps_total: 369000
  training_iteration: 369
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    369 |          5164.65 | 369000 | 5.44095e+06 |          7.25484e+06 |             -198.044 |            8379.57 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 370000
  custom_metrics: {}
  date: 2021-08-18_11-25-35
  done: false
  episode_len_mean: 8379.568181818182
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5440953.750942413
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 44
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 369928
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12.564044952392578
          max_q: 7253287.5
          mean_q: 302219.53125
          mean_td_error: -64.12564086914062
          min_q: -2.212432384490967
        model: {}
        td_error: "[-2.14885950e-01 -6.99231803e-01 -1.06456995e-01  1.21166587e-01\n\
          \  4.63297367e-02  3.95022631e-01  1.31524444e-01 -8.08916688e-02\n -6.36946440e-01\
          \  2.72630453e-02 -1.76866531e-01 -3.10751081e-01\n -6.04020834e-01  5.98422170e-01\
          \  2.00198293e-01  9.35362577e-02\n -1.91038847e-03 -1.53600000e+03 -5.93482256e-02\
          \  1.16685629e-01\n  1.20645285e-01 -2.49484777e-01 -1.10703707e-02 -2.18242884e-01\n\
          \ -1.53600000e+03 -4.43332016e-01  5.23840189e-02  5.62473536e-02\n -2.84598351e-01\
          \  3.08963060e-02 -3.45944881e-01  1.72975898e-01\n -6.97490573e-02  1.40110135e-01\
          \  3.00666809e-01 -3.20346951e-02\n -3.19806397e-01 -2.27556229e-02  3.86959434e-01\
          \ -4.08446133e-01\n  9.22492743e-02 -5.79516053e-01 -3.87915373e-02 -2.58360505e-01\n\
          \ -2.40056467e+00  8.68546963e-03 -3.84756327e-02 -5.10339797e-01]"
    num_agent_steps_sampled: 370000
    num_agent_steps_trained: 4428048
    num_steps_sampled: 370000
    num_steps_trained: 4428048
    num_target_updates: 733
  iterations_since_restore: 370
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.41250000000001
    ram_util_percent: 32.40625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049224212456731725
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8415512672426795
    mean_inference_ms: 1.5875558330603219
    mean_raw_obs_processing_ms: 0.14411084218102924
  time_since_restore: 5175.58765912056
  time_this_iter_s: 10.939967632293701
  time_total_s: 5175.58765912056
  timers:
    learn_throughput: 4984.355
    learn_time_ms: 9.63
    update_time_ms: 2.765
  timestamp: 1629285935
  timesteps_since_restore: 0
  timesteps_total: 370000
  training_iteration: 370
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    370 |          5175.59 | 370000 | 5.44095e+06 |          7.25484e+06 |             -198.044 |            8379.57 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 371000
  custom_metrics: {}
  date: 2021-08-18_11-25-48
  done: false
  episode_len_mean: 8379.568181818182
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5440953.750942413
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 44
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 370936
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.857987880706787
          max_q: 7256135.0
          mean_q: 151168.78125
          mean_td_error: 27.308515548706055
          min_q: -1.8444907665252686
        model: {}
        td_error: "[ 2.0463079e-01  1.0130870e-01  3.8011134e-02  5.9315342e-01\n -1.5415955e-01\
          \ -1.8413806e-01  8.4229946e-02  2.2312325e-01\n  1.1071336e-01 -3.3299601e-01\
          \  1.3105000e+03  4.3167627e-01\n -4.2206407e-02  2.0424891e-01 -1.7862004e-01\
          \  2.1871042e-01\n -2.6026487e-02 -3.3297306e-01  5.0794053e-01  4.4319749e-01\n\
          \  1.0267672e-01 -1.5155333e-01 -7.6142550e-03  2.5879145e-01\n  8.1692457e-02\
          \  6.5495992e-01  3.7135184e-02  9.5847607e-02\n -2.8160352e-01 -1.0949680e+00\
          \ -8.3465064e-01 -2.1969378e-02\n  3.0233908e-01  1.7429602e-01 -2.6039088e-01\
          \  2.9349029e-01\n  2.6702881e-01 -1.7368841e-01  1.0091281e-01  7.0845485e-02\n\
          \  6.6294789e-02 -3.2416207e-01 -3.9744559e-01 -2.7892828e-02\n -7.5637627e-01\
          \ -3.3363557e-01  3.8234830e-01  1.7606509e-01]"
    num_agent_steps_sampled: 371000
    num_agent_steps_trained: 4440048
    num_steps_sampled: 371000
    num_steps_trained: 4440048
    num_target_updates: 735
  iterations_since_restore: 371
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.1888888888889
    ram_util_percent: 32.40555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049224212456731725
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8415512672426795
    mean_inference_ms: 1.5875558330603219
    mean_raw_obs_processing_ms: 0.14411084218102924
  time_since_restore: 5187.517463445663
  time_this_iter_s: 11.92980432510376
  time_total_s: 5187.517463445663
  timers:
    learn_throughput: 4921.328
    learn_time_ms: 9.753
    update_time_ms: 2.802
  timestamp: 1629285948
  timesteps_since_restore: 0
  timesteps_total: 371000
  training_iteration: 371
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    371 |          5187.52 | 371000 | 5.44095e+06 |          7.25484e+06 |             -198.044 |            8379.57 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 372000
  custom_metrics: {}
  date: 2021-08-18_11-26-00
  done: false
  episode_len_mean: 8379.568181818182
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5440953.750942413
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 44
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 371944
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1037229597568512
          max_q: 3.399362087249756
          mean_q: -0.8143741488456726
          mean_td_error: -0.05681884288787842
          min_q: -2.3358471393585205
        model: {}
        td_error: "[-0.57274365 -0.12516856  0.20912874 -0.3568442   0.10937828 -0.16675341\n\
          \  0.096416    0.33776742  0.1903925  -0.36621153 -0.37389684 -0.20231533\n\
          \  0.26003218  0.01420629 -0.39257187 -0.20405155  0.09188437 -0.27181482\n\
          \ -0.63451326  0.1794079  -0.38618445 -0.1899848   0.10163116 -0.09018242\n\
          \ -0.07743859  0.03086391 -0.4078145   0.15014875  0.10442007  0.02356923\n\
          \ -0.07588935 -0.22788727  0.06203485  0.08686543 -0.43234074  0.30115527\n\
          \  0.2794081   0.06270427  0.26273167  0.23338938  0.38240492 -0.0215497\n\
          \ -0.03133619 -0.16449308 -0.30364257 -0.15519398 -0.06995612  0.00353384]"
    num_agent_steps_sampled: 372000
    num_agent_steps_trained: 4452048
    num_steps_sampled: 372000
    num_steps_trained: 4452048
    num_target_updates: 737
  iterations_since_restore: 372
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.516666666666666
    ram_util_percent: 32.4
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049224212456731725
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8415512672426795
    mean_inference_ms: 1.5875558330603219
    mean_raw_obs_processing_ms: 0.14411084218102924
  time_since_restore: 5199.722498893738
  time_this_iter_s: 12.20503544807434
  time_total_s: 5199.722498893738
  timers:
    learn_throughput: 4758.257
    learn_time_ms: 10.088
    update_time_ms: 2.872
  timestamp: 1629285960
  timesteps_since_restore: 0
  timesteps_total: 372000
  training_iteration: 372
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    372 |          5199.72 | 372000 | 5.44095e+06 |          7.25484e+06 |             -198.044 |            8379.57 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 373000
  custom_metrics: {}
  date: 2021-08-18_11-26-12
  done: false
  episode_len_mean: 8279.733333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5481258.703705232
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 372952
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0725875049829483
          max_q: 2.4555346965789795
          mean_q: -1.0163882970809937
          mean_td_error: -0.04330385476350784
          min_q: -2.047102928161621
        model: {}
        td_error: "[-0.20373714  0.30910206  0.07645404  0.73554206 -0.29917276  0.0983572\n\
          \ -0.04017639  0.50491107  0.26819706  0.34407043 -0.04300785  0.00447237\n\
          \  0.08637285 -0.32102394  0.55645776 -0.31739056  0.00290132  0.04364455\n\
          \ -0.24041384 -0.4164145  -0.4065259  -0.48807824 -0.15276998  0.10981035\n\
          \ -0.19283295 -0.3012774   0.09569621  0.26138997 -0.1366036  -0.01667523\n\
          \  0.13110447 -0.618148    0.25246435  0.16967815 -0.47283065 -0.4117025\n\
          \  0.1080333  -0.05003697 -0.2232377  -0.24675179  0.25665402  0.38822174\n\
          \  0.3991323  -0.70143664 -0.0555017  -0.11644989 -0.59336615 -0.21569014]"
    num_agent_steps_sampled: 373000
    num_agent_steps_trained: 4464048
    num_steps_sampled: 373000
    num_steps_trained: 4464048
    num_target_updates: 739
  iterations_since_restore: 373
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.56470588235294
    ram_util_percent: 32.40588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922190376511922
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8515835037418205
    mean_inference_ms: 1.587607320569381
    mean_raw_obs_processing_ms: 0.14411693620951938
  time_since_restore: 5211.183385372162
  time_this_iter_s: 11.460886478424072
  time_total_s: 5211.183385372162
  timers:
    learn_throughput: 4767.756
    learn_time_ms: 10.068
    update_time_ms: 2.597
  timestamp: 1629285972
  timesteps_since_restore: 0
  timesteps_total: 373000
  training_iteration: 373
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    373 |          5211.18 | 373000 | 5.48126e+06 |          7.25484e+06 |             -198.044 |            8279.73 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 374000
  custom_metrics: {}
  date: 2021-08-18_11-26-24
  done: false
  episode_len_mean: 8279.733333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5481258.703705232
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 45
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 373960
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06659097969532013
          max_q: 2.921863317489624
          mean_q: -0.9344260096549988
          mean_td_error: -0.03434386104345322
          min_q: -2.311540365219116
        model: {}
        td_error: "[-0.11561638  0.16887963  0.64195555  0.05026659  0.69063866 -0.34830964\n\
          \  0.3315521   0.28718734 -0.2792827   0.2988779   0.3132043   0.05639857\n\
          \ -0.25424522 -0.25294232 -0.05446035  0.09152484  0.3178566  -0.0210464\n\
          \ -0.4134196   0.23143852 -0.32869387  0.25242364  0.05096984 -0.27222162\n\
          \  0.02411406 -0.23484719  0.26672304 -0.81510144 -0.46060538 -0.02586973\n\
          \ -0.22611296 -0.24444556 -0.31570005  0.03206229  0.22699583 -0.10358143\n\
          \  0.3812763  -0.11446911 -0.39677697 -0.40602058 -0.01950048 -0.34396642\n\
          \ -0.11347902  0.3208223   0.09732008  0.2715269  -0.5614731  -0.33033246]"
    num_agent_steps_sampled: 374000
    num_agent_steps_trained: 4476048
    num_steps_sampled: 374000
    num_steps_trained: 4476048
    num_target_updates: 741
  iterations_since_restore: 374
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.69375
    ram_util_percent: 32.40625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922190376511922
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8515835037418205
    mean_inference_ms: 1.587607320569381
    mean_raw_obs_processing_ms: 0.14411693620951938
  time_since_restore: 5222.612526655197
  time_this_iter_s: 11.429141283035278
  time_total_s: 5222.612526655197
  timers:
    learn_throughput: 4898.004
    learn_time_ms: 9.8
    update_time_ms: 2.66
  timestamp: 1629285984
  timesteps_since_restore: 0
  timesteps_total: 374000
  training_iteration: 374
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    374 |          5222.61 | 374000 | 5.48126e+06 |          7.25484e+06 |             -198.044 |            8279.73 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 375000
  custom_metrics: {}
  date: 2021-08-18_11-26-37
  done: false
  episode_len_mean: 8279.733333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5481258.703705232
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 45
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 374968
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05297687277197838
          max_q: 6.212685585021973
          mean_q: -0.5601271390914917
          mean_td_error: -0.011211564764380455
          min_q: -1.6056287288665771
        model: {}
        td_error: "[-0.28874242 -0.02117109 -0.09235704 -0.09775621  0.29200864 -0.20770532\n\
          \  0.220065   -0.15205401  0.22910762 -0.515579    0.08890629  0.1455499\n\
          \ -0.4074726  -0.87775385  0.5834315  -0.23858654  0.14421976  0.06288803\n\
          \  0.06699616  0.02728546 -0.24927098  0.07161117  0.1364069   0.5824754\n\
          \ -0.00482166  0.36785626  0.46014786 -0.5436036   0.5155113  -0.492512\n\
          \  0.01827085  0.10095793 -0.02506363  0.22321129 -0.09642529 -0.88933086\n\
          \  0.06211728  0.30009186 -0.45834553  0.20637572  0.1759938   0.6314169\n\
          \ -0.05853689 -0.55174553 -0.02849281  0.18825436 -0.01501548 -0.12696993]"
    num_agent_steps_sampled: 375000
    num_agent_steps_trained: 4488048
    num_steps_sampled: 375000
    num_steps_trained: 4488048
    num_target_updates: 743
  iterations_since_restore: 375
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.21111111111111
    ram_util_percent: 32.40555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922190376511922
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8515835037418205
    mean_inference_ms: 1.587607320569381
    mean_raw_obs_processing_ms: 0.14411693620951938
  time_since_restore: 5234.881859302521
  time_this_iter_s: 12.269332647323608
  time_total_s: 5234.881859302521
  timers:
    learn_throughput: 4067.196
    learn_time_ms: 11.802
    update_time_ms: 3.835
  timestamp: 1629285997
  timesteps_since_restore: 0
  timesteps_total: 375000
  training_iteration: 375
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    375 |          5234.88 | 375000 | 5.48126e+06 |          7.25484e+06 |             -198.044 |            8279.73 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 376000
  custom_metrics: {}
  date: 2021-08-18_11-26-50
  done: false
  episode_len_mean: 8279.733333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5481258.703705232
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 45
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 375976
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 11.745280265808105
          max_q: 7254297.5
          mean_q: 302261.6875
          mean_td_error: -22.02899932861328
          min_q: -1.9245997667312622
        model: {}
        td_error: "[ 2.3524880e-01 -5.1951528e-02 -3.5938203e-01 -7.8249216e-02\n -1.3465595e-01\
          \  5.3832889e-01  1.4404714e-01  6.1899602e-02\n -1.8879002e-01 -1.5357286e-01\
          \ -5.2600000e+02 -1.2332046e-01\n -2.5108820e-01 -2.9230964e-01 -1.2607825e-01\
          \ -1.7991066e-02\n  5.6799889e-01 -4.3473673e-01 -6.6366792e-02  1.2310648e-01\n\
          \ -3.2950985e-01  1.8033648e-01 -3.0830479e-01  5.2771199e-01\n  1.7192626e-01\
          \ -2.8808093e+00 -8.5304379e-02 -1.6706598e-01\n -4.1452742e-01  2.9269314e-01\
          \  3.4725142e-01  4.8352385e-01\n -1.1424191e+00  5.4797173e-02 -6.6980439e-01\
          \  5.2388549e-02\n  6.2201595e-01 -4.0013552e-01 -5.2600000e+02 -1.1456311e-01\n\
          \ -3.0493122e-01 -3.5511494e-01  3.4149885e-03 -6.6410661e-02\n -5.4998159e-02\
          \ -1.8696427e-01 -2.3866659e-01  1.9942701e-01]"
    num_agent_steps_sampled: 376000
    num_agent_steps_trained: 4500048
    num_steps_sampled: 376000
    num_steps_trained: 4500048
    num_target_updates: 745
  iterations_since_restore: 376
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.75
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922190376511922
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8515835037418205
    mean_inference_ms: 1.587607320569381
    mean_raw_obs_processing_ms: 0.14411693620951938
  time_since_restore: 5247.933589935303
  time_this_iter_s: 13.051730632781982
  time_total_s: 5247.933589935303
  timers:
    learn_throughput: 4961.227
    learn_time_ms: 9.675
    update_time_ms: 2.727
  timestamp: 1629286010
  timesteps_since_restore: 0
  timesteps_total: 376000
  training_iteration: 376
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    376 |          5247.93 | 376000 | 5.48126e+06 |          7.25484e+06 |             -198.044 |            8279.73 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 377000
  custom_metrics: {}
  date: 2021-08-18_11-27-03
  done: false
  episode_len_mean: 8279.733333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5481258.703705232
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 45
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 376984
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.041904378682374954
          max_q: 4.310296535491943
          mean_q: -0.987490177154541
          mean_td_error: -0.018288692459464073
          min_q: -3.12247633934021
        model: {}
        td_error: "[-0.31877536  0.00293455 -1.0872436  -0.36479205 -0.19386053  0.20444793\n\
          \ -0.71333325  0.11997974 -0.02633464 -0.42349806  0.31315136  0.65845895\n\
          \  0.0409255  -0.00723088 -0.12127951 -0.01058519  0.54097086 -0.5773135\n\
          \  0.2821771   0.01973236  0.09451675  0.46024537  0.1293968  -0.18524599\n\
          \ -0.0056659  -0.1445694   0.32175213 -0.1727007   0.41700733  0.35045707\n\
          \ -0.43799013  0.02399385 -0.20552987  0.17873669  0.04096818  0.12579632\n\
          \  0.05790353  0.46853054  0.1049571  -0.13197279 -0.02008855  0.57398665\n\
          \ -0.7548074  -0.0996117  -0.13600034 -0.0917443  -0.19278204  0.01407182]"
    num_agent_steps_sampled: 377000
    num_agent_steps_trained: 4512048
    num_steps_sampled: 377000
    num_steps_trained: 4512048
    num_target_updates: 747
  iterations_since_restore: 377
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.516666666666666
    ram_util_percent: 32.4
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922190376511922
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8515835037418205
    mean_inference_ms: 1.587607320569381
    mean_raw_obs_processing_ms: 0.14411693620951938
  time_since_restore: 5260.160245656967
  time_this_iter_s: 12.226655721664429
  time_total_s: 5260.160245656967
  timers:
    learn_throughput: 4948.8
    learn_time_ms: 9.699
    update_time_ms: 2.72
  timestamp: 1629286023
  timesteps_since_restore: 0
  timesteps_total: 377000
  training_iteration: 377
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    377 |          5260.16 | 377000 | 5.48126e+06 |          7.25484e+06 |             -198.044 |            8279.73 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 378000
  custom_metrics: {}
  date: 2021-08-18_11-27-17
  done: false
  episode_len_mean: 8279.733333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5481258.703705232
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 45
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 377992
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.72346019744873
          max_q: 7255890.0
          mean_q: 151163.46875
          mean_td_error: 22.116498947143555
          min_q: -3.199908494949341
        model: {}
        td_error: "[-4.31690156e-01 -1.11823332e+00 -5.11456847e-01 -3.60463858e-02\n\
          \  4.00744677e-02  2.78955340e-01  1.34664416e-01 -1.78033650e-01\n -2.04916775e-01\
          \ -9.84781384e-01  6.93583488e-03  3.87794971e-02\n  7.97915459e-02 -9.20367241e-02\
          \  3.20057392e-01  1.56906128e-01\n -1.70328379e-01  8.98072124e-02 -5.91155291e-02\
          \ -7.08411187e-02\n -3.85062814e-01  4.44963932e-01  2.42778540e-01  1.06538415e-01\n\
          \ -8.76687765e-02 -5.90002596e-01 -4.70710516e-01  1.07119679e-01\n  2.44298339e-01\
          \ -3.31379801e-01  1.66678071e-01 -5.82061827e-01\n -3.66472244e-01 -4.27102983e-01\
          \  1.06500000e+03 -3.86505544e-01\n -3.28603983e-02  1.73894644e-01 -3.13091278e-02\
          \  3.98519039e-01\n -1.53587818e-01  2.33186245e-01 -1.94332480e-01  4.51496840e-01\n\
          \  2.06416011e-01  1.89462781e-01  3.27595532e-01  4.96152937e-02]"
    num_agent_steps_sampled: 378000
    num_agent_steps_trained: 4524048
    num_steps_sampled: 378000
    num_steps_trained: 4524048
    num_target_updates: 749
  iterations_since_restore: 378
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.160000000000004
    ram_util_percent: 32.40999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922190376511922
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8515835037418205
    mean_inference_ms: 1.587607320569381
    mean_raw_obs_processing_ms: 0.14411693620951938
  time_since_restore: 5274.233770847321
  time_this_iter_s: 14.073525190353394
  time_total_s: 5274.233770847321
  timers:
    learn_throughput: 5068.722
    learn_time_ms: 9.47
    update_time_ms: 2.803
  timestamp: 1629286037
  timesteps_since_restore: 0
  timesteps_total: 378000
  training_iteration: 378
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    378 |          5274.23 | 378000 | 5.48126e+06 |          7.25484e+06 |             -198.044 |            8279.73 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 379000
  custom_metrics: {}
  date: 2021-08-18_11-27-32
  done: false
  episode_len_mean: 8279.733333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5481258.703705232
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 45
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 379000
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10635833442211151
          max_q: 4.890342712402344
          mean_q: -0.6254121661186218
          mean_td_error: -0.0559798888862133
          min_q: -1.9739553928375244
        model: {}
        td_error: "[ 0.49909103  0.16006833  0.35739613 -0.6170888   0.00699055 -0.23666364\n\
          \ -1.2579362   0.2714975   0.2204355   0.1466384  -0.03904808 -0.05128855\n\
          \ -0.22819996  0.12801874 -0.06953681 -0.2239207  -0.06588155  0.6138139\n\
          \  0.0352664   0.89691854  0.2269215   0.0821017   0.00672889 -0.4138652\n\
          \  0.2199682  -0.10747802 -0.12195301 -1.1273452  -0.25476223 -0.11691082\n\
          \ -0.1044215   0.16655731 -0.2151174   0.2043289   0.00366509  0.21267408\n\
          \ -0.21718168 -0.10336018 -0.21262169  0.8333813   0.39838642 -0.42851734\n\
          \ -0.49519914 -0.27052993  0.47090983 -0.83257544 -0.20256221 -0.83482754]"
    num_agent_steps_sampled: 379000
    num_agent_steps_trained: 4536048
    num_steps_sampled: 379000
    num_steps_trained: 4536048
    num_target_updates: 751
  iterations_since_restore: 379
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.83333333333333
    ram_util_percent: 32.4047619047619
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04922190376511922
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.8515835037418205
    mean_inference_ms: 1.587607320569381
    mean_raw_obs_processing_ms: 0.14411693620951938
  time_since_restore: 5288.908263206482
  time_this_iter_s: 14.674492359161377
  time_total_s: 5288.908263206482
  timers:
    learn_throughput: 4958.527
    learn_time_ms: 9.68
    update_time_ms: 2.822
  timestamp: 1629286052
  timesteps_since_restore: 0
  timesteps_total: 379000
  training_iteration: 379
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    379 |          5288.91 | 379000 | 5.48126e+06 |          7.25484e+06 |             -198.044 |            8279.73 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 380000
  custom_metrics: {}
  date: 2021-08-18_11-27-45
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 379504
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.720605373382568
          max_q: 7254325.5
          mean_q: 151130.90625
          mean_td_error: -10.419927597045898
          min_q: -2.0005598068237305
        model: {}
        td_error: "[-5.2390146e-01 -1.0487078e+00  3.0954170e-01 -5.0100000e+02\n  2.2217417e-01\
          \  4.0086198e-01  5.2183962e-01  4.9425101e-01\n -1.4419258e-01 -3.4964973e-01\
          \  2.0725286e-01  2.5526881e-02\n  9.3839645e-02 -1.5855265e-01  3.0754644e-01\
          \ -7.1299672e-02\n -1.3487935e-02  1.9748800e-01 -1.0169637e-01  3.0062711e-01\n\
          \  3.3650613e-01 -7.3044538e-02  6.0650602e-02  4.7508001e-02\n -2.1652043e-01\
          \ -1.2674546e-01  9.3548656e-02  3.1714773e-01\n -2.2047806e-01 -9.6036911e-02\
          \  2.2346842e-01  1.5338337e-01\n -1.0355054e+00  4.1396117e-01 -6.6504139e-01\
          \  9.2208457e-01\n  8.1375241e-02 -5.5239350e-01  9.3316877e-01  3.6915433e-01\n\
          \  3.9737582e-02 -7.9154849e-02 -5.6109285e-01  5.9219480e-02\n  1.2570161e-01\
          \ -2.8945386e-01  2.1285307e-01 -2.9999512e-01]"
    num_agent_steps_sampled: 380000
    num_agent_steps_trained: 4548048
    num_steps_sampled: 380000
    num_steps_trained: 4548048
    num_target_updates: 752
  iterations_since_restore: 380
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.522222222222226
    ram_util_percent: 32.40555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5300.812766551971
  time_this_iter_s: 11.904503345489502
  time_total_s: 5300.812766551971
  timers:
    learn_throughput: 4716.488
    learn_time_ms: 10.177
    update_time_ms: 2.831
  timestamp: 1629286065
  timesteps_since_restore: 0
  timesteps_total: 380000
  training_iteration: 380
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    380 |          5300.81 | 380000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 381000
  custom_metrics: {}
  date: 2021-08-18_11-27-56
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 380512
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 18.91887855529785
          max_q: 7253994.0
          mean_q: 151124.109375
          mean_td_error: -17.350021362304688
          min_q: -1.9125934839248657
        model: {}
        td_error: "[ 3.54397297e-01  2.70873368e-01  3.03665042e-01 -1.26518965e-01\n\
          \  5.83749652e-01 -2.75589824e-02 -6.00791812e-01  3.05402517e-01\n  3.28760982e-01\
          \ -5.48030615e-01 -5.27968109e-01 -2.95354307e-01\n -4.86094713e-01  2.62496352e-01\
          \ -2.77051449e-01 -1.36227548e-01\n -2.68647075e-01  5.34061193e-02  2.48084545e-01\
          \  1.00705624e-01\n  3.20608616e-01 -1.02772236e-01  2.52699912e-01 -1.95956588e-01\n\
          \ -7.64271855e-01 -3.68791103e-01  2.94079214e-01 -4.59695905e-01\n  1.99203491e-01\
          \ -2.53208876e-02 -3.07521284e-01 -3.07175159e-01\n -4.92609352e-01  3.12182307e-01\
          \  9.27597284e-02 -2.58490801e-01\n -5.78043461e-02  1.44948602e-01  8.06240320e-01\
          \ -1.55028105e-02\n -3.93483281e-01  1.99030459e-01 -8.31500000e+02  1.86277151e-01\n\
          \ -2.29605377e-01  1.99595451e-01 -7.53750801e-02  2.28318334e-01]"
    num_agent_steps_sampled: 381000
    num_agent_steps_trained: 4560048
    num_steps_sampled: 381000
    num_steps_trained: 4560048
    num_target_updates: 754
  iterations_since_restore: 381
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.82352941176471
    ram_util_percent: 32.40588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5312.065305948257
  time_this_iter_s: 11.25253939628601
  time_total_s: 5312.065305948257
  timers:
    learn_throughput: 5094.928
    learn_time_ms: 9.421
    update_time_ms: 2.739
  timestamp: 1629286076
  timesteps_since_restore: 0
  timesteps_total: 381000
  training_iteration: 381
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    381 |          5312.07 | 381000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 382000
  custom_metrics: {}
  date: 2021-08-18_11-28-08
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 381520
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.051407571882009506
          max_q: 2.682013511657715
          mean_q: -1.2133457660675049
          mean_td_error: -0.0532347671687603
          min_q: -2.6962313652038574
        model: {}
        td_error: "[ 0.13766623 -1.1533251  -0.66152775  0.23050737 -0.30477738 -0.38023126\n\
          \ -0.10043979 -0.17259538  0.27951062  0.1863091   0.04465562 -0.11372685\n\
          \ -0.24588168  0.04117322 -0.20276755  0.14563656 -0.10731459 -0.03326643\n\
          \  0.0760982  -0.48479152 -0.43370727  0.01924282 -0.03106105  0.29072785\n\
          \  0.3313867   0.45008326 -0.05245811  0.28230917 -0.05877197 -0.16965401\n\
          \  0.2616576   0.12069273 -0.00127113  0.4089644  -0.5053001  -0.17631298\n\
          \  0.01354527 -0.44426048 -0.59977925 -0.24845195 -0.01766396  0.15321112\n\
          \  0.5810652   0.06862473  0.04978478 -0.07718885  0.15064037 -0.10223544]"
    num_agent_steps_sampled: 382000
    num_agent_steps_trained: 4572048
    num_steps_sampled: 382000
    num_steps_trained: 4572048
    num_target_updates: 756
  iterations_since_restore: 382
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.405882352941184
    ram_util_percent: 32.40588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5323.797954320908
  time_this_iter_s: 11.732648372650146
  time_total_s: 5323.797954320908
  timers:
    learn_throughput: 4772.276
    learn_time_ms: 10.058
    update_time_ms: 2.821
  timestamp: 1629286088
  timesteps_since_restore: 0
  timesteps_total: 382000
  training_iteration: 382
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    382 |           5323.8 | 382000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 383000
  custom_metrics: {}
  date: 2021-08-18_11-28-21
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 382528
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.052780888974666595
          max_q: 3.645524501800537
          mean_q: -1.0306546688079834
          mean_td_error: -0.06266382336616516
          min_q: -2.263064384460449
        model: {}
        td_error: "[ 0.04727054 -0.8373097  -0.3480999   0.6657722   0.36625397  0.0506632\n\
          \  0.05974686 -0.07772326  0.10113966 -0.1601901   0.17435241  0.02978885\n\
          \  0.11811101  0.07933712 -0.11631942 -0.05295821 -0.5060857  -0.069363\n\
          \ -0.29742765  0.04381084 -0.20733017 -3.5088673   0.23910403  0.17875504\n\
          \ -0.04788053 -0.7495043  -0.05727875  0.05496967  0.0708822  -0.3682447\n\
          \ -0.45654976  0.7271291  -0.05067992 -0.10876481  0.06703413  0.12672764\n\
          \ -0.1588831   0.58594847  0.37355232  0.4030484   0.18739417 -0.13273114\n\
          \  0.35377717  0.00915056  0.45348632  0.24507344 -0.60796404  0.10001278]"
    num_agent_steps_sampled: 383000
    num_agent_steps_trained: 4584048
    num_steps_sampled: 383000
    num_steps_trained: 4584048
    num_target_updates: 758
  iterations_since_restore: 383
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.74444444444445
    ram_util_percent: 32.40555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5336.426973819733
  time_this_iter_s: 12.629019498825073
  time_total_s: 5336.426973819733
  timers:
    learn_throughput: 5016.485
    learn_time_ms: 9.568
    update_time_ms: 2.716
  timestamp: 1629286101
  timesteps_since_restore: 0
  timesteps_total: 383000
  training_iteration: 383
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    383 |          5336.43 | 383000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 384000
  custom_metrics: {}
  date: 2021-08-18_11-28-35
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 383536
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12.470294952392578
          max_q: 7254679.5
          mean_q: 302277.46875
          mean_td_error: -5.987923622131348
          min_q: -2.5015106201171875
        model: {}
        td_error: "[ 1.9699824e-01  8.6860454e-01  3.7539810e-01  5.6638002e-01\n -1.4450000e+02\
          \ -6.5977943e-01  3.4300208e-01 -1.4450000e+02\n  2.2821915e-01  2.5006378e-01\
          \  2.0184875e-02 -4.0389419e-02\n -1.5563917e-01 -1.8567806e-01  5.8825016e-01\
          \ -2.8007913e-01\n -4.2381376e-01  3.4762990e-01 -2.6506424e-02  1.1251092e-01\n\
          \  1.1182666e-02 -1.2665895e-01  2.8589916e-01 -1.4488411e-01\n  3.8123539e-01\
          \ -6.7979252e-01  2.0225322e-01  2.8149533e-01\n  2.1336031e-01  3.7147218e-01\
          \  1.2390602e-01  4.9395084e-02\n  7.1398497e-02 -1.3033235e-01 -2.0434439e-01\
          \  2.7012455e-01\n  5.0999010e-01  2.7014017e-03  2.9955053e-01 -2.5542551e-01\n\
          \ -7.4041319e-01 -6.8839556e-01 -4.8527336e-01  5.1158667e-02\n  1.1669928e-01\
          \ -2.3063421e-03 -2.4945021e-01 -8.0231011e-02]"
    num_agent_steps_sampled: 384000
    num_agent_steps_trained: 4596048
    num_steps_sampled: 384000
    num_steps_trained: 4596048
    num_target_updates: 760
  iterations_since_restore: 384
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.7
    ram_util_percent: 32.40526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5349.378252744675
  time_this_iter_s: 12.951278924942017
  time_total_s: 5349.378252744675
  timers:
    learn_throughput: 4728.229
    learn_time_ms: 10.152
    update_time_ms: 2.97
  timestamp: 1629286115
  timesteps_since_restore: 0
  timesteps_total: 384000
  training_iteration: 384
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    384 |          5349.38 | 384000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 385000
  custom_metrics: {}
  date: 2021-08-18_11-28-49
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 384544
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.730175495147705
          max_q: 7254834.0
          mean_q: 151141.53125
          mean_td_error: 0.18868547677993774
          min_q: -1.9713926315307617
        model: {}
        td_error: "[ 4.16231751e-01  1.15199208e-01  1.50136232e-01 -3.76442432e-01\n\
          \ -2.49771953e-01  2.52173185e-01 -3.84892702e-01  4.93318319e-01\n -2.16115594e-01\
          \  3.05607319e-02 -6.39609098e-02 -5.51832914e-02\n -3.07276368e-01 -6.12328053e-02\
          \ -2.56757081e-01 -4.86486137e-01\n  1.13888383e-01  2.58525878e-01 -4.45359945e-02\
          \ -3.56331110e-01\n  3.81240606e-01 -2.98588276e-01  3.06521416e-01 -1.02748275e-01\n\
          \ -1.55586243e-01  6.95353746e-02  3.53686213e-01 -3.30489039e-01\n  4.30161834e-01\
          \ -1.96572781e-01  1.31551743e-01 -8.94097149e-01\n -1.24553442e-02  1.49938226e-01\
          \  1.13511324e-01  1.96350396e-01\n -6.26070499e-02 -1.57763362e-01  2.38492608e-01\
          \  2.16162205e-03\n -1.23853207e-01  1.00000000e+01  4.98211265e-01  4.00469899e-01\n\
          \ -9.13199186e-02 -6.05575860e-01 -4.02879834e-01  2.48558879e-01]"
    num_agent_steps_sampled: 385000
    num_agent_steps_trained: 4608048
    num_steps_sampled: 385000
    num_steps_trained: 4608048
    num_target_updates: 762
  iterations_since_restore: 385
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.76000000000001
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5362.731481075287
  time_this_iter_s: 13.353228330612183
  time_total_s: 5362.731481075287
  timers:
    learn_throughput: 3547.149
    learn_time_ms: 13.532
    update_time_ms: 5.453
  timestamp: 1629286129
  timesteps_since_restore: 0
  timesteps_total: 385000
  training_iteration: 385
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    385 |          5362.73 | 385000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 386000
  custom_metrics: {}
  date: 2021-08-18_11-29-03
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 385552
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.217961311340332
          max_q: 7255349.0
          mean_q: 151151.953125
          mean_td_error: 10.840993881225586
          min_q: -2.709019660949707
        model: {}
        td_error: "[-8.4830165e-02  4.5857966e-02 -3.0190706e-01  1.9112210e-01\n -4.6317875e-01\
          \ -1.9810367e-01 -4.5596719e-01 -4.1701674e-01\n -7.1643591e-02  7.1613669e-02\
          \ -7.0137191e-01  2.0972502e-01\n -1.1504173e-02  2.1992683e-01  2.1624613e-01\
          \  1.2173951e-01\n  1.7079985e-01  8.5772425e-02 -6.6463351e-02 -9.6097589e-02\n\
          \ -6.0053676e-02 -1.9400644e-01 -3.2900250e-01  1.4015937e-01\n -3.7371659e-01\
          \  2.0781875e-02 -4.7845671e-01  8.8787556e-02\n  1.7304230e-01  4.1277432e-01\
          \ -3.6218762e-01  1.9079006e-01\n  7.6023221e-02 -3.1611681e-02  2.7772403e-01\
          \ -4.8816085e-02\n -3.9961910e-01  1.0521412e-02 -9.4075131e-01 -4.2848825e-02\n\
          \  1.5130043e-03 -1.6292489e-01  5.2450000e+02  5.7719946e-02\n -1.8728143e-01\
          \ -3.5294020e-01 -5.6469905e-01  4.8200178e-01]"
    num_agent_steps_sampled: 386000
    num_agent_steps_trained: 4620048
    num_steps_sampled: 386000
    num_steps_trained: 4620048
    num_target_updates: 764
  iterations_since_restore: 386
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.685714285714276
    ram_util_percent: 32.4047619047619
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5377.067875385284
  time_this_iter_s: 14.336394309997559
  time_total_s: 5377.067875385284
  timers:
    learn_throughput: 5097.611
    learn_time_ms: 9.416
    update_time_ms: 2.881
  timestamp: 1629286143
  timesteps_since_restore: 0
  timesteps_total: 386000
  training_iteration: 386
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    386 |          5377.07 | 386000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 387000
  custom_metrics: {}
  date: 2021-08-18_11-29-18
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 386560
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.3929924964904785
          max_q: 7254241.5
          mean_q: 151128.84375
          mean_td_error: -12.16281509399414
          min_q: -2.291592597961426
        model: {}
        td_error: "[-2.62644291e-02 -3.65130424e-01  3.25880170e-01  1.05620861e-01\n\
          \ -9.87925529e-02 -3.21981907e-01  1.04396701e-01  2.88678527e-01\n  3.37862372e-01\
          \ -2.09905624e-01 -1.48470283e-01 -4.38060135e-01\n -3.49207342e-01 -3.79423887e-01\
          \  3.28803062e-03  3.37698460e-02\n  2.30098248e-01  1.29843473e-01 -1.90422058e-01\
          \  5.51030636e-02\n -1.04281545e-01  2.73445874e-01 -2.09905624e-01  3.77042174e-01\n\
          \  3.05162430e-01 -1.57206655e-02  1.00545168e-01  4.86924648e-02\n -2.81891584e-01\
          \ -5.83500000e+02 -1.77562237e-02 -5.53647161e-01\n  3.93590331e-01 -1.34997368e-01\
          \  5.29253483e-02 -5.91455698e-02\n -8.32701206e-01  8.90858173e-02  6.21362150e-01\
          \  1.37223125e-01\n -7.65581727e-02  2.21021414e-01  3.20354700e-01  6.18927479e-02\n\
          \ -2.26946592e-01  1.69688076e-01 -2.58147001e-01  1.97744846e-01]"
    num_agent_steps_sampled: 387000
    num_agent_steps_trained: 4632048
    num_steps_sampled: 387000
    num_steps_trained: 4632048
    num_target_updates: 766
  iterations_since_restore: 387
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.63809523809523
    ram_util_percent: 32.39999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5391.441697359085
  time_this_iter_s: 14.37382197380066
  time_total_s: 5391.441697359085
  timers:
    learn_throughput: 4932.831
    learn_time_ms: 9.731
    update_time_ms: 2.873
  timestamp: 1629286158
  timesteps_since_restore: 0
  timesteps_total: 387000
  training_iteration: 387
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    387 |          5391.44 | 387000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 388000
  custom_metrics: {}
  date: 2021-08-18_11-29-33
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 387568
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 11.014399528503418
          max_q: 7255042.0
          mean_q: 302292.5
          mean_td_error: 8.879722595214844
          min_q: -2.204777717590332
        model: {}
        td_error: "[-2.25721741e+00  6.59887791e-02  4.22814846e-01  2.17000000e+02\n\
          \ -7.07445860e-01 -1.51062250e-01  7.84611702e-02 -3.16036940e-02\n -3.02170694e-01\
          \ -1.04468465e+00 -1.11671865e-01 -4.75355446e-01\n -3.53993744e-01  9.38280821e-02\
          \ -1.24843299e-01 -1.69337273e-01\n  2.17000000e+02  1.15307301e-01 -7.31696784e-01\
          \ -2.88576782e-01\n -2.36875474e-01 -3.28351259e-02 -1.23623915e-01 -1.00652516e-01\n\
          \  4.57855582e-01  8.95226002e-03  1.03015900e-01  9.55511332e-02\n -4.46721137e-01\
          \  2.43732333e-01 -5.28718472e-01  1.81189179e-01\n -1.35665655e-01 -1.35412335e-01\
          \ -4.15958971e-01  1.15299821e-01\n  5.15920043e-01  1.94955528e-01 -3.48864794e-02\
          \  1.64259791e-01\n -4.54247236e-01 -5.31040907e-01 -1.01831317e-01  1.16837382e-01\n\
          \ -2.65693426e-01  1.40969157e-01 -1.21532679e-01 -4.72880900e-01]"
    num_agent_steps_sampled: 388000
    num_agent_steps_trained: 4644048
    num_steps_sampled: 388000
    num_steps_trained: 4644048
    num_target_updates: 768
  iterations_since_restore: 388
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.94999999999998
    ram_util_percent: 32.40909090909091
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5406.058792591095
  time_this_iter_s: 14.617095232009888
  time_total_s: 5406.058792591095
  timers:
    learn_throughput: 4810.384
    learn_time_ms: 9.978
    update_time_ms: 3.318
  timestamp: 1629286173
  timesteps_since_restore: 0
  timesteps_total: 388000
  training_iteration: 388
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    388 |          5406.06 | 388000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 389000
  custom_metrics: {}
  date: 2021-08-18_11-29-51
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 388576
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06577200442552567
          max_q: 1.1698980331420898
          mean_q: -1.0860471725463867
          mean_td_error: -0.01889153942465782
          min_q: -2.5779213905334473
        model: {}
        td_error: "[ 0.4215964  -0.5321555   0.32982457  0.7462586  -0.24526119  0.08975834\n\
          \ -0.43187448  0.48642266  0.9730996   0.17348886 -0.4733584  -0.1629195\n\
          \  0.24933076  0.74274004  0.39613995  0.16513723 -0.26098722 -0.5047519\n\
          \ -0.01429772  0.19295454  0.09555125 -0.21623546 -0.41140282 -0.28248027\n\
          \  0.02802396  0.25460756  0.04433107  0.2631836  -0.22542042 -0.52569985\n\
          \ -0.37030983  0.29039606  0.02056444  0.28084803  0.17637241  0.00282669\n\
          \ -0.8654375   0.4771819  -0.0822264   0.09242821  0.02733135 -0.43644965\n\
          \ -0.29825234 -0.6562115  -0.08579993  0.01422822 -0.5898075  -0.2700807 ]"
    num_agent_steps_sampled: 389000
    num_agent_steps_trained: 4656048
    num_steps_sampled: 389000
    num_steps_trained: 4656048
    num_target_updates: 770
  iterations_since_restore: 389
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.32
    ram_util_percent: 32.464
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5423.184659481049
  time_this_iter_s: 17.125866889953613
  time_total_s: 5423.184659481049
  timers:
    learn_throughput: 4836.512
    learn_time_ms: 9.925
    update_time_ms: 2.996
  timestamp: 1629286191
  timesteps_since_restore: 0
  timesteps_total: 389000
  training_iteration: 389
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    389 |          5423.18 | 389000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 390000
  custom_metrics: {}
  date: 2021-08-18_11-30-08
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 389584
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.085077285766602
          max_q: 7254075.0
          mean_q: 151125.6875
          mean_td_error: -15.659164428710938
          min_q: -1.843052625656128
        model: {}
        td_error: "[ 6.90745115e-02 -8.22302103e-02  1.88809633e-02  8.66456032e-02\n\
          \ -2.10431486e-01  3.05569530e-01  6.39307499e-02  1.21090055e-01\n  1.37092113e-01\
          \ -1.60170346e-01 -3.46644521e-01  3.84876728e-01\n -1.76945925e-02 -1.92253649e-01\
          \  5.89499116e-01 -1.18088901e-01\n -4.99697208e-01 -1.44890678e+00 -3.40609670e-01\
          \ -1.03221655e-01\n -3.87459636e-01 -1.57735157e+00  2.56406307e-01 -3.77621591e-01\n\
          \  4.64812517e-02  5.75262070e-01  1.99280679e-01 -4.14554566e-01\n  5.07564902e-01\
          \ -2.34697461e-01  2.61568666e-01  7.06065893e-02\n -1.29705906e-01 -7.50000000e+02\
          \ -3.16068709e-01  7.16679096e-02\n  4.80036855e-01  2.46792316e-01  3.35949659e-01\
          \ -4.35281157e-01\n -1.08483046e-01  3.76469970e-01  3.14147472e-02  3.11064720e-01\n\
          \ -1.76427007e-01  8.11734378e-01  8.49872231e-02 -4.06337976e-01]"
    num_agent_steps_sampled: 390000
    num_agent_steps_trained: 4668048
    num_steps_sampled: 390000
    num_steps_trained: 4668048
    num_target_updates: 772
  iterations_since_restore: 390
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.158333333333324
    ram_util_percent: 32.50833333333333
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5439.921716213226
  time_this_iter_s: 16.737056732177734
  time_total_s: 5439.921716213226
  timers:
    learn_throughput: 4918.418
    learn_time_ms: 9.759
    update_time_ms: 2.949
  timestamp: 1629286208
  timesteps_since_restore: 0
  timesteps_total: 390000
  training_iteration: 390
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    390 |          5439.92 | 390000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 391000
  custom_metrics: {}
  date: 2021-08-18_11-30-26
  done: false
  episode_len_mean: 8248.152173913044
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5519810.733652944
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 390592
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 17.582164764404297
          max_q: 7254921.5
          mean_q: 302287.71875
          mean_td_error: 4.081779479980469
          min_q: -1.5142781734466553
        model: {}
        td_error: "[ 1.9169497e-01 -2.4927068e-01 -1.8282378e-01 -2.5526655e-01\n -1.0633004e-01\
          \ -1.3232589e-02 -3.8707721e-01 -4.5808357e-01\n -2.6346505e-01  3.5878420e-03\
          \  4.3777943e-02  3.5410941e-01\n -6.2995481e-01  9.7000000e+01 -2.3797214e-02\
          \  5.8396012e-01\n -1.4184475e-02  7.4658871e-02  1.1077154e-01  2.9818946e-01\n\
          \ -1.2811530e-01  4.1209275e-01  6.6188335e-02  3.2624346e-01\n -3.1576276e-02\
          \ -5.4347199e-01  1.5437510e+00  4.5183310e-01\n  6.8749547e-02 -2.8727877e-01\
          \  7.7744193e-02  6.2178886e-01\n -3.2761157e-01  6.6647148e-01  9.9240184e-01\
          \ -1.6405559e-01\n -3.6650038e-01  1.8687165e-01  9.7000000e+01  9.0583920e-02\n\
          \  3.4593427e-01 -2.2640747e-01  2.6542842e-01 -6.4039898e-01\n -1.8146092e-01\
          \ -3.3821422e-01  2.4844897e-01 -2.8130794e-01]"
    num_agent_steps_sampled: 391000
    num_agent_steps_trained: 4680048
    num_steps_sampled: 391000
    num_steps_trained: 4680048
    num_target_updates: 774
  iterations_since_restore: 391
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.207692307692305
    ram_util_percent: 32.55384615384615
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049219578289414694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.860707440454974
    mean_inference_ms: 1.5876487309136218
    mean_raw_obs_processing_ms: 0.14412187152338962
  time_since_restore: 5457.830639839172
  time_this_iter_s: 17.908923625946045
  time_total_s: 5457.830639839172
  timers:
    learn_throughput: 4779.766
    learn_time_ms: 10.042
    update_time_ms: 3.1
  timestamp: 1629286226
  timesteps_since_restore: 0
  timesteps_total: 391000
  training_iteration: 391
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    391 |          5457.83 | 391000 | 5.51981e+06 |          7.25484e+06 |             -198.044 |            8248.15 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 392000
  custom_metrics: {}
  date: 2021-08-18_11-30-40
  done: false
  episode_len_mean: 8328.489361702128
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5556721.6008444335
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 391600
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.352726459503174
          max_q: 7254529.5
          mean_q: 151135.25
          mean_td_error: -6.181206703186035
          min_q: -2.7275874614715576
        model: {}
        td_error: "[-3.4977198e-02  5.9929848e-01  1.4444911e-01  3.5872149e-01\n  2.7113652e-01\
          \  8.5545838e-02  4.4875181e-01 -2.1738780e-01\n  2.6890424e-01  2.3959839e-01\
          \  2.3356330e-01  5.5785072e-01\n -2.0043731e-01  3.8404441e-01 -2.8062975e-01\
          \  1.8931007e-01\n  8.3597088e-01 -2.9550000e+02  2.4438214e-01  1.2692523e-01\n\
          \ -8.2214713e-02  4.0941215e-01 -6.0032511e-01  2.4003994e-01\n -1.3192540e-01\
          \  4.6050012e-01 -1.6923630e-01 -8.8239551e-02\n -8.6799860e-03 -7.7699566e-01\
          \  2.1461630e-01 -5.1905930e-01\n -1.2377934e+00  4.6510136e-01 -8.3987415e-01\
          \  1.5793872e-01\n  2.6190370e-02 -9.7455621e-02 -1.8951881e-01 -9.7966868e-01\n\
          \ -2.9346269e-01 -3.3564687e-02  4.2691672e-01  1.8693137e-01\n  6.6768062e-01\
          \ -8.3325148e-02 -2.6165180e+00  3.9577007e-02]"
    num_agent_steps_sampled: 392000
    num_agent_steps_trained: 4692048
    num_steps_sampled: 392000
    num_steps_trained: 4692048
    num_target_updates: 776
  iterations_since_restore: 392
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.55500000000001
    ram_util_percent: 32.559999999999995
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049217043479756015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.869634033376158
    mean_inference_ms: 1.5876723870417266
    mean_raw_obs_processing_ms: 0.14412676837228214
  time_since_restore: 5471.460462808609
  time_this_iter_s: 13.629822969436646
  time_total_s: 5471.460462808609
  timers:
    learn_throughput: 4864.43
    learn_time_ms: 9.868
    update_time_ms: 3.016
  timestamp: 1629286240
  timesteps_since_restore: 0
  timesteps_total: 392000
  training_iteration: 392
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    392 |          5471.46 | 392000 | 5.55672e+06 |          7.25484e+06 |             -198.044 |            8328.49 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 393000
  custom_metrics: {}
  date: 2021-08-18_11-30-52
  done: false
  episode_len_mean: 8328.489361702128
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5556721.6008444335
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 47
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 392608
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0469544418156147
          max_q: 1.5377579927444458
          mean_q: -1.046705961227417
          mean_td_error: -0.017482012510299683
          min_q: -1.8659814596176147
        model: {}
        td_error: "[-0.17135322 -1.2741965  -0.58452904  0.3139392  -0.22981083  0.48461294\n\
          \ -0.10331273  0.09137154 -0.31261694  0.16299272 -0.32547104  0.14200151\n\
          \ -0.21815011  0.19888854 -0.48763746 -0.47694838  0.23796809  0.08264935\n\
          \ -0.3067193   0.01704676  0.3780372  -0.15788925  0.0193876   0.37338948\n\
          \  0.4072219  -0.3217702  -0.1483227   0.2175802   0.2283839  -0.04234016\n\
          \  0.09651649 -0.01187086 -0.5273111  -0.06356013  0.05814815  0.10674059\n\
          \  0.2210038   0.2953094  -0.42998123 -0.05510175  0.02149761 -0.37512934\n\
          \  0.31720996 -0.03883088  0.5021107   0.44654953  0.23940122  0.16375804]"
    num_agent_steps_sampled: 393000
    num_agent_steps_trained: 4704048
    num_steps_sampled: 393000
    num_steps_trained: 4704048
    num_target_updates: 778
  iterations_since_restore: 393
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.25555555555555
    ram_util_percent: 32.48888888888889
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049217043479756015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.869634033376158
    mean_inference_ms: 1.5876723870417266
    mean_raw_obs_processing_ms: 0.14412676837228214
  time_since_restore: 5483.1912450790405
  time_this_iter_s: 11.730782270431519
  time_total_s: 5483.1912450790405
  timers:
    learn_throughput: 4951.039
    learn_time_ms: 9.695
    update_time_ms: 2.672
  timestamp: 1629286252
  timesteps_since_restore: 0
  timesteps_total: 393000
  training_iteration: 393
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    393 |          5483.19 | 393000 | 5.55672e+06 |          7.25484e+06 |             -198.044 |            8328.49 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 394000
  custom_metrics: {}
  date: 2021-08-18_11-31-05
  done: false
  episode_len_mean: 8328.489361702128
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5556721.6008444335
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 47
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 393616
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06194406375288963
          max_q: 1.0996637344360352
          mean_q: -1.0696476697921753
          mean_td_error: -0.005869776010513306
          min_q: -2.340167284011841
        model: {}
        td_error: "[-0.08585778 -0.08948278 -0.0860076  -0.60715294 -0.46553606 -0.06722099\n\
          \ -0.41672045 -0.0933181   0.29003227  0.40463805  0.12337947  0.10232639\n\
          \ -0.07926047  0.4369992  -0.79558325  0.19957215  0.4621848   2.4189298\n\
          \ -0.09375477  0.5745808   0.04608989  0.07989693  0.05293524 -0.30534697\n\
          \  0.13850105  0.47525167  0.13948321 -0.32940114  0.21644902  0.00804508\n\
          \ -0.16583169 -0.17805481 -0.48924327  0.14598888 -0.7539722   0.02658355\n\
          \ -1.0439987   0.83177036 -0.11371863  0.48137206  0.03704035  0.2259103\n\
          \ -0.74451566 -1.3395274  -0.05061364  0.34035516  0.10335696 -0.2493025 ]"
    num_agent_steps_sampled: 394000
    num_agent_steps_trained: 4716048
    num_steps_sampled: 394000
    num_steps_trained: 4716048
    num_target_updates: 780
  iterations_since_restore: 394
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.99411764705883
    ram_util_percent: 32.5
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049217043479756015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.869634033376158
    mean_inference_ms: 1.5876723870417266
    mean_raw_obs_processing_ms: 0.14412676837228214
  time_since_restore: 5495.190150499344
  time_this_iter_s: 11.998905420303345
  time_total_s: 5495.190150499344
  timers:
    learn_throughput: 4966.992
    learn_time_ms: 9.664
    update_time_ms: 2.877
  timestamp: 1629286265
  timesteps_since_restore: 0
  timesteps_total: 394000
  training_iteration: 394
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    394 |          5495.19 | 394000 | 5.55672e+06 |          7.25484e+06 |             -198.044 |            8328.49 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 395000
  custom_metrics: {}
  date: 2021-08-18_11-31-19
  done: false
  episode_len_mean: 8328.489361702128
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5556721.6008444335
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 47
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 394624
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 21.56578826904297
          max_q: 7257928.0
          mean_q: 453619.59375
          mean_td_error: 193.9632568359375
          min_q: -2.1612839698791504
        model: {}
        td_error: "[ 2.4564028e-02 -4.0269732e-02  7.0019531e-01 -6.6117120e-01\n -7.4973583e-01\
          \  3.1030000e+03 -3.8568062e-01  3.6979866e-01\n -1.3600850e-01 -4.1504347e-01\
          \ -3.1725299e-01 -4.0071487e-02\n  3.3564472e-01  2.4148059e-01 -2.9436588e-02\
          \  2.6170313e-01\n -5.4867315e-01  3.8190603e-02 -1.6988111e-01  1.0025370e-01\n\
          \ -6.8825126e-02  9.7624183e-02  2.0907331e-01  1.5335608e-01\n  1.0571921e-01\
          \  2.4890399e-01  3.1030000e+03  2.6234734e-01\n  3.1775963e-01 -1.0322928e-02\
          \  1.3344407e-01  3.2018900e-02\n  6.6616929e-01  3.1933177e-01 -5.9203523e-01\
          \ -3.3642185e-01\n  3.3078098e-01  9.5778823e-02 -2.3428380e-01  1.1239040e-01\n\
          \  5.9476972e-02 -6.4969420e-02 -4.0452987e-01  3.7026483e-01\n  3.1030000e+03\
          \  6.0173982e-01 -4.7191417e-01  7.2418749e-01]"
    num_agent_steps_sampled: 395000
    num_agent_steps_trained: 4728048
    num_steps_sampled: 395000
    num_steps_trained: 4728048
    num_target_updates: 782
  iterations_since_restore: 395
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.94500000000001
    ram_util_percent: 32.495
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049217043479756015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.869634033376158
    mean_inference_ms: 1.5876723870417266
    mean_raw_obs_processing_ms: 0.14412676837228214
  time_since_restore: 5508.757705688477
  time_this_iter_s: 13.56755518913269
  time_total_s: 5508.757705688477
  timers:
    learn_throughput: 4929.232
    learn_time_ms: 9.738
    update_time_ms: 2.848
  timestamp: 1629286279
  timesteps_since_restore: 0
  timesteps_total: 395000
  training_iteration: 395
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    395 |          5508.76 | 395000 | 5.55672e+06 |          7.25484e+06 |             -198.044 |            8328.49 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 396000
  custom_metrics: {}
  date: 2021-08-18_11-31-33
  done: false
  episode_len_mean: 8328.489361702128
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5556721.6008444335
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 47
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 395632
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1061929315328598
          max_q: 6.704441070556641
          mean_q: -0.5560580492019653
          mean_td_error: 0.1140771135687828
          min_q: -2.1076581478118896
        model: {}
        td_error: "[ 0.15592855  0.261243    0.13603142  1.2820821   0.1118764   0.7296114\n\
          \  0.6683099   0.08028257  0.3073821   0.4263417  -0.5604063  -0.0992732\n\
          \  0.2838707   0.4743572  -0.00592971 -0.06462216 -0.09646219  0.42805326\n\
          \ -0.06651521  0.23280871  0.58437693 -0.29588938  0.165936    0.4916355\n\
          \  0.16332221 -0.24750018  0.26796448  0.1672383   0.09820831 -0.18024838\n\
          \  0.3188548  -1.1081288   0.6524202   0.310884    0.19285369  0.27422458\n\
          \  0.48783332 -0.2275343   0.2997297   0.46028805  0.21133006 -0.15102184\n\
          \ -0.48769373  0.5660843  -1.2373381  -0.01874506 -1.154738    0.18638444]"
    num_agent_steps_sampled: 396000
    num_agent_steps_trained: 4740048
    num_steps_sampled: 396000
    num_steps_trained: 4740048
    num_target_updates: 784
  iterations_since_restore: 396
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.89000000000001
    ram_util_percent: 32.5
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049217043479756015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.869634033376158
    mean_inference_ms: 1.5876723870417266
    mean_raw_obs_processing_ms: 0.14412676837228214
  time_since_restore: 5522.2603187561035
  time_this_iter_s: 13.502613067626953
  time_total_s: 5522.2603187561035
  timers:
    learn_throughput: 4878.09
    learn_time_ms: 9.84
    update_time_ms: 2.852
  timestamp: 1629286293
  timesteps_since_restore: 0
  timesteps_total: 396000
  training_iteration: 396
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    396 |          5522.26 | 396000 | 5.55672e+06 |          7.25484e+06 |             -198.044 |            8328.49 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 397000
  custom_metrics: {}
  date: 2021-08-18_11-31-47
  done: false
  episode_len_mean: 8328.489361702128
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5556721.6008444335
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 47
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 396640
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.506210327148438
          max_q: 7256306.0
          mean_q: 302345.4375
          mean_td_error: 61.81914520263672
          min_q: -2.293348789215088
        model: {}
        td_error: "[ 4.43079054e-01  4.88231421e-01  5.46202242e-01 -1.01572394e-01\n\
          \ -1.29611015e-01  2.16832638e-01 -5.56180477e-02 -3.42537880e-01\n -9.08718109e-02\
          \  4.62976336e-01  2.59127617e-01 -5.82529306e-01\n  1.79391146e-01  3.95156622e-01\
          \  7.34320521e-01  4.21167612e-01\n  5.41800082e-01 -3.53421569e-01  1.02535486e-01\
          \ -9.04296637e-02\n  1.48050000e+03  4.18409228e-01  1.03872061e-01 -4.87731695e-02\n\
          \  6.92906380e-01 -1.15682125e-01  5.15121460e-01  6.65100813e-02\n  3.85539234e-01\
          \ -3.02827656e-01 -4.70077634e-01  2.16327310e-01\n  3.99833113e-01  4.61792111e-01\
          \ -3.41257989e-01  1.58091664e-01\n  2.40251780e-01  5.09891510e-02  2.29969621e-01\
          \  7.39528418e-01\n -6.06741250e-01  4.64043379e-01  1.48050000e+03  1.67005062e-01\n\
          \ -1.64008498e-01  3.38032722e-01 -2.30378985e-01 -9.35741067e-02]"
    num_agent_steps_sampled: 397000
    num_agent_steps_trained: 4752048
    num_steps_sampled: 397000
    num_steps_trained: 4752048
    num_target_updates: 786
  iterations_since_restore: 397
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.02380952380951
    ram_util_percent: 32.5
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049217043479756015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.869634033376158
    mean_inference_ms: 1.5876723870417266
    mean_raw_obs_processing_ms: 0.14412676837228214
  time_since_restore: 5536.194728136063
  time_this_iter_s: 13.934409379959106
  time_total_s: 5536.194728136063
  timers:
    learn_throughput: 4588.891
    learn_time_ms: 10.46
    update_time_ms: 3.184
  timestamp: 1629286307
  timesteps_since_restore: 0
  timesteps_total: 397000
  training_iteration: 397
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    397 |          5536.19 | 397000 | 5.55672e+06 |          7.25484e+06 |             -198.044 |            8328.49 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 398000
  custom_metrics: {}
  date: 2021-08-18_11-32-02
  done: false
  episode_len_mean: 8328.489361702128
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5556721.6008444335
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 47
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 397648
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06605233997106552
          max_q: 6.440392971038818
          mean_q: -1.0100696086883545
          mean_td_error: -0.07780434936285019
          min_q: -2.109983205795288
        model: {}
        td_error: "[-0.11177808 -0.23726434 -0.26437724 -0.04257274 -0.45272332 -0.20353019\n\
          \ -0.19605437 -0.8211529   0.1718514   0.12488657  0.11204803  0.37543643\n\
          \ -0.12784398 -0.3435096   0.33545887 -0.29748535  0.2627008   0.2515025\n\
          \  0.21778905  0.86625636 -0.28062904  0.28637695 -0.24555534 -0.25098097\n\
          \  0.08787435 -0.39423323 -0.28292972  0.21450704 -0.4217298   0.08511043\n\
          \ -0.16985434 -0.02796566 -0.31828254  0.08452725 -0.37323928 -0.20470726\n\
          \  0.16306591 -0.50031924 -0.38037777  0.23644936 -0.05946827 -0.11293554\n\
          \ -0.10997421  0.52893865 -0.1876905  -0.63366884  0.06722116 -0.15377593]"
    num_agent_steps_sampled: 398000
    num_agent_steps_trained: 4764048
    num_steps_sampled: 398000
    num_steps_trained: 4764048
    num_target_updates: 788
  iterations_since_restore: 398
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.61428571428573
    ram_util_percent: 32.5
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049217043479756015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.869634033376158
    mean_inference_ms: 1.5876723870417266
    mean_raw_obs_processing_ms: 0.14412676837228214
  time_since_restore: 5550.6160345077515
  time_this_iter_s: 14.421306371688843
  time_total_s: 5550.6160345077515
  timers:
    learn_throughput: 4833.772
    learn_time_ms: 9.93
    update_time_ms: 2.889
  timestamp: 1629286322
  timesteps_since_restore: 0
  timesteps_total: 398000
  training_iteration: 398
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    398 |          5550.62 | 398000 | 5.55672e+06 |          7.25484e+06 |             -198.044 |            8328.49 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 399000
  custom_metrics: {}
  date: 2021-08-18_11-32-16
  done: false
  episode_len_mean: 8305.333333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5592094.779987604
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 398656
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10023338347673416
          max_q: 3.4206743240356445
          mean_q: -0.9183144569396973
          mean_td_error: -0.0009564980864524841
          min_q: -2.0247888565063477
        model: {}
        td_error: "[ 0.14942873 -0.24583459 -0.17086434 -0.8850175  -0.15442646  0.00484419\n\
          \  0.07270211  0.26308417  0.05276179  0.45181942  0.5167396  -0.06912899\n\
          \  0.52569306  0.16617215  0.0033021   0.14209366  0.51391673 -0.03707927\n\
          \  0.16509008 -0.07611555 -0.32489753 -0.01570451 -0.21554607 -0.5161773\n\
          \ -0.05911326 -0.22632623  0.20921397  0.44805217 -0.7029211  -0.02498078\n\
          \ -0.03472316 -0.30765116 -0.41555774 -0.29100436 -0.08027089  0.5958979\n\
          \ -0.5157381   0.19085968 -0.3953963   0.31592584  0.29104573 -0.41447675\n\
          \  0.75207865  0.3810295  -0.0265165  -0.07958615  0.90602535 -0.8786338 ]"
    num_agent_steps_sampled: 399000
    num_agent_steps_trained: 4776048
    num_steps_sampled: 399000
    num_steps_trained: 4776048
    num_target_updates: 790
  iterations_since_restore: 399
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.879999999999995
    ram_util_percent: 32.474999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049214266229916294
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.877965413065934
    mean_inference_ms: 1.5876861693986515
    mean_raw_obs_processing_ms: 0.1441298869339222
  time_since_restore: 5564.278691768646
  time_this_iter_s: 13.662657260894775
  time_total_s: 5564.278691768646
  timers:
    learn_throughput: 5085.52
    learn_time_ms: 9.439
    update_time_ms: 2.785
  timestamp: 1629286336
  timesteps_since_restore: 0
  timesteps_total: 399000
  training_iteration: 399
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    399 |          5564.28 | 399000 | 5.59209e+06 |          7.25484e+06 |             -198.044 |            8305.33 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 400000
  custom_metrics: {}
  date: 2021-08-18_11-32-29
  done: false
  episode_len_mean: 8305.333333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5592094.779987604
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 48
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 399664
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.041059013456106186
          max_q: 7.154901504516602
          mean_q: -0.840758204460144
          mean_td_error: -0.013099400326609612
          min_q: -2.737603187561035
        model: {}
        td_error: "[ 0.33785558 -0.24238926 -0.03173709  0.10725245  0.55217856  0.2627232\n\
          \  0.01006365 -0.06975579 -0.39729714 -0.04760653 -0.43096185 -0.24399233\n\
          \ -0.4476529   0.08052897 -0.24283826 -0.06908834  0.34247887 -0.07852161\n\
          \  0.41338956 -0.03008473 -0.27516836 -0.14829409 -0.10709113  0.4857211\n\
          \ -0.07112551  0.16732275 -0.01441604  0.27639723 -0.02073598 -0.48941088\n\
          \  0.37278914  0.19771743  0.19707143  0.55828536  0.33910704 -0.03575358\n\
          \  0.43059444 -0.84665823  0.20299023  0.11349177 -1.7017527   0.2599082\n\
          \ -0.04395771  0.0150075  -0.57827216 -0.03911817 -0.29672515  0.6487597 ]"
    num_agent_steps_sampled: 400000
    num_agent_steps_trained: 4788048
    num_steps_sampled: 400000
    num_steps_trained: 4788048
    num_target_updates: 792
  iterations_since_restore: 400
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.91764705882352
    ram_util_percent: 32.40588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049214266229916294
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.877965413065934
    mean_inference_ms: 1.5876861693986515
    mean_raw_obs_processing_ms: 0.1441298869339222
  time_since_restore: 5575.952540397644
  time_this_iter_s: 11.673848628997803
  time_total_s: 5575.952540397644
  timers:
    learn_throughput: 3445.126
    learn_time_ms: 13.933
    update_time_ms: 3.788
  timestamp: 1629286349
  timesteps_since_restore: 0
  timesteps_total: 400000
  training_iteration: 400
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    400 |          5575.95 | 400000 | 5.59209e+06 |          7.25484e+06 |             -198.044 |            8305.33 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 401000
  custom_metrics: {}
  date: 2021-08-18_11-32-42
  done: false
  episode_len_mean: 8305.333333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5592094.779987604
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 48
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 400672
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04872305691242218
          max_q: 6.715541839599609
          mean_q: -0.5620931386947632
          mean_td_error: -0.040183648467063904
          min_q: -1.9604853391647339
        model: {}
        td_error: "[ 0.51277924  0.3823732  -0.10880518 -0.5897314   0.05052376 -0.05511647\n\
          \ -0.01716745 -1.8987063   0.31760168  0.44024003 -0.02380843 -0.07390118\n\
          \ -0.02600026  0.10928345 -0.21113944  0.31008768  0.15609753 -1.1336942\n\
          \ -0.13072622 -0.0662353   0.02086335  0.47174668  0.17945588 -0.06792223\n\
          \  0.42215228 -0.04632223  0.26707292  0.6860516  -0.7376603   0.15123475\n\
          \ -0.07484114  0.14884055 -0.33712888  0.18060672 -0.14413452  0.28847706\n\
          \ -0.450958   -0.36197305  0.16933757 -0.39222115  0.13719141 -0.5538082\n\
          \ -0.20860624 -0.00672626  0.08332109  0.02738404  0.23491812  0.04087806]"
    num_agent_steps_sampled: 401000
    num_agent_steps_trained: 4800048
    num_steps_sampled: 401000
    num_steps_trained: 4800048
    num_target_updates: 794
  iterations_since_restore: 401
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.620000000000005
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049214266229916294
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.877965413065934
    mean_inference_ms: 1.5876861693986515
    mean_raw_obs_processing_ms: 0.1441298869339222
  time_since_restore: 5589.02321100235
  time_this_iter_s: 13.07067060470581
  time_total_s: 5589.02321100235
  timers:
    learn_throughput: 4969.346
    learn_time_ms: 9.659
    update_time_ms: 2.883
  timestamp: 1629286362
  timesteps_since_restore: 0
  timesteps_total: 401000
  training_iteration: 401
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    401 |          5589.02 | 401000 | 5.59209e+06 |          7.25484e+06 |             -198.044 |            8305.33 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 402000
  custom_metrics: {}
  date: 2021-08-18_11-32-56
  done: false
  episode_len_mean: 8305.333333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5592094.779987604
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 48
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 401680
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.4375
          max_q: 7255027.0
          mean_q: 151145.71875
          mean_td_error: 4.254924297332764
          min_q: -1.942310094833374
        model: {}
        td_error: "[ 1.3124007e-01 -1.9902444e-01 -2.9575604e-01 -5.8885574e-02\n -1.8923604e-01\
          \ -6.6654086e-02  1.8903702e-01 -1.6381621e-01\n -1.2899047e-01 -2.1886480e-01\
          \  9.6421838e-02  2.1274161e-01\n  1.6199708e-01  4.7034189e-01  3.2795954e-01\
          \ -5.1877046e-01\n  5.7108670e-01  1.5269256e-01  3.1538379e-01  4.7813523e-01\n\
          \  1.1722720e-01  2.1812463e-01 -1.0904932e-01  1.8390548e-01\n -2.4051440e-01\
          \ -9.8022521e-02  8.2508761e-01 -5.3042799e-01\n  1.4269942e-01  9.1382265e-02\
          \  2.0250000e+02 -5.5601406e-01\n  7.0601940e-02  3.2111204e-01 -1.3834488e-01\
          \ -1.6313815e-01\n  3.1126696e-01 -6.0156411e-01  2.8728682e-01  1.1944652e-02\n\
          \  3.2416129e-01  9.6792758e-02  3.0856788e-02  7.3172897e-02\n -2.7812910e-01\
          \ -2.1553978e-01 -1.5182388e-01  4.4626784e-01]"
    num_agent_steps_sampled: 402000
    num_agent_steps_trained: 4812048
    num_steps_sampled: 402000
    num_steps_trained: 4812048
    num_target_updates: 796
  iterations_since_restore: 402
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.47894736842105
    ram_util_percent: 32.40526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049214266229916294
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.877965413065934
    mean_inference_ms: 1.5876861693986515
    mean_raw_obs_processing_ms: 0.1441298869339222
  time_since_restore: 5602.3297526836395
  time_this_iter_s: 13.306541681289673
  time_total_s: 5602.3297526836395
  timers:
    learn_throughput: 5081.721
    learn_time_ms: 9.446
    update_time_ms: 2.757
  timestamp: 1629286376
  timesteps_since_restore: 0
  timesteps_total: 402000
  training_iteration: 402
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    402 |          5602.33 | 402000 | 5.59209e+06 |          7.25484e+06 |             -198.044 |            8305.33 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 403000
  custom_metrics: {}
  date: 2021-08-18_11-33-10
  done: false
  episode_len_mean: 8305.333333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5592094.779987604
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 48
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 402688
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.318877220153809
          max_q: 7254024.0
          mean_q: 151124.46875
          mean_td_error: -16.561569213867188
          min_q: -3.0952467918395996
        model: {}
        td_error: "[ 2.89524138e-01  8.37435782e-01 -4.48754072e-01  1.31274700e-01\n\
          \  8.25622082e-02  2.19873428e-01  2.17324972e-01 -3.78787518e-01\n -2.59563982e-01\
          \ -4.42184359e-01  4.28363323e-01 -2.91952372e-01\n  6.50207877e-01  5.11016607e-01\
          \  8.87113810e-03  2.93591857e-01\n  3.43042612e-01  7.25334287e-01  4.37224150e-01\
          \  2.17437863e-01\n  9.96930599e-02 -1.16179228e-01  3.92841458e-01 -7.99500000e+02\n\
          \ -2.29791045e-01  5.10653138e-01  2.94137657e-01  3.67223024e-02\n  1.05487883e-01\
          \  7.15221405e-01  3.13638926e-01 -2.61518955e-02\n -1.43672466e-01 -4.98803854e-02\
          \ -1.35450363e-01 -1.77379608e-01\n -1.16226506e+00 -2.32113749e-02 -7.07075357e-01\
          \  2.78852463e-01\n -3.82465124e-02  5.48304915e-02  2.44518280e-01  4.42862511e-04\n\
          \  1.11914635e-01  3.55300903e-01  4.04586673e-01 -1.36598110e-01]"
    num_agent_steps_sampled: 403000
    num_agent_steps_trained: 4824048
    num_steps_sampled: 403000
    num_steps_trained: 4824048
    num_target_updates: 798
  iterations_since_restore: 403
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.635000000000005
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049214266229916294
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.877965413065934
    mean_inference_ms: 1.5876861693986515
    mean_raw_obs_processing_ms: 0.1441298869339222
  time_since_restore: 5615.750788927078
  time_this_iter_s: 13.42103624343872
  time_total_s: 5615.750788927078
  timers:
    learn_throughput: 5009.021
    learn_time_ms: 9.583
    update_time_ms: 2.839
  timestamp: 1629286390
  timesteps_since_restore: 0
  timesteps_total: 403000
  training_iteration: 403
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    403 |          5615.75 | 403000 | 5.59209e+06 |          7.25484e+06 |             -198.044 |            8305.33 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 404000
  custom_metrics: {}
  date: 2021-08-18_11-33-25
  done: false
  episode_len_mean: 8305.333333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5592094.779987604
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 48
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 403696
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.368903160095215
          max_q: 7253292.5
          mean_q: 151109.765625
          mean_td_error: -31.98226547241211
          min_q: -3.0921149253845215
        model: {}
        td_error: "[-1.1350667e+00  2.2756863e-01 -3.5520613e-01 -7.2335660e-02\n  2.7528131e-01\
          \ -3.1657785e-01 -2.6331699e-01 -2.8043270e-01\n -7.8718543e-01  5.7865375e-01\
          \  7.9589963e-02  2.9979706e-01\n  9.3249702e-01  1.3217854e-01  1.0749209e-01\
          \  7.8771412e-02\n  5.5408168e-01  1.8930733e-01  8.8562083e-01 -7.3893833e-01\n\
          \  9.7605944e-02  1.1213973e-01 -6.5900362e-01 -1.7706573e-01\n -3.5531321e-01\
          \ -2.0122230e-02  1.8708944e-01 -2.5259132e+00\n -1.7918634e-01 -5.8747888e-01\
          \  2.2756863e-01  8.0244696e-01\n  4.1821277e-01  3.1455863e-01 -1.2585568e-01\
          \  2.8380072e-01\n -3.3586282e-01 -1.5330000e+03  2.0676535e-01 -3.5076070e-01\n\
          \  5.7693779e-01 -1.3149846e-01 -5.4024816e-02  1.2357816e-01\n -1.6246033e-01\
          \  2.7110887e-01 -3.5474664e-01 -1.4312720e-01]"
    num_agent_steps_sampled: 404000
    num_agent_steps_trained: 4836048
    num_steps_sampled: 404000
    num_steps_trained: 4836048
    num_target_updates: 800
  iterations_since_restore: 404
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.3047619047619
    ram_util_percent: 32.409523809523805
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049214266229916294
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.877965413065934
    mean_inference_ms: 1.5876861693986515
    mean_raw_obs_processing_ms: 0.1441298869339222
  time_since_restore: 5630.440023183823
  time_this_iter_s: 14.689234256744385
  time_total_s: 5630.440023183823
  timers:
    learn_throughput: 4940.093
    learn_time_ms: 9.716
    update_time_ms: 2.874
  timestamp: 1629286405
  timesteps_since_restore: 0
  timesteps_total: 404000
  training_iteration: 404
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    404 |          5630.44 | 404000 | 5.59209e+06 |          7.25484e+06 |             -198.044 |            8305.33 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 405000
  custom_metrics: {}
  date: 2021-08-18_11-33-40
  done: false
  episode_len_mean: 8305.333333333334
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5592094.779987604
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 48
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 404704
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7.622270107269287
          max_q: 7252752.5
          mean_q: 151098.0
          mean_td_error: -43.107635498046875
          min_q: -2.0225484371185303
        model: {}
        td_error: "[ 3.24853778e-01 -1.00201011e-01 -4.14340615e-01  3.47171068e-01\n\
          \  3.48785996e-01  1.20637357e-01  1.55416727e-02  1.40576899e-01\n -8.96793187e-01\
          \ -9.49116945e-02  1.94038033e-01 -1.87262535e-01\n -2.07250000e+03 -3.44625711e-02\
          \  3.86847258e-02  6.72688246e-01\n  1.44557357e-01  7.26304054e-02 -1.95968032e-01\
          \  1.17930770e-01\n  1.65744662e-01 -7.93063641e-02  4.20637965e-01  1.84483647e-01\n\
          \  6.23877287e-01  1.98198915e-01 -3.60760570e-01 -4.15384769e-02\n  6.97160959e-02\
          \  2.18797684e-01  2.80860543e-01  4.98137593e-01\n -1.80438519e-01 -1.13758564e-01\
          \ -3.25273514e-01 -3.10958505e-01\n  5.97797871e-01  5.22655487e-01 -9.55969095e-04\
          \ -3.61124516e-01\n  5.28701603e-01  1.94388866e-01 -1.14065409e-02 -1.17514491e-01\n\
          \  1.32583082e-01 -2.47588396e-01 -1.84021890e-01  4.17150497e-01]"
    num_agent_steps_sampled: 405000
    num_agent_steps_trained: 4848048
    num_steps_sampled: 405000
    num_steps_trained: 4848048
    num_target_updates: 802
  iterations_since_restore: 405
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.75
    ram_util_percent: 32.40454545454545
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049214266229916294
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.877965413065934
    mean_inference_ms: 1.5876861693986515
    mean_raw_obs_processing_ms: 0.1441298869339222
  time_since_restore: 5645.113198518753
  time_this_iter_s: 14.67317533493042
  time_total_s: 5645.113198518753
  timers:
    learn_throughput: 5017.873
    learn_time_ms: 9.566
    update_time_ms: 2.75
  timestamp: 1629286420
  timesteps_since_restore: 0
  timesteps_total: 405000
  training_iteration: 405
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    405 |          5645.11 | 405000 | 5.59209e+06 |          7.25484e+06 |             -198.044 |            8305.33 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 406000
  custom_metrics: {}
  date: 2021-08-18_11-33-53
  done: false
  episode_len_mean: 8272.632653061224
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5626024.2919885395
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 405712
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0762738510966301
          max_q: 6.808445930480957
          mean_q: -0.5706605315208435
          mean_td_error: 0.09999293088912964
          min_q: -3.5365750789642334
        model: {}
        td_error: "[ 0.38959157  0.16904783 -0.0154922   0.17134666 -0.34853578  0.33597243\n\
          \ -0.05768359 -0.08113849  0.23765028  0.318304    0.15656932 -0.31070232\n\
          \  0.05282569 -0.11382318  0.07605708 -0.05881011  0.05329537  0.20055854\n\
          \  0.26299936 -0.01346409  0.16498935  0.13635302  0.09831941  0.04538405\n\
          \  0.01476526  0.15276843  1.0973072   0.8465378  -0.02641082 -0.84793645\n\
          \ -0.19415873 -0.552323    0.32549232  0.6290933  -0.01411629 -0.10866082\n\
          \ -0.00613344  0.3397981   0.29783654  0.00907314  0.33236265  0.30382776\n\
          \  0.23654413  0.0960176   0.26242685 -0.17068672 -0.25281763  0.15943944]"
    num_agent_steps_sampled: 406000
    num_agent_steps_trained: 4860048
    num_steps_sampled: 406000
    num_steps_trained: 4860048
    num_target_updates: 804
  iterations_since_restore: 406
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.04210526315789
    ram_util_percent: 32.41052631578947
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921154662457491
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.885756382618337
    mean_inference_ms: 1.5876918053300166
    mean_raw_obs_processing_ms: 0.14413189959203754
  time_since_restore: 5657.710117101669
  time_this_iter_s: 12.59691858291626
  time_total_s: 5657.710117101669
  timers:
    learn_throughput: 5001.505
    learn_time_ms: 9.597
    update_time_ms: 2.956
  timestamp: 1629286433
  timesteps_since_restore: 0
  timesteps_total: 406000
  training_iteration: 406
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    406 |          5657.71 | 406000 | 5.62602e+06 |          7.25484e+06 |             -198.044 |            8272.63 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 407000
  custom_metrics: {}
  date: 2021-08-18_11-34-05
  done: false
  episode_len_mean: 8272.632653061224
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5626024.2919885395
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 49
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 406720
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07644747942686081
          max_q: 8.219205856323242
          mean_q: -0.8098461031913757
          mean_td_error: 0.01377556286752224
          min_q: -2.9420135021209717
        model: {}
        td_error: "[-0.07753122  0.25363135  0.08441973  0.19936574  0.6719372   0.13011897\n\
          \  0.19423485  0.29590857 -0.1878705  -1.0872878   0.37625086  0.32514253\n\
          \  0.35607958  0.9867649   0.40722275 -0.19803953  0.5697694  -0.16968697\n\
          \  0.25175607  0.39989948  0.79148793  0.47298574 -0.07729435  0.07019532\n\
          \  0.5433712  -0.5335231  -0.3437351   0.11261547  0.20493269  0.53310263\n\
          \  0.09675074 -0.20949036 -0.2550562  -0.01039922  0.33110332 -1.6623969\n\
          \ -0.04204404  0.01637816 -0.07207026 -0.4423979  -2.6533976   0.12376875\n\
          \ -0.5822945  -0.39219314 -0.34243822  0.60034156  0.41075796  0.1900804 ]"
    num_agent_steps_sampled: 407000
    num_agent_steps_trained: 4872048
    num_steps_sampled: 407000
    num_steps_trained: 4872048
    num_target_updates: 806
  iterations_since_restore: 407
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.62352941176471
    ram_util_percent: 32.41176470588235
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921154662457491
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.885756382618337
    mean_inference_ms: 1.5876918053300166
    mean_raw_obs_processing_ms: 0.14413189959203754
  time_since_restore: 5669.422734737396
  time_this_iter_s: 11.712617635726929
  time_total_s: 5669.422734737396
  timers:
    learn_throughput: 5085.289
    learn_time_ms: 9.439
    update_time_ms: 2.765
  timestamp: 1629286445
  timesteps_since_restore: 0
  timesteps_total: 407000
  training_iteration: 407
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    407 |          5669.42 | 407000 | 5.62602e+06 |          7.25484e+06 |             -198.044 |            8272.63 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 408000
  custom_metrics: {}
  date: 2021-08-18_11-34-18
  done: false
  episode_len_mean: 8272.632653061224
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5626024.2919885395
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 49
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 407728
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.386206150054932
          max_q: 7253722.0
          mean_q: 151118.296875
          mean_td_error: -23.058876037597656
          min_q: -3.4067258834838867
        model: {}
        td_error: "[ 2.8104222e-01  4.5879602e-01 -3.2412773e-01  4.3569565e-02\n  2.2403789e-01\
          \ -1.4966750e-01 -1.1798954e-01  6.3559151e-01\n -6.7245531e-01 -2.6288700e-01\
          \  1.1016529e+00  2.2657454e-01\n -2.5567740e-01 -6.2831640e-02 -2.1560866e-01\
          \ -1.4635265e-01\n -7.5323373e-02 -7.1212411e-02 -1.2572959e-01 -7.9950804e-01\n\
          \  9.6181333e-02 -7.6790905e-01  6.7037284e-02 -9.5365614e-01\n  1.4818048e-01\
          \ -4.0240669e-01 -4.1640639e-02  4.1589415e-01\n  2.0425999e-01 -1.7787647e-01\
          \  1.0622892e-01 -6.2668735e-01\n -1.2045749e+00  3.3494502e-01 -4.5905271e-01\
          \  1.5511930e-01\n -7.2690487e-02  2.9241794e-01  1.3757688e-01 -1.1035000e+03\n\
          \  6.4475167e-01 -1.2421772e-01 -5.0604028e-01  9.3741536e-02\n -7.0583856e-01\
          \ -1.1689663e-01  6.2755203e-01 -1.8229294e-01]"
    num_agent_steps_sampled: 408000
    num_agent_steps_trained: 4884048
    num_steps_sampled: 408000
    num_steps_trained: 4884048
    num_target_updates: 808
  iterations_since_restore: 408
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.2421052631579
    ram_util_percent: 32.41052631578947
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921154662457491
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.885756382618337
    mean_inference_ms: 1.5876918053300166
    mean_raw_obs_processing_ms: 0.14413189959203754
  time_since_restore: 5682.27515912056
  time_this_iter_s: 12.852424383163452
  time_total_s: 5682.27515912056
  timers:
    learn_throughput: 3426.981
    learn_time_ms: 14.006
    update_time_ms: 3.635
  timestamp: 1629286458
  timesteps_since_restore: 0
  timesteps_total: 408000
  training_iteration: 408
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    408 |          5682.28 | 408000 | 5.62602e+06 |          7.25484e+06 |             -198.044 |            8272.63 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 409000
  custom_metrics: {}
  date: 2021-08-18_11-34-32
  done: false
  episode_len_mean: 8272.632653061224
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5626024.2919885395
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 49
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 408736
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.981433391571045
          max_q: 7255046.0
          mean_q: 151145.875
          mean_td_error: 4.617391586303711
          min_q: -2.5982377529144287
        model: {}
        td_error: "[-1.08352184e-01 -3.62266660e-01  4.11741972e-01  5.25023937e-02\n\
          \ -4.83711660e-02  4.16482687e-01  2.70765066e-01  2.21500000e+02\n  1.62882447e-01\
          \  1.66058898e-01 -2.56731510e-02  3.09240818e-01\n -1.14793420e-01 -7.16040134e-02\
          \ -1.80926085e-01 -1.78831100e-01\n  1.41079903e-01 -7.91651011e-03  5.10594845e-02\
          \  2.37772167e-01\n -9.64882374e-02  4.11343575e-03 -1.55511439e-01 -1.55374765e-01\n\
          \  1.28538847e-01  8.88886690e-01  1.90786839e-01 -1.96328044e-01\n  7.17244864e-01\
          \  1.87461615e-01  3.13359261e-01 -2.97940433e-01\n  4.30732191e-01  2.05226183e-01\
          \  1.52844429e-01 -3.73308420e-01\n -5.75421929e-01  4.33942616e-01 -7.37494230e-02\
          \  5.04100323e-02\n  5.55975199e-01 -2.08591044e-01 -8.32079411e-01  1.35997295e-01\n\
          \ -2.25280714e+00  2.87171483e-01 -3.13755512e-01 -1.37401700e-01]"
    num_agent_steps_sampled: 409000
    num_agent_steps_trained: 4896048
    num_steps_sampled: 409000
    num_steps_trained: 4896048
    num_target_updates: 810
  iterations_since_restore: 409
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.485
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921154662457491
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.885756382618337
    mean_inference_ms: 1.5876918053300166
    mean_raw_obs_processing_ms: 0.14413189959203754
  time_since_restore: 5695.781757116318
  time_this_iter_s: 13.506597995758057
  time_total_s: 5695.781757116318
  timers:
    learn_throughput: 5110.785
    learn_time_ms: 9.392
    update_time_ms: 2.687
  timestamp: 1629286472
  timesteps_since_restore: 0
  timesteps_total: 409000
  training_iteration: 409
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    409 |          5695.78 | 409000 | 5.62602e+06 |          7.25484e+06 |             -198.044 |            8272.63 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 410000
  custom_metrics: {}
  date: 2021-08-18_11-34-46
  done: false
  episode_len_mean: 8272.632653061224
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5626024.2919885395
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 49
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 409744
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08164305239915848
          max_q: 2.8306117057800293
          mean_q: -0.8041571974754333
          mean_td_error: -0.006883931811898947
          min_q: -2.0547704696655273
        model: {}
        td_error: "[ 0.3556813   0.30634093  0.09552264 -0.03898856 -0.18767662  0.33687532\n\
          \ -0.12295938  0.00494057 -0.24777514 -0.02072363 -0.6880893  -0.14538348\n\
          \  0.37089926  0.0385257   0.31566298  0.15481067  0.1842407  -0.06288981\n\
          \ -0.13189578 -0.01150835 -0.1667006   0.10020697 -0.42994118 -0.34784448\n\
          \  0.19683719 -0.8748427  -0.21545666  0.21744263  0.5256425   0.290388\n\
          \ -0.47785425  0.1390127   0.3444829   0.11809576 -1.3262581   0.09197879\n\
          \  0.75013983  0.07663059 -0.0526495  -2.0647786   0.28259337  0.28570437\n\
          \  0.63046587  0.447806   -0.4367597   0.07261938  0.7681531   0.21884727]"
    num_agent_steps_sampled: 410000
    num_agent_steps_trained: 4908048
    num_steps_sampled: 410000
    num_steps_trained: 4908048
    num_target_updates: 812
  iterations_since_restore: 410
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.800000000000004
    ram_util_percent: 32.40526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921154662457491
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.885756382618337
    mean_inference_ms: 1.5876918053300166
    mean_raw_obs_processing_ms: 0.14413189959203754
  time_since_restore: 5708.978994607925
  time_this_iter_s: 13.197237491607666
  time_total_s: 5708.978994607925
  timers:
    learn_throughput: 5066.936
    learn_time_ms: 9.473
    update_time_ms: 2.886
  timestamp: 1629286486
  timesteps_since_restore: 0
  timesteps_total: 410000
  training_iteration: 410
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    410 |          5708.98 | 410000 | 5.62602e+06 |          7.25484e+06 |             -198.044 |            8272.63 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 411000
  custom_metrics: {}
  date: 2021-08-18_11-35-00
  done: false
  episode_len_mean: 8272.632653061224
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5626024.2919885395
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 49
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 410752
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08096089959144592
          max_q: 8.027891159057617
          mean_q: -0.8032970428466797
          mean_td_error: -0.04348039627075195
          min_q: -2.4786453247070312
        model: {}
        td_error: "[ 0.2023617  -0.82510054 -0.21883225  0.01838493 -0.27486908 -0.6138654\n\
          \ -0.30658114 -0.12822366 -0.02287793 -0.0126549  -0.12037385 -0.33180523\n\
          \ -0.00270784  1.0516744  -0.2389304   0.51587033 -0.03213584  0.58663404\n\
          \  0.2109828  -0.2884735   0.19185126 -0.352888   -0.42525756 -0.24603105\n\
          \  0.10793075  0.14021587 -0.00273734  0.06031191  0.36173022  0.06606174\n\
          \ -0.74681026  0.31001115 -0.62815976 -0.12254691 -0.2819816   0.34513807\n\
          \ -0.46017706  0.14463985 -0.4010111   0.1658516  -0.23739684  0.05079728\n\
          \  0.24975133 -0.13373232  0.21103072  0.48855865 -0.01276535 -0.09792107]"
    num_agent_steps_sampled: 411000
    num_agent_steps_trained: 4920048
    num_steps_sampled: 411000
    num_steps_trained: 4920048
    num_target_updates: 814
  iterations_since_restore: 411
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.400000000000006
    ram_util_percent: 32.4047619047619
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921154662457491
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.885756382618337
    mean_inference_ms: 1.5876918053300166
    mean_raw_obs_processing_ms: 0.14413189959203754
  time_since_restore: 5723.013708353043
  time_this_iter_s: 14.034713745117188
  time_total_s: 5723.013708353043
  timers:
    learn_throughput: 4856.111
    learn_time_ms: 9.884
    update_time_ms: 2.854
  timestamp: 1629286500
  timesteps_since_restore: 0
  timesteps_total: 411000
  training_iteration: 411
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    411 |          5723.01 | 411000 | 5.62602e+06 |          7.25484e+06 |             -198.044 |            8272.63 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 412000
  custom_metrics: {}
  date: 2021-08-18_11-35-16
  done: false
  episode_len_mean: 8272.632653061224
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5626024.2919885395
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 49
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 411760
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.2114763259887695
          max_q: 7254988.0
          mean_q: 151144.703125
          mean_td_error: 3.4778289794921875
          min_q: -3.212912082672119
        model: {}
        td_error: "[ 5.3828263e-01  4.4183803e-01 -3.8500607e-01 -2.3721790e-01\n  3.4392148e-02\
          \  7.0553136e-01 -1.8047404e-01 -6.1012143e-01\n  2.2565353e-01  5.0864840e-01\
          \ -2.5229454e-02 -8.8258862e-02\n -2.6778102e-02  3.1488788e-01  1.2826920e-03\
          \ -3.2605505e-01\n -1.8052167e-01  2.9129297e-01  1.0046911e-01  1.6400000e+02\n\
          \ -2.5909591e-01 -2.8534603e-01  1.0680723e-01 -2.4195290e-01\n  8.4316492e-02\
          \ -1.4971447e-01  7.6158786e-01 -5.0554502e-01\n -5.3127289e-02  1.7760813e-01\
          \ -9.6302450e-02 -2.9652798e-01\n  4.3127263e-01  3.1047082e-01 -1.4323831e-01\
          \ -3.0892265e-01\n -5.0381303e-01 -2.2358495e-01 -7.2258848e-01  1.8260300e-02\n\
          \  5.3939939e-02  1.5605992e-01  2.1601813e+00  4.0425313e-01\n  6.3703394e-01\
          \ -3.6264545e-01  4.2620283e-01  2.5756598e-01]"
    num_agent_steps_sampled: 412000
    num_agent_steps_trained: 4932048
    num_steps_sampled: 412000
    num_steps_trained: 4932048
    num_target_updates: 816
  iterations_since_restore: 412
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.53181818181817
    ram_util_percent: 32.449999999999996
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04921154662457491
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.885756382618337
    mean_inference_ms: 1.5876918053300166
    mean_raw_obs_processing_ms: 0.14413189959203754
  time_since_restore: 5738.31267118454
  time_this_iter_s: 15.298962831497192
  time_total_s: 5738.31267118454
  timers:
    learn_throughput: 5088.232
    learn_time_ms: 9.434
    update_time_ms: 2.74
  timestamp: 1629286516
  timesteps_since_restore: 0
  timesteps_total: 412000
  training_iteration: 412
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    412 |          5738.31 | 412000 | 5.62602e+06 |          7.25484e+06 |             -198.044 |            8272.63 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 413000
  custom_metrics: {}
  date: 2021-08-18_11-35-27
  done: false
  episode_len_mean: 8241.1
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5658596.426914363
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 412768
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1083555817604065
          max_q: 3.63417387008667
          mean_q: -0.6841296553611755
          mean_td_error: -0.05233407020568848
          min_q: -2.769306182861328
        model: {}
        td_error: "[ 0.5036361   0.7117885  -0.1516549   0.04774757 -2.8586354  -0.20510936\n\
          \  0.16334713  0.7563922   0.15442985 -0.7895379  -0.648473   -0.04261899\n\
          \  0.52654076 -0.05880928  0.11916161 -0.11594355  0.16107517  0.1986255\n\
          \ -0.63492846  0.46988374 -0.3471141   0.08195376 -0.12953678  0.3085618\n\
          \  0.19975948  0.08691475 -0.23759606 -0.25818872 -0.1685398  -1.0706778\n\
          \  0.00877666  0.3417071   0.3412943   0.09206915 -1.4673221   0.40032053\n\
          \ -0.3271997   0.43034744  0.05104923 -0.19424236 -0.10734826  0.12734759\n\
          \ -0.04901713  0.3193344   0.1336627  -0.01499996  0.45002556  0.17970574]"
    num_agent_steps_sampled: 413000
    num_agent_steps_trained: 4944048
    num_steps_sampled: 413000
    num_steps_trained: 4944048
    num_target_updates: 818
  iterations_since_restore: 413
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.59375
    ram_util_percent: 32.41875
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920877108598182
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.89297239054013
    mean_inference_ms: 1.5876795190399002
    mean_raw_obs_processing_ms: 0.14413278249180939
  time_since_restore: 5749.11524772644
  time_this_iter_s: 10.802576541900635
  time_total_s: 5749.11524772644
  timers:
    learn_throughput: 4697.57
    learn_time_ms: 10.218
    update_time_ms: 2.888
  timestamp: 1629286527
  timesteps_since_restore: 0
  timesteps_total: 413000
  training_iteration: 413
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    413 |          5749.12 | 413000 | 5.6586e+06 |          7.25484e+06 |             -198.044 |             8241.1 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 414000
  custom_metrics: {}
  date: 2021-08-18_11-35-40
  done: false
  episode_len_mean: 8241.1
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5658596.426914363
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 50
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 413776
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 11.377706527709961
          max_q: 7254698.0
          mean_q: 302278.0625
          mean_td_error: -5.39552116394043
          min_q: -3.3459818363189697
        model: {}
        td_error: "[ 1.70191407e-01  4.97257710e-03 -8.51958990e-02 -1.33864641e-01\n\
          \  8.51810575e-02 -1.28000000e+02 -5.91706634e-01  3.36061716e-02\n  7.25721121e-01\
          \ -1.95646167e-01 -3.33875418e-02  1.00462675e-01\n  5.65540791e-03  2.52532959e-02\
          \ -1.95609331e-01  2.25791097e-01\n -2.55046248e-01 -1.06089026e-01  1.30911827e-01\
          \ -4.04101610e-02\n -7.27109313e-02 -2.60398984e-01 -1.52982473e-01  4.49579120e-01\n\
          \ -8.44680071e-02 -3.42986941e-01 -3.89769077e-01  9.90063325e-02\n -5.25539637e-01\
          \  4.75044250e-02 -2.02023268e-01 -3.75626326e-01\n  3.73092413e-01  2.63522387e-01\
          \ -1.28000000e+02  2.57050991e-01\n -3.87177885e-01 -7.18898058e-01 -3.42064142e-01\
          \  6.21442795e-02\n -2.85321951e-01 -4.39697206e-02 -2.23221183e-01 -2.08875358e-01\n\
          \  2.58184314e-01  2.89351821e-01 -3.24956834e-01 -1.42342448e-02]"
    num_agent_steps_sampled: 414000
    num_agent_steps_trained: 4956048
    num_steps_sampled: 414000
    num_steps_trained: 4956048
    num_target_updates: 820
  iterations_since_restore: 414
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.55263157894737
    ram_util_percent: 32.41052631578947
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920877108598182
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.89297239054013
    mean_inference_ms: 1.5876795190399002
    mean_raw_obs_processing_ms: 0.14413278249180939
  time_since_restore: 5761.673236608505
  time_this_iter_s: 12.55798888206482
  time_total_s: 5761.673236608505
  timers:
    learn_throughput: 4649.79
    learn_time_ms: 10.323
    update_time_ms: 2.953
  timestamp: 1629286540
  timesteps_since_restore: 0
  timesteps_total: 414000
  training_iteration: 414
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    414 |          5761.67 | 414000 | 5.6586e+06 |          7.25484e+06 |             -198.044 |             8241.1 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 415000
  custom_metrics: {}
  date: 2021-08-18_11-35-53
  done: false
  episode_len_mean: 8241.1
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5658596.426914363
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 50
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 414784
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10221784561872482
          max_q: 4.402469635009766
          mean_q: -0.7388855814933777
          mean_td_error: 0.09879418462514877
          min_q: -3.8006203174591064
        model: {}
        td_error: "[ 0.39975762  0.1988768  -0.02741212  0.24111092  0.5234775   0.452538\n\
          \  0.13066494 -0.27472568 -0.10807717  0.02094007  0.10784638  0.12925959\n\
          \  0.05749601 -0.5766642  -0.08896446  1.2174904   0.486174    0.39005637\n\
          \  0.1140185  -0.00414884 -0.27006996  0.01208639  0.3657825  -0.14645672\n\
          \ -0.05746615  0.31417248  0.3787136   0.17809469 -0.37871885  0.17305648\n\
          \  0.12093735  0.3355863   0.5778196  -0.23428273 -0.37362134 -0.14976263\n\
          \  0.50688803 -1.1743226   0.19899261  0.3972656  -0.62262523  0.04741633\n\
          \  0.89479995  0.26563263 -0.14399981  0.09691694  0.148319   -0.10874808]"
    num_agent_steps_sampled: 415000
    num_agent_steps_trained: 4968048
    num_steps_sampled: 415000
    num_steps_trained: 4968048
    num_target_updates: 822
  iterations_since_restore: 415
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.505882352941185
    ram_util_percent: 32.40588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920877108598182
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.89297239054013
    mean_inference_ms: 1.5876795190399002
    mean_raw_obs_processing_ms: 0.14413278249180939
  time_since_restore: 5773.982942581177
  time_this_iter_s: 12.309705972671509
  time_total_s: 5773.982942581177
  timers:
    learn_throughput: 4924.024
    learn_time_ms: 9.748
    update_time_ms: 2.757
  timestamp: 1629286553
  timesteps_since_restore: 0
  timesteps_total: 415000
  training_iteration: 415
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    415 |          5773.98 | 415000 | 5.6586e+06 |          7.25484e+06 |             -198.044 |             8241.1 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 416000
  custom_metrics: {}
  date: 2021-08-18_11-36-07
  done: false
  episode_len_mean: 8241.1
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5658596.426914363
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 50
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 415792
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.051911868155002594
          max_q: 5.539925575256348
          mean_q: -0.9547091722488403
          mean_td_error: 0.06035890430212021
          min_q: -2.795823574066162
        model: {}
        td_error: "[ 0.63282156  0.16082114  0.76068175  0.14707053  0.35920334  0.21313\n\
          \ -0.17683327  0.02160043  0.82133174 -0.34186602  0.16540837 -0.03533328\n\
          \  0.22620422 -0.23892689 -0.08769065  0.5752435   0.02605551  0.08517706\n\
          \  0.19928432 -0.05104172  0.1207267   0.00664663 -0.04955247 -0.5703201\n\
          \ -0.08337975  0.4441241  -0.82099575 -0.16927838 -0.12005055 -0.29335904\n\
          \  0.69874215 -0.09098637 -0.31201243  0.18994284 -0.0573734  -0.07337391\n\
          \ -0.44501036  0.11274624  0.28530312 -0.11646795  0.20550942  0.07972419\n\
          \  0.35920596  0.08926159 -0.37322867  0.3669638   0.3711431  -0.31976494]"
    num_agent_steps_sampled: 416000
    num_agent_steps_trained: 4980048
    num_steps_sampled: 416000
    num_steps_trained: 4980048
    num_target_updates: 824
  iterations_since_restore: 416
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.07499999999999
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920877108598182
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.89297239054013
    mean_inference_ms: 1.5876795190399002
    mean_raw_obs_processing_ms: 0.14413278249180939
  time_since_restore: 5786.942855834961
  time_this_iter_s: 12.95991325378418
  time_total_s: 5786.942855834961
  timers:
    learn_throughput: 5012.576
    learn_time_ms: 9.576
    update_time_ms: 2.745
  timestamp: 1629286567
  timesteps_since_restore: 0
  timesteps_total: 416000
  training_iteration: 416
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    416 |          5786.94 | 416000 | 5.6586e+06 |          7.25484e+06 |             -198.044 |             8241.1 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 417000
  custom_metrics: {}
  date: 2021-08-18_11-36-18
  done: false
  episode_len_mean: 8157.450980392156
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5689892.529295152
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 416800
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 9.916618347167969
          max_q: 7255685.0
          mean_q: 151159.3125
          mean_td_error: 17.89797592163086
          min_q: -3.431889533996582
        model: {}
        td_error: "[ 5.29748201e-03  8.98333788e-02 -4.87802982e-01  8.60000000e+02\n\
          \ -1.61360860e-01 -8.71530771e-02  8.48873854e-02 -5.02712488e-01\n  5.19323587e-01\
          \  4.80221033e-01 -1.42483234e-01 -7.22980976e-01\n -9.39632058e-02  3.90130401e-01\
          \  4.64748800e-01  6.77535057e-01\n -1.77429438e-01  1.85165703e-01 -1.60415769e-01\
          \  3.13850403e-01\n  5.05097389e-01 -8.38029385e-02 -1.11908793e+00 -5.93588412e-01\n\
          \ -1.92068815e-02  8.86232853e-02 -2.79340744e-02  1.38926983e-01\n  2.56479144e-01\
          \  1.09494925e-01 -9.43839550e-05 -1.60973549e-01\n -4.94700730e-01 -2.51458240e+00\
          \  7.30991364e-04  6.59097016e-01\n -4.98279572e-01  4.30792212e-01  2.57534504e-01\
          \  4.85140085e-01\n -1.44299090e-01  4.32650745e-01  7.74974823e-02  3.51244211e-01\n\
          \ -2.36003578e-01  5.92882037e-02  2.89463997e-02  4.39089537e-01]"
    num_agent_steps_sampled: 417000
    num_agent_steps_trained: 4992048
    num_steps_sampled: 417000
    num_steps_trained: 4992048
    num_target_updates: 826
  iterations_since_restore: 417
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.225
    ram_util_percent: 32.40625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920600293006091
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.899586348251128
    mean_inference_ms: 1.5876624275880649
    mean_raw_obs_processing_ms: 0.14413311669410672
  time_since_restore: 5798.22389626503
  time_this_iter_s: 11.28104043006897
  time_total_s: 5798.22389626503
  timers:
    learn_throughput: 5025.89
    learn_time_ms: 9.551
    update_time_ms: 2.64
  timestamp: 1629286578
  timesteps_since_restore: 0
  timesteps_total: 417000
  training_iteration: 417
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    417 |          5798.22 | 417000 | 5.68989e+06 |          7.25484e+06 |             -198.044 |            8157.45 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 418000
  custom_metrics: {}
  date: 2021-08-18_11-36-30
  done: false
  episode_len_mean: 8157.450980392156
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5689892.529295152
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 51
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 417808
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08711022883653641
          max_q: 5.838557720184326
          mean_q: 0.09518806636333466
          mean_td_error: -0.031986914575099945
          min_q: -2.1586861610412598
        model: {}
        td_error: "[-0.05605227 -0.67341197 -0.9037505   0.2786827   0.12355399  0.06340944\n\
          \  0.04144764 -0.0833748   0.04018296 -0.08616638  0.12355614 -0.7313793\n\
          \  0.4013964  -0.39632583  0.259242   -0.21370006 -0.00504017 -0.4182744\n\
          \ -0.4287145   0.90629244 -0.36441225  0.47185588 -0.16832793 -0.44083166\n\
          \ -0.25154817 -0.5331617   0.9316545   0.36440527 -1.1480048  -0.17289269\n\
          \  0.7856667  -0.49414927 -0.06573439  0.03592217  0.26746544  0.7568789\n\
          \ -0.3704909   0.14376546  0.8045149  -0.09271586  0.15774289 -0.21008015\n\
          \  0.02945495  0.02065057  0.4080521  -0.06783599  0.2712615  -0.84605074]"
    num_agent_steps_sampled: 418000
    num_agent_steps_trained: 5004048
    num_steps_sampled: 418000
    num_steps_trained: 5004048
    num_target_updates: 828
  iterations_since_restore: 418
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.84117647058823
    ram_util_percent: 32.40588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920600293006091
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.899586348251128
    mean_inference_ms: 1.5876624275880649
    mean_raw_obs_processing_ms: 0.14413311669410672
  time_since_restore: 5809.410792350769
  time_this_iter_s: 11.186896085739136
  time_total_s: 5809.410792350769
  timers:
    learn_throughput: 4739.003
    learn_time_ms: 10.129
    update_time_ms: 2.896
  timestamp: 1629286590
  timesteps_since_restore: 0
  timesteps_total: 418000
  training_iteration: 418
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    418 |          5809.41 | 418000 | 5.68989e+06 |          7.25484e+06 |             -198.044 |            8157.45 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 419000
  custom_metrics: {}
  date: 2021-08-18_11-36-44
  done: false
  episode_len_mean: 8157.450980392156
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5689892.529295152
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 51
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 418816
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.293715000152588
          max_q: 7255076.0
          mean_q: 151147.078125
          mean_td_error: 5.21986722946167
          min_q: -2.7926113605499268
        model: {}
        td_error: "[ 4.5272148e-01  2.5629163e-02 -3.2057381e-01  2.1104656e-02\n  1.8218803e-01\
          \ -1.2804645e-01 -2.8169274e-02 -7.2907817e-01\n  3.8768619e-01 -5.6607103e-01\
          \  5.1528502e-01  4.3048239e-01\n -2.7647561e-01 -1.5502590e-01  4.2023087e-01\
          \  3.0055487e-01\n  1.0362375e-01  6.6629982e-01  3.9518464e-01 -4.0064424e-01\n\
          \ -4.1963199e-01 -3.9691448e-02  6.4535141e-03  2.5050000e+02\n  6.5593243e-02\
          \ -7.1670532e-02  4.4433057e-01  4.5617586e-01\n  5.2332377e-01 -1.9723079e+00\
          \ -2.5307196e-01 -7.6990819e-01\n  1.9412738e-01  6.1196327e-01  3.7388563e-01\
          \ -2.9748201e-02\n  3.5108000e-02  7.4243599e-01  1.0468972e+00 -6.4139795e-01\n\
          \ -1.3486195e-01 -8.5970336e-01 -4.6539307e-02  6.7251772e-02\n -3.3272493e-01\
          \ -3.0286434e-01  3.2450080e-02  3.0820489e-02]"
    num_agent_steps_sampled: 419000
    num_agent_steps_trained: 5016048
    num_steps_sampled: 419000
    num_steps_trained: 5016048
    num_target_updates: 830
  iterations_since_restore: 419
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.03684210526315
    ram_util_percent: 32.41052631578947
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920600293006091
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.899586348251128
    mean_inference_ms: 1.5876624275880649
    mean_raw_obs_processing_ms: 0.14413311669410672
  time_since_restore: 5822.5161254405975
  time_this_iter_s: 13.105333089828491
  time_total_s: 5822.5161254405975
  timers:
    learn_throughput: 5075.034
    learn_time_ms: 9.458
    update_time_ms: 2.732
  timestamp: 1629286604
  timesteps_since_restore: 0
  timesteps_total: 419000
  training_iteration: 419
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    419 |          5822.52 | 419000 | 5.68989e+06 |          7.25484e+06 |             -198.044 |            8157.45 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 420000
  custom_metrics: {}
  date: 2021-08-18_11-36-58
  done: false
  episode_len_mean: 8157.450980392156
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5689892.529295152
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 51
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 419824
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.11463339626789093
          max_q: 3.1067123413085938
          mean_q: -0.8159056901931763
          mean_td_error: -0.1407245397567749
          min_q: -2.3432765007019043
        model: {}
        td_error: "[-0.48106122 -0.0181312   0.02940488 -0.00493193 -0.17447412 -0.33109933\n\
          \  0.22653699 -0.27428842 -0.1008476  -0.364362   -0.37387544  0.24469948\n\
          \ -0.25681973 -0.09079838  0.42693567  0.01978803 -0.2671674   0.01880038\n\
          \ -0.4320386  -0.39778847 -0.24442685 -0.40507972  0.41256845 -0.00627169\n\
          \ -0.41539901 -0.4352765  -0.04450846  0.1089595  -0.15858793  0.55155706\n\
          \  0.11359881 -0.8761544   0.2600019  -0.00918901 -0.1722871  -0.82729614\n\
          \ -0.6030882  -0.23935895 -0.5849241   0.18544722 -0.23552728  0.00623941\n\
          \ -0.00863874  0.02694547  0.5008309  -0.00708556 -0.5331386  -0.51317   ]"
    num_agent_steps_sampled: 420000
    num_agent_steps_trained: 5028048
    num_steps_sampled: 420000
    num_steps_trained: 5028048
    num_target_updates: 832
  iterations_since_restore: 420
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.830000000000005
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920600293006091
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.899586348251128
    mean_inference_ms: 1.5876624275880649
    mean_raw_obs_processing_ms: 0.14413311669410672
  time_since_restore: 5835.996945858002
  time_this_iter_s: 13.480820417404175
  time_total_s: 5835.996945858002
  timers:
    learn_throughput: 4941.949
    learn_time_ms: 9.713
    update_time_ms: 2.801
  timestamp: 1629286618
  timesteps_since_restore: 0
  timesteps_total: 420000
  training_iteration: 420
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    420 |             5836 | 420000 | 5.68989e+06 |          7.25484e+06 |             -198.044 |            8157.45 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 421000
  custom_metrics: {}
  date: 2021-08-18_11-37-13
  done: false
  episode_len_mean: 8157.450980392156
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5689892.529295152
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 51
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 420832
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.09676782041788101
          max_q: 3.8548741340637207
          mean_q: -0.3655456304550171
          mean_td_error: -0.09493740648031235
          min_q: -2.9444265365600586
        model: {}
        td_error: "[-0.2461915  -0.3926494  -0.1864717  -0.7797805  -0.3357817  -0.25190866\n\
          \ -1.0175086   0.10533547 -0.01019287 -0.22310781  0.1900649  -0.24699926\n\
          \  0.2872181  -0.08187258 -0.3353151   0.20820142 -0.16543645  0.03125513\n\
          \ -0.2520215   0.660132   -0.5340582  -0.5912299   0.00823596 -0.46950614\n\
          \  0.550272    0.2680769   0.03777659 -0.16170073 -0.4112122  -0.17890787\n\
          \ -0.47941357  0.34198117  0.11885911 -0.10527694  0.1776396   0.5211741\n\
          \  0.7454462  -0.09995866  0.34433907 -0.37103498 -0.00830513 -0.0594894\n\
          \ -0.754936   -0.58819854  0.10600209  0.34384596  0.05288815 -0.3172729 ]"
    num_agent_steps_sampled: 421000
    num_agent_steps_trained: 5040048
    num_steps_sampled: 421000
    num_steps_trained: 5040048
    num_target_updates: 834
  iterations_since_restore: 421
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.47142857142857
    ram_util_percent: 32.4047619047619
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920600293006091
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.899586348251128
    mean_inference_ms: 1.5876624275880649
    mean_raw_obs_processing_ms: 0.14413311669410672
  time_since_restore: 5850.417642831802
  time_this_iter_s: 14.42069697380066
  time_total_s: 5850.417642831802
  timers:
    learn_throughput: 5050.07
    learn_time_ms: 9.505
    update_time_ms: 2.708
  timestamp: 1629286633
  timesteps_since_restore: 0
  timesteps_total: 421000
  training_iteration: 421
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    421 |          5850.42 | 421000 | 5.68989e+06 |          7.25484e+06 |             -198.044 |            8157.45 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 422000
  custom_metrics: {}
  date: 2021-08-18_11-37-28
  done: false
  episode_len_mean: 8157.450980392156
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5689892.529295152
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 51
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 421840
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10987535119056702
          max_q: 6.087226390838623
          mean_q: -0.4407401978969574
          mean_td_error: -0.2541522979736328
          min_q: -3.639700412750244
        model: {}
        td_error: "[-1.6781597  -3.3035793  -0.22605139 -0.29948455 -1.3503704  -0.14495409\n\
          \  0.04241288  0.2475239   0.16241312  0.79452586 -0.24083647 -0.36794233\n\
          \ -0.34560728  0.24654448 -0.49051148 -0.6644558  -0.33543873  0.01204908\n\
          \ -0.06913793 -0.17385983  0.42025864 -0.26531523  0.24043107  0.11522615\n\
          \  0.16574544  0.05259633 -0.49877268  0.04372978 -0.24619532 -0.24598524\n\
          \ -0.2995057  -0.16802633 -0.10818577  0.14406872 -0.34203187 -0.07337052\n\
          \  0.02750927  0.01553345 -0.02222276 -0.07133424 -0.12989199  0.36962175\n\
          \ -0.33836192 -2.1338336  -0.01452041 -0.07247663 -0.6577823   0.07870245]"
    num_agent_steps_sampled: 422000
    num_agent_steps_trained: 5052048
    num_steps_sampled: 422000
    num_steps_trained: 5052048
    num_target_updates: 836
  iterations_since_restore: 422
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.11818181818181
    ram_util_percent: 32.40909090909091
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920600293006091
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.899586348251128
    mean_inference_ms: 1.5876624275880649
    mean_raw_obs_processing_ms: 0.14413311669410672
  time_since_restore: 5865.350034236908
  time_this_iter_s: 14.93239140510559
  time_total_s: 5865.350034236908
  timers:
    learn_throughput: 4697.987
    learn_time_ms: 10.217
    update_time_ms: 2.908
  timestamp: 1629286648
  timesteps_since_restore: 0
  timesteps_total: 422000
  training_iteration: 422
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    422 |          5865.35 | 422000 | 5.68989e+06 |          7.25484e+06 |             -198.044 |            8157.45 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 423000
  custom_metrics: {}
  date: 2021-08-18_11-37-43
  done: false
  episode_len_mean: 8157.450980392156
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5689892.529295152
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 51
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 422848
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.11624720692634583
          max_q: 7.081753730773926
          mean_q: -0.36703452467918396
          mean_td_error: -0.18831416964530945
          min_q: -2.9777586460113525
        model: {}
        td_error: "[ 1.27933383e-01 -1.66985631e-01 -5.30539513e-01 -4.82330173e-01\n\
          \  1.52225971e-01 -6.15281641e-01  5.24909496e-02  6.02534711e-02\n -3.19354713e-01\
          \  2.40170479e-01  6.67764664e-01  7.28044510e-02\n -2.41325879e+00 -1.49997234e-01\
          \ -5.73860705e-01 -7.65090704e-01\n  1.24302268e-01 -3.57699454e-01 -1.63800329e-01\
          \  2.80750036e-01\n  4.07265425e-02 -3.42447758e-02 -1.35902691e+00  5.36337852e-01\n\
          \ -3.51403356e-01 -4.10321951e-02 -2.97049463e-01 -2.23665237e-02\n  2.07594395e-01\
          \ -3.42469215e-02 -5.19845486e-02 -1.74136937e-01\n  1.28985167e-01 -2.95143723e-01\
          \ -1.21853948e-01 -1.18776798e-01\n -4.12449121e-01  3.35097313e-04 -5.96120596e-01\
          \ -2.57874101e-01\n  2.81049252e-01  4.46441174e-02 -4.76393998e-01  9.26082850e-01\n\
          \  1.10411525e-01  4.29631710e-01 -6.00188971e-04 -2.34067106e+00]"
    num_agent_steps_sampled: 423000
    num_agent_steps_trained: 5064048
    num_steps_sampled: 423000
    num_steps_trained: 5064048
    num_target_updates: 838
  iterations_since_restore: 423
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.35
    ram_util_percent: 32.449999999999996
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920600293006091
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.899586348251128
    mean_inference_ms: 1.5876624275880649
    mean_raw_obs_processing_ms: 0.14413311669410672
  time_since_restore: 5880.074428081512
  time_this_iter_s: 14.724393844604492
  time_total_s: 5880.074428081512
  timers:
    learn_throughput: 4922.988
    learn_time_ms: 9.75
    update_time_ms: 2.898
  timestamp: 1629286663
  timesteps_since_restore: 0
  timesteps_total: 423000
  training_iteration: 423
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    423 |          5880.07 | 423000 | 5.68989e+06 |          7.25484e+06 |             -198.044 |            8157.45 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 424000
  custom_metrics: {}
  date: 2021-08-18_11-37-59
  done: false
  episode_len_mean: 8153.346153846154
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5719982.991290311
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 423856
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.226008415222168
          max_q: 7255034.0
          mean_q: 151146.046875
          mean_td_error: 4.130661964416504
          min_q: -2.7092928886413574
        model: {}
        td_error: "[ 2.99711227e-01  1.80387497e-01 -5.61745524e-01 -2.74202204e+00\n\
          \ -3.52031142e-02 -9.54706132e-01 -3.38801324e-01  6.40690327e-04\n  2.17697620e-02\
          \ -8.68004560e-02 -5.94581366e-02 -7.07070827e-02\n -1.61357284e-01  1.12763643e-02\
          \  2.00574279e-01  5.48847318e-01\n -1.13585234e-01 -1.43058300e-01 -3.33835244e-01\
          \ -1.75229907e-01\n -1.24910474e-02  3.64271641e-01 -2.28201866e-01 -8.74994755e-01\n\
          \ -1.08252645e-01 -9.89807844e-02  6.29594326e-02 -4.02877718e-01\n -5.40613949e-01\
          \  2.52740383e-02  1.28722191e-03 -2.52541542e-01\n -2.19800901e+00  3.76623273e-02\
          \  1.63854122e-01 -8.35783362e-01\n -3.41201365e-01  7.03376353e-01  4.81370926e-01\
          \ -2.19912171e-01\n -2.53888369e-02  5.66625595e-02 -5.74629545e-01 -1.83647275e-01\n\
          \  5.69941401e-02 -3.04237366e-01  2.08000000e+02  3.31152678e-02]"
    num_agent_steps_sampled: 424000
    num_agent_steps_trained: 5076048
    num_steps_sampled: 424000
    num_steps_trained: 5076048
    num_target_updates: 840
  iterations_since_restore: 424
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.65454545454544
    ram_util_percent: 32.50909090909091
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920305627252153
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.905949734465221
    mean_inference_ms: 1.5876362454303623
    mean_raw_obs_processing_ms: 0.14413304814373298
  time_since_restore: 5895.34937620163
  time_this_iter_s: 15.274948120117188
  time_total_s: 5895.34937620163
  timers:
    learn_throughput: 4212.602
    learn_time_ms: 11.394
    update_time_ms: 3.658
  timestamp: 1629286679
  timesteps_since_restore: 0
  timesteps_total: 424000
  training_iteration: 424
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    424 |          5895.35 | 424000 | 5.71998e+06 |          7.25484e+06 |             -198.044 |            8153.35 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 425000
  custom_metrics: {}
  date: 2021-08-18_11-38-10
  done: false
  episode_len_mean: 8153.346153846154
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5719982.991290311
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 52
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 424864
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.062299080193042755
          max_q: 3.818737268447876
          mean_q: -0.5556517839431763
          mean_td_error: 0.006907912902534008
          min_q: -3.8164563179016113
        model: {}
        td_error: "[ 5.64880371e-02  1.70939684e-01 -6.00028932e-02  4.80360150e-01\n\
          \  4.32148099e-01  1.21851325e-01 -8.18817616e-02 -2.46167183e-04\n -2.07932830e-01\
          \  3.47341821e-02  6.23084307e-02 -2.35102654e-01\n -3.80991459e-01  9.79850292e-02\
          \ -1.40008986e-01  5.00226974e-01\n -2.04413772e-01 -1.15588844e-01  1.04846716e-01\
          \  2.46813655e-01\n -4.40103799e-01 -4.88721609e-01  1.12250447e-02  1.24463558e-01\n\
          \  4.00125504e-01  2.24235296e-01 -1.00221634e-02  5.44712901e-01\n -2.44087726e-01\
          \ -2.74206042e-01 -3.62185240e-01 -1.74966991e-01\n  6.20830119e-01 -1.71774745e-01\
          \  3.82073879e-01  2.23111749e-01\n -3.30859900e-01  3.74503136e-02 -3.06628227e-01\
          \ -8.17970037e-02\n -5.58939397e-01  1.43393874e-01  3.59070301e-01 -6.39004588e-01\n\
          \  1.19601393e+00 -7.61241496e-01  7.17999935e-02 -4.49206829e-02]"
    num_agent_steps_sampled: 425000
    num_agent_steps_trained: 5088048
    num_steps_sampled: 425000
    num_steps_trained: 5088048
    num_target_updates: 842
  iterations_since_restore: 425
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.431250000000006
    ram_util_percent: 32.40625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920305627252153
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.905949734465221
    mean_inference_ms: 1.5876362454303623
    mean_raw_obs_processing_ms: 0.14413304814373298
  time_since_restore: 5905.901194572449
  time_this_iter_s: 10.551818370819092
  time_total_s: 5905.901194572449
  timers:
    learn_throughput: 4372.141
    learn_time_ms: 10.979
    update_time_ms: 4.254
  timestamp: 1629286690
  timesteps_since_restore: 0
  timesteps_total: 425000
  training_iteration: 425
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    425 |           5905.9 | 425000 | 5.71998e+06 |          7.25484e+06 |             -198.044 |            8153.35 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 426000
  custom_metrics: {}
  date: 2021-08-18_11-38-23
  done: false
  episode_len_mean: 8153.346153846154
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5719982.991290311
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 52
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 425872
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.550843238830566
          max_q: 7253441.0
          mean_q: 151112.75
          mean_td_error: -28.903331756591797
          min_q: -2.830447196960449
        model: {}
        td_error: "[ 1.4940739e-02 -4.5827657e-01 -2.9745054e-01 -3.4670687e-01\n  1.9653600e-01\
          \  1.0290742e-01 -9.3427122e-02  5.1406705e-01\n  2.5911689e-01  3.3223307e-01\
          \ -1.5580014e+00  2.3218036e-01\n  1.5911859e-01  3.9044631e-01 -3.1759709e-01\
          \ -3.2042056e-01\n  2.0323271e-01 -2.8722954e-01  1.8272501e-01  2.9648423e-01\n\
          \ -2.8374076e-01  2.9914469e-01  3.2418233e-01 -1.3845000e+03\n  1.6899914e-02\
          \ -3.7782574e-01  1.5303165e-01  1.8956661e-01\n  2.3462534e-02 -2.5053823e-01\
          \  4.8840761e-02 -4.3007684e-01\n  2.6189089e-01 -5.2187920e-01 -2.5481129e-01\
          \  1.7400718e-01\n -2.0567644e-01 -3.0733943e-01 -4.2553854e-01 -1.0373016e-01\n\
          \ -2.3446262e-01 -3.0469000e-01 -4.1839767e-01  3.3432066e-01\n -4.0920886e-01\
          \  3.0252850e-01  2.5970185e-01  7.5520992e-02]"
    num_agent_steps_sampled: 426000
    num_agent_steps_trained: 5100048
    num_steps_sampled: 426000
    num_steps_trained: 5100048
    num_target_updates: 844
  iterations_since_restore: 426
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.75555555555556
    ram_util_percent: 32.40555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920305627252153
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.905949734465221
    mean_inference_ms: 1.5876362454303623
    mean_raw_obs_processing_ms: 0.14413304814373298
  time_since_restore: 5918.45684671402
  time_this_iter_s: 12.555652141571045
  time_total_s: 5918.45684671402
  timers:
    learn_throughput: 4891.435
    learn_time_ms: 9.813
    update_time_ms: 2.695
  timestamp: 1629286703
  timesteps_since_restore: 0
  timesteps_total: 426000
  training_iteration: 426
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    426 |          5918.46 | 426000 | 5.71998e+06 |          7.25484e+06 |             -198.044 |            8153.35 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 427000
  custom_metrics: {}
  date: 2021-08-18_11-38-36
  done: false
  episode_len_mean: 8153.346153846154
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5719982.991290311
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 52
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 426880
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10380294919013977
          max_q: 6.407629013061523
          mean_q: -0.2990241050720215
          mean_td_error: 0.07933105528354645
          min_q: -2.9106531143188477
        model: {}
        td_error: "[ 0.616439    0.01507121  0.5935368  -0.4003526   0.65756214  0.00356746\n\
          \ -0.43999827  0.47402477  0.21668005 -0.56083864 -1.1630092   0.03323084\n\
          \  1.2216213  -0.3393365   0.5819068  -0.1063993   0.03839672  0.67112976\n\
          \ -0.05779135  0.1669029  -0.24889445 -0.15846556  0.38594437 -0.2331028\n\
          \  0.24817806  0.19385278  0.34056675  0.08281946 -0.21578449 -0.03947553\n\
          \  0.33684742  0.02757603 -0.40423638  0.18920004  0.30435562 -0.07477045\n\
          \  0.25714552 -0.05720651  0.5844524   0.944357   -0.3321605   0.05528939\n\
          \ -0.24663997  0.2569548  -0.16054773  0.02826595 -0.04446268 -0.43451178]"
    num_agent_steps_sampled: 427000
    num_agent_steps_trained: 5112048
    num_steps_sampled: 427000
    num_steps_trained: 5112048
    num_target_updates: 846
  iterations_since_restore: 427
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.25
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04920305627252153
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.905949734465221
    mean_inference_ms: 1.5876362454303623
    mean_raw_obs_processing_ms: 0.14413304814373298
  time_since_restore: 5931.650011539459
  time_this_iter_s: 13.193164825439453
  time_total_s: 5931.650011539459
  timers:
    learn_throughput: 4963.025
    learn_time_ms: 9.672
    update_time_ms: 2.691
  timestamp: 1629286716
  timesteps_since_restore: 0
  timesteps_total: 427000
  training_iteration: 427
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    427 |          5931.65 | 427000 | 5.71998e+06 |          7.25484e+06 |             -198.044 |            8153.35 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 428000
  custom_metrics: {}
  date: 2021-08-18_11-38-50
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 427888
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06878546625375748
          max_q: 2.990659475326538
          mean_q: -0.6950439214706421
          mean_td_error: -0.04042656347155571
          min_q: -3.2316527366638184
        model: {}
        td_error: "[-6.41747475e-01  6.21385813e-01 -2.49427795e-01 -2.44852364e-01\n\
          \ -1.02494860e+00 -9.77424383e-02  1.30985188e+00 -8.91491175e-02\n -9.08561409e-01\
          \  2.60031223e-01  2.15373456e-01  7.18787909e-02\n  1.79399729e-01 -1.18790060e-01\
          \  1.93810463e-03 -1.85400367e-01\n -9.45223570e-02  4.44122493e-01  5.76219559e-02\
          \ -2.51083851e-01\n  3.06247860e-01 -6.34001017e-01 -5.71496248e-01  3.14443290e-01\n\
          \ -5.82165658e-01  1.38810933e-01  2.23830089e-01 -3.50034475e-01\n  3.07724595e-01\
          \  1.04919302e+00  7.66775250e-01 -3.32329273e-01\n  2.50596404e-01  2.03347683e-01\
          \ -5.08170366e-01  2.66507983e-01\n -1.24186754e-01 -3.92779231e-01 -1.59793258e+00\
          \ -2.17506766e-01\n  3.94623280e-02 -3.09852362e-01  3.15083921e-01  1.59272611e-01\n\
          \  4.69861031e-02 -1.34799182e-02  5.09727933e-02 -1.17290020e-03]"
    num_agent_steps_sampled: 428000
    num_agent_steps_trained: 5124048
    num_steps_sampled: 428000
    num_steps_trained: 5124048
    num_target_updates: 848
  iterations_since_restore: 428
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.247368421052634
    ram_util_percent: 32.4
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 5944.522497653961
  time_this_iter_s: 12.872486114501953
  time_total_s: 5944.522497653961
  timers:
    learn_throughput: 4951.015
    learn_time_ms: 9.695
    update_time_ms: 2.764
  timestamp: 1629286730
  timesteps_since_restore: 0
  timesteps_total: 428000
  training_iteration: 428
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    428 |          5944.52 | 428000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 429000
  custom_metrics: {}
  date: 2021-08-18_11-39-02
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 428896
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.311588764190674
          max_q: 7257397.5
          mean_q: 151195.53125
          mean_td_error: 53.60200119018555
          min_q: -2.4122865200042725
        model: {}
        td_error: "[ 5.96064568e-01  2.52053499e-01  5.44959307e-03 -4.12357211e-01\n\
          \  9.99501348e-01 -1.80596709e-01  2.73492277e-01  5.03599644e-02\n -1.60396099e-02\
          \  3.22342634e-01 -1.65791139e-01  3.45916569e-01\n -3.14082026e-01 -3.88727576e-01\
          \  3.16401124e-02  9.83724594e-02\n  1.83209240e-01  1.36723518e-02 -5.27393401e-01\
          \  4.23397064e-01\n -1.64815545e-01 -7.97071457e-02 -3.45292538e-02 -2.56966650e-01\n\
          \  6.49963915e-02 -2.12840378e-01  1.19245052e-01 -5.00818491e-02\n -1.10160351e-01\
          \  7.32503653e-01 -2.73608446e-01 -1.50057077e-01\n -6.62309349e-01  6.57558441e-04\
          \  8.49047899e-02  6.30651712e-02\n  5.73047638e-01  9.40171480e-02 -7.48538971e-02\
          \  5.55595398e-01\n  2.57150000e+03 -1.11851275e-01  5.42168140e-01 -3.05753350e-01\n\
          \ -3.31603169e-01 -6.80747688e-01  2.94162005e-01  1.81380987e-01]"
    num_agent_steps_sampled: 429000
    num_agent_steps_trained: 5136048
    num_steps_sampled: 429000
    num_steps_trained: 5136048
    num_target_updates: 850
  iterations_since_restore: 429
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.688235294117646
    ram_util_percent: 32.40588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 5956.262415409088
  time_this_iter_s: 11.739917755126953
  time_total_s: 5956.262415409088
  timers:
    learn_throughput: 4932.106
    learn_time_ms: 9.732
    update_time_ms: 3.152
  timestamp: 1629286742
  timesteps_since_restore: 0
  timesteps_total: 429000
  training_iteration: 429
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    429 |          5956.26 | 429000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 430000
  custom_metrics: {}
  date: 2021-08-18_11-39-16
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 429904
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.121063709259033
          max_q: 7253076.0
          mean_q: 151105.46875
          mean_td_error: -36.5219612121582
          min_q: -2.2438645362854004
        model: {}
        td_error: "[-3.7299693e-01  1.4170027e-01  3.1377292e-01 -3.4155595e-01\n  5.7466507e-01\
          \ -1.9933569e-01 -2.5263107e-01 -1.8172354e-01\n  2.7707338e-01  1.1420411e-01\
          \ -2.9699937e-02 -1.0947777e+00\n -2.1083689e-01 -1.1530757e-02  1.1936091e-01\
          \  3.1384045e-01\n  4.1108727e-02 -4.5492196e-01 -5.8570862e-02 -2.2008431e-01\n\
          \ -4.5469952e-01 -1.6392124e-01 -9.3379289e-02 -6.4905500e-01\n  3.5121870e-01\
          \  1.4086103e-01  1.8836105e-01  6.7780375e-02\n -1.1866434e+00 -9.2779398e-02\
          \ -4.6184206e-01  1.3814807e+00\n -3.3405986e-01 -3.3867466e-01  1.1651460e+00\
          \  1.5911794e-01\n -9.1668010e-02 -5.6632507e-01 -9.1397953e-01 -1.1131835e-01\n\
          \ -3.0932191e-01  8.4272861e-02 -6.6309929e-02  2.7645779e-01\n -9.5320344e-02\
          \ -1.6651261e-01  2.5990534e-01 -1.7495000e+03]"
    num_agent_steps_sampled: 430000
    num_agent_steps_trained: 5148048
    num_steps_sampled: 430000
    num_steps_trained: 5148048
    num_target_updates: 852
  iterations_since_restore: 430
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.355
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 5969.558849334717
  time_this_iter_s: 13.296433925628662
  time_total_s: 5969.558849334717
  timers:
    learn_throughput: 4716.101
    learn_time_ms: 10.178
    update_time_ms: 2.953
  timestamp: 1629286756
  timesteps_since_restore: 0
  timesteps_total: 430000
  training_iteration: 430
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    430 |          5969.56 | 430000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 431000
  custom_metrics: {}
  date: 2021-08-18_11-39-29
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 430912
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06276758760213852
          max_q: 3.594909191131592
          mean_q: -0.3585333526134491
          mean_td_error: -0.10671946406364441
          min_q: -2.4269816875457764
        model: {}
        td_error: "[ 0.06758487  0.02411351  0.22049785  0.25786996  0.11180997  0.21559638\n\
          \ -0.2421943   0.36023712 -0.27927113 -1.3372173   0.18122113 -0.1237542\n\
          \  1.1463296   0.20455945  0.22980371  0.47444236 -0.15820736  0.30195725\n\
          \  0.6293607   0.02908432 -0.09990811 -0.18265685 -0.24807465  0.01513186\n\
          \  0.4889989  -0.44267166  0.3615896  -3.5624557   0.12601066 -0.133407\n\
          \ -0.16662726  0.4688164  -0.00606793 -0.91229725 -0.64796185 -0.31560427\n\
          \  0.27367973  0.48882508  0.03841066 -0.22764623 -2.9229696  -0.13015279\n\
          \  0.39888793  0.27597308  0.02976716 -0.03018939  0.01384497 -0.387604  ]"
    num_agent_steps_sampled: 431000
    num_agent_steps_trained: 5160048
    num_steps_sampled: 431000
    num_steps_trained: 5160048
    num_target_updates: 854
  iterations_since_restore: 431
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.857894736842105
    ram_util_percent: 32.40526315789473
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 5982.461724758148
  time_this_iter_s: 12.902875423431396
  time_total_s: 5982.461724758148
  timers:
    learn_throughput: 5029.581
    learn_time_ms: 9.544
    update_time_ms: 2.866
  timestamp: 1629286769
  timesteps_since_restore: 0
  timesteps_total: 431000
  training_iteration: 431
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    431 |          5982.46 | 431000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 432000
  custom_metrics: {}
  date: 2021-08-18_11-39-43
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 431920
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 21.47361183166504
          max_q: 7254510.5
          mean_q: 453406.5
          mean_td_error: -19.829242706298828
          min_q: -2.494900703430176
        model: {}
        td_error: "[-6.0967684e-02 -1.9187951e-01  4.3243855e-01  2.0746493e-01\n -1.2311950e-01\
          \ -6.9501221e-02 -3.2257056e-01  4.6472937e-01\n -5.4710209e-01 -4.8413995e-01\
          \  3.1052375e-01  6.8200421e-01\n -3.5858321e-01 -7.3930722e-01 -3.1500000e+02\
          \ -8.5091650e-01\n  3.8736472e-01  1.2092316e-01  2.7841496e-01  2.1532106e-01\n\
          \ -8.0265999e-03 -3.1500000e+02 -2.2668490e-01 -2.8634191e-01\n -6.6124701e-01\
          \  4.1748047e-02  7.1250063e-01 -3.3898389e-01\n -4.7545433e-02 -3.0143762e-01\
          \ -1.1717210e+00 -2.5539942e+00\n -3.6552846e-02 -2.2297132e-01  5.2443361e-01\
          \ -2.9670966e-01\n -7.3776484e-02 -8.1447244e-02  3.7350923e-01 -2.4230444e-01\n\
          \  1.2805557e-01 -3.5493219e-01  3.6119890e-01 -4.3090338e-01\n -3.2855636e-01\
          \ -3.1500000e+02 -2.0444608e-01 -4.2763269e-01]"
    num_agent_steps_sampled: 432000
    num_agent_steps_trained: 5172048
    num_steps_sampled: 432000
    num_steps_trained: 5172048
    num_target_updates: 856
  iterations_since_restore: 432
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.215
    ram_util_percent: 32.404999999999994
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 5996.132986068726
  time_this_iter_s: 13.671261310577393
  time_total_s: 5996.132986068726
  timers:
    learn_throughput: 4881.153
    learn_time_ms: 9.834
    update_time_ms: 2.884
  timestamp: 1629286783
  timesteps_since_restore: 0
  timesteps_total: 432000
  training_iteration: 432
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    432 |          5996.13 | 432000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 433000
  custom_metrics: {}
  date: 2021-08-18_11-39-58
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 432928
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 9.71056842803955
          max_q: 7253810.0
          mean_q: 302241.59375
          mean_td_error: -42.314453125
          min_q: -2.9212589263916016
        model: {}
        td_error: "[ 5.3069603e-01  7.0572138e-02  7.2426707e-01 -4.6184391e-01\n  4.4955599e-01\
          \  3.7663579e-01 -4.5003617e-01  2.7326488e-01\n  4.9905837e-02 -1.6162866e-01\
          \  1.7791033e-02  1.4754605e-01\n -2.4647215e-01  1.9560266e-01 -7.5940907e-02\
          \ -7.7266914e-01\n -3.3799005e-01  1.2751579e-02 -4.9630454e-01  1.1780124e+00\n\
          \ -1.3726354e-01  1.9716346e-01  2.0452690e-01 -9.0540409e-02\n  3.6187363e-01\
          \ -8.7015808e-01 -4.3551743e-01  4.4293046e-01\n  7.1948767e-02 -1.6144782e-01\
          \ -1.0155000e+03  7.6416731e-02\n -1.0155000e+03 -5.6350112e-02 -5.0188458e-01\
          \ -1.0955608e+00\n  9.3136311e-02 -3.4757423e-01  3.7392282e-01  3.3561105e-01\n\
          \  6.2701410e-01 -1.1535311e-01  1.1218071e-01 -1.7474604e-01\n -3.0756903e-01\
          \ -4.3922651e-01 -2.8406811e-01  1.0031331e+00]"
    num_agent_steps_sampled: 433000
    num_agent_steps_trained: 5184048
    num_steps_sampled: 433000
    num_steps_trained: 5184048
    num_target_updates: 858
  iterations_since_restore: 433
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.77
    ram_util_percent: 32.39999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6009.943982362747
  time_this_iter_s: 13.810996294021606
  time_total_s: 6009.943982362747
  timers:
    learn_throughput: 4769.19
    learn_time_ms: 10.065
    update_time_ms: 3.243
  timestamp: 1629286798
  timesteps_since_restore: 0
  timesteps_total: 433000
  training_iteration: 433
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    433 |          6009.94 | 433000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 434000
  custom_metrics: {}
  date: 2021-08-18_11-40-14
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 433936
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 16.347383499145508
          max_q: 7257465.5
          mean_q: 302394.28125
          mean_td_error: 109.83000183105469
          min_q: -2.248438596725464
        model: {}
        td_error: "[ 1.93595886e-02  2.63950000e+03 -1.23774886e-01 -8.96925211e-01\n\
          \  4.91959214e-01 -2.18156576e-02 -1.08981311e-01 -2.87786484e-01\n  3.29290628e-01\
          \  2.18520045e-01 -3.37786007e+00 -6.15184069e-01\n  2.63950000e+03 -2.32528269e-01\
          \ -7.02611923e-01 -2.65205085e-01\n  1.47659183e-01 -1.39685535e+00  4.90896940e-01\
          \  2.75210440e-01\n -4.60860670e-01  5.07215321e-01 -7.84468651e-01 -4.09657776e-01\n\
          \  2.09081173e-01 -3.39981794e-01  3.22355330e-01  5.21100044e-01\n -8.45433176e-02\
          \ -5.57173967e-01 -8.78119767e-01 -3.01091909e-01\n -9.49464321e-01  2.19136357e-01\
          \  9.91968513e-02  2.73379683e-01\n  9.95572090e-01  3.85656834e-01  1.89445674e-01\
          \ -4.37536478e-01\n  1.70697808e-01 -1.97694898e-01  9.70730782e-02 -1.30134583e-01\n\
          \  2.32356668e-01  2.17132747e-01 -1.93043947e-02  6.79349899e-03]"
    num_agent_steps_sampled: 434000
    num_agent_steps_trained: 5196048
    num_steps_sampled: 434000
    num_steps_trained: 5196048
    num_target_updates: 860
  iterations_since_restore: 434
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.13333333333334
    ram_util_percent: 32.4625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6025.753690242767
  time_this_iter_s: 15.809707880020142
  time_total_s: 6025.753690242767
  timers:
    learn_throughput: 4905.714
    learn_time_ms: 9.785
    update_time_ms: 2.779
  timestamp: 1629286814
  timesteps_since_restore: 0
  timesteps_total: 434000
  training_iteration: 434
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    434 |          6025.75 | 434000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 435000
  custom_metrics: {}
  date: 2021-08-18_11-40-30
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 434944
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.12590348720550537
          max_q: 6.535858631134033
          mean_q: -0.760748028755188
          mean_td_error: -0.1592944860458374
          min_q: -3.4226245880126953
        model: {}
        td_error: "[-0.1906609  -0.34761858  0.69014037 -0.30209613 -1.3959378  -0.5049623\n\
          \ -0.00279474  0.45292896 -0.2002846   0.02438688  0.67041487  1.1044624\n\
          \  0.22583246 -0.47486556 -0.12300777 -0.06764409 -0.2377851  -0.40131643\n\
          \ -0.11081886 -0.05957893 -0.3505625  -0.26278234  0.5132618  -0.11793709\n\
          \ -0.2757293  -0.06136608 -0.77220273 -1.3051641  -0.28811836  0.04090595\n\
          \ -0.16038254 -0.61200273  0.19612944 -0.5493293  -0.15239823 -0.88049483\n\
          \  0.0453428  -0.09043264 -0.34814084  0.5726409   0.03849113  0.14354599\n\
          \ -0.24644113  0.14870381 -0.2957126  -0.948913   -0.24237967 -0.13346124]"
    num_agent_steps_sampled: 435000
    num_agent_steps_trained: 5208048
    num_steps_sampled: 435000
    num_steps_trained: 5208048
    num_target_updates: 862
  iterations_since_restore: 435
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.100000000000016
    ram_util_percent: 32.50454545454546
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6040.806673288345
  time_this_iter_s: 15.052983045578003
  time_total_s: 6040.806673288345
  timers:
    learn_throughput: 4870.196
    learn_time_ms: 9.856
    update_time_ms: 3.045
  timestamp: 1629286830
  timesteps_since_restore: 0
  timesteps_total: 435000
  training_iteration: 435
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    435 |          6040.81 | 435000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 436000
  custom_metrics: {}
  date: 2021-08-18_11-40-46
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 435952
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1674930304288864
          max_q: 7.941582202911377
          mean_q: 0.2953433394432068
          mean_td_error: 0.10864344239234924
          min_q: -3.503404378890991
        model: {}
        td_error: "[ 0.1400708   0.40708232  0.07064158 -0.54968333  0.1473012   0.03735697\n\
          \  2.231316    0.48321605 -0.07122785  0.16247118 -0.18836237  1.0043006\n\
          \ -1.2838492   0.51956606  0.9033777  -0.38863224  0.16663843  0.41423553\n\
          \  0.6677061  -0.32630348 -0.41536212  0.22885132 -0.19590163  0.6841188\n\
          \  0.5593035   0.1975652   0.7548203   0.05668068  1.4266174  -0.17702955\n\
          \ -1.3865819  -1.0632045   0.00594056 -0.18153334  0.0312705   0.33782956\n\
          \ -0.17355204 -0.07561398  0.02121329  0.11055315 -0.2704082  -0.60958743\n\
          \  0.20500708  0.80984044  0.3278777  -0.6879798   0.0284462   0.11848235]"
    num_agent_steps_sampled: 436000
    num_agent_steps_trained: 5220048
    num_steps_sampled: 436000
    num_steps_trained: 5220048
    num_target_updates: 864
  iterations_since_restore: 436
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.02083333333333
    ram_util_percent: 32.50833333333333
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6057.242254257202
  time_this_iter_s: 16.43558096885681
  time_total_s: 6057.242254257202
  timers:
    learn_throughput: 4796.665
    learn_time_ms: 10.007
    update_time_ms: 2.898
  timestamp: 1629286846
  timesteps_since_restore: 0
  timesteps_total: 436000
  training_iteration: 436
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    436 |          6057.24 | 436000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 437000
  custom_metrics: {}
  date: 2021-08-18_11-41-04
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 436960
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08458861708641052
          max_q: 9.37643051147461
          mean_q: -0.44289112091064453
          mean_td_error: 0.061468057334423065
          min_q: -4.661707878112793
        model: {}
        td_error: "[-1.3056061   0.1637708   0.44539618  0.13846587 -0.17075655 -0.1284914\n\
          \  0.43913627  0.5543232  -0.0110811  -0.5080104  -0.07155299  0.7765112\n\
          \ -0.27619684  0.03075708  0.45121908 -0.7852402   0.16441274  0.6278424\n\
          \  0.19374084 -0.08089483 -0.05147839  0.59007484  0.3035426  -0.32897586\n\
          \  0.18732035  0.5323297  -0.04243219 -0.16871226  0.30816543 -0.24743783\n\
          \  0.30816543 -0.17498207 -0.45391387 -0.777423    0.26596665  0.22613502\n\
          \ -0.0815216  -0.26968306  0.05804682  0.92455447  0.04191935  0.14274561\n\
          \  0.79444325 -0.06862795 -0.4234903   0.14714646  1.0421991  -0.48135522]"
    num_agent_steps_sampled: 437000
    num_agent_steps_trained: 5232048
    num_steps_sampled: 437000
    num_steps_trained: 5232048
    num_target_updates: 866
  iterations_since_restore: 437
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.584
    ram_util_percent: 32.588
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6074.196032524109
  time_this_iter_s: 16.95377826690674
  time_total_s: 6074.196032524109
  timers:
    learn_throughput: 4752.966
    learn_time_ms: 10.099
    update_time_ms: 3.034
  timestamp: 1629286864
  timesteps_since_restore: 0
  timesteps_total: 437000
  training_iteration: 437
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    437 |           6074.2 | 437000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 438000
  custom_metrics: {}
  date: 2021-08-18_11-41-22
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 437968
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08864807337522507
          max_q: 9.537873268127441
          mean_q: -0.041175585240125656
          mean_td_error: -0.08085186779499054
          min_q: -1.8135851621627808
        model: {}
        td_error: "[-1.4956379e-01  1.2238255e-01 -9.5530564e-01 -3.1336093e-01\n -7.6364875e-03\
          \ -2.0131704e-01  6.9944072e-01 -1.6239026e-01\n  1.0181916e-01 -5.7594538e-01\
          \  3.4308594e-01  8.9146793e-02\n  4.3833137e-01  2.4315238e-02 -8.5079432e-02\
          \ -1.4113140e-01\n -7.1319282e-02 -1.5307763e-01 -1.5004635e-02  9.1227531e-02\n\
          \ -1.6764443e-01 -2.8520441e-01 -3.4119868e-01 -5.9877497e-01\n -2.9818535e-02\
          \ -5.5357331e-01 -8.4934658e-01  6.0348296e-01\n  1.8167245e-01  2.5665820e-01\
          \  6.7873609e-01  5.0078750e-02\n -2.0857048e-01  2.1181250e-01 -8.5181236e-02\
          \ -1.8876731e-01\n -5.7859242e-02  2.8964221e-01  3.9468783e-01  1.5536106e-01\n\
          \ -1.0355926e+00 -8.3414006e-01 -7.0205009e-01  4.6601176e-01\n  1.9931793e-04\
          \ -1.4475220e-01  6.4007902e-01 -8.0545521e-01]"
    num_agent_steps_sampled: 438000
    num_agent_steps_trained: 5244048
    num_steps_sampled: 438000
    num_steps_trained: 5244048
    num_target_updates: 868
  iterations_since_restore: 438
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.65384615384615
    ram_util_percent: 32.60769230769232
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6092.153357505798
  time_this_iter_s: 17.957324981689453
  time_total_s: 6092.153357505798
  timers:
    learn_throughput: 4913.545
    learn_time_ms: 9.769
    update_time_ms: 3.022
  timestamp: 1629286882
  timesteps_since_restore: 0
  timesteps_total: 438000
  training_iteration: 438
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    438 |          6092.15 | 438000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 439000
  custom_metrics: {}
  date: 2021-08-18_11-41-42
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 438976
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.12515251338481903
          max_q: 8.995279312133789
          mean_q: -0.326952189207077
          mean_td_error: -0.12664248049259186
          min_q: -2.283155918121338
        model: {}
        td_error: "[-0.5402453  -0.33123016 -0.86781394 -0.14816105  0.01181066 -0.07542074\n\
          \  0.07772231 -0.42868727 -0.58279836  0.03823495 -0.5453753  -0.02635193\n\
          \  0.06433833 -0.45582664 -0.07866353 -0.7113661   0.09738448  0.20630765\n\
          \  0.40698886 -0.4680556   0.01117355  0.17966455  0.10890627  0.4451246\n\
          \ -0.07589221 -0.03629482  0.14008904 -0.05952901 -0.6498995  -0.55419964\n\
          \ -0.97090805  0.21739876  0.08154136 -0.08667243 -0.26860297 -0.96080565\n\
          \ -0.5477015   0.12391508  0.16238773 -0.02816367  0.09437275  0.35627955\n\
          \  0.4013542  -0.01910114  1.0876541  -0.05348873 -1.0108039   0.19057155]"
    num_agent_steps_sampled: 439000
    num_agent_steps_trained: 5256048
    num_steps_sampled: 439000
    num_steps_trained: 5256048
    num_target_updates: 870
  iterations_since_restore: 439
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.457142857142856
    ram_util_percent: 32.66785714285715
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6111.394154071808
  time_this_iter_s: 19.24079656600952
  time_total_s: 6111.394154071808
  timers:
    learn_throughput: 4886.722
    learn_time_ms: 9.823
    update_time_ms: 3.092
  timestamp: 1629286902
  timesteps_since_restore: 0
  timesteps_total: 439000
  training_iteration: 439
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    439 |          6111.39 | 439000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 440000
  custom_metrics: {}
  date: 2021-08-18_11-42-01
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 439984
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.11417675763368607
          max_q: 11.764025688171387
          mean_q: 0.07494151592254639
          mean_td_error: -0.13290102779865265
          min_q: -3.1506965160369873
        model: {}
        td_error: "[-1.3437326   0.8130735   0.24221802  0.1934514  -0.42041504  0.06171858\n\
          \ -1.2294054   0.43705297  0.02133644 -0.186064   -0.24412262 -0.9390869\n\
          \ -0.13633901  0.55135685 -0.20128226 -0.25346804 -0.02767158 -0.682197\n\
          \ -0.45765066 -0.60550165 -0.05619907 -0.18259925 -0.11631656 -0.03006601\n\
          \  0.47318995 -1.1670458   0.10675383  0.9041256  -0.12422192 -0.33700505\n\
          \  0.955781   -0.18662697 -0.18261337 -0.2408995  -0.08418643 -0.60774004\n\
          \  0.29422843 -0.58946514 -0.39901376  0.18555903  0.0739699   0.02689362\n\
          \ -0.0600695  -0.07168043  0.33493388 -0.62701225  0.20548964 -0.47068375]"
    num_agent_steps_sampled: 440000
    num_agent_steps_trained: 5268048
    num_steps_sampled: 440000
    num_steps_trained: 5268048
    num_target_updates: 872
  iterations_since_restore: 440
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.89259259259258
    ram_util_percent: 32.711111111111116
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6130.298013210297
  time_this_iter_s: 18.90385913848877
  time_total_s: 6130.298013210297
  timers:
    learn_throughput: 4770.558
    learn_time_ms: 10.062
    update_time_ms: 3.0
  timestamp: 1629286921
  timesteps_since_restore: 0
  timesteps_total: 440000
  training_iteration: 440
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    440 |           6130.3 | 440000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 441000
  custom_metrics: {}
  date: 2021-08-18_11-42-21
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 440992
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1012776792049408
          max_q: 7.745028495788574
          mean_q: 0.04437863081693649
          mean_td_error: 0.02027839981019497
          min_q: -3.691701889038086
        model: {}
        td_error: "[ 0.07743365  0.23857671  0.5013838  -0.06204891  0.0926882  -0.1740942\n\
          \  0.03160143 -1.0466034  -0.6312866   0.63025093  0.15789604  0.06840885\n\
          \ -0.8076934   0.11763711  0.29936123  0.25130177  0.19893861 -0.75423056\n\
          \ -0.1755073   0.5124498   0.39126134  0.16942155 -0.18597049  0.3406992\n\
          \  0.16381776 -0.05632091  0.73678654  0.12624443  0.01533622 -0.98472273\n\
          \  0.8294748   1.0382982  -0.27768102  0.13121152  0.42007685 -0.22551534\n\
          \  0.60652065 -0.2718893   0.96070975 -1.2002482   0.6140861  -0.3241024\n\
          \ -0.5469403  -1.0323169   0.07204026  0.41649866 -0.26660162 -0.21327507]"
    num_agent_steps_sampled: 441000
    num_agent_steps_trained: 5280048
    num_steps_sampled: 441000
    num_steps_trained: 5280048
    num_target_updates: 874
  iterations_since_restore: 441
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.30714285714286
    ram_util_percent: 32.80357142857142
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6149.298765659332
  time_this_iter_s: 19.000752449035645
  time_total_s: 6149.298765659332
  timers:
    learn_throughput: 4828.844
    learn_time_ms: 9.94
    update_time_ms: 2.866
  timestamp: 1629286941
  timesteps_since_restore: 0
  timesteps_total: 441000
  training_iteration: 441
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    441 |           6149.3 | 441000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 442000
  custom_metrics: {}
  date: 2021-08-18_11-42-42
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 442000
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10937530547380447
          max_q: 7.933322906494141
          mean_q: 0.23431605100631714
          mean_td_error: -0.1450646072626114
          min_q: -2.3362252712249756
        model: {}
        td_error: "[-5.67795396e-01  3.01563740e-03 -5.20162404e-01  4.42222357e-02\n\
          \  6.43826723e-02 -8.83012414e-02 -4.44544077e-01 -3.35410357e-01\n  1.68105602e-01\
          \ -1.59932518e+00  1.26475930e-01 -1.54488087e-02\n -5.65087795e-02  1.10167265e-01\
          \ -5.32326698e-01  3.00755739e-01\n -2.65052617e-02  1.39683247e-01 -1.10382438e+00\
          \ -1.48941374e+00\n -3.70909274e-01 -3.63623548e+00 -1.51720083e+00  2.61748433e-01\n\
          \  7.36957192e-02  6.22725844e-01 -1.14102125e-01  8.21035385e-01\n  2.97370148e+00\
          \  5.58250606e-01  4.80299294e-02  6.53223455e-01\n  7.52574205e-02 -4.16272640e-01\
          \ -2.13859081e-01  9.95659232e-02\n  4.83013868e-01  1.66764796e-01 -2.93414831e-01\
          \ -8.09460878e-02\n -2.16153812e+00  7.22049475e-02  9.48168039e-02 -3.92712802e-01\n\
          \  4.72658157e-01  3.88362110e-01  3.87062550e-01 -1.95269585e-01]"
    num_agent_steps_sampled: 442000
    num_agent_steps_trained: 5292048
    num_steps_sampled: 442000
    num_steps_trained: 5292048
    num_target_updates: 876
  iterations_since_restore: 442
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.13548387096774
    ram_util_percent: 32.80645161290321
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6170.36758351326
  time_this_iter_s: 21.068817853927612
  time_total_s: 6170.36758351326
  timers:
    learn_throughput: 4489.318
    learn_time_ms: 10.692
    update_time_ms: 3.192
  timestamp: 1629286962
  timesteps_since_restore: 0
  timesteps_total: 442000
  training_iteration: 442
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    442 |          6170.37 | 442000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 443000
  custom_metrics: {}
  date: 2021-08-18_11-43-04
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 442504
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 11.83995246887207
          max_q: 7253403.5
          mean_q: 151112.4375
          mean_td_error: -29.509418487548828
          min_q: -3.5461978912353516
        model: {}
        td_error: "[-2.1318841e-01 -4.8623323e-02  3.4742928e-01 -9.2918968e-01\n  1.7014513e+00\
          \ -1.5633751e+00 -2.6317716e-01  2.2141671e-01\n  6.2757850e-02 -1.4230000e+03\
          \ -8.9690924e-02  3.0275536e-01\n  1.2289870e-01  1.8507254e-01 -2.9975414e-02\
          \  1.8986001e+00\n  4.5542026e-01  2.3377120e-02  8.2173842e-01  3.7628257e-01\n\
          \  1.4370406e-01  6.6828555e-01 -5.5522478e-01 -2.0876655e-01\n  6.3717151e-01\
          \ -3.2500631e-01  7.9294634e-01  5.0613165e-02\n -1.0858059e-02  1.9666862e-01\
          \  3.9834976e-01  1.6048253e-01\n -1.7993468e-01  5.1186800e-02 -5.9911501e-01\
          \ -5.8195923e-02\n -3.5853982e-02  2.5295210e-01 -2.7174091e-01 -2.4062061e-01\n\
          \  6.1697447e-01  9.8605275e-01  4.2974877e-01  3.0764341e-03\n  8.4450722e-02\
          \ -9.4787061e-02  1.9077015e-01  8.2716197e-02]"
    num_agent_steps_sampled: 443000
    num_agent_steps_trained: 5304048
    num_steps_sampled: 443000
    num_steps_trained: 5304048
    num_target_updates: 877
  iterations_since_restore: 443
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.874193548387105
    ram_util_percent: 32.90322580645161
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6191.8237063884735
  time_this_iter_s: 21.456122875213623
  time_total_s: 6191.8237063884735
  timers:
    learn_throughput: 4724.734
    learn_time_ms: 10.159
    update_time_ms: 2.93
  timestamp: 1629286984
  timesteps_since_restore: 0
  timesteps_total: 443000
  training_iteration: 443
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    443 |          6191.82 | 443000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 444000
  custom_metrics: {}
  date: 2021-08-18_11-43-29
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 443512
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.12703342735767365
          max_q: 7.652670860290527
          mean_q: -0.46274539828300476
          mean_td_error: -0.11582441627979279
          min_q: -1.818769097328186
        model: {}
        td_error: "[ 7.1730089e-01 -4.9468696e-01 -1.1435251e+00 -4.4084519e-01\n  1.1730003e-01\
          \ -4.2390209e-01  3.4266776e-01 -1.2475960e+00\n -3.0155075e-01  1.9417897e+00\
          \ -8.8234288e-01 -1.5863180e-02\n  2.6853925e-01 -3.3177626e-01 -2.0120978e-02\
          \  2.3229098e-01\n -3.3196495e+00  2.0718193e-01  2.7200520e-01  2.3674536e-01\n\
          \  9.9596226e-01 -1.6465786e-01  6.5333104e-01  1.1600360e+00\n  2.7521253e-03\
          \  3.7707853e-01 -3.5426683e+00  6.2484366e-01\n  2.0148981e-01 -1.5304470e-01\
          \ -8.6761981e-02  5.2082729e-01\n -2.1403581e-01 -4.0836215e-02  1.6277277e-01\
          \  1.5510345e-01\n -6.4672875e-01 -1.6032642e-01 -6.2126100e-02  3.8318706e-01\n\
          \  2.4668014e-01 -2.7531177e-01  6.0351646e-01 -5.9365010e-01\n -3.4454244e-01\
          \ -3.7313807e-01 -1.7443717e-01 -5.2884877e-01]"
    num_agent_steps_sampled: 444000
    num_agent_steps_trained: 5316048
    num_steps_sampled: 444000
    num_steps_trained: 5316048
    num_target_updates: 879
  iterations_since_restore: 444
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.09444444444445
    ram_util_percent: 32.952777777777776
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6216.656308889389
  time_this_iter_s: 24.832602500915527
  time_total_s: 6216.656308889389
  timers:
    learn_throughput: 4750.812
    learn_time_ms: 10.104
    update_time_ms: 3.018
  timestamp: 1629287009
  timesteps_since_restore: 0
  timesteps_total: 444000
  training_iteration: 444
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    444 |          6216.66 | 444000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 445000
  custom_metrics: {}
  date: 2021-08-18_11-43-54
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 444520
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06002160534262657
          max_q: 3.533963203430176
          mean_q: -0.5631258487701416
          mean_td_error: 0.0643550381064415
          min_q: -3.168170928955078
        model: {}
        td_error: "[-2.62843966e-01 -6.04289174e-01 -9.54337120e-02  5.11364222e-01\n\
          \  1.66158289e-01 -1.69956923e-01  6.78360462e-02 -3.22717428e-02\n -8.92981887e-04\
          \  1.13512278e-02  2.74789906e+00  5.29675484e-01\n  3.55438590e-02 -7.88842440e-02\
          \  3.80373001e-03  5.51659584e-01\n  6.72078967e-01 -1.37114525e-01 -1.90817803e-01\
          \  9.76900399e-01\n -7.25935698e-01 -8.67312670e-01 -6.07855916e-02 -1.76755190e-02\n\
          \  2.72900939e-01  4.11997974e-01 -3.47862244e-02 -1.15490723e+00\n  4.71237779e-01\
          \ -2.02687383e-02  1.03993940e+00 -8.57874155e-01\n -9.02843475e-03  2.74702549e-01\
          \ -3.36058915e-01 -1.63423896e-01\n  3.67487192e-01  2.04269260e-01  2.43441820e-01\
          \  1.25568151e-01\n  1.85495377e-01 -9.84725714e-01 -2.95344353e-01 -6.62224889e-01\n\
          \  5.48300207e-01  1.12152666e-01 -1.61633492e-01  4.81767654e-01]"
    num_agent_steps_sampled: 445000
    num_agent_steps_trained: 5328048
    num_steps_sampled: 445000
    num_steps_trained: 5328048
    num_target_updates: 881
  iterations_since_restore: 445
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.480000000000004
    ram_util_percent: 33.00285714285714
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6240.771949768066
  time_this_iter_s: 24.115640878677368
  time_total_s: 6240.771949768066
  timers:
    learn_throughput: 4781.389
    learn_time_ms: 10.039
    update_time_ms: 3.053
  timestamp: 1629287034
  timesteps_since_restore: 0
  timesteps_total: 445000
  training_iteration: 445
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    445 |          6240.77 | 445000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 446000
  custom_metrics: {}
  date: 2021-08-18_11-44-20
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 445528
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1272844821214676
          max_q: 4.247025966644287
          mean_q: -0.550091028213501
          mean_td_error: 0.19126532971858978
          min_q: -2.045656442642212
        model: {}
        td_error: "[-1.1023457   0.28932512  1.2269168   0.59125    -0.2923916  -0.8016447\n\
          \  1.7965653   0.6520127  -1.2767949   0.5239094   3.9153087   0.08615983\n\
          \  0.3675022   0.6289363   0.04533124  0.01057243  0.96449226  0.3276525\n\
          \ -0.18938422  0.7657007  -0.33449405 -1.6659684  -0.56855166  1.8389807\n\
          \  0.08633653  0.63940996  0.18283117  0.08261009 -0.06076604 -0.1141817\n\
          \ -0.05438302  1.5942957  -0.57828766 -0.77919996  0.6172215   1.2124412\n\
          \ -0.05260456 -0.12863469  0.08182228 -0.28123385 -1.140039   -0.08560038\n\
          \  0.5846739   0.10373569  0.05539709 -0.3368199  -0.7361538   0.48882326]"
    num_agent_steps_sampled: 446000
    num_agent_steps_trained: 5340048
    num_steps_sampled: 446000
    num_steps_trained: 5340048
    num_target_updates: 883
  iterations_since_restore: 446
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.81351351351351
    ram_util_percent: 33.02162162162161
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6266.066214084625
  time_this_iter_s: 25.294264316558838
  time_total_s: 6266.066214084625
  timers:
    learn_throughput: 4736.539
    learn_time_ms: 10.134
    update_time_ms: 3.028
  timestamp: 1629287060
  timesteps_since_restore: 0
  timesteps_total: 446000
  training_iteration: 446
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    446 |          6266.07 | 446000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 447000
  custom_metrics: {}
  date: 2021-08-18_11-44-46
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 446536
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.12251824140548706
          max_q: 5.3924336433410645
          mean_q: -0.28385692834854126
          mean_td_error: 0.021362897008657455
          min_q: -3.919985294342041
        model: {}
        td_error: "[-6.16474628e-01 -1.92759812e-01 -7.60545850e-01  4.92132902e-01\n\
          \  4.96032238e-01  7.76005983e-02 -5.99750757e-01  2.52760470e-01\n  2.46348590e-01\
          \ -4.18023527e-01  6.16592526e-01 -3.24954391e-02\n  5.26349425e-01 -1.24696016e-01\
          \  2.99737513e-01  1.79885864e-01\n  8.45089197e-01 -6.05258465e+00  5.24949491e-01\
          \  2.84604847e-01\n  1.78852677e-01  9.37424898e-02 -3.27480674e-01  2.75832355e-01\n\
          \  7.05605030e-01 -8.39482248e-02 -8.79452229e-01 -2.80224085e-02\n  1.37946665e+00\
          \  8.97030056e-01  2.03083277e-01 -1.20254993e-01\n -1.25584698e+00 -1.65550232e-01\
          \  2.55788207e-01  1.24754310e-01\n  4.72146630e-01  7.48208165e-02 -1.03081465e-01\
          \  5.83368123e-01\n -1.10005379e-01  5.28502464e-03  1.82472169e-01  2.31687635e-01\n\
          \  5.83914518e-01  1.83332860e+00  4.76318240e-01 -5.03187656e-01]"
    num_agent_steps_sampled: 447000
    num_agent_steps_trained: 5352048
    num_steps_sampled: 447000
    num_steps_trained: 5352048
    num_target_updates: 885
  iterations_since_restore: 447
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.5263157894737
    ram_util_percent: 33.10263157894736
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6292.0255699157715
  time_this_iter_s: 25.95935583114624
  time_total_s: 6292.0255699157715
  timers:
    learn_throughput: 4715.185
    learn_time_ms: 10.18
    update_time_ms: 3.177
  timestamp: 1629287086
  timesteps_since_restore: 0
  timesteps_total: 447000
  training_iteration: 447
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    447 |          6292.03 | 447000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 448000
  custom_metrics: {}
  date: 2021-08-18_11-45-13
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 447544
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08598857372999191
          max_q: 3.6532349586486816
          mean_q: -0.4716382622718811
          mean_td_error: 0.014854232780635357
          min_q: -3.05234956741333
        model: {}
        td_error: "[ 3.2750052e-01  8.5020161e-01  4.9889767e-01  5.1871026e-01\n  9.4574988e-01\
          \ -5.7947516e-02  3.8933447e-01  3.3197165e-01\n  2.6243985e-01 -4.1959870e-01\
          \ -8.9756429e-01 -7.3733374e-02\n  2.2315019e-01 -7.3047447e-01 -1.4610025e+00\
          \  2.5182962e-02\n  3.4954429e-01  2.9005623e-01 -9.4273210e-02  3.5608816e-01\n\
          \ -3.5376981e-01 -4.5152760e-01 -1.1167002e-01  3.0658141e-01\n -8.7925696e-01\
          \ -8.2167530e-01  3.9093614e-02 -2.1790135e-01\n -4.7525775e-01 -2.7301264e+00\
          \ -5.4761469e-02  3.4639388e-03\n  2.3132596e+00  4.1475523e-01 -5.5340624e-01\
          \ -5.7444435e-01\n  4.4705999e-01 -1.4214379e-01 -3.4478939e-01  1.1625791e+00\n\
          \ -3.5919157e-01 -2.4412717e-01 -1.7767334e-01 -1.4795840e-02\n -1.9574165e-04\
          \  1.7114754e+00  1.0240459e+00  1.6316938e-01]"
    num_agent_steps_sampled: 448000
    num_agent_steps_trained: 5364048
    num_steps_sampled: 448000
    num_steps_trained: 5364048
    num_target_updates: 887
  iterations_since_restore: 448
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 58.92162162162163
    ram_util_percent: 33.10540540540539
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6317.766290187836
  time_this_iter_s: 25.74072027206421
  time_total_s: 6317.766290187836
  timers:
    learn_throughput: 4743.749
    learn_time_ms: 10.119
    update_time_ms: 3.034
  timestamp: 1629287113
  timesteps_since_restore: 0
  timesteps_total: 448000
  training_iteration: 448
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    448 |          6317.77 | 448000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 449000
  custom_metrics: {}
  date: 2021-08-18_11-45-39
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 448552
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.278718948364258
          max_q: 7257277.0
          mean_q: 151192.96875
          mean_td_error: 51.14809799194336
          min_q: -2.6751208305358887
        model: {}
        td_error: "[-6.61150157e-01  4.31054831e-01  5.07433116e-01  1.74557567e-01\n\
          \  4.05009687e-01 -2.35066414e-02  2.31258035e-01 -1.01545501e+00\n -5.11704385e-01\
          \  1.83748960e-01 -3.04314971e-01  2.45050000e+03\n -4.93927091e-01  3.35573912e-01\
          \  2.07073212e-01 -8.96307707e-01\n  4.84484196e-01  6.24934614e-01 -2.92076707e-01\
          \ -5.77226043e-01\n  6.75616264e-02  1.21991336e-01  9.42163229e-01  4.19241667e-01\n\
          \  3.98432016e-02  7.89341927e-01  8.87331963e-02  5.92508793e-01\n  1.99385083e+00\
          \  4.23975110e-01 -8.97409916e-02  1.23503864e-01\n  6.07645273e-01 -1.29682481e-01\
          \  4.45490003e-01  3.62697959e-01\n -4.96554613e-01  1.19293773e+00 -1.99492216e-01\
          \  4.42754626e-02\n  1.20585561e-02 -7.51662254e-01 -8.06100845e-01 -1.57608390e-02\n\
          \ -1.51479006e-01  5.58100700e-01 -2.87501097e-01 -9.87839103e-02]"
    num_agent_steps_sampled: 449000
    num_agent_steps_trained: 5376048
    num_steps_sampled: 449000
    num_steps_trained: 5376048
    num_target_updates: 889
  iterations_since_restore: 449
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.69473684210528
    ram_util_percent: 33.181578947368436
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6343.968009233475
  time_this_iter_s: 26.201719045639038
  time_total_s: 6343.968009233475
  timers:
    learn_throughput: 4445.169
    learn_time_ms: 10.798
    update_time_ms: 3.024
  timestamp: 1629287139
  timesteps_since_restore: 0
  timesteps_total: 449000
  training_iteration: 449
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    449 |          6343.97 | 449000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 450000
  custom_metrics: {}
  date: 2021-08-18_11-46-07
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 449560
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10171210020780563
          max_q: 1.807829737663269
          mean_q: -0.5980135202407837
          mean_td_error: -0.0425436794757843
          min_q: -2.0265722274780273
        model: {}
        td_error: "[ 0.29724824  0.06396294 -0.25340354  0.54020435 -0.70194983  0.1520049\n\
          \ -0.22713032 -0.02268285 -0.5911501   0.30223873  0.08655143 -0.67509246\n\
          \  1.206388    0.930466    0.01634908  0.39051855  0.14064169  0.46099925\n\
          \ -1.3875372   0.5367652   0.18642092 -0.33456045 -0.09985811  0.29883814\n\
          \ -0.10396308 -0.9997652  -1.0526924   0.6746547  -2.513548   -0.10021473\n\
          \  0.02793336  0.0805369   0.36823034 -0.02922809  0.50952387  0.07330966\n\
          \ -0.08181679  0.6434011   0.529118   -0.07598734 -0.02772576  0.33694863\n\
          \ -0.5907444  -0.29587388 -0.52614105  0.22281432 -0.18929619 -0.23780298]"
    num_agent_steps_sampled: 450000
    num_agent_steps_trained: 5388048
    num_steps_sampled: 450000
    num_steps_trained: 5388048
    num_target_updates: 891
  iterations_since_restore: 450
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.37948717948717
    ram_util_percent: 33.20256410256411
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6371.062313556671
  time_this_iter_s: 27.09430432319641
  time_total_s: 6371.062313556671
  timers:
    learn_throughput: 4789.157
    learn_time_ms: 10.023
    update_time_ms: 3.048
  timestamp: 1629287167
  timesteps_since_restore: 0
  timesteps_total: 450000
  training_iteration: 450
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    450 |          6371.06 | 450000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 451000
  custom_metrics: {}
  date: 2021-08-18_11-46-36
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 450568
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.83207893371582
          max_q: 7254796.0
          mean_q: 151141.65625
          mean_td_error: -0.7645919322967529
          min_q: -1.2389464378356934
        model: {}
        td_error: "[-1.3070846e-01  3.1273770e-01 -2.4709445e-01  2.5718212e-01\n  6.2574625e-02\
          \  1.5216196e-01 -1.6584978e+00  2.3995638e-01\n -5.1295948e-01 -9.7438002e-01\
          \ -4.0442324e-01 -2.0460135e-01\n  7.9526353e-01 -3.2284606e-01 -1.0638542e+00\
          \  7.9191524e-01\n -1.8660951e-01 -8.0558300e-01  1.4953679e-01  1.4551644e+00\n\
          \  5.0162399e-01  2.1999872e-01  4.8622715e-01 -2.3738235e-01\n -3.0000000e+01\
          \  1.9177973e-02 -8.6486280e-01 -1.0974883e+00\n -1.9339496e-01  6.8925071e-01\
          \  3.4236157e-01 -3.5374409e-01\n -1.6606367e-01 -2.8391272e-01  4.2092979e-02\
          \ -4.4731247e-01\n -1.5101734e-01  5.5368960e-02 -3.5566494e-01  2.2280610e-01\n\
          \ -6.1994171e-01 -1.3465519e+00 -7.5318575e-02 -4.0910923e-01\n -8.3618701e-01\
          \  8.1123984e-01 -6.7197156e-01  3.1442392e-01]"
    num_agent_steps_sampled: 451000
    num_agent_steps_trained: 5400048
    num_steps_sampled: 451000
    num_steps_trained: 5400048
    num_target_updates: 893
  iterations_since_restore: 451
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.900000000000006
    ram_util_percent: 33.20697674418605
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6400.277312517166
  time_this_iter_s: 29.214998960494995
  time_total_s: 6400.277312517166
  timers:
    learn_throughput: 4715.682
    learn_time_ms: 10.179
    update_time_ms: 2.951
  timestamp: 1629287196
  timesteps_since_restore: 0
  timesteps_total: 451000
  training_iteration: 451
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    451 |          6400.28 | 451000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 452000
  custom_metrics: {}
  date: 2021-08-18_11-47-04
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 451576
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.12320472300052643
          max_q: 9.07535171508789
          mean_q: 0.2414524257183075
          mean_td_error: -0.10549177974462509
          min_q: -2.4114131927490234
        model: {}
        td_error: "[-1.303668    0.5854174   0.191436   -1.9177096  -0.5003712   0.32779765\n\
          \ -0.67869246 -0.0642097   0.08780262  0.31925112  0.3373708   0.25480783\n\
          \  0.7655176   0.47903317 -0.18666673 -0.21619093 -1.5334461   0.04147971\n\
          \  0.20066947  0.07234579 -0.6768278   0.5240328  -0.413571    0.6326877\n\
          \  0.11084062 -2.6174328   0.04205966  0.40356803  2.3414824   0.6177794\n\
          \ -0.8179792   0.21281779 -3.915537   -0.05751419  0.28959286 -0.16289341\n\
          \ -0.18056878  0.26283884  0.5018571   0.05778849  0.21877491  0.13087785\n\
          \  1.1735746  -0.1833666   0.5613202  -0.61794424 -1.0030594   0.23922232]"
    num_agent_steps_sampled: 452000
    num_agent_steps_trained: 5412048
    num_steps_sampled: 452000
    num_steps_trained: 5412048
    num_target_updates: 895
  iterations_since_restore: 452
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 58.55749999999999
    ram_util_percent: 33.22500000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6427.840209245682
  time_this_iter_s: 27.562896728515625
  time_total_s: 6427.840209245682
  timers:
    learn_throughput: 4629.805
    learn_time_ms: 10.368
    update_time_ms: 3.035
  timestamp: 1629287224
  timesteps_since_restore: 0
  timesteps_total: 452000
  training_iteration: 452
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    452 |          6427.84 | 452000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 453000
  custom_metrics: {}
  date: 2021-08-18_11-47-35
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 452584
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.15309441089630127
          max_q: 6.655632972717285
          mean_q: -0.4201734960079193
          mean_td_error: -0.14429448544979095
          min_q: -2.0245018005371094
        model: {}
        td_error: "[ 0.20108086 -2.0926042   1.0745239  -0.03218889  0.13318372 -0.6923602\n\
          \ -1.1097213  -0.7343312  -0.40608078 -1.2969737  -0.4297157   2.3579645\n\
          \ -0.24978119 -0.50571513  0.10791308 -0.07463729 -0.01130867  0.2439735\n\
          \  0.27336413 -0.10923028 -0.731982   -0.71726805 -0.6449779   0.11399627\n\
          \  0.1078192  -0.52753824 -0.540151   -0.11221957  0.4382484  -0.41387272\n\
          \  0.1307323   0.33198595  0.27116007 -0.23227549 -0.18672132 -0.283211\n\
          \ -0.32139322  0.24008393 -0.47746938 -0.26018703  0.7058279   0.06457812\n\
          \ -0.06862062 -0.75142795 -0.4352986   0.4534065   0.04893732  0.22434807]"
    num_agent_steps_sampled: 453000
    num_agent_steps_trained: 5424048
    num_steps_sampled: 453000
    num_steps_trained: 5424048
    num_target_updates: 897
  iterations_since_restore: 453
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.59534883720931
    ram_util_percent: 33.295348837209296
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6457.407827615738
  time_this_iter_s: 29.567618370056152
  time_total_s: 6457.407827615738
  timers:
    learn_throughput: 4622.406
    learn_time_ms: 10.384
    update_time_ms: 3.152
  timestamp: 1629287255
  timesteps_since_restore: 0
  timesteps_total: 453000
  training_iteration: 453
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    453 |          6457.41 | 453000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 454000
  custom_metrics: {}
  date: 2021-08-18_11-48-06
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 453592
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06616564840078354
          max_q: 3.0698862075805664
          mean_q: -0.5955344438552856
          mean_td_error: -217625.9375
          min_q: -1.988980770111084
        model: {}
        td_error: "[-6.0532790e-01  1.0196598e+00 -9.1212916e-01 -1.8218160e-03\n  1.3722754e-01\
          \ -3.7112051e-01  2.7757668e-01 -1.5430593e-01\n -4.7391233e-01  4.9901021e-01\
          \ -2.1095151e-01 -1.0340428e-01\n  4.9124026e-01  2.0879111e-01 -1.0074985e+00\
          \ -1.7410070e+06\n -6.1231399e-01 -1.7410070e+06  5.7870746e-02  2.2850239e-01\n\
          \ -1.7410070e+06 -1.9964614e+00  3.5389155e-01  7.7861118e-01\n -3.1111526e-01\
          \  3.5722256e-02  4.9140990e-02 -2.9608011e-03\n -1.7410070e+06  2.0868301e-02\
          \  3.8453615e-01 -1.7410070e+06\n -1.7410070e+06  1.2274833e+00 -4.3995422e-01\
          \  2.5625306e-01\n  1.2038362e-01 -2.4179476e-01  7.3327565e-01 -2.1927137e+00\n\
          \  3.7632406e-01 -3.4272218e-01 -8.6610699e-01 -2.5619382e-01\n  6.4252096e-01\
          \ -4.1960055e-01  8.0415571e-01 -6.9068968e-02]"
    num_agent_steps_sampled: 454000
    num_agent_steps_trained: 5436048
    num_steps_sampled: 454000
    num_steps_trained: 5436048
    num_target_updates: 899
  iterations_since_restore: 454
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.652272727272724
    ram_util_percent: 33.30681818181818
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6487.931835651398
  time_this_iter_s: 30.52400803565979
  time_total_s: 6487.931835651398
  timers:
    learn_throughput: 4744.397
    learn_time_ms: 10.117
    update_time_ms: 3.025
  timestamp: 1629287286
  timesteps_since_restore: 0
  timesteps_total: 454000
  training_iteration: 454
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    454 |          6487.93 | 454000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 455000
  custom_metrics: {}
  date: 2021-08-18_11-48-38
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 454600
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.08841708302497864
          max_q: 8.223804473876953
          mean_q: -0.19956806302070618
          mean_td_error: -350872.0
          min_q: -1.8794399499893188
        model: {}
        td_error: "[-1.8713180e+06 -3.6719704e-01  1.1022302e+00  2.9000813e-01\n  3.3972660e-01\
          \ -1.7314601e-01  8.2555664e-01 -7.7689123e-01\n -2.6460719e-01  4.2074859e-01\
          \ -1.8713180e+06 -6.7960954e-01\n  3.4598267e-01  6.9278252e-01  1.1264675e+00\
          \ -1.8713180e+06\n  1.8746656e-01 -1.8713180e+06 -4.3815744e-01  1.4288169e-01\n\
          \ -1.8713180e+06  3.3303916e-02  3.0777115e-01  3.1544447e-02\n -4.2135251e-01\
          \ -3.3497271e-01  5.9433818e-02  4.8018515e-01\n  3.7863332e-01  1.2679338e-01\
          \  8.1803566e-01 -1.8713180e+06\n  3.7910283e-01 -7.0214903e-01  1.7484707e-01\
          \ -4.1058993e-01\n -1.7867368e-01  2.5535059e-01  1.8933356e-01 -1.8713180e+06\n\
          \ -7.3826104e-01  4.0858030e-02 -1.8713180e+06  4.7686321e-01\n  3.6207277e-01\
          \  1.1526833e+00  1.8333626e-01 -1.8713180e+06]"
    num_agent_steps_sampled: 455000
    num_agent_steps_trained: 5448048
    num_steps_sampled: 455000
    num_steps_trained: 5448048
    num_target_updates: 901
  iterations_since_restore: 455
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.424444444444454
    ram_util_percent: 33.357777777777784
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6519.176581144333
  time_this_iter_s: 31.24474549293518
  time_total_s: 6519.176581144333
  timers:
    learn_throughput: 4636.992
    learn_time_ms: 10.352
    update_time_ms: 3.162
  timestamp: 1629287318
  timesteps_since_restore: 0
  timesteps_total: 455000
  training_iteration: 455
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    455 |          6519.18 | 455000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 456000
  custom_metrics: {}
  date: 2021-08-18_11-49-11
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 455608
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04026033729314804
          max_q: 42.48310470581055
          mean_q: 1.0760133266448975
          mean_td_error: -305267.25
          min_q: -1.3062043190002441
        model: {}
        td_error: "[ 2.5682479e-01 -5.8598864e-01  4.5515823e-01  3.1318569e-01\n -1.9581550e+06\
          \ -1.9581550e+06  6.8467724e-01 -1.9581550e+06\n  2.6068223e-01  2.8537965e-01\
          \  4.2999160e-01 -1.9581550e+06\n  6.3925999e-01 -1.9581550e+06  2.2233027e-01\
          \  3.7682056e-01\n -1.8112526e+00 -3.5535097e-03 -2.2490740e-02  2.8143710e-01\n\
          \ -1.9982836e-01 -9.4573925e+05 -4.6009660e-02  1.0804504e-01\n -1.5699258e-01\
          \  3.6379346e-01  1.3032973e-01  6.4595556e-01\n  2.4326682e-02 -3.2243431e-01\
          \ -2.9063272e-01 -1.4138694e+00\n -5.3586215e-01 -1.9581550e+06  4.1904479e-02\
          \ -4.3567258e-01\n -4.6063530e-01 -3.0495256e-02 -4.3465080e+00  2.5088751e-01\n\
          \ -1.9581550e+06 -2.3867536e-01  6.5623856e-01  3.9480335e-01\n  4.4598067e-01\
          \  1.7551303e-02  2.5534916e-01  9.7944260e-02]"
    num_agent_steps_sampled: 456000
    num_agent_steps_trained: 5460048
    num_steps_sampled: 456000
    num_steps_trained: 5460048
    num_target_updates: 903
  iterations_since_restore: 456
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.57872340425533
    ram_util_percent: 33.406382978723414
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6551.49387049675
  time_this_iter_s: 32.31728935241699
  time_total_s: 6551.49387049675
  timers:
    learn_throughput: 4479.289
    learn_time_ms: 10.716
    update_time_ms: 3.191
  timestamp: 1629287351
  timesteps_since_restore: 0
  timesteps_total: 456000
  training_iteration: 456
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    456 |          6551.49 | 456000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 457000
  custom_metrics: {}
  date: 2021-08-18_11-49-44
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 456616
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.09941750019788742
          max_q: 73.81761169433594
          mean_q: 14.417852401733398
          mean_td_error: -662338.1875
          min_q: -1.0195188522338867
        model: {}
        td_error: "[-5.4757315e-01  4.7931451e-01 -2.1174252e+06  1.1450458e+00\n -1.1797758e+06\
          \  6.3132644e-02 -2.4140173e-01 -2.1174252e+06\n  1.2811300e+00 -1.1797758e+06\
          \ -2.1174252e+06 -3.4508961e-01\n  4.5073265e-01  1.1029980e+00 -2.4275008e-01\
          \  1.0158281e+00\n -2.1174252e+06 -2.1875471e-01 -7.7290624e-01 -2.1174252e+06\n\
          \ -2.1174252e+06 -2.1174252e+06 -2.9416382e-02 -1.1797758e+06\n -1.1797758e+06\
          \  2.2520167e-01 -1.1797758e+06  8.4534824e-02\n -4.4373167e-01 -1.9384950e-01\
          \ -2.1174252e+06  2.5084868e-01\n -3.5685712e-01  2.9161084e-01  1.5479612e-01\
          \ -1.3073081e-01\n -1.1797758e+06 -2.1174252e+06 -3.3688420e-01  1.6959634e-01\n\
          \  2.5501782e-01 -1.1797758e+06 -4.1762763e-01 -5.4453075e-01\n  3.9719152e-01\
          \ -1.1797758e+06 -1.1797758e+06 -2.1174252e+06]"
    num_agent_steps_sampled: 457000
    num_agent_steps_trained: 5472048
    num_steps_sampled: 457000
    num_steps_trained: 5472048
    num_target_updates: 905
  iterations_since_restore: 457
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.125
    ram_util_percent: 33.475
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6584.411804437637
  time_this_iter_s: 32.91793394088745
  time_total_s: 6584.411804437637
  timers:
    learn_throughput: 4751.933
    learn_time_ms: 10.101
    update_time_ms: 3.194
  timestamp: 1629287384
  timesteps_since_restore: 0
  timesteps_total: 457000
  training_iteration: 457
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    457 |          6584.41 | 457000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 458000
  custom_metrics: {}
  date: 2021-08-18_11-50-18
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 457624
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.092535972595215
          max_q: 7252797.5
          mean_q: 151099.6875
          mean_td_error: -42.266334533691406
          min_q: -1.180537223815918
        model: {}
        td_error: "[-2.1797857e-01 -2.8935418e-01 -7.3648119e-01 -1.3803881e+00\n  1.5143182e+00\
          \  3.3190206e-01  2.5629312e-01 -2.5127530e-01\n  1.3615341e+00 -2.3023373e-01\
          \  1.9902086e-01  3.1680572e-01\n -2.3956707e-01  7.1401125e-01  6.4048141e-01\
          \ -6.1930799e-01\n -3.4835908e-01  4.0459633e-04  2.4934325e-01 -2.0285000e+03\n\
          \ -2.6562738e-01  1.4249086e-02 -2.8592920e-01 -3.9736748e-02\n  2.0610094e-01\
          \  6.1238718e-01 -1.5638826e+00  5.6621313e-01\n  8.5180700e-02 -5.2750885e-02\
          \  1.1984582e+00 -7.4826634e-01\n -8.3488697e-01  1.7303959e-01 -2.3434281e-01\
          \  1.6418099e-04\n  2.2370631e-01  4.0757656e-02 -8.2122719e-01 -4.7276795e-02\n\
          \  1.2302023e-01  4.1863799e-01  1.8646753e-01  5.4641962e-02\n  2.8620523e-01\
          \ -8.3902240e-02 -2.9366541e-01 -4.7294098e-01]"
    num_agent_steps_sampled: 458000
    num_agent_steps_trained: 5484048
    num_steps_sampled: 458000
    num_steps_trained: 5484048
    num_target_updates: 907
  iterations_since_restore: 458
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.810416666666676
    ram_util_percent: 33.50833333333333
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6618.0821413993835
  time_this_iter_s: 33.670336961746216
  time_total_s: 6618.0821413993835
  timers:
    learn_throughput: 4497.421
    learn_time_ms: 10.673
    update_time_ms: 3.149
  timestamp: 1629287418
  timesteps_since_restore: 0
  timesteps_total: 458000
  training_iteration: 458
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    458 |          6618.08 | 458000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 459000
  custom_metrics: {}
  date: 2021-08-18_11-50-54
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 458632
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.1151486337184906
          max_q: 4.88215446472168
          mean_q: -0.2219775915145874
          mean_td_error: -0.016802098602056503
          min_q: -1.2611184120178223
        model: {}
        td_error: "[ 0.08629805 -0.18369931  0.2798388  -1.2637913   0.9117677   0.08654037\n\
          \ -0.16079855  0.66514575  0.4306581   0.6612107  -1.3616686  -0.5897058\n\
          \  0.18971634  0.15875196 -0.18693605  0.49341625 -0.8548416   0.13375738\n\
          \  0.07350105  0.07874697  0.04301268 -0.6776565  -0.61167073  0.06046337\n\
          \  1.1771348   1.4327629   0.00786269 -0.22272652 -0.11258322 -0.2451581\n\
          \ -1.4613354  -0.58166844  0.21454501  0.28861532  0.36128342 -0.09945789\n\
          \  0.12193894  0.32209337 -0.5382432  -0.40684026 -0.3181292  -0.25625363\n\
          \  0.39340162  1.268214   -1.0611833   0.42729902  0.26079527 -0.24092495]"
    num_agent_steps_sampled: 459000
    num_agent_steps_trained: 5496048
    num_steps_sampled: 459000
    num_steps_trained: 5496048
    num_target_updates: 909
  iterations_since_restore: 459
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.84705882352941
    ram_util_percent: 33.5078431372549
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6653.412503957748
  time_this_iter_s: 35.33036255836487
  time_total_s: 6653.412503957748
  timers:
    learn_throughput: 4590.953
    learn_time_ms: 10.455
    update_time_ms: 3.163
  timestamp: 1629287454
  timesteps_since_restore: 0
  timesteps_total: 459000
  training_iteration: 459
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.2/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    459 |          6653.41 | 459000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 460000
  custom_metrics: {}
  date: 2021-08-18_11-51-30
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 459640
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06087416037917137
          max_q: 3.5812571048736572
          mean_q: -0.23635074496269226
          mean_td_error: 0.035142865031957626
          min_q: -1.1881661415100098
        model: {}
        td_error: "[-0.39818773 -0.39870894  0.05380523 -0.15793906  0.18901968  0.16063172\n\
          \ -0.29480726 -0.11096776 -0.25096768  0.03628388 -0.2899351  -0.04354513\n\
          \  0.45519704  0.05628639  0.74924874  0.16630238 -0.21488166 -0.00716501\n\
          \ -0.51008224 -0.37991357  0.03483278  0.205957    0.3279634   0.17665002\n\
          \  0.15744787  0.05461314 -0.67539084 -0.16457283 -0.49935362 -0.6922176\n\
          \  0.22343147 -0.13685459  0.8268553   0.9027249   1.1050476   0.72522074\n\
          \ -0.14299345 -0.0826177  -0.4112181   1.3587484  -0.0321914   0.31598145\n\
          \ -0.28288233  0.32254153 -0.05988669 -0.46338868 -0.34627938  0.12901485]"
    num_agent_steps_sampled: 460000
    num_agent_steps_trained: 5508048
    num_steps_sampled: 460000
    num_steps_trained: 5508048
    num_target_updates: 911
  iterations_since_restore: 460
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 58.43846153846154
    ram_util_percent: 33.57499999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6689.239584445953
  time_this_iter_s: 35.827080488204956
  time_total_s: 6689.239584445953
  timers:
    learn_throughput: 4639.61
    learn_time_ms: 10.346
    update_time_ms: 3.111
  timestamp: 1629287490
  timesteps_since_restore: 0
  timesteps_total: 460000
  training_iteration: 460
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.3/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    460 |          6689.24 | 460000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 461000
  custom_metrics: {}
  date: 2021-08-18_11-52-09
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 460648
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05370502918958664
          max_q: 2.0440168380737305
          mean_q: -0.3701723515987396
          mean_td_error: -0.07957999408245087
          min_q: -1.431382656097412
        model: {}
        td_error: "[-0.95184785 -0.23295462  0.2932874  -1.4532809  -0.9302098  -0.11798015\n\
          \ -0.03076398  0.20025247 -1.263521    0.12117243 -0.30609012  0.06305265\n\
          \  0.05885226 -0.163706   -0.3722149   0.84490865 -0.00257099 -0.09011087\n\
          \ -0.24295723 -0.31082922  0.5681708  -0.4973756  -0.6623777   0.60654664\n\
          \  0.08630911  0.22276843  0.361125    0.07229626  0.38793397 -0.08321804\n\
          \  0.34975296  0.11839986  0.0739058  -0.04569411  0.6787643   0.4197114\n\
          \  0.17220062  0.26689738 -0.10409218  0.15040058 -1.1186295  -0.21565005\n\
          \ -0.09319913  0.35579073 -0.34215742 -0.0973343   0.13613766 -0.699711  ]"
    num_agent_steps_sampled: 461000
    num_agent_steps_trained: 5520048
    num_steps_sampled: 461000
    num_steps_trained: 5520048
    num_target_updates: 913
  iterations_since_restore: 461
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.51818181818182
    ram_util_percent: 33.61454545454546
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6727.377472162247
  time_this_iter_s: 38.137887716293335
  time_total_s: 6727.377472162247
  timers:
    learn_throughput: 4699.456
    learn_time_ms: 10.214
    update_time_ms: 3.131
  timestamp: 1629287529
  timesteps_since_restore: 0
  timesteps_total: 461000
  training_iteration: 461
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.3/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    461 |          6727.38 | 461000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 462000
  custom_metrics: {}
  date: 2021-08-18_11-52-48
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 461656
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.052363134920597076
          max_q: 3.1455821990966797
          mean_q: -0.07143202424049377
          mean_td_error: -0.07212386280298233
          min_q: -1.0625557899475098
        model: {}
        td_error: "[-0.32432383 -0.25579137 -0.3128394  -0.22357434 -0.4262091   0.00642025\n\
          \  0.23341024 -0.18644807 -0.01059607 -0.4492281   0.00646013  0.17908359\n\
          \ -1.0859735  -0.24525839 -0.39937395  0.1823762  -0.5641522   1.7652674\n\
          \  0.02138168 -0.20984721 -0.24221388  0.61374795 -0.9726391  -0.10745034\n\
          \  0.42929256 -0.90602535 -0.22908202  0.7608621   1.1602697   0.21381116\n\
          \ -0.69536537 -0.22773048 -1.5592703  -0.135688   -0.31704992 -0.3351503\n\
          \  0.17393526  0.01221211 -0.63138807  0.35132182  0.1470215   0.05363467\n\
          \ -0.1851625  -0.02156389  0.2958947   0.20341823  0.7907313   0.19689712]"
    num_agent_steps_sampled: 462000
    num_agent_steps_trained: 5532048
    num_steps_sampled: 462000
    num_steps_trained: 5532048
    num_target_updates: 915
  iterations_since_restore: 462
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.46607142857143
    ram_util_percent: 33.70178571428571
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6766.306084156036
  time_this_iter_s: 38.92861199378967
  time_total_s: 6766.306084156036
  timers:
    learn_throughput: 4504.938
    learn_time_ms: 10.655
    update_time_ms: 3.057
  timestamp: 1629287568
  timesteps_since_restore: 0
  timesteps_total: 462000
  training_iteration: 462
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.3/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    462 |          6766.31 | 462000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 463000
  custom_metrics: {}
  date: 2021-08-18_11-53-28
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 462664
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07718250900506973
          max_q: 1.5213978290557861
          mean_q: -0.1677408665418625
          mean_td_error: 0.0023696820717304945
          min_q: -1.183370590209961
        model: {}
        td_error: "[-0.27817237  0.23346916  0.00807658 -0.19959149 -0.6881687   0.0186539\n\
          \ -0.1633488  -1.7096384  -0.24280566  0.52422774  0.34479266 -0.02576005\n\
          \  0.1880559  -0.2238129   0.60205257  0.80713856  0.25916964 -0.23975731\n\
          \ -0.20706627  0.5316806  -0.38935435 -0.20477206 -0.37518218 -0.45055032\n\
          \ -0.147556    0.60205257 -0.20464353 -0.24214204  0.21498609  0.09971731\n\
          \  0.51267284  0.24773371 -0.06069648 -0.22942907  0.10427767 -0.00752494\n\
          \  0.23131534 -0.195526   -0.3215197  -0.44681877  0.6643585   0.30553544\n\
          \ -0.44479278  0.20942193  0.3624215   0.2718651  -0.09175363  0.56045336]"
    num_agent_steps_sampled: 463000
    num_agent_steps_trained: 5544048
    num_steps_sampled: 463000
    num_steps_trained: 5544048
    num_target_updates: 917
  iterations_since_restore: 463
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.09649122807018
    ram_util_percent: 33.705263157894734
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6805.514221429825
  time_this_iter_s: 39.20813727378845
  time_total_s: 6805.514221429825
  timers:
    learn_throughput: 4578.58
    learn_time_ms: 10.484
    update_time_ms: 3.298
  timestamp: 1629287608
  timesteps_since_restore: 0
  timesteps_total: 463000
  training_iteration: 463
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.3/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    463 |          6805.51 | 463000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 464000
  custom_metrics: {}
  date: 2021-08-18_11-54-08
  done: false
  episode_len_mean: 8072.8490566037735
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5748939.339192459
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 53
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 463672
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0725979283452034
          max_q: 0.794006884098053
          mean_q: -0.16559924185276031
          mean_td_error: 0.08151242136955261
          min_q: -0.8733983635902405
        model: {}
        td_error: "[ 3.7283164e-01  2.2371846e-01  2.6133412e-01 -9.8806798e-02\n -2.3757070e-02\
          \ -4.9803913e-02  1.8081629e-01 -6.1639148e-01\n -7.8143597e-02 -1.4045012e+00\
          \  3.9254189e-02  7.4734062e-01\n  1.2719631e-03  6.4193225e-01  5.6981057e-01\
          \  1.3299206e-01\n -1.4258304e-01  2.0770270e-01 -6.7129552e-02  4.8273802e-01\n\
          \  2.6627213e-02  7.4061823e-01 -1.2659302e-01  5.3287470e-01\n  5.7851106e-01\
          \  1.6850853e-01 -2.1446782e-01 -2.0951760e-01\n  2.7686113e-01  2.2335109e-01\
          \  1.3301435e-01 -1.4926612e-01\n  2.9113442e-02 -1.6143107e-01  1.5802777e-01\
          \ -2.6242602e-01\n  2.6315391e-02 -2.3146252e-01  4.1047275e-02  4.1740438e-01\n\
          \ -3.5360551e-01 -2.9464540e-01  1.5417987e-01  5.3289998e-01\n  1.5324321e-01\
          \  8.1304938e-02 -6.4544350e-02  3.2602680e-01]"
    num_agent_steps_sampled: 464000
    num_agent_steps_trained: 5556048
    num_steps_sampled: 464000
    num_steps_trained: 5556048
    num_target_updates: 919
  iterations_since_restore: 464
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.68103448275861
    ram_util_percent: 33.71206896551724
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0491999602037967
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.911821701043019
    mean_inference_ms: 1.5876042643868433
    mean_raw_obs_processing_ms: 0.14413258550038746
  time_since_restore: 6845.366600751877
  time_this_iter_s: 39.852379322052
  time_total_s: 6845.366600751877
  timers:
    learn_throughput: 4588.829
    learn_time_ms: 10.46
    update_time_ms: 3.123
  timestamp: 1629287648
  timesteps_since_restore: 0
  timesteps_total: 464000
  training_iteration: 464
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.3/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    464 |          6845.37 | 464000 | 5.74894e+06 |          7.25484e+06 |             -198.044 |            8072.85 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 465000
  custom_metrics: {}
  date: 2021-08-18_11-54-49
  done: false
  episode_len_mean: 8610.462962962964
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5776820.453588795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 464680
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07870534807443619
          max_q: 0.8013007640838623
          mean_q: -0.3293517231941223
          mean_td_error: 0.1161864623427391
          min_q: -0.842909038066864
        model: {}
        td_error: "[ 0.03588262  0.16755101 -0.256665   -0.15672779 -0.37139308  0.20539999\n\
          \  0.66832215  0.49657106  0.4069634   0.47095042 -0.09581482 -0.16246171\n\
          \  0.0904372  -0.23946536  0.03524792  0.19119358 -0.3459612   0.22373691\n\
          \  0.26536483 -0.02390301  0.15003893  0.11758673  0.2903365   0.5862833\n\
          \ -0.12162757  0.39941412  0.06755531  0.284185   -0.22557688  0.28863287\n\
          \  0.03029507  0.32159626  0.21507233 -0.03728223  0.09366316 -0.2713737\n\
          \  0.3625626  -0.29140845 -0.24847503  0.8260925   0.16238129 -0.20093466\n\
          \  0.16211641 -0.42323473  0.44394922  0.46498656  0.3719108   0.1529755 ]"
    num_agent_steps_sampled: 465000
    num_agent_steps_trained: 5568048
    num_steps_sampled: 465000
    num_steps_trained: 5568048
    num_target_updates: 921
  iterations_since_restore: 465
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.094736842105256
    ram_util_percent: 33.80350877192982
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919921215733356
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.933959689483076
    mean_inference_ms: 1.5876616973232909
    mean_raw_obs_processing_ms: 0.14414999589008184
  time_since_restore: 6885.347480297089
  time_this_iter_s: 39.98087954521179
  time_total_s: 6885.347480297089
  timers:
    learn_throughput: 5026.467
    learn_time_ms: 9.549
    update_time_ms: 2.927
  timestamp: 1629287689
  timesteps_since_restore: 0
  timesteps_total: 465000
  training_iteration: 465
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    465 |          6885.35 | 465000 | 5.77682e+06 |          7.25484e+06 |             -198.044 |            8610.46 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 466000
  custom_metrics: {}
  date: 2021-08-18_11-55-00
  done: false
  episode_len_mean: 8610.462962962964
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5776820.453588795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 54
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 465688
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04122791439294815
          max_q: 1.359858512878418
          mean_q: -0.23911535739898682
          mean_td_error: -0.01615741290152073
          min_q: -0.774951696395874
        model: {}
        td_error: "[ 0.15730286 -0.4026751  -0.0499199  -0.26283973  0.24048007  0.7767666\n\
          \ -0.07741284 -0.47248974 -0.3383119   0.31564856  0.30860496 -0.3384019\n\
          \ -0.23678239  0.20746902  0.03703696 -0.11698836  0.13241738  0.04931387\n\
          \  0.1952753   0.07471478 -0.09388719  0.13090394  0.1499545  -0.35260952\n\
          \ -0.07694784 -0.03782451  0.23129064  0.08222443 -0.01849991  0.2541226\n\
          \ -0.47941688  0.0606223   0.15560722  0.15792161  0.31337214 -0.14528227\n\
          \ -0.14855456 -0.23531353 -0.2583297  -0.78013414  0.31132537 -0.04855824\n\
          \ -0.713955    0.00799844  0.02995634  0.45134288 -0.03650835  0.11441499]"
    num_agent_steps_sampled: 466000
    num_agent_steps_trained: 5580048
    num_steps_sampled: 466000
    num_steps_trained: 5580048
    num_target_updates: 923
  iterations_since_restore: 466
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.2625
    ram_util_percent: 32.60625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919921215733356
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.933959689483076
    mean_inference_ms: 1.5876616973232909
    mean_raw_obs_processing_ms: 0.14414999589008184
  time_since_restore: 6896.236812353134
  time_this_iter_s: 10.889332056045532
  time_total_s: 6896.236812353134
  timers:
    learn_throughput: 3713.999
    learn_time_ms: 12.924
    update_time_ms: 3.889
  timestamp: 1629287700
  timesteps_since_restore: 0
  timesteps_total: 466000
  training_iteration: 466
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    466 |          6896.24 | 466000 | 5.77682e+06 |          7.25484e+06 |             -198.044 |            8610.46 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 467000
  custom_metrics: {}
  date: 2021-08-18_11-55-13
  done: false
  episode_len_mean: 8610.462962962964
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5776820.453588795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 54
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 466696
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04522642120718956
          max_q: 1.6941978931427002
          mean_q: -0.09495656937360764
          mean_td_error: 0.017236214131116867
          min_q: -0.8233973979949951
        model: {}
        td_error: "[-0.07350155  0.31524312  0.19996464 -0.10319704 -0.28252238  0.63962835\n\
          \  0.09355561  0.41492468  0.19447303  0.5840843  -0.10335547  0.15924752\n\
          \ -0.26133174 -0.03078735  0.16653995  0.5073754  -0.16540201 -0.46773133\n\
          \  0.22141103  0.15444635  0.28374404 -0.04299188 -0.4966274  -0.41687977\n\
          \  0.03069347 -0.42021975  0.5464999  -0.4839759   0.5672606  -0.17698427\n\
          \  0.4196095   0.09180015 -0.42481512 -0.56379014 -0.28276935  0.08346176\n\
          \  0.00655103 -1.110765    0.04335541  0.1647937  -0.49551547  0.46512675\n\
          \  0.3819849  -0.15597048 -0.10581273  0.0877296   0.26996315  0.39881617]"
    num_agent_steps_sampled: 467000
    num_agent_steps_trained: 5592048
    num_steps_sampled: 467000
    num_steps_trained: 5592048
    num_target_updates: 925
  iterations_since_restore: 467
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.6388888888889
    ram_util_percent: 32.60555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919921215733356
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.933959689483076
    mean_inference_ms: 1.5876616973232909
    mean_raw_obs_processing_ms: 0.14414999589008184
  time_since_restore: 6907.77570271492
  time_this_iter_s: 11.538890361785889
  time_total_s: 6907.77570271492
  timers:
    learn_throughput: 3777.95
    learn_time_ms: 12.705
    update_time_ms: 3.585
  timestamp: 1629287713
  timesteps_since_restore: 0
  timesteps_total: 467000
  training_iteration: 467
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    467 |          6907.78 | 467000 | 5.77682e+06 |          7.25484e+06 |             -198.044 |            8610.46 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 468000
  custom_metrics: {}
  date: 2021-08-18_11-55-25
  done: false
  episode_len_mean: 8610.462962962964
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5776820.453588795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 54
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 467704
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.058633990585803986
          max_q: 2.1125450134277344
          mean_q: -0.052475735545158386
          mean_td_error: 0.05522763729095459
          min_q: -0.9839854836463928
        model: {}
        td_error: "[ 0.16136563  0.1545783   0.17637827  0.05675146 -0.48559242 -0.10104024\n\
          \  0.1505461  -0.46955013 -0.01818454  0.20045558  0.4103601   0.3369841\n\
          \  0.11815351  0.0048328  -0.05859783 -0.14784569  0.26246607 -0.21267334\n\
          \  0.03758442  0.4550537  -0.2970125   0.1378293   0.08113071  0.39744294\n\
          \ -0.337628   -0.0233106   0.09568095  0.08877301 -0.15085427  0.18070728\n\
          \  0.27002913 -0.2573169   0.16621843 -0.19283758 -0.41109133  0.27223247\n\
          \ -0.08729467  0.03028838  0.39007306 -0.00361016  0.30780864 -0.2931041\n\
          \ -0.00801951  0.46893713  0.20968011  0.289971    0.16634324  0.12783474]"
    num_agent_steps_sampled: 468000
    num_agent_steps_trained: 5604048
    num_steps_sampled: 468000
    num_steps_trained: 5604048
    num_target_updates: 927
  iterations_since_restore: 468
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.08235294117646
    ram_util_percent: 32.60588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919921215733356
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.933959689483076
    mean_inference_ms: 1.5876616973232909
    mean_raw_obs_processing_ms: 0.14414999589008184
  time_since_restore: 6919.722758293152
  time_this_iter_s: 11.947055578231812
  time_total_s: 6919.722758293152
  timers:
    learn_throughput: 4929.654
    learn_time_ms: 9.737
    update_time_ms: 2.646
  timestamp: 1629287725
  timesteps_since_restore: 0
  timesteps_total: 468000
  training_iteration: 468
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    468 |          6919.72 | 468000 | 5.77682e+06 |          7.25484e+06 |             -198.044 |            8610.46 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 469000
  custom_metrics: {}
  date: 2021-08-18_11-55-39
  done: false
  episode_len_mean: 8610.462962962964
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5776820.453588795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 54
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 468712
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4.098138809204102
          max_q: 7254200.5
          mean_q: 151129.0
          mean_td_error: -12.995722770690918
          min_q: -0.684659481048584
        model: {}
        td_error: "[ 1.4471003e-01  4.3523073e-02 -1.9340980e-01  3.0517715e-01\n  1.2560251e-01\
          \  1.2592411e-01  3.0033922e-01  1.8916023e-01\n  4.5520830e-01  3.7194327e-02\
          \ -2.1476190e-01  2.1872997e-02\n  3.1728244e-01  1.0241103e-01 -2.5366142e-01\
          \ -1.4744768e-01\n -2.3650587e-01 -2.5486648e-01  1.6208434e-01  2.6593053e-01\n\
          \  7.2990400e-01  3.8935214e-01 -2.5044629e-01 -1.1276138e-01\n  1.4710093e-01\
          \ -8.3009720e-01  1.8496725e-01  2.7317035e-01\n -1.8609641e-01 -2.2848788e-01\
          \ -6.2700000e+02  1.2416458e-01\n  6.2613297e-01  1.3162032e-01 -7.5038701e-02\
          \  3.7900108e-01\n -3.0710408e-01 -2.7711859e-01  9.9282950e-02  4.0502167e-01\n\
          \  2.1039456e-01  3.4309396e-01  1.2889403e-01 -6.4542383e-01\n  1.4533007e-01\
          \  1.3821702e-01  1.8505359e-01  1.8146580e-01]"
    num_agent_steps_sampled: 469000
    num_agent_steps_trained: 5616048
    num_steps_sampled: 469000
    num_steps_trained: 5616048
    num_target_updates: 929
  iterations_since_restore: 469
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.41
    ram_util_percent: 32.605000000000004
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919921215733356
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.933959689483076
    mean_inference_ms: 1.5876616973232909
    mean_raw_obs_processing_ms: 0.14414999589008184
  time_since_restore: 6933.132831573486
  time_this_iter_s: 13.410073280334473
  time_total_s: 6933.132831573486
  timers:
    learn_throughput: 4935.891
    learn_time_ms: 9.725
    update_time_ms: 2.738
  timestamp: 1629287739
  timesteps_since_restore: 0
  timesteps_total: 469000
  training_iteration: 469
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    469 |          6933.13 | 469000 | 5.77682e+06 |          7.25484e+06 |             -198.044 |            8610.46 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 470000
  custom_metrics: {}
  date: 2021-08-18_11-55-53
  done: false
  episode_len_mean: 8610.462962962964
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5776820.453588795
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 54
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 469720
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.03385517746210098
          max_q: 4.530921459197998
          mean_q: -0.09509867429733276
          mean_td_error: 0.024759715422987938
          min_q: -0.7480159997940063
        model: {}
        td_error: "[ 0.44295025  0.16928244  0.2245411  -0.10446756 -1.0591164   0.18147102\n\
          \ -0.10375047  0.77903384 -0.26527786 -0.6014277  -0.7117631  -0.10415764\n\
          \  0.16162202  0.03194293 -0.60128     0.36482623  0.16371664 -0.10524464\n\
          \  0.08009455  0.05928838 -0.03427762 -0.13918856  0.24129361  0.00675493\n\
          \  0.4709071   0.22853279 -0.06831777  0.04979295 -0.40544665  0.13031438\n\
          \  0.10505036  0.09208652  0.35238242  0.40286952  0.11367017 -0.8363855\n\
          \  0.52493596 -0.21940249  0.16219354  0.5410949   0.09333456  0.13601032\n\
          \  0.27280873 -0.28339916 -0.36163136  0.21270388  0.12506007  0.2724347 ]"
    num_agent_steps_sampled: 470000
    num_agent_steps_trained: 5628048
    num_steps_sampled: 470000
    num_steps_trained: 5628048
    num_target_updates: 931
  iterations_since_restore: 470
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.84285714285714
    ram_util_percent: 32.604761904761915
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919921215733356
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.933959689483076
    mean_inference_ms: 1.5876616973232909
    mean_raw_obs_processing_ms: 0.14414999589008184
  time_since_restore: 6947.128150224686
  time_this_iter_s: 13.99531865119934
  time_total_s: 6947.128150224686
  timers:
    learn_throughput: 4542.732
    learn_time_ms: 10.566
    update_time_ms: 2.932
  timestamp: 1629287753
  timesteps_since_restore: 0
  timesteps_total: 470000
  training_iteration: 470
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    470 |          6947.13 | 470000 | 5.77682e+06 |          7.25484e+06 |             -198.044 |            8610.46 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 471000
  custom_metrics: {}
  date: 2021-08-18_11-56-05
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 470728
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.018378594890236855
          max_q: 1.6280937194824219
          mean_q: -0.026688169687986374
          mean_td_error: 0.0024833481293171644
          min_q: -0.8361532688140869
        model: {}
        td_error: "[-0.48391372 -0.62890726 -0.14654784 -0.3827644  -0.12319161  0.2313002\n\
          \  0.08033317 -0.1008413  -0.27126676  0.1491369   0.32939956  0.13737434\n\
          \  0.07277966 -0.26933593 -0.29648823  0.2062025   0.6969122  -0.19793463\n\
          \ -0.16783094  0.38318545  0.11010611  0.77744293  0.5012586   0.23830974\n\
          \  0.16550362 -0.06523493  0.26425987 -0.19271043 -0.17465815  0.19047636\n\
          \  0.18613178 -0.4618505  -0.46462882 -0.06090486 -0.2764923  -0.28639105\n\
          \  0.01003703  0.21491921  0.13061345 -0.03539708 -0.5172208   0.48687494\n\
          \ -0.12107646 -0.03255214 -0.10395157  0.07325244  0.17570469  0.16977757]"
    num_agent_steps_sampled: 471000
    num_agent_steps_trained: 5640048
    num_steps_sampled: 471000
    num_steps_trained: 5640048
    num_target_updates: 933
  iterations_since_restore: 471
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.31176470588235
    ram_util_percent: 32.60588235294118
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 6959.07234954834
  time_this_iter_s: 11.944199323654175
  time_total_s: 6959.07234954834
  timers:
    learn_throughput: 4707.401
    learn_time_ms: 10.197
    update_time_ms: 2.972
  timestamp: 1629287765
  timesteps_since_restore: 0
  timesteps_total: 471000
  training_iteration: 471
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    471 |          6959.07 | 471000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 472000
  custom_metrics: {}
  date: 2021-08-18_11-56-19
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 471736
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.032256241887807846
          max_q: 2.247215509414673
          mean_q: -0.1432979255914688
          mean_td_error: 0.04438260942697525
          min_q: -0.7772682309150696
        model: {}
        td_error: "[ 0.04960036  0.16758905  0.04680616  0.27590755 -0.06349687 -0.14677936\n\
          \ -0.16000661 -0.18714684  0.13593316  0.10217434  0.05732697  0.01009277\n\
          \  0.25365084 -0.03462978  0.10803425 -0.02110273 -0.07124041  0.11885792\n\
          \  0.06195103 -0.03235516  0.47828928  0.01844391 -0.36856216 -0.06116709\n\
          \ -0.26163888  0.2662211   0.24752572  0.14651525  0.15237862  0.25233048\n\
          \ -0.38533056 -0.09010527  0.15514147  0.36853248  0.3695826   0.13388176\n\
          \ -0.41402078 -0.20853794 -0.18482552  0.18259697  0.26889956 -0.05581683\n\
          \  0.22964224  0.084699    0.30793035 -0.20243949 -0.45540604  0.4844382 ]"
    num_agent_steps_sampled: 472000
    num_agent_steps_trained: 5652048
    num_steps_sampled: 472000
    num_steps_trained: 5652048
    num_target_updates: 935
  iterations_since_restore: 472
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.121052631578955
    ram_util_percent: 32.6
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 6971.786241769791
  time_this_iter_s: 12.713892221450806
  time_total_s: 6971.786241769791
  timers:
    learn_throughput: 3212.652
    learn_time_ms: 14.941
    update_time_ms: 4.26
  timestamp: 1629287779
  timesteps_since_restore: 0
  timesteps_total: 472000
  training_iteration: 472
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    472 |          6971.79 | 472000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 473000
  custom_metrics: {}
  date: 2021-08-18_11-56-31
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 472744
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06073134392499924
          max_q: 1.8097786903381348
          mean_q: -0.17862245440483093
          mean_td_error: -0.09245811402797699
          min_q: -0.8043637275695801
        model: {}
        td_error: "[-8.62357616e-01 -1.86039090e-01 -3.09806079e-01  2.04366744e-01\n\
          \  7.22487867e-02 -4.50134277e-02 -8.73342156e-04 -4.02273834e-02\n  1.75273031e-01\
          \ -4.85047162e-01  1.06520802e-01  3.26250315e-01\n  1.48694575e-01 -2.82650888e-01\
          \ -2.71005988e-01  3.08794320e-01\n -2.33690113e-01  5.96692264e-02 -2.14828908e-01\
          \ -6.10902011e-02\n  6.35516644e-03  5.95027804e-02  8.78317952e-02  7.47583807e-02\n\
          \ -1.03579849e-01  1.92159772e-01 -3.49600554e-01  4.49364305e-01\n  3.33281755e-02\
          \ -2.42807388e-01 -1.47336781e-01 -2.64608681e-01\n  1.85778379e-01 -2.13525832e-01\
          \  7.84906745e-02 -2.69235492e-01\n -4.01016891e-01 -7.43737221e-02 -8.94879639e-01\
          \ -2.24919155e-01\n  3.05796862e-01  6.93351924e-02 -6.60343915e-02 -2.51466423e-01\n\
          \ -2.03749046e-01 -2.18718529e-01 -3.54046941e-01 -1.09978676e-01]"
    num_agent_steps_sampled: 473000
    num_agent_steps_trained: 5664048
    num_steps_sampled: 473000
    num_steps_trained: 5664048
    num_target_updates: 937
  iterations_since_restore: 473
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.794444444444444
    ram_util_percent: 32.6
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 6984.161170721054
  time_this_iter_s: 12.374928951263428
  time_total_s: 6984.161170721054
  timers:
    learn_throughput: 4912.226
    learn_time_ms: 9.772
    update_time_ms: 3.086
  timestamp: 1629287791
  timesteps_since_restore: 0
  timesteps_total: 473000
  training_iteration: 473
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    473 |          6984.16 | 473000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 474000
  custom_metrics: {}
  date: 2021-08-18_11-56-45
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 473752
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.040345121175050735
          max_q: 0.4920836091041565
          mean_q: -0.22666582465171814
          mean_td_error: -0.013804985210299492
          min_q: -0.7477777004241943
        model: {}
        td_error: "[ 0.23881483  0.10195518 -0.14186798  0.41667712  0.29916972  0.31655228\n\
          \  0.35654634  0.33317518 -0.5526495  -0.13301075  0.20379174 -0.6120088\n\
          \ -0.49465424 -0.57772595  0.30392107 -0.19219173  0.10036004  0.22746153\n\
          \ -0.23048946 -0.11172163  0.05505094 -0.02900767  0.11579305  0.41462243\n\
          \ -0.09101275 -0.15573911  0.31295186  0.16609503 -0.46495742  0.3247174\n\
          \  0.04608223  0.14664575 -0.3197442   0.01118183  0.3000704  -0.08669478\n\
          \ -0.2079382   0.28370368  0.04805005  0.58452487  0.00216264 -0.6827361\n\
          \  0.15360469 -0.59772396 -0.36099094 -0.02009016 -0.49055457  0.02718884]"
    num_agent_steps_sampled: 474000
    num_agent_steps_trained: 5676048
    num_steps_sampled: 474000
    num_steps_trained: 5676048
    num_target_updates: 939
  iterations_since_restore: 474
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.89999999999999
    ram_util_percent: 32.6
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 6997.038412094116
  time_this_iter_s: 12.877241373062134
  time_total_s: 6997.038412094116
  timers:
    learn_throughput: 4946.271
    learn_time_ms: 9.704
    update_time_ms: 2.706
  timestamp: 1629287805
  timesteps_since_restore: 0
  timesteps_total: 474000
  training_iteration: 474
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    474 |          6997.04 | 474000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 475000
  custom_metrics: {}
  date: 2021-08-18_11-56-59
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 474760
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.6168212890625
          max_q: 7255877.0
          mean_q: 151163.859375
          mean_td_error: 21.77130889892578
          min_q: -1.0620689392089844
        model: {}
        td_error: "[-9.09611583e-02 -3.64935696e-01 -4.50814933e-01 -4.01246130e-01\n\
          \  1.26475185e-01 -2.99728513e-02 -4.45977747e-02 -6.26616657e-01\n  2.93612182e-01\
          \  2.50952989e-01  1.55247033e-01 -1.45454168e-01\n  9.00081992e-02 -9.94169712e-03\
          \ -8.67506802e-01  2.69070625e-01\n  7.28756189e-03 -2.44237095e-01 -4.23477173e-01\
          \  2.62173712e-01\n -1.98381647e-01 -9.06898379e-02 -4.07030761e-01 -2.46046171e-01\n\
          \  1.61113441e-01 -2.04786599e-01 -6.23333275e-01 -1.75955892e-02\n  1.06150120e-01\
          \ -5.91205776e-01 -1.18324548e-01  7.50968456e-02\n  2.05443799e-01 -8.42482030e-01\
          \ -1.66394264e-01  1.04950000e+03\n  3.81047845e-01 -1.80258960e-01  1.19783044e-01\
          \ -2.67067552e-01\n  3.94056797e-01 -5.82394600e-02  1.10010237e-01  2.67656684e-01\n\
          \  1.97979212e-02 -1.71556115e-01  2.14625597e-01 -1.03622139e-01]"
    num_agent_steps_sampled: 475000
    num_agent_steps_trained: 5688048
    num_steps_sampled: 475000
    num_steps_trained: 5688048
    num_target_updates: 941
  iterations_since_restore: 475
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.661904761904744
    ram_util_percent: 32.60000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 7010.8437695503235
  time_this_iter_s: 13.805357456207275
  time_total_s: 7010.8437695503235
  timers:
    learn_throughput: 5116.045
    learn_time_ms: 9.382
    update_time_ms: 2.703
  timestamp: 1629287819
  timesteps_since_restore: 0
  timesteps_total: 475000
  training_iteration: 475
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    475 |          7010.84 | 475000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 476000
  custom_metrics: {}
  date: 2021-08-18_11-57-15
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 475768
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07121727615594864
          max_q: 6.621694087982178
          mean_q: -0.01558288000524044
          mean_td_error: 0.010767574422061443
          min_q: -0.7584875226020813
        model: {}
        td_error: "[-0.48271957  0.22848666 -0.08209148 -0.41946095 -0.06868351  0.19704756\n\
          \  0.01443833 -0.02120158 -0.18270999 -0.48332688  0.26093066 -0.12698776\n\
          \ -0.02261239  0.13542551 -0.21480261  0.83100796 -0.21315953  0.12999767\n\
          \  0.24368292  0.32766205  0.1120044   0.09208123  0.02238801  0.48260435\n\
          \  0.07030648  0.24666779 -0.46270388  0.09781408  0.38485634 -0.07787615\n\
          \ -0.18206613  0.1063351   0.06401229  0.09368348  0.34982532  0.16660947\n\
          \  0.00760645 -2.207147    0.27243125  0.1253016  -0.04910168 -0.03169367\n\
          \ -0.00631104  0.07504171  0.11220402  0.06615993  0.2330367   0.30185008]"
    num_agent_steps_sampled: 476000
    num_agent_steps_trained: 5700048
    num_steps_sampled: 476000
    num_steps_trained: 5700048
    num_target_updates: 943
  iterations_since_restore: 476
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 66.43636363636364
    ram_util_percent: 32.50909090909091
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 7026.141227245331
  time_this_iter_s: 15.297457695007324
  time_total_s: 7026.141227245331
  timers:
    learn_throughput: 4717.14
    learn_time_ms: 10.176
    update_time_ms: 3.043
  timestamp: 1629287835
  timesteps_since_restore: 0
  timesteps_total: 476000
  training_iteration: 476
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    476 |          7026.14 | 476000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 477000
  custom_metrics: {}
  date: 2021-08-18_11-57-30
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 476776
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06275518983602524
          max_q: 2.0562198162078857
          mean_q: -0.14522287249565125
          mean_td_error: -0.026026751846075058
          min_q: -1.0017807483673096
        model: {}
        td_error: "[ 0.06599747  0.2771079   0.16351756  0.09992796  0.35763073  0.23300004\n\
          \  0.14881301 -0.09757137 -0.28520852 -0.07659981 -0.22486754 -0.24338205\n\
          \ -0.08293162  0.33828524 -0.22630149  0.07253022  0.15215075  0.39689863\n\
          \  0.09047446  0.1056245   0.31081852  0.10590574 -0.6541698  -0.4163982\n\
          \  0.56210005  0.14261448 -0.08613002  0.20260492  0.09563032  0.14313951\n\
          \ -0.18308249  0.38168913  0.14334384 -0.14719489  0.11488977 -1.9824488\n\
          \ -0.12134017 -1.8714008   0.27708358 -0.09607524 -0.08160195 -0.6417341\n\
          \  0.31057554  0.40113747  0.16293249  0.27658284  0.00943585  0.12671256]"
    num_agent_steps_sampled: 477000
    num_agent_steps_trained: 5712048
    num_steps_sampled: 477000
    num_steps_trained: 5712048
    num_target_updates: 945
  iterations_since_restore: 477
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.40454545454547
    ram_util_percent: 32.59545454545455
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 7041.00429224968
  time_this_iter_s: 14.863065004348755
  time_total_s: 7041.00429224968
  timers:
    learn_throughput: 4752.405
    learn_time_ms: 10.1
    update_time_ms: 2.844
  timestamp: 1629287850
  timesteps_since_restore: 0
  timesteps_total: 477000
  training_iteration: 477
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    477 |             7041 | 477000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 478000
  custom_metrics: {}
  date: 2021-08-18_11-57-47
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 477784
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.701568603515625
          max_q: 7255907.5
          mean_q: 151164.578125
          mean_td_error: 22.51757049560547
          min_q: -0.6842458248138428
        model: {}
        td_error: "[-5.20872325e-02  2.92899251e-01  2.96335101e-01  4.30170059e-01\n\
          \ -5.08055925e-01  2.00860322e-01  3.21526974e-01  1.53267682e-01\n -4.40885350e-02\
          \ -4.86586243e-03 -8.42016935e-03 -4.19536114e-01\n -3.00053209e-01 -1.32217199e-01\
          \ -9.87523496e-02  3.42284560e-01\n  3.10465693e-01 -3.33052814e-01 -1.81922883e-01\
          \  1.08050000e+03\n -2.23105311e-01  2.57819712e-01  4.82999980e-01  6.99221492e-02\n\
          \ -1.40947372e-01 -3.37983072e-02  4.07558650e-01  1.61836624e-01\n -2.17926785e-01\
          \  7.43598938e-02 -1.74155802e-01 -2.36014783e-01\n -7.15733171e-01  1.29471362e-01\
          \ -2.99604386e-01  1.22577548e-01\n -1.52397454e-02 -1.15826249e-01  5.45912385e-02\
          \ -7.43578821e-02\n  1.83471680e-01  2.18219399e-01 -5.41979671e-02 -5.34041524e-02\n\
          \ -1.66028336e-01  2.85080284e-01  1.24895245e-01  2.60939002e-02]"
    num_agent_steps_sampled: 478000
    num_agent_steps_trained: 5724048
    num_steps_sampled: 478000
    num_steps_trained: 5724048
    num_target_updates: 947
  iterations_since_restore: 478
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.260869565217384
    ram_util_percent: 32.60000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 7056.86402463913
  time_this_iter_s: 15.859732389450073
  time_total_s: 7056.86402463913
  timers:
    learn_throughput: 3488.386
    learn_time_ms: 13.76
    update_time_ms: 4.068
  timestamp: 1629287867
  timesteps_since_restore: 0
  timesteps_total: 478000
  training_iteration: 478
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    478 |          7056.86 | 478000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 479000
  custom_metrics: {}
  date: 2021-08-18_11-58-04
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 478792
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6.236720085144043
          max_q: 7255583.0
          mean_q: 151157.921875
          mean_td_error: 15.79530143737793
          min_q: -0.5165318250656128
        model: {}
        td_error: "[ 1.03023827e-01  6.53212965e-02  3.15205157e-01 -1.50718287e-01\n\
          \  3.32921773e-01  5.41941524e-02 -5.41641116e-02  6.43068552e-03\n  3.32709491e-01\
          \  1.99511200e-01 -3.14737737e-01  3.17396760e-01\n  7.56000000e+02 -2.22494781e-01\
          \  2.28787899e-01 -1.09204030e+00\n -2.17210427e-02 -9.90354717e-02  2.95229077e-01\
          \  3.82738799e-01\n  6.43894136e-01  3.09941471e-01  5.41265011e-02  2.41328537e-01\n\
          \ -3.51259977e-01 -2.84477234e-01  1.97416633e-01 -2.32327878e-02\n -1.53378323e-01\
          \ -2.08330899e-01 -2.55493969e-02  3.92352939e-02\n  3.62650782e-01  3.20836902e-01\
          \  2.59250164e-01  5.25790393e-01\n -3.09264660e-02  5.87867260e-01  1.04157686e-01\
          \ -3.48679423e-01\n  2.04872310e-01 -2.11941704e-01 -3.60881984e-01 -1.90150976e-01\n\
          \  2.52488196e-01  3.07406574e-01  2.00864673e-02 -7.46741116e-01]"
    num_agent_steps_sampled: 479000
    num_agent_steps_trained: 5736048
    num_steps_sampled: 479000
    num_steps_trained: 5736048
    num_target_updates: 949
  iterations_since_restore: 479
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.096
    ram_util_percent: 32.588
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 7073.249540567398
  time_this_iter_s: 16.385515928268433
  time_total_s: 7073.249540567398
  timers:
    learn_throughput: 4843.68
    learn_time_ms: 9.91
    update_time_ms: 2.95
  timestamp: 1629287884
  timesteps_since_restore: 0
  timesteps_total: 479000
  training_iteration: 479
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    479 |          7073.25 | 479000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 480000
  custom_metrics: {}
  date: 2021-08-18_11-58-19
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 479800
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06572123616933823
          max_q: 2.727353811264038
          mean_q: -0.14641311764717102
          mean_td_error: -0.07073269784450531
          min_q: -0.7045328617095947
        model: {}
        td_error: "[-0.16575688 -0.19127196  0.13183506 -0.25056058 -0.06966086 -0.4246062\n\
          \ -0.3840419  -0.1252669   0.1318621  -0.22428165  0.18037897  0.01813674\n\
          \ -0.14286566 -0.30256537  0.4014138  -0.01199584  0.11540008 -0.19772053\n\
          \ -1.1650758   0.21399221  0.06074145  0.10545063 -0.13596326  0.70388865\n\
          \ -0.8845636  -0.36164334 -0.01490749 -0.15861452 -0.05927733  0.28103375\n\
          \  0.35166118  0.15254512 -0.01709801 -0.20885834  0.10489246 -0.3122878\n\
          \ -0.21179762  0.0503535   0.13268459 -0.04998831  0.12218726  0.19861251\n\
          \ -0.64058185  0.07196552 -0.11258466  0.23251092 -0.46598566  0.133106  ]"
    num_agent_steps_sampled: 480000
    num_agent_steps_trained: 5748048
    num_steps_sampled: 480000
    num_steps_trained: 5748048
    num_target_updates: 951
  iterations_since_restore: 480
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.45454545454545
    ram_util_percent: 32.60000000000001
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 7088.628081321716
  time_this_iter_s: 15.378540754318237
  time_total_s: 7088.628081321716
  timers:
    learn_throughput: 3861.358
    learn_time_ms: 12.431
    update_time_ms: 4.142
  timestamp: 1629287899
  timesteps_since_restore: 0
  timesteps_total: 480000
  training_iteration: 480
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    480 |          7088.63 | 480000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 481000
  custom_metrics: {}
  date: 2021-08-18_11-58-36
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 480808
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06669048964977264
          max_q: 2.027672529220581
          mean_q: -0.22993354499340057
          mean_td_error: 0.03592498227953911
          min_q: -1.12273108959198
        model: {}
        td_error: "[-0.12333834  0.01429582 -0.23809922  0.06586474  0.08090857 -0.43243137\n\
          \ -0.18848053 -0.0917862   0.2591148  -0.16054638 -0.3743118   0.17098808\n\
          \ -0.4210925   0.01986301  0.1943839   0.2339409   0.0362134  -0.05015329\n\
          \ -0.12837903 -0.19912843 -0.21676871  0.03596574 -0.08542043  0.57545835\n\
          \  0.21821159  0.03836671 -0.14813328 -0.03237832  0.18996906  0.19552712\n\
          \  0.14297816  0.06404197  0.1863764   0.27012163 -0.03191335 -0.39693138\n\
          \  0.16832137  0.17001134  0.3877324  -0.23437904  0.41244867  0.01081939\n\
          \  0.19285822  0.05567789  0.49934596  0.00066951 -0.01812801  0.405724  ]"
    num_agent_steps_sampled: 481000
    num_agent_steps_trained: 5760048
    num_steps_sampled: 481000
    num_steps_trained: 5760048
    num_target_updates: 953
  iterations_since_restore: 481
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.35833333333333
    ram_util_percent: 32.60416666666667
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 7104.867470979691
  time_this_iter_s: 16.239389657974243
  time_total_s: 7104.867470979691
  timers:
    learn_throughput: 4608.408
    learn_time_ms: 10.416
    update_time_ms: 2.945
  timestamp: 1629287916
  timesteps_since_restore: 0
  timesteps_total: 481000
  training_iteration: 481
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    481 |          7104.87 | 481000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 482000
  custom_metrics: {}
  date: 2021-08-18_11-58-53
  done: false
  episode_len_mean: 8549.672727272728
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5803690.463119005
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 55
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 481816
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.053938768804073334
          max_q: 4.751365661621094
          mean_q: 0.02701268158853054
          mean_td_error: 0.0009368534083478153
          min_q: -0.6067861914634705
        model: {}
        td_error: "[-0.51563966 -0.05274843  0.33996522 -0.19351786 -1.0272753  -0.28479356\n\
          \  0.07263148 -0.02119479 -0.01202887  0.23065841  0.27185252 -0.20744461\n\
          \ -0.01331377  0.05316243 -0.012705    0.30766273  0.05131519  0.21092701\n\
          \ -0.14900336  0.32610607 -0.00763877  0.36599797  0.5199364   0.44277668\n\
          \  0.40070552 -0.15047777  0.29655528  0.24244404 -0.08180696 -0.26513082\n\
          \ -0.36808574 -0.26114553  0.1859889  -0.2463947  -0.36635035  0.34074622\n\
          \  0.3596549   0.14570725  0.08382018 -0.09010267 -0.44980183 -0.01241022\n\
          \ -0.0351693  -0.33477163 -0.1513776  -0.04583505  0.03811675  0.11440188]"
    num_agent_steps_sampled: 482000
    num_agent_steps_trained: 5772048
    num_steps_sampled: 482000
    num_steps_trained: 5772048
    num_target_updates: 955
  iterations_since_restore: 482
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.35
    ram_util_percent: 32.60416666666667
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04919843721426881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.95471358988261
    mean_inference_ms: 1.5877200385655577
    mean_raw_obs_processing_ms: 0.14416588939229322
  time_since_restore: 7121.208224058151
  time_this_iter_s: 16.340753078460693
  time_total_s: 7121.208224058151
  timers:
    learn_throughput: 4616.502
    learn_time_ms: 10.397
    update_time_ms: 3.546
  timestamp: 1629287933
  timesteps_since_restore: 0
  timesteps_total: 482000
  training_iteration: 482
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |      reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    482 |          7121.21 | 482000 | 5.80369e+06 |          7.25484e+06 |             -198.044 |            8549.67 |
+----------------------------+----------+----------------+--------+------------------+--------+-------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 483000
  custom_metrics: {}
  date: 2021-08-18_11-59-07
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 482824
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.218477249145508
          max_q: 7255336.5
          mean_q: 151152.671875
          mean_td_error: 10.59469985961914
          min_q: -0.6470863819122314
        model: {}
        td_error: "[-9.3541846e-02  1.9839582e-01  7.4156404e-02  1.9641188e-01\n  2.8509426e-01\
          \ -4.6766445e-02 -2.1763690e-01 -9.3189985e-02\n -2.0472546e-01  1.9335431e-01\
          \  1.6705394e-01 -1.6067125e-01\n -6.8468982e-01 -9.3688428e-02  4.6606541e-02\
          \ -3.4319645e-01\n -8.6308032e-02 -6.8857306e-01  1.4342365e-01  1.5007800e-01\n\
          \  3.4683320e-01  4.0136725e-01 -7.8907371e-02  1.0269782e-01\n -3.4495994e-01\
          \  2.4839264e-01 -5.6585151e-01 -1.1463921e-01\n -1.6576451e-01  5.0900000e+02\
          \ -1.4177056e-01 -1.0198009e-01\n  2.2682130e-01 -6.7993879e-02 -2.9136118e-01\
          \  2.9413098e-01\n  1.0877684e-01  2.9763103e-01  1.8697119e-01  5.5705518e-02\n\
          \  1.3218397e-01 -3.0809054e-01 -1.7442365e-01 -2.0477355e-02\n -3.0896023e-01\
          \  3.8143411e-01  1.5558118e-01  5.5066615e-01]"
    num_agent_steps_sampled: 483000
    num_agent_steps_trained: 5784048
    num_steps_sampled: 483000
    num_steps_trained: 5784048
    num_target_updates: 957
  iterations_since_restore: 483
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.86842105263158
    ram_util_percent: 32.48947368421052
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7134.240106344223
  time_this_iter_s: 13.031882286071777
  time_total_s: 7134.240106344223
  timers:
    learn_throughput: 5038.821
    learn_time_ms: 9.526
    update_time_ms: 2.84
  timestamp: 1629287947
  timesteps_since_restore: 0
  timesteps_total: 483000
  training_iteration: 483
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    483 |          7134.24 | 483000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 484000
  custom_metrics: {}
  date: 2021-08-18_11-59-19
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 483832
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.02269679307937622
          max_q: 2.8047280311584473
          mean_q: -0.032063573598861694
          mean_td_error: -0.01237911731004715
          min_q: -0.7568131685256958
        model: {}
        td_error: "[-0.06566098  0.00534841  0.00557475 -0.16346504 -0.32434657  0.00181281\n\
          \ -0.13229144  0.03919873  0.38655388 -0.1812231   0.20323518 -0.10369021\n\
          \ -0.14129394  0.26985154 -0.14532644 -0.02307579  0.00306681 -0.14921415\n\
          \  0.08756757 -0.6064689   0.14838982  0.0432274   0.13065161 -0.2909506\n\
          \ -0.1373054   0.38301247 -0.16381861 -0.08086711 -0.4248644   0.03971583\n\
          \  0.0299378  -0.29285544 -0.03172269  0.02762595 -0.27692458 -0.2604083\n\
          \  0.24831197  0.0979324  -0.25491065  0.14978015  0.1805858   0.18190908\n\
          \  0.13430366  0.34431714  0.32596445 -0.20102575  0.28434741  0.10528983]"
    num_agent_steps_sampled: 484000
    num_agent_steps_trained: 5796048
    num_steps_sampled: 484000
    num_steps_trained: 5796048
    num_target_updates: 959
  iterations_since_restore: 484
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.699999999999996
    ram_util_percent: 32.40555555555555
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7146.121531486511
  time_this_iter_s: 11.881425142288208
  time_total_s: 7146.121531486511
  timers:
    learn_throughput: 5079.874
    learn_time_ms: 9.449
    update_time_ms: 2.745
  timestamp: 1629287959
  timesteps_since_restore: 0
  timesteps_total: 484000
  training_iteration: 484
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    484 |          7146.12 | 484000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 485000
  custom_metrics: {}
  date: 2021-08-18_11-59-32
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 484840
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.029264891520142555
          max_q: 4.296302795410156
          mean_q: -0.0693359300494194
          mean_td_error: -0.016904674470424652
          min_q: -1.1517807245254517
        model: {}
        td_error: "[-0.02554554  0.2483759  -0.6809658   0.27618432  0.26844454  0.2719531\n\
          \  0.1872565  -0.01732757  0.03791359  0.06242478 -0.15868141 -0.06177141\n\
          \  0.02415445  0.11984447  0.22795385  0.15686782 -0.21003714 -0.25792232\n\
          \  0.31170523  0.19325602  0.21718818  0.12647718 -0.29331604 -0.07296954\n\
          \ -0.7364738  -0.1845801   0.19120848  0.09543693 -0.11315824 -0.0539431\n\
          \ -0.133997   -0.12965584  0.11534727  0.11904341  0.49455357 -0.11283562\n\
          \  0.07859582 -0.22776994  0.17938313  0.26562497  0.12741542 -0.34841597\n\
          \ -0.29977036 -0.21680659 -0.21654114 -0.2627018  -0.40790308  0.01505595]"
    num_agent_steps_sampled: 485000
    num_agent_steps_trained: 5808048
    num_steps_sampled: 485000
    num_steps_trained: 5808048
    num_target_updates: 961
  iterations_since_restore: 485
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.31111111111112
    ram_util_percent: 32.49444444444444
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7158.36837553978
  time_this_iter_s: 12.246844053268433
  time_total_s: 7158.36837553978
  timers:
    learn_throughput: 5065.852
    learn_time_ms: 9.475
    update_time_ms: 2.636
  timestamp: 1629287972
  timesteps_since_restore: 0
  timesteps_total: 485000
  training_iteration: 485
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    485 |          7158.37 | 485000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 486000
  custom_metrics: {}
  date: 2021-08-18_11-59-46
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 485848
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06106676533818245
          max_q: 3.018068313598633
          mean_q: -0.06272362172603607
          mean_td_error: 0.028895480558276176
          min_q: -0.45962321758270264
        model: {}
        td_error: "[-0.12589546 -0.07646753 -0.40363008  0.22744972  0.27932626  0.3147738\n\
          \ -0.2609707  -0.03349536 -0.10996452 -0.17593828 -0.14314616  0.26590365\n\
          \  0.2102324  -0.07449877 -0.28653502 -0.16794667 -0.12045972  0.23374069\n\
          \  0.27688515  0.32870322 -0.06666443 -0.3737534  -0.17631738  0.19858533\n\
          \  0.22628668  0.10933197  0.28919753  0.2160793   0.04795584 -0.04615626\n\
          \  0.02752262  0.4416772   0.7013974   0.08791411  0.26435053  0.09689291\n\
          \ -0.69514734 -0.16282468  0.12001938  0.23305267 -0.26901117 -0.28482902\n\
          \ -0.22337134  0.46276623  0.01715034 -0.19579995 -0.1742149   0.3568262 ]"
    num_agent_steps_sampled: 486000
    num_agent_steps_trained: 5820048
    num_steps_sampled: 486000
    num_steps_trained: 5820048
    num_target_updates: 963
  iterations_since_restore: 486
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.504999999999995
    ram_util_percent: 32.40999999999999
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7171.790009975433
  time_this_iter_s: 13.421634435653687
  time_total_s: 7171.790009975433
  timers:
    learn_throughput: 4924.867
    learn_time_ms: 9.746
    update_time_ms: 2.755
  timestamp: 1629287986
  timesteps_since_restore: 0
  timesteps_total: 486000
  training_iteration: 486
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    486 |          7171.79 | 486000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 487000
  custom_metrics: {}
  date: 2021-08-18_11-59-59
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 486856
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05315803363919258
          max_q: 4.903295040130615
          mean_q: -0.08406233787536621
          mean_td_error: -0.047976650297641754
          min_q: -0.5999281406402588
        model: {}
        td_error: "[-0.38510984 -0.19891573  0.00847843  0.39264795 -0.12394165 -0.63766444\n\
          \  0.18389508 -0.13925853  0.01836857 -0.34080774  0.11717421  0.36417675\n\
          \ -0.50728226  0.34431303  0.46638012 -0.30262554  0.21653253 -0.3962901\n\
          \  0.0923183  -0.3144168   0.252989   -0.3714072   0.11243087 -0.10331401\n\
          \  0.13221043  0.0171082  -0.02659725 -0.07730389  0.03047016  0.15459764\n\
          \ -0.2806672  -0.2935685  -0.07940252  0.01454177  0.25066543 -0.30989006\n\
          \ -0.61762226  0.02276522  0.21599501  0.03504276  0.17269903  0.33359432\n\
          \ -0.18832624 -0.15635222 -0.02915209  0.13534185 -0.31723076 -0.190469  ]"
    num_agent_steps_sampled: 487000
    num_agent_steps_trained: 5832048
    num_steps_sampled: 487000
    num_steps_trained: 5832048
    num_target_updates: 965
  iterations_since_restore: 487
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.879999999999995
    ram_util_percent: 32.495
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7184.843740224838
  time_this_iter_s: 13.053730249404907
  time_total_s: 7184.843740224838
  timers:
    learn_throughput: 4870.538
    learn_time_ms: 9.855
    update_time_ms: 2.901
  timestamp: 1629287999
  timesteps_since_restore: 0
  timesteps_total: 487000
  training_iteration: 487
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    487 |          7184.84 | 487000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 488000
  custom_metrics: {}
  date: 2021-08-18_12-00-15
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 487864
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.10491792857646942
          max_q: 2.2590103149414062
          mean_q: -0.17117714881896973
          mean_td_error: 0.0560506135225296
          min_q: -0.646815836429596
        model: {}
        td_error: "[-0.2182858  -0.1700477   0.2253328  -0.32534513 -0.21573378  0.0170612\n\
          \ -0.13033411  0.3312769   0.07595348 -0.05772495  0.26707482  0.08349302\n\
          \ -0.05493879 -0.3327906  -0.14399552  0.15123051  0.1779452   0.15555124\n\
          \ -0.05361414 -0.35723227  1.8518703   0.03126442 -0.33434886 -0.31755143\n\
          \ -0.12806565 -0.21439388  0.14174646  0.12009799 -0.12836498  0.13562864\n\
          \ -0.07689315 -0.20106095  0.09094384  0.4965983  -0.43863708  0.20204341\n\
          \  0.20656323  0.2934878   0.5806393   0.14960462  0.3156317   0.11390075\n\
          \ -0.2791699  -0.216971    0.32272708  0.28149992 -0.02962759  0.2963897 ]"
    num_agent_steps_sampled: 488000
    num_agent_steps_trained: 5844048
    num_steps_sampled: 488000
    num_steps_trained: 5844048
    num_target_updates: 967
  iterations_since_restore: 488
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.78571428571428
    ram_util_percent: 32.4047619047619
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7199.600466966629
  time_this_iter_s: 14.756726741790771
  time_total_s: 7199.600466966629
  timers:
    learn_throughput: 4687.115
    learn_time_ms: 10.241
    update_time_ms: 3.198
  timestamp: 1629288015
  timesteps_since_restore: 0
  timesteps_total: 488000
  training_iteration: 488
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    488 |           7199.6 | 488000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 489000
  custom_metrics: {}
  date: 2021-08-18_12-00-30
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 488872
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.677708625793457
          max_q: 7256322.0
          mean_q: 151173.15625
          mean_td_error: 31.062253952026367
          min_q: -0.6610231399536133
        model: {}
        td_error: "[-1.53374910e-01  2.26644516e-01 -9.18458402e-02  2.40465462e-01\n\
          \ -1.94941729e-01 -3.63256574e-01  1.07631505e-01  2.41373420e-01\n -1.26921862e-01\
          \ -2.15850264e-01  1.49450000e+03 -5.78792095e-02\n -2.16025621e-01  8.73991847e-03\
          \ -5.78933656e-01  1.38751268e-02\n  4.10113633e-01 -4.14510250e-01 -1.88850060e-01\
          \  1.09483600e-01\n -3.37362289e-05 -2.27539271e-01  4.24871385e-01 -8.31408203e-02\n\
          \  5.17943501e-02 -4.85746115e-02 -2.43511409e-01  9.44468677e-02\n -1.60702288e-01\
          \  1.34705007e-02  2.94276834e-01 -5.50461292e-01\n  1.55094564e-02  1.16090298e-01\
          \  1.81296706e-01  1.38241768e-01\n -1.21874976e+00 -5.68639278e-01 -6.42349869e-02\
          \ -8.27672482e-02\n -1.20906532e-02  1.92554772e-01  1.13405466e-01  1.42899811e-01\n\
          \ -1.33260518e-01 -1.88649178e-01 -3.51649880e-01 -1.12484187e-01]"
    num_agent_steps_sampled: 489000
    num_agent_steps_trained: 5856048
    num_steps_sampled: 489000
    num_steps_trained: 5856048
    num_target_updates: 969
  iterations_since_restore: 489
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.286363636363625
    ram_util_percent: 32.49545454545454
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7214.387368440628
  time_this_iter_s: 14.786901473999023
  time_total_s: 7214.387368440628
  timers:
    learn_throughput: 4736.818
    learn_time_ms: 10.133
    update_time_ms: 3.011
  timestamp: 1629288030
  timesteps_since_restore: 0
  timesteps_total: 489000
  training_iteration: 489
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    489 |          7214.39 | 489000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 490000
  custom_metrics: {}
  date: 2021-08-18_12-00-46
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 489880
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.94151782989502
          max_q: 7253373.5
          mean_q: 151111.8125
          mean_td_error: -30.31226921081543
          min_q: -0.7556502819061279
        model: {}
        td_error: "[-2.16828063e-01 -1.08251333e-01  1.92552149e-01 -1.08663395e-01\n\
          \ -5.51763535e-01  5.10332525e-01  2.97510356e-01 -1.68061703e-02\n -1.17542744e+00\
          \ -4.45478261e-02  2.08951235e-02  8.14208984e-02\n  1.68931782e-01  9.61189866e-02\
          \  3.00364554e-01  3.51623833e-01\n -8.62371624e-02  2.58147776e-01  2.58599401e-01\
          \  1.73087239e-01\n -6.06160760e-02 -5.20689785e-02  2.90219843e-01  2.24437654e-01\n\
          \  1.06996894e-02 -3.84502769e-01 -6.49979770e-01  8.01513195e-02\n -2.02426225e-01\
          \  2.86611319e-02 -3.53941023e-02  2.47207612e-01\n -2.01128572e-01 -1.45400000e+03\
          \ -7.79397488e-02 -4.44606543e-02\n  5.45726061e-01 -3.89768451e-01  1.00000165e-01\
          \ -1.16659045e-01\n -2.51951516e-01  1.29737377e-01 -6.71327353e-01 -9.11423266e-02\n\
          \  2.44522214e-01 -2.55331397e-01  5.11521101e-02  1.42250061e-01]"
    num_agent_steps_sampled: 490000
    num_agent_steps_trained: 5868048
    num_steps_sampled: 490000
    num_steps_trained: 5868048
    num_target_updates: 971
  iterations_since_restore: 490
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.97391304347825
    ram_util_percent: 32.504347826086956
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7230.0714638233185
  time_this_iter_s: 15.68409538269043
  time_total_s: 7230.0714638233185
  timers:
    learn_throughput: 4874.571
    learn_time_ms: 9.847
    update_time_ms: 2.881
  timestamp: 1629288046
  timesteps_since_restore: 0
  timesteps_total: 490000
  training_iteration: 490
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    490 |          7230.07 | 490000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 491000
  custom_metrics: {}
  date: 2021-08-18_12-01-02
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 490888
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.021354669705033302
          max_q: 4.281576156616211
          mean_q: -0.1568402200937271
          mean_td_error: -0.0038863234221935272
          min_q: -0.69728022813797
        model: {}
        td_error: "[ 0.02219039 -0.11414149  0.3049742   0.30014133 -0.3450064  -0.14215747\n\
          \ -0.4259935   0.27799675  0.13064766 -0.7220415  -0.35126978 -0.0213564\n\
          \ -0.07557496  0.17791358  0.37220702  0.16294724 -0.0486238  -0.06144214\n\
          \  0.33661604  0.02003968 -0.0908829  -0.03017604  0.2424382  -0.28965676\n\
          \ -0.0975624  -0.19828534  0.1244455   0.73975706  0.14250594  0.24086612\n\
          \  0.04382867 -0.22527933 -0.24175423  0.10156679 -0.37588555  0.19716561\n\
          \  0.43682128  0.05497748 -0.36304396 -0.08347739  0.12587631 -0.0554938\n\
          \ -0.28948402 -0.42227402  0.3772828  -0.2669005  -0.00489739  0.22291195]"
    num_agent_steps_sampled: 491000
    num_agent_steps_trained: 5880048
    num_steps_sampled: 491000
    num_steps_trained: 5880048
    num_target_updates: 973
  iterations_since_restore: 491
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.1304347826087
    ram_util_percent: 32.504347826086956
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7245.504577875137
  time_this_iter_s: 15.433114051818848
  time_total_s: 7245.504577875137
  timers:
    learn_throughput: 4774.732
    learn_time_ms: 10.053
    update_time_ms: 2.997
  timestamp: 1629288062
  timesteps_since_restore: 0
  timesteps_total: 491000
  training_iteration: 491
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    491 |           7245.5 | 491000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 492000
  custom_metrics: {}
  date: 2021-08-18_12-01-19
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 491896
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.07401558011770248
          max_q: 2.7568373680114746
          mean_q: -0.12543885409832
          mean_td_error: -0.03730890154838562
          min_q: -0.6125483512878418
        model: {}
        td_error: "[-0.2451452  -0.04260983 -0.2135602  -0.32604992  0.1409226  -0.29358727\n\
          \ -0.23634294  0.10418862  0.21719462 -0.15364283  0.05443485  0.33175564\n\
          \ -0.16840866 -0.07827866 -0.17791344 -0.11706719 -0.46431157  0.01649204\n\
          \  0.6655358  -0.2507311   0.10154951 -0.22459294 -0.08794007  0.07046729\n\
          \  0.21043593  0.07685846 -0.17309129 -0.12504196 -0.14542508  0.05022478\n\
          \  0.11574522  0.11944383  0.23340237 -0.5424187   0.09258112  0.08199972\n\
          \  0.1314969   0.301916    0.10859177 -0.10469255 -0.8398957   0.2587763\n\
          \  0.28477347 -0.06780046 -0.54339087  0.25234735 -0.16079688 -0.02922608]"
    num_agent_steps_sampled: 492000
    num_agent_steps_trained: 5892048
    num_steps_sampled: 492000
    num_steps_trained: 5892048
    num_target_updates: 975
  iterations_since_restore: 492
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.38333333333334
    ram_util_percent: 32.5625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7261.809947729111
  time_this_iter_s: 16.30536985397339
  time_total_s: 7261.809947729111
  timers:
    learn_throughput: 4888.063
    learn_time_ms: 9.82
    update_time_ms: 2.997
  timestamp: 1629288079
  timesteps_since_restore: 0
  timesteps_total: 492000
  training_iteration: 492
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    492 |          7261.81 | 492000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 493000
  custom_metrics: {}
  date: 2021-08-18_12-01-36
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 492904
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06357401609420776
          max_q: 1.1899136304855347
          mean_q: -0.20361016690731049
          mean_td_error: 0.07542197406291962
          min_q: -0.6662917733192444
        model: {}
        td_error: "[ 0.17894566  0.16301614  0.21551728  0.32880878 -0.32716    -0.09575757\n\
          \  0.29672885  0.36751908 -0.03174394 -0.241972    0.3319717   0.2653867\n\
          \ -0.22087592 -0.21394935 -0.08228949 -0.1431688   0.04626018 -0.05203483\n\
          \  0.00329277  0.08183831  0.26422447  0.29520077  0.35524237 -0.06568649\n\
          \  0.06374799 -0.07627589  0.2595544   0.1832931   0.3897701   0.2185269\n\
          \ -0.02029917  0.24646717  0.00345241  0.21521562 -0.4536608   0.2398481\n\
          \  0.2800169   0.24423544  0.14340258 -0.08750197  0.20578796  0.11628646\n\
          \ -0.15079889 -0.16905835 -0.24289496  0.43639392  0.06903031 -0.21359944]"
    num_agent_steps_sampled: 493000
    num_agent_steps_trained: 5904048
    num_steps_sampled: 493000
    num_steps_trained: 5904048
    num_target_updates: 977
  iterations_since_restore: 493
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.96666666666667
    ram_util_percent: 32.60416666666667
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7278.290459394455
  time_this_iter_s: 16.48051166534424
  time_total_s: 7278.290459394455
  timers:
    learn_throughput: 4724.49
    learn_time_ms: 10.16
    update_time_ms: 2.895
  timestamp: 1629288096
  timesteps_since_restore: 0
  timesteps_total: 493000
  training_iteration: 493
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    493 |          7278.29 | 493000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 494000
  custom_metrics: {}
  date: 2021-08-18_12-01-54
  done: false
  episode_len_mean: 8611.357142857143
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5829599.873081724
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 493912
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04758317396044731
          max_q: 1.531747817993164
          mean_q: -0.3100265860557556
          mean_td_error: -0.028286408632993698
          min_q: -0.7835907936096191
        model: {}
        td_error: "[ 0.33679295 -0.00968683  0.23536956 -0.07977229  0.28132486  0.32922822\n\
          \ -0.01680636  0.01845074  0.12738973  0.23466855 -0.00371975 -0.104173\n\
          \  0.1845699  -0.05943722 -0.00743872 -0.00748724  0.5323878  -0.11112684\n\
          \ -0.03716548  0.08462808  0.10989636 -0.9690371  -0.7530401   0.20571947\n\
          \  0.17867428 -0.01587835  0.05102903 -0.18998255  0.10574931 -0.38316736\n\
          \ -0.2126939   0.16420043 -0.620352    0.14578271  0.05650777  0.27868223\n\
          \ -0.02536079 -1.1793838  -0.7463846  -0.04970559  0.15835011 -0.23447086\n\
          \ -0.16790092  0.11659536  0.04823852  0.185489    0.17067796  0.28602117]"
    num_agent_steps_sampled: 494000
    num_agent_steps_trained: 5916048
    num_steps_sampled: 494000
    num_steps_trained: 5916048
    num_target_updates: 979
  iterations_since_restore: 494
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.80384615384615
    ram_util_percent: 32.60384615384616
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049197585210563465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.974582625518457
    mean_inference_ms: 1.587786415242538
    mean_raw_obs_processing_ms: 0.1441815707643738
  time_since_restore: 7295.730366706848
  time_this_iter_s: 17.43990731239319
  time_total_s: 7295.730366706848
  timers:
    learn_throughput: 4867.535
    learn_time_ms: 9.861
    update_time_ms: 2.827
  timestamp: 1629288114
  timesteps_since_restore: 0
  timesteps_total: 494000
  training_iteration: 494
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    494 |          7295.73 | 494000 | 5.8296e+06 |          7.25484e+06 |             -198.044 |            8611.36 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 495000
  custom_metrics: {}
  date: 2021-08-18_12-02-06
  done: false
  episode_len_mean: 8671.350877192983
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5854601.221001545
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 494920
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.0539504736661911
          max_q: 0.21725904941558838
          mean_q: -0.31069812178611755
          mean_td_error: 0.02895466238260269
          min_q: -0.5700327754020691
        model: {}
        td_error: "[ 0.15017241  0.33362585 -0.162227    0.23434561 -0.45644915 -0.09244728\n\
          \  0.03496948  0.279279   -0.31673196  0.09881404  0.15324995  0.25386828\n\
          \  0.17611676 -0.1580357   0.29597968  0.26559737  0.29374808 -0.4249838\n\
          \  0.09157109  0.3445124   0.05535397  0.03547865  0.35319698 -0.10247591\n\
          \ -0.09773898  0.42474794  0.29555213  0.06862628 -0.01093814  0.16514102\n\
          \ -0.10179058  0.3138121  -0.12596679  0.40568596  0.11415964 -0.2023143\n\
          \  0.18157038 -0.09371525  0.18884653 -0.11444527  0.15491828 -1.1367291\n\
          \ -0.06043309  0.2500044  -0.6387758  -0.01597473 -0.23058829 -0.08035946]"
    num_agent_steps_sampled: 495000
    num_agent_steps_trained: 5928048
    num_steps_sampled: 495000
    num_steps_trained: 5928048
    num_target_updates: 981
  iterations_since_restore: 495
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.611111111111114
    ram_util_percent: 32.544444444444444
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196744241303006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.993587003746503
    mean_inference_ms: 1.587859461660134
    mean_raw_obs_processing_ms: 0.14419670339265098
  time_since_restore: 7307.826204538345
  time_this_iter_s: 12.095837831497192
  time_total_s: 7307.826204538345
  timers:
    learn_throughput: 4900.949
    learn_time_ms: 9.794
    update_time_ms: 2.708
  timestamp: 1629288126
  timesteps_since_restore: 0
  timesteps_total: 495000
  training_iteration: 495
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    495 |          7307.83 | 495000 | 5.8546e+06 |          7.25484e+06 |             -198.044 |            8671.35 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 496000
  custom_metrics: {}
  date: 2021-08-18_12-02-18
  done: false
  episode_len_mean: 8671.350877192983
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5854601.221001545
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 57
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 495928
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.06084909662604332
          max_q: 1.1074283123016357
          mean_q: -0.3622080981731415
          mean_td_error: -0.049004822969436646
          min_q: -0.692286491394043
        model: {}
        td_error: "[ 0.0572035  -0.6584122   0.2473318   0.03441152 -0.37447757  0.10284925\n\
          \ -0.22300321  0.09407181  0.28798378  0.08548355 -0.15362535  0.38573745\n\
          \ -0.02931491  0.6391332   0.03601599 -0.42484993 -0.03594247  0.1565448\n\
          \  0.01991621 -1.1139823   0.24509674  0.04749268 -0.2078172  -0.00223106\n\
          \ -0.18153852 -0.30213735  0.16343242  0.22736979 -0.39255238 -0.06259051\n\
          \ -0.34044576 -0.19669983 -0.01560503  0.0573781   0.23460269  0.1024999\n\
          \  0.30915827 -0.1226294  -0.08362997 -0.15909392  0.24547696  0.3360862\n\
          \ -0.12483305 -0.3900888  -0.211057   -0.14238663 -0.26050845 -0.25805542]"
    num_agent_steps_sampled: 496000
    num_agent_steps_trained: 5940048
    num_steps_sampled: 496000
    num_steps_trained: 5940048
    num_target_updates: 983
  iterations_since_restore: 496
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.487500000000004
    ram_util_percent: 32.50625
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196744241303006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.993587003746503
    mean_inference_ms: 1.587859461660134
    mean_raw_obs_processing_ms: 0.14419670339265098
  time_since_restore: 7318.939659833908
  time_this_iter_s: 11.113455295562744
  time_total_s: 7318.939659833908
  timers:
    learn_throughput: 5073.998
    learn_time_ms: 9.46
    update_time_ms: 2.899
  timestamp: 1629288138
  timesteps_since_restore: 0
  timesteps_total: 496000
  training_iteration: 496
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    496 |          7318.94 | 496000 | 5.8546e+06 |          7.25484e+06 |             -198.044 |            8671.35 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 497000
  custom_metrics: {}
  date: 2021-08-18_12-02-30
  done: false
  episode_len_mean: 8671.350877192983
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5854601.221001545
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 57
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 496936
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.05113682150840759
          max_q: 3.4484076499938965
          mean_q: -0.1783016324043274
          mean_td_error: 0.0117610152810812
          min_q: -0.6601129174232483
        model: {}
        td_error: "[ 0.15716034  0.16307676  0.4841091   0.36718935  0.40329492 -0.17923057\n\
          \ -0.5134022   0.07664657  0.04840238 -0.02935994  0.00555289 -0.5580531\n\
          \  0.14104122  0.1735327   0.02619326  0.2369489  -0.18737507  0.21541393\n\
          \  0.01223111 -0.09406006  0.3422187  -0.4748528  -0.26449323 -0.5104369\n\
          \ -1.6044489  -0.05182192 -0.3094262   0.34480458  0.8144584  -0.33933634\n\
          \ -0.11794239  0.10025775  0.02593881 -0.02745885  0.08479744  0.10250175\n\
          \ -0.09919888  0.09694541 -0.05699831  0.00793415  0.44896883  0.14554852\n\
          \  0.17472994  0.35940737  0.31077087  0.22940499 -0.41291624  0.29585987]"
    num_agent_steps_sampled: 497000
    num_agent_steps_trained: 5952048
    num_steps_sampled: 497000
    num_steps_trained: 5952048
    num_target_updates: 985
  iterations_since_restore: 497
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 65.67777777777778
    ram_util_percent: 32.50555555555556
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196744241303006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.993587003746503
    mean_inference_ms: 1.587859461660134
    mean_raw_obs_processing_ms: 0.14419670339265098
  time_since_restore: 7330.72677397728
  time_this_iter_s: 11.787114143371582
  time_total_s: 7330.72677397728
  timers:
    learn_throughput: 4996.652
    learn_time_ms: 9.606
    update_time_ms: 2.832
  timestamp: 1629288150
  timesteps_since_restore: 0
  timesteps_total: 497000
  training_iteration: 497
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    497 |          7330.73 | 497000 | 5.8546e+06 |          7.25484e+06 |             -198.044 |            8671.35 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 498000
  custom_metrics: {}
  date: 2021-08-18_12-02-44
  done: false
  episode_len_mean: 8671.350877192983
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5854601.221001545
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 57
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 497944
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8.208986282348633
          max_q: 7255524.5
          mean_q: 151156.453125
          mean_td_error: 14.391066551208496
          min_q: -0.9441640973091125
        model: {}
        td_error: "[-2.97169089e-01 -5.03600538e-02  6.57613277e-02  4.26594198e-01\n\
          \ -1.96235180e-02 -1.44377202e-01 -1.53717309e-01 -8.73363316e-02\n  4.00701463e-01\
          \  6.96500000e+02  1.37035787e-01 -1.97542667e-01\n -2.36426413e-01 -2.59084016e-01\
          \ -1.71385020e-01 -2.06972927e-01\n  3.80222499e-02  1.38031125e-01  1.12918615e-01\
          \  4.16850567e-01\n  1.02849662e-01 -2.30070770e-01  1.65251970e-01 -4.19755310e-01\n\
          \ -8.28363299e-02  3.08088481e-01 -1.42801404e-01 -2.71019608e-01\n -1.83343470e-01\
          \ -2.74394423e-01 -6.59870744e-01 -2.67812908e-01\n -4.40606892e-01 -7.34329700e-01\
          \ -4.94611382e-01  1.46045983e-01\n -1.67033017e-01 -1.49475366e-01 -4.80529070e-02\
          \  4.36957419e-01\n -9.49462056e-02 -5.41073322e-01 -2.11182982e-01 -1.34863710e+00\n\
          \ -1.73007846e-02 -1.38348281e-01  2.00061202e-01 -8.25244039e-02]"
    num_agent_steps_sampled: 498000
    num_agent_steps_trained: 5964048
    num_steps_sampled: 498000
    num_steps_trained: 5964048
    num_target_updates: 987
  iterations_since_restore: 498
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.073684210526324
    ram_util_percent: 32.50526315789474
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196744241303006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.993587003746503
    mean_inference_ms: 1.587859461660134
    mean_raw_obs_processing_ms: 0.14419670339265098
  time_since_restore: 7343.869494199753
  time_this_iter_s: 13.142720222473145
  time_total_s: 7343.869494199753
  timers:
    learn_throughput: 5016.885
    learn_time_ms: 9.568
    update_time_ms: 2.76
  timestamp: 1629288164
  timesteps_since_restore: 0
  timesteps_total: 498000
  training_iteration: 498
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    498 |          7343.87 | 498000 | 5.8546e+06 |          7.25484e+06 |             -198.044 |            8671.35 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 499000
  custom_metrics: {}
  date: 2021-08-18_12-02-57
  done: false
  episode_len_mean: 8671.350877192983
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5854601.221001545
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 57
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 498952
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.04326397925615311
          max_q: 1.1034445762634277
          mean_q: -0.32313090562820435
          mean_td_error: 0.0038958885706961155
          min_q: -1.426210641860962
        model: {}
        td_error: "[ 0.22847849 -0.07640833 -0.08169723  0.4136948  -0.27103484  0.20485997\n\
          \  0.05656677  0.08676207 -0.22384878  0.18028247  0.24947512 -0.07242733\n\
          \  0.10769463  0.50485444 -0.04108709 -0.19015709 -0.02994221 -0.33596683\n\
          \ -0.4166255   0.36428314  0.0133644  -0.01310129  0.07359976  0.13513821\n\
          \  0.22484393 -0.25259376 -0.06487501  0.2751299  -0.32779902 -0.04304615\n\
          \  0.1071603   0.15094516 -0.14359593  0.13159412 -0.4023443   0.28222007\n\
          \  0.01752585 -0.05367559 -0.14490652 -0.08296583  0.10280192 -0.0822224\n\
          \ -0.24168241 -0.18579428 -0.61828196 -0.03665173 -0.01788747  0.7263459 ]"
    num_agent_steps_sampled: 499000
    num_agent_steps_trained: 5976048
    num_steps_sampled: 499000
    num_steps_trained: 5976048
    num_target_updates: 989
  iterations_since_restore: 499
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.51052631578948
    ram_util_percent: 32.50526315789474
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196744241303006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.993587003746503
    mean_inference_ms: 1.587859461660134
    mean_raw_obs_processing_ms: 0.14419670339265098
  time_since_restore: 7356.676274299622
  time_this_iter_s: 12.806780099868774
  time_total_s: 7356.676274299622
  timers:
    learn_throughput: 4737.999
    learn_time_ms: 10.131
    update_time_ms: 2.786
  timestamp: 1629288177
  timesteps_since_restore: 0
  timesteps_total: 499000
  training_iteration: 499
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    499 |          7356.68 | 499000 | 5.8546e+06 |          7.25484e+06 |             -198.044 |            8671.35 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


Result for DQN_TradingEnv_a4fd9_00000:
  agent_timesteps_total: 500000
  custom_metrics: {}
  date: 2021-08-18_12-03-12
  done: true
  episode_len_mean: 8671.350877192983
  episode_media: {}
  episode_reward_max: 7254837.97357804
  episode_reward_mean: 5854601.221001545
  episode_reward_min: -198.0439419037809
  episodes_this_iter: 0
  episodes_total: 57
  experiment_id: a8ea4185ca4449cc997720f481df63f1
  hostname: b76cb4a90e1c
  info:
    last_target_update_ts: 499960
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5.0625081062316895
          max_q: 7257338.0
          mean_q: 151194.34375
          mean_td_error: 52.23897933959961
          min_q: -0.6778321266174316
        model: {}
        td_error: "[-4.3808436e-01 -1.9195080e-03  1.5329248e-01  2.1181226e-01\n  8.7464780e-02\
          \  1.9072884e-01  1.6644192e-01 -6.1962628e-01\n -9.4363391e-02 -1.2531095e+00\
          \ -1.6934367e-01  1.4252198e-01\n  2.6468915e-01 -2.2762334e-01  1.9423395e-02\
          \  1.2940040e-01\n  1.3930422e-01  3.0019695e-01 -1.5354449e-01  1.5867470e-01\n\
          \ -5.2530527e-02 -1.4027319e+00 -7.2023228e-02  1.2458083e-01\n -1.9688380e-01\
          \ -6.0204715e-02  1.8056528e-01  5.0258934e-02\n  4.0237164e-01 -6.3160479e-02\
          \ -2.2987925e-01  2.1858096e-01\n -3.0340624e-01  3.4630537e-01 -8.0110878e-02\
          \  2.1536356e-01\n  2.0159625e-01  6.0154974e-02 -3.0942973e-01  2.4088860e-01\n\
          \ -8.8613796e-01 -3.2580331e-01  2.5105000e+03 -2.7605554e-01\n -2.2909513e-01\
          \  2.8382730e-01 -2.8367096e-01  4.1116387e-01]"
    num_agent_steps_sampled: 500000
    num_agent_steps_trained: 5988048
    num_steps_sampled: 500000
    num_steps_trained: 5988048
    num_target_updates: 991
  iterations_since_restore: 500
  node_ip: 172.19.2.2
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.34761904761905
    ram_util_percent: 32.50476190476191
  pid: 459
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.049196744241303006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 4.993587003746503
    mean_inference_ms: 1.587859461660134
    mean_raw_obs_processing_ms: 0.14419670339265098
  time_since_restore: 7370.506464719772
  time_this_iter_s: 13.830190420150757
  time_total_s: 7370.506464719772
  timers:
    learn_throughput: 4767.101
    learn_time_ms: 10.069
    update_time_ms: 3.042
  timestamp: 1629288192
  timesteps_since_restore: 0
  timesteps_total: 500000
  training_iteration: 500
  trial_id: a4fd9_00000
  
== Status ==
Memory usage on this node: 5.1/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 RUNNING)
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status   | loc            |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | RUNNING  | 172.19.2.2:459 |    500 |          7370.51 | 500000 | 5.8546e+06 |          7.25484e+06 |             -198.044 |            8671.35 |
+----------------------------+----------+----------------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 2.3/15.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.26 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 GPU_group_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 accelerator_type:P100, 0.0/1.0 CPU_group_1_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 GPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/1.0 CPU_group_0_7e53569a92f48ca0c2744cdd5b2faa15, 0.0/2.0 CPU_group_7e53569a92f48ca0c2744cdd5b2faa15)
Result logdir: /kaggle/working/crypto-v2/ray_results/DQN
Number of trials: 1/1 (1 TERMINATED)
+----------------------------+------------+-------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+
| Trial name                 | status     | loc   |   iter |   total time (s) |     ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|----------------------------+------------+-------+--------+------------------+--------+------------+----------------------+----------------------+--------------------|
| DQN_TradingEnv_a4fd9_00000 | TERMINATED |       |    500 |          7370.51 | 500000 | 5.8546e+06 |          7.25484e+06 |             -198.044 |            8671.35 |
+----------------------------+------------+-------+--------+------------------+--------+------------+----------------------+----------------------+--------------------+


2021-08-18 12:03:13,520	INFO tune.py:550 -- Total run time: 7567.62 seconds (7566.68 seconds for the tuning loop).